<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" 
"http://www.w3.org/TR/html4/loose.dtd">
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.2.1/dist/css/bootstrap.min.css" integrity="sha384-GJzZqFGwb1QTTN6wy59ffF1BuGJpLSa9DkKMp0DgiMDm4iYMj70gZWKYbI706tWS" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.5.0/font/bootstrap-icons.css">
<link rel="stylesheet" href="mystyle.css">
<title>AWS Certified Solutions Architect - Associate (SAA-C02)</title>
</head>
<body>
<nav class="navbar navbar-expand-lg navbar-light bg-light">
  <a class="navbar-brand" href="#">AWS Exam Questions</a>
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse" id="navbarNav">
    <ul class="navbar-nav">
     <li class='nav-item'><a class='nav-link' href='#All'>All(790)</a></li><li class='nav-item'><a class='nav-link' href='#S3'>S3(155)</a></li><li class='nav-item'><a class='nav-link' href='#EC2'>EC2(90)</a></li><li class='nav-item'><a class='nav-link' href='#CloudFront'>CloudFront(52)</a></li><li class='nav-item'><a class='nav-link' href='#VPC'>VPC(43)</a></li><li class='nav-item'><a class='nav-link' href='#SQS'>SQS(36)</a></li><li class='nav-item'><a class='nav-link' href='#EFS'>EFS(30)</a></li><li class='nav-item'><a class='nav-link' href='#EBS'>EBS(22)</a></li><li class='nav-item'><a class='nav-link' href='#IAM'>IAM(22)</a></li><li class='nav-item'><a class='nav-link' href='#security_group'>security group(19)</a></li><li class='nav-item'><a class='nav-link' href='#ECS'>ECS(13)</a></li><li class='nav-item'><a class='nav-link' href='#AMI'>AMI(6)</a></li>
    </ul>
  </div>
</nav>



<nav aria-label='Page navigation example'>
  <ul class='pagination'>
</nav><hr><div class='container'><a id=All><h2>All</h2></a> - 790 Questions <br><a href='#All'>All(790)</a> <a href='#' <i class='bi bi&#45;house'> &nbsp;Home</i><hr> </a><div class='row' id=All_1><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 1</p><br/>A company slops a cluster of Amazon EC2 instances over a weekend. The costs decrease, but they do not drop to zero.<br/><br/>Which resources could still be generating costs? (Select TWO.)<br/><br/>A. Elastic IP addresses<br/>B. Data transfer out<br/>C. Regional data transfers<br/>D. Amazon Elastic Block Store (Amazon EBS) volumes<br/>E. AWS Auto Scaling<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample562' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_2'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_372'>Random</a></p><div class='collapse' id='collapseExample562'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Elastic IP addresses
<br><b>D. </b>Amazon Elastic Block Store (Amazon EBS) volumes</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 0%;" aria-valuenow="0" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_2><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 2</p><br/>A company recently released a new type of internet&#8211;connected sensor. The company is expecting to sell thousands of sensors, which are designed to stream high volumes of data each second to a central location. A solutions architect must design a solution that ingests and stores data so that engineering teams can analyze it in near&#8211;real&#8211;time with millisecond responsiveness.<br/><br/>Which solution should the solutions architect recommend?<br/><br/>A. Use an Amazon SQS queue to ingest the data. Consume the data with an AWS Lambda function, which then stores the data in Amazon Redshift.<br/>B. Use an Amazon SQS queue to ingest the data. Consume the data with an AWS Lambda function, which then stores the data in Amazon DynamoDB.<br/>C. Use Amazon Kinesis Data Streams to ingest the data. Consume the data with an AWS Lambda function, which then stores the data in Amazon Redshift.<br/>D. Use Amazon Kinesis Data Streams to ingest the data. Consume the data with an AWS Lambda function, which then stores the data in Amazon DynamoDB.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample116' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_3'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_154'>Random</a></p><div class='collapse' id='collapseExample116'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Use Amazon Kinesis Data Streams to ingest the data. Consume the data with an AWS Lambda function, which then stores the data in Amazon DynamoDB.

References:

AWS Big Data Blog > Analyze data in Amazon DynamoDB using Amazon SageMaker for real-time prediction</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 0%;" aria-valuenow="0" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_3><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 3</p><br/>A solutions architect is creating a data processing job that runs once daily and can take up to 2 hours to complete If the job is interrupted, it has to restart from the beginning<br/><br/>How should the solutions architect address this issue in the MOST cost&#8211;effective manner?<br/><br/>A. Create a script that runs locally on an Amazon EC2 Reserved Instance that is triggered by a cron job.<br/>B. Create an AWS Lambda function triggered by an Amazon EventBridge (Amazon CloudWatch Events} scheduled event<br/>C. Use an Amazon Elastic Container Service (Amazon ECS) Fargate task triggered by an Amazon EventBridge (Amazon CloudWatch Events) scheduled event.<br/>D. Use an Amazon Elastic Container Service (Amazon ECS) task running on Amazon EC2 triggered by an Amazon EventBridge (Amazon CloudWatch Events) scheduled event.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample486' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_4'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_534'>Random</a></p><div class='collapse' id='collapseExample486'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Use an Amazon Elastic Container Service (Amazon ECS) Fargate task triggered by an Amazon EventBridge (Amazon CloudWatch Events) scheduled event.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 0%;" aria-valuenow="0" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_4><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 4</p><br/>A company is performing an AWS Well&#8211;Architected Framework review of an existing workload deployed on AWS. The review identified a public&#8211;facing website running on the same Amazon EC2 instance as a Microsoft Active Directory domain controller that was installed recently to support other AWS services. A solutions architect needs to recommend a new design that would improve the security of the architecture and minimize the administrative demand on IT staff.<br/><br/>What should the solutions architect recommend?<br/><br/>A. Use AWS Directory Service to create a managed Active Directory. Uninstall Active Directory on the current EC2 instance.<br/>B. Create another EC2 instance in the same subnet and reinstall Active Directory on it. Uninstall Active Directory.<br/>C. Use AWS Directory Service to create an Active Directory connector. Proxy Active Directory requests to the Active domain controller running on the current EC2 instance.<br/>D. Enable AWS Single Sign&#8211;On (AWS SSO) with Security Assertion Markup Language (SAML) 2.0 federation with the current Active Directory controller. Modify the EC2 instance's security group to deny public access to Active Directory.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample25' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation25' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_5'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_353'>Random</a></p><div class='collapse' id='collapseExample25'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Use AWS Directory Service to create a managed Active Directory. Uninstall Active Directory on the current EC2 instance.</div></div></div><div class='collapse' id='explanation25'><div class='card card&#45;body'><div>
AWS Managed Microsoft AD: AWS Directory Service lets you run Microsoft Active Directory (AD) as a managed service. AWS Directory Service for Microsoft Active Directory, also referred to as AWS Managed Microsoft AD, is powered by Windows Server 2012 R2. When you select and launch this directory type, it is created as a highly available pair of domain controllers connected to your virtual private cloud (VPC). The domain controllers run in different Availability Zones in a region of your choice. Host monitoring and recovery, data replication, snapshots, and software updates are automatically configured and managed for you.

Migrate AD to AWS Managed AD and keep the webserver alone. Reduce risk = remove AD from that EC2. Minimize admin = remove AD from any EC2

-> use AWS Directory Service

Active Directory connector is only for ON-PREM AD. The one they have exists in the cloud already.
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 0%;" aria-valuenow="0" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_5><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 5</p><br/>You've created your first load balancer and have registered your EC2 instances with the load balancer. Elastic Load Balancing routinely performs health checks on all the registered EC2 instances and automatically distributes all incoming requests to the DNS name of your load balancer across your registered, healthy EC2 instances. By default, the load balancer uses the protocol for checking the health of your instances.<br/><br/>A. HTTPS<br/>B. HTTP<br/>C. ICMP<br/>D. IPv6<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample739' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation739' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_6'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_512'>Random</a></p><div class='collapse' id='collapseExample739'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>HTTP</div></div></div><div class='collapse' id='explanation739'><div class='card card&#45;body'><div>
In Elastic Load Balancing a health configuration uses information such as protocol, ping port, ping path (URL), response timeout period, and health check interval to determine the health state of the instances registered with the load balancer. Currently, HTTP on port 80 is the default health check.

References:

Elastic Load Balancing > User Guide > How Elastic Load Balancing works</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 0%;" aria-valuenow="0" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_6><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 6</p><br/>A company is building a payment application that must be highly available even during regional service disruptions. A solutions architect must design a data storage solution that can be easily replicated and used in other AWS Regions. The application also requires low&#8211;latency atomicity, consistency, isolation, and durability (ACID) transactions that need to be immediately available to generate reports The development team also needs to use SQL.<br/><br/>Which data storage solution meets these requirements?<br/><br/>A. Amazon Aurora Global Database<br/>B. Amazon DynamoDB global tables<br/>C. Amazon S3 with cross&#8211;Region replication and Amazon Athena<br/>D. MySQL on Amazon EC2 instances with Amazon Elastic Block Store (Amazon EBS) snapshot replication<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample338' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_7'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_713'>Random</a></p><div class='collapse' id='collapseExample338'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Amazon S3 with cross-Region replication and Amazon Athena</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 0%;" aria-valuenow="0" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_7><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 7</p><br/>An entertainment company is using Amazon DynamoDB to store media metadata. The application is read intensive and experiencing delays.<br/><br/>The company does not have staff to handle additional operational overhead and needs to improve the performance efficiency of DynamoDB without reconfiguring the application.<br/><br/>What should a solutions architect recommend to meet this requirement?<br/><br/>A. Use Amazon ElastiCache for Redis<br/>B. Use Amazon DynamoDB Accelerate (DAX)<br/>C. Replicate data by using DynamoDB global tables<br/>D. Use Amazon ElastiCache for Memcached with Auto Discovery enabled<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample581' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_8'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_10'>Random</a></p><div class='collapse' id='collapseExample581'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Use Amazon DynamoDB Accelerate (DAX)</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 0%;" aria-valuenow="0" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_8><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 8</p><br/>A company is running an application on Amazon EC2 instances. Traffic to the workload increases substantially during business hours and decreases afterward. The CPU utilization of an EC2 instance is a strong indicator of end&#8211;user demand on the application.<br/><br/>The company has configured an Auto Scaling group to have a minimum group size of 2 EC2 instances and a maximum group size of 10 EC2 instances.<br/><br/>The company is concerned that the current scaling policy that is associated with the Auto Scaling group might not be correct. The company must avoid over&#8211;provisioning EC2 instances and incurring unnecessary costs.<br/><br/>What should a solutions architect recommend to meet these requirements?<br/><br/>A. Configure Amazon EC2 Auto Scaling to use a scheduled scaling plan and launch an additional 8 EC2 instances during business hours.<br/>B. Configure AWS Auto Scaling to use a scaling plan that enables predictive scaling. Configure predictive scaling with a scaling mode of forecast and scale, and to enforce the maximum capacity setting during scaling.<br/>C. Configure a step scaling policy to add 4 EC2 instances at 50% CPU utilization and add another 4 EC2 instances at 90% CPU utilization. Configure scale&#8211;in policies to perform the reverse and remove EC2 instances based on the two values.<br/>D. Configure AWS Auto Scaling to have a desired capacity of 5 EC2 instances, and disable any existing scaling policies. Monitor the CPU utilization metric for 1 week. Then create dynamic scaling policies that are based on the observed values.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample435' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_9'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_668'>Random</a></p><div class='collapse' id='collapseExample435'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Configure AWS Auto Scaling to have a desired capacity of 5 EC2 instances, and disable any existing scaling policies. Monitor the CPU utilization metric for 1 week. Then create dynamic scaling policies that are based on the observed values.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 1%;" aria-valuenow="1" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_9><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 9</p><br/>A company must migrate 20 TB of data from a data center to the AWS Cloud within 30 days. The company's network bandwidth is limited to 15 Mbps and cannot exceed 70% utilization. What should a solutions architect do to meet these requirements?<br/><br/>A. Use AWS Snowball.<br/>B. Use AWS DataSync.<br/>C. Use a secure VPN connection.<br/>D. Use Amazon S3 Transfer Acceleration.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample60' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_10'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_775'>Random</a></p><div class='collapse' id='collapseExample60'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Use AWS Snowball.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 1%;" aria-valuenow="1" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_10><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 10</p><br/>A company hosts historical weather records in Amazon S3. The records are downloaded from the company's website by a way of a URL that resolves to a domain name. Users all over the world access this content through subscriptions. A third&#8211;party provider hosts the company's root domain name, but the company recently migrated some of its services to Amazon Route 53. The company wants to consolidate contracts, reduce latency for users, and reduce costs related to serving the application to subscribers.<br/><br/>Which solution meets these requirements?<br/><br/>A. Create a web distribution on Amazon CloudFront to serve the S3 content for the application. Create a CNAME record in a Route 53 hosted zone that points to the CloudFront distribution, resolving to the application's URL domain name.<br/>B. Create a web distribution on Amazon CloudFront to serve the S3 content for the application. Create an ALIAS record in the Amazon Route 53 hosted zone that points to the CloudFront distribution, resolving to the application's URL domain name.<br/>C. Create an A record in a Route 53 hosted zone for the application. Create a Route 53 traffic policy for the web application, and configure a geolocation rule. Configure health checks to check the health of the endpoint and route DNS queries to other endpoints if an endpoint is unhealthy.<br/>D. Create an A record in a Route 53 hosted zone for the application. Create a Route 53 traffic policy for the web application, and configure a geoproximity rule. Configure health checks to check the health of the endpoint and route DNS queries to other endpoints if an endpoint is unhealthy.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample250' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_11'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_145'>Random</a></p><div class='collapse' id='collapseExample250'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Create a web distribution on Amazon CloudFront to serve the S3 content for the application. Create an ALIAS record in the Amazon Route 53 hosted zone that points to the CloudFront distribution, resolving to the application's URL domain name.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 1%;" aria-valuenow="1" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_11><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 11</p><br/>A company stores call recordings on a monthly basis Statistically, the recorded data may be referenced randomly within a year but accessed rarely after 1 year.<br/><br/>Files that are newer than 1 year old must be queried and retrieved as quickly as possible.<br/><br/>A delay in retrieving older files is acceptable A solutions architect needs to store the recorded data at a minimal cost.<br/><br/>Which solution is MOST cost&#8211;effective?<br/><br/>A. Store individual files in Amazon S3 Glacier and store search metadata in object tags created in S3 Glacier. Query S3 Glacier tags and retrieve the files from S3 Glacier<br/>B. Store individual files in Amazon S3 Use lifecycle policies to move the files to Amazon S3 Glacier after 1 year. Query and retrieve the files from Amazon S3 or S3 Glacier.<br/>C. Archive individual files and store search metadata for each archive in Amazon S3. Use lifecycle policies to move the files to Amazon S3 Glacier after 1 year. Query and retrieve the files by searching for metadata from Amazon S3<br/>D. Archive individual files in Amazon S3. Use lifecycle policies to move the files to Amazon S3 Glacier after 1 year. Store search metadata in Amazon DynamoDB Query the files from DynamoDB and retrieve them from Amazon S3 or S3 Glacier<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample715' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_12'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_194'>Random</a></p><div class='collapse' id='collapseExample715'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Store individual files in Amazon S3 Use lifecycle policies to move the files to Amazon S3 Glacier after 1 year. Query and retrieve the files from Amazon S3 or S3 Glacier.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 1%;" aria-valuenow="1" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_12><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 12</p><br/>A solutions architect is designing a security solution for a company that wants to provide developers with individual AWS accounts through AWS Organizations, while also maintaining standard security controls.<br/><br/>Because the individual developers will have AWS account root user&#8211;level access to their own accounts, the solutions architect wants to ensure that the mandatory AWS CloudTrail configuration that is applied to new developer accounts is not modified.<br/><br/>Which action meets these requirements?<br/><br/>A. Create an IAM policy that prohibits changes to CloudTrail, and attach it to the root user.<br/>B. Create a new trail in CloudTrail from within the developer accounts with the organization trails option enabled.<br/>C. Create a service control policy (SCP) the prohibits changes to CloudTrail, and attach it the developer accounts.<br/>D. Create a service&#8211;linked role for CloudTrail with a policy condition that allows changes only from an Amazon Resource Name (ARN) in the master account.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample223' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_13'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_71'>Random</a></p><div class='collapse' id='collapseExample223'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Create a service control policy (SCP) the prohibits changes to CloudTrail, and attach it the developer accounts.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 1%;" aria-valuenow="1" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_13><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 13</p><br/>A company's legacy application is currently relying on a single&#8211;instance Amazon RDS MySQL database without encryption Due to new compliance requirements, all existing and new data in this database must be encrypted<br/><br/>How should this be accomplished?<br/><br/>A. Create an Amazon S3 bucket with server&#8211;side encryption enabled Move all the data to Amazon S3 Delete the RDS instance<br/>B. Enable RDS Multi&#8211;AZ mode with encryption at rest enabled Perform a failover to the standby instance to delete the original instance<br/>C. Take a snapshot of the RDS instance Create an encrypted copy of the snapshot Restore the RDS instance from the encrypted snapshot<br/>D. Create an RDS read replica with encryption at rest enabled Promote the read replica to master and switch the application over to the new master Delete the old RDS instance.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample506' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation506' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_14'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_163'>Random</a></p><div class='collapse' id='collapseExample506'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Take a snapshot of the RDS instance Create an encrypted copy of the snapshot Restore the RDS instance from the encrypted snapshot</div></div></div><div class='collapse' id='explanation506'><div class='card card&#45;body'><div>
How do I encrypt Amazon RDS snapshots?
The following steps are applicable to Amazon RDS for MySQL, Oracle, SQL Server, PostgreSQL, or MariaDB.
Important: If you use Amazon Aurora, you can restore an unencrypted Aurora DB cluster snapshot to an encrypted Aurora DB cluster if you specify an AWS Key Management Service (AWS KMS) encryption key when you restore from the unencrypted DB cluster snapshot. For more information, see Limitations of Amazon RDS Encrypted DB Instances.
Open the Amazon RDS console, and then choose Snapshots from the navigation pane.
Select the snapshot that you want to encrypt.
Under Snapshot Actions, choose Copy Snapshot.
Choose your Destination Region, and then enter your New DB Snapshot Identifier.
Change Enable Encryption to Yes.
Select your Master Key from the list, and then choose Copy Snapshot.
After the snapshot status is available, the Encrypted field will be True to indicate that the snapshot is encrypted.
You now have an encrypted snapshot of your DB. You can use this encrypted DB snapshot to restore the DB instance from the DB snapshot.
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 1%;" aria-valuenow="1" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_14><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 14</p><br/>A public&#8211;facing web application queries a database hosted on an Amazon EC2 instance in a private subnet.<br/><br/>A large number of queries involve multiple table joins, and the application performance has been degrading due to an increase in complex queries. The application team will be performing updates to improve performance.<br/><br/>What should a solutions architect recommend to the application team? (Choose two.)<br/><br/>A. Cache query data in Amazon SQS<br/>B. Create a read replica to offload queries<br/>C. Migrate the database to Amazon Athena<br/>D. Implement Amazon DynamoDB Accelerator to cache data.<br/>E. Migrate the database to Amazon RDS<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample194' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_15'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_724'>Random</a></p><div class='collapse' id='collapseExample194'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Create a read replica to offload queries
<br><b>E. </b>Migrate the database to Amazon RDS</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 1%;" aria-valuenow="1" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_15><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 15</p><br/>A company wants to improve the availability and performance of its hybrid application. The application consists of a stateful TCP&#8211;based workload hosted on Amazon EC2 instances in different AWS Regions and a stateless UOP&#8211;based workload hosted on&#8211;premises.<br/><br/>Which combination of actions should a solutions architect take to improve availability and performance? (Choose two.)<br/><br/>A. Create an accelerator using AWS Global Accelerator. Add the load balancers as endpoints.<br/>B. Create an Amazon CloudFront distribution with an origin that uses Amazon Route 53 latency&#8211;based routing to route requests to the load balancers.<br/>C. Configure two Application Load Balancers in each Region. The first will route to the EC2 endpoints and the second will route to the on&#8211;premises endpoints.<br/>D. Configure a Network Load Balancer in each Region to address the EC2 endpoints. Configure a Network Load Balancer in each Region that routes to the on&#8211;premises endpoints.<br/>E. Configure a Network Load Balancer in each Region to address the EC2 endpoints. Configure an Application Load Balancer in each Region that routes to the on&#8211;premises endpoints.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample294' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_16'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_26'>Random</a></p><div class='collapse' id='collapseExample294'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Create an accelerator using AWS Global Accelerator. Add the load balancers as endpoints.
<br><b>D. </b>Configure a Network Load Balancer in each Region to address the EC2 endpoints. Configure a Network Load Balancer in each Region that routes to the on-premises endpoints.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 1%;" aria-valuenow="1" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_16><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 16</p><br/>A company has a customer relationship management (CRM) application that stores data in an Amazon RDS DB instance that runs Microsoft SQL Server. The company's IT staff has administrative access to the database. The database contains sensitive data. The company wants to ensure that the data is not accessible to the IT staff and that only authorized personnel can view the data.<br/><br/>What should a solutions architect do to secure the data?<br/><br/>A. Use client&#8211;side encryption with an Amazon RDS managed key.<br/>B. Use client&#8211;side encryption with an AWS Key Management Service (AWS KMS) customer managed key.<br/>C. Use Amazon RDS encryption with an AWS Key Management Service (AWS KMS) default encryption key.<br/>D. Use Amazon RDS encryption with an AWS Key Management Service (AWS KMS) customer managed key.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample470' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_17'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_696'>Random</a></p><div class='collapse' id='collapseExample470'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Use Amazon RDS encryption with an AWS Key Management Service (AWS KMS) customer managed key.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 2%;" aria-valuenow="2" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_17><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 17</p><br/>A company is working with an external vendor that requires write access to the company's Amazon Simple Queue Service (Amazon SQS) queue. The vendor has its own AWS account.<br/><br/>What should a solutions architect do to implement least privilege access?<br/><br/>A. Update the permission policy on the SQS queue to give write access to the vendor's AWS account.<br/>B. Create an IAM user with write access to the SQS queue and share the credentials for the IAM user.<br/>C. Update AWS Resource Access Manager to provide write access to the SQS queue from the vendor's AWS account.<br/>D. Create a cross&#8211;account role with access to all SQS queues and use the vendor's AWS account in the trust document for the role.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample319' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_18'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_605'>Random</a></p><div class='collapse' id='collapseExample319'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Create a cross-account role with access to all SQS queues and use the vendor's AWS account in the trust document for the role.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 2%;" aria-valuenow="2" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_18><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 18</p><br/>A company's packaged application dynamically creates and returns single&#8211;use text files in response to user requests. The company is using Amazon CloudFront for distribution, but wants to further reduce data transfer costs. The company cannot modify the application's source code.<br/><br/>What should a solutions architect do to reduce costs?<br/><br/>A. Use Lambda@Edge to compress the files as they are sent to users.<br/>B. Enable Amazon S3 Transfer Acceleration to reduce the response times.<br/>C. Enable caching on the CloudFront distribution to store generated files at the edge.<br/>D. Use Amazon S3 multipart uploads to move the files to Amazon S3 before returning them to users.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample120' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation120' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_19'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_298'>Random</a></p><div class='collapse' id='collapseExample120'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Use Lambda@Edge to compress the files as they are sent to users.</div></div></div><div class='collapse' id='explanation120'><div class='card card&#45;body'><div>
B seems more expensive; C does not seem right because they are single use files and will not be needed again from the cache; D multipart mainly for large files and will not reduce data and cost; A seems the best: change the application code to compress the files and reduce the amount of data transferred to save costs.
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 2%;" aria-valuenow="2" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_19><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 19</p><br/>A company has an application that is hosted on Amazon EC2 instances in two private subnets. A solutions architect must make the application available on the public internet with the least amount of administrative effort.<br/><br/>What should the solutions architect recommend?<br/><br/>A. Create a load balancer and associate two public subnets from the same Availability Zones as the private instances. Add the private instances to the load balancer.<br/>B. Create a load balancer and associate two private subnets from the same Availability Zones as the private instances. Add the private instances to the load balancer.<br/>C. Create an Amazon Machine Image (AMI) of the instances in the private subnet and restore in the public subnet. Create a load balancer and associate two public subnets from the same Availability Zones as the public instances.<br/>D. Create an Amazon Machine Image (AMI) of the instances in the private subnet and restore in the public subnet. Create a load balancer and associate two private subnets from the same Availability Zones as the public instances.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample290' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_20'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_584'>Random</a></p><div class='collapse' id='collapseExample290'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Create an Amazon Machine Image (AMI) of the instances in the private subnet and restore in the public subnet. Create a load balancer and associate two public subnets from the same Availability Zones as the public instances.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 2%;" aria-valuenow="2" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_20><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 20</p><br/>An edge location refers to which Amazon Web Service?<br/><br/>A. An edge location is referred to the network configured within a Zone or Region<br/>B. An edge location is an AWS Region<br/>C. An edge location is the location of the data center used for Amazon CloudFront.<br/>D. An edge location is a Zone within an AWS Region<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample769' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation769' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_21'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_754'>Random</a></p><div class='collapse' id='collapseExample769'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>An edge location is the location of the data center used for Amazon CloudFront.</div></div></div><div class='collapse' id='explanation769'><div class='card card&#45;body'><div>
Amazon CloudFront is a content distribution network. A content delivery network or content distribution network (CDN) is a large distributed system of servers deployed in multiple data centers across the world. The location of the data center used for CDN is called edge location. Amazon CloudFront can cache static content at each edge location. This means that your popular static content (e.g., your site's logo, navigational images, cascading style sheets, JavaScript code, etc.) will be available at a nearby edge location for the browsers to download with low latency and improved performance for viewers. Caching popular static content with Amazon CloudFront also helps you offload requests for such files from your origin server – CloudFront serves the cached copy when available and only makes a request to your origin server if the edge location receiving the browser's request does not have a copy of the file.

References:

Amazon CloudFront</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 2%;" aria-valuenow="2" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_21><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 21</p><br/>A company has copied 1 PB of data from a colocation facility to an Amazon S3 bucket in the us&#8211;east&#8211;1 Region using an AWS Direct Connect link. The company now wants to copy the data to another S3 bucket in the us&#8211;west&#8211;2 Region. The colocation facility does not allow the use of AWS Snowball.<br/><br/>What should a solutions architect recommend to accomplish this?<br/><br/>A. Order a Snowball Edge device to copy the data from one Region to another Region.<br/>B. Transfer contents from the source S3 bucket to a target S3 bucket using the S3 console.<br/>C. Use the aws S3 sync command to copy data from the source bucket to the destination bucket.<br/>D. Add a cross&#8211;Region replication configuration to copy objects across S3 buckets in different Regions.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample221' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_22'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_207'>Random</a></p><div class='collapse' id='collapseExample221'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Use the aws S3 sync command to copy data from the source bucket to the destination bucket.

References:

How can I copy all objects from one Amazon S3 bucket to another bucket?</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 2%;" aria-valuenow="2" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_22><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 22</p><br/>A bicycle sharing company is developing a multi&#8211;tier architecture to track the location of its bicycles during peak operating hours. The company wants to use these data points in its existing analytics platform. A solutions architect must determine the most viable multi&#8211;tier option to support this architecture. The data points must be accessible from the REST API.<br/><br/>Which action meets these requirements for storing and retrieving location data?<br/><br/>A. Use Amazon Athena with Amazon S3.<br/>B. Use Amazon API Gateway with AWS Lambda.<br/>C. Use Amazon QuickSight with Amazon Redshift.<br/>D. Use Amazon API Gateway with Amazon Kinesis Data Analytics.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample157' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation157' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_23'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_358'>Random</a></p><div class='collapse' id='collapseExample157'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Use Amazon API Gateway with AWS Lambda.</div></div></div><div class='collapse' id='explanation157'><div class='card card&#45;body'><div>
Keyword: Data points in its existing analytics platform + Data points must be accessible from the REST API + Track the location of its bicycles during peak operating hours

They already have an analytics platform, A (Athena) and D (Kinesis Data Analytics) are out of the race even though S3 & APT Gateway Support REST API. Now B and C are in Race. C will not support REST API. So answer should be B as per below details.

Now if we talk about data type, we are talking about GEO location data for their bicycles. API Gateway will be support REST API. So, exact solution should be API Gateway with AWS Lambda along with Amazon Kinesis Data Analytics (Assume its used already).

CORRECT: "Use Amazon API Gateway with AWS Lambda" is the correct answer. INCORRECT: "Use Amazon Athena with Amazon S3" is incorrect as they already have analytics platform.

INCORRECT: "Use Amazon QuickSight with Amazon Redshift" is incorrect. This is not support REST API.

INCORRECT: "Use Amazon API Gateway with Amazon Kinesis Data Analytics" is incorrect as they already have analytics platform.

References:

Amazon API Gateway
AWS Lambda
Amazon Kinesis Data Analytics</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 2%;" aria-valuenow="2" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_23><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 23</p><br/>A company has recently updated its internal security standards.<br/><br/>The company must now ensure all Amazon S3 buckets and Amazon Elastic Block Store (Amazon EBS) volumes are encrypted with keys created and periodically rotated by internal security specialists.<br/><br/>The company is looking for a native, software&#8211;based AWS service to accomplish this goal.<br/><br/>What should a solutions architect recommend as a solution?<br/><br/>A. Use AWS Secrets Manager with customer master keys (CMKs) to store master key material and apply a routine to create a new CMK periodically and replace it in AWS Secrets Manager.<br/>B. Use AWS Key Management Service (AWS KMS) with customer master keys (CMKs) to store master key material and apply a routing to re&#8211;create a new key periodically and replace it in AWS KMS.<br/>C. Use an AWS CloudHSM cluster with customer master keys (CMKs) to store master key material and apply a routine a re&#8211;create a new key periodically and replace it in the CloudHSM cluster nodes.<br/>D. Use AWS Systems Manager Parameter Store with customer master keys (CMKs) keys to store master key material and apply a routine to re&#8211;create a new periodically and replace it in the Parameter Store.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample718' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation718' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_24'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_6'>Random</a></p><div class='collapse' id='collapseExample718'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Use AWS Secrets Manager with customer master keys (CMKs) to store master key material and apply a routine to create a new CMK periodically and replace it in AWS Secrets Manager.</div></div></div><div class='collapse' id='explanation718'><div class='card card&#45;body'><div>
AWS Secrets Manager provides full lifecycle management for secrets within your environment. In this post, Maitreya and I will show you how to use Secrets Manager to store, deliver, and rotate SSH keypairs used for communication within compute clusters. Rotation of these keypairs is a security best practice, and sometimes a regulatory requirement. Traditionally, these keypairs have been associated with a number of tough challenges. For example, synchronizing key rotation across all compute nodes, enable detailed logging and auditing, and manage access to users in order to modify secrets.
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 2%;" aria-valuenow="2" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_24><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 24</p><br/>A company seeks a storage solution for its application. The solution must be highly available and scalable.<br/><br/>The solution also must function as a file system, be mountable by multiple Linux instances in AWS and on&#8211;premises through native protocols, and have no minimum size requirements.<br/><br/>The company has set up a Site&#8211;to&#8211;Site VPN for access from its on&#8211;premises network to its VPC. Which storage solution meets these requirements?<br/><br/>A. Amazon FSx Multi&#8211;AZ deployments<br/>B. Amazon Elastic Block Store (Amazon EBS) Multi&#8211;Attach volumes<br/>C. Amazon Elastic File System (Amazon EFS) with multiple mount targets<br/>D. Amazon Elastic File System (Amazon EFS) with a single mount target and multiple access points<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample646' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_25'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_478'>Random</a></p><div class='collapse' id='collapseExample646'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Amazon Elastic File System (Amazon EFS) with multiple mount targets</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 3%;" aria-valuenow="3" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_25><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 25</p><br/>A company has a Microsoft NET application that runs on an on&#8211;premises Windows Server. The application stores data by using an Oracle Database Standard Edition server.<br/><br/>The company is planning a migration to AWS and wants to minimize development changes while moving the application.<br/><br/>The AWS application environment should be highly available.<br/><br/>Which combination of actions should the company take to meet these requirements? (Select TWO)<br/><br/>A. Refactor the application as serverless with AWS Lambda functions running NET Core<br/>B. Rehost the application in AWS Elastic Beanstalk with the NET platform in a Multi&#8211;AZ deployment<br/>C. Replatform the application to run on Amazon EC2 with the Amazon Linux Amazon Machine Image (AMI).<br/>D. Use AWS Database Migration Service (AWS DMS) to migrate from the Oracle database to Amazon DynamoDB in a Multi&#8211;AZ deployment<br/>E. Use AWS Database Migration Service (AWS DMS) to migrate from the Oracle database to Oracle on Amazon RDS in a Multi&#8211;AZ deployment<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample636' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_26'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_544'>Random</a></p><div class='collapse' id='collapseExample636'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Refactor the application as serverless with AWS Lambda functions running NET Core
<br><b>E. </b>Use AWS Database Migration Service (AWS DMS) to migrate from the Oracle database to Oracle on Amazon RDS in a Multi-AZ deployment</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 3%;" aria-valuenow="3" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_26><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 26</p><br/>A company's security team requests that network traffic be captured in VPC Flow Logs. The logs will be frequently accessed for 90 days and then accessed intermittently.<br/><br/>What should a solutions architect do to meet these requirements when configuring the logs?<br/><br/>A. Use Amazon CloudWatch as the target. Set the CloudWatch log group with an expiration of 90 days.<br/>B. Use Amazon Kinesis as the target. Configure the Kinesis stream to always retain the logs for 90 days.<br/>C. Use AWS CloudTrail as the target. Configure CloudTrail to save to an Amazon S3 bucket, and enable S3 Intelligent&#8211;Tiering.<br/>D. Use Amazon S3 as the target. Enable an S3 Lifecycle policy to transition the logs to S3 StandardInfrequent Access (S3 Standard&#8211;IA) after 90 days.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample416' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_27'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_531'>Random</a></p><div class='collapse' id='collapseExample416'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Use Amazon S3 as the target. Enable an S3 Lifecycle policy to transition the logs to S3 StandardInfrequent Access (S3 Standard-IA) after 90 days.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 3%;" aria-valuenow="3" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_27><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 27</p><br/>A company is looking for a solution that can store video archives in AWS from old news footage. The company needs to minimize costs and will rarely need to restore these files. When the files are needed, they must be available in a maximum of five minutes.<br/><br/>What is the MOST cost&#8211;effective solution?<br/><br/>A. Store the video archives in Amazon S3 Glacier and use Expedited retrievals.<br/>B. Store the video archives in Amazon S3 Glacier and use Standard retrievals.<br/>C. Store the video archives in Amazon S3 Standard&#8211;Infrequent Access (S3 Standard&#8211;IA).<br/>D. Store the video archives in Amazon S3 One Zone&#8211;Infrequent Access (S3 One Zone&#8211;IA).<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample192' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_28'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_331'>Random</a></p><div class='collapse' id='collapseExample192'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Store the video archives in Amazon S3 Glacier and use Expedited retrievals.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 3%;" aria-valuenow="3" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_28><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 28</p><br/>A solutions architect is designing a VPC with public and private subnets. The VPC and subnets use IPv4 CIDR blocks. There is one public subnet and one private subnet in each of three Availability Zones (AZs) for high availability. An internet gateway is used to provide internet access for the public subnets. The private subnets require access to the internet to allow Amazon EC2 instances to download software updates.<br/><br/>What should the solutions architect do to enable internet access for the private subnets?<br/><br/>A. Create three NAT gateways, one for each public subnet in each AZ. Create a private route table for each AZ that forwards non&#8211;VPC traffic to the NAT gateway in its AZ.<br/>B. Create three NAT instances, one for each private subnet in each AZ. Create a private route table for each AZ that forwards non&#8211;VPC traffic to the NAT instance in its AZ.<br/>C. Create a second internet gateway on one of the private subnets. Update the route table for the private subnets that forward non&#8211;VPC traffic to the private internet gateway.<br/>D. Create an egress&#8211;only internet gateway on one of the public subnets. Update the route table for the private subnets that forward non&#8211;VPC traffic to the egress&#8211;only internet gateway.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample216' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_29'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_555'>Random</a></p><div class='collapse' id='collapseExample216'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Create three NAT instances, one for each private subnet in each AZ. Create a private route table for each AZ that forwards non-VPC traffic to the NAT instance in its AZ.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 3%;" aria-valuenow="3" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_29><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 29</p><br/>A company is launching a new application deployed on an Amazon Elastic Container Service (Amazon ECS) cluster and is using the Fargate launch type for ECS tasks. The company is monitoring CPU and memory usage because it is expecting high traffic to the application upon its launch. However, the company wants to reduce costs when utilization decreases.<br/><br/>What should a solutions architect recommend?<br/><br/>A. Use Amazon EC2 Auto Scaling to scale at certain periods based on previous traffic patterns.<br/>B. Use an AWS Lambda function to scale Amazon ECS based on metric breaches that trigger an Amazon CloudWatch alarm.<br/>C. Use Amazon EC2 Auto Scaling with simple scaling policies to scale when ECS metric breaches trigger an Amazon CloudWatch alarm.<br/>D. Use AWS Application Auto Scaling with target tracking policies to scale when ECS metric breaches trigger an Amazon CloudWatch alarm.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample288' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_30'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_229'>Random</a></p><div class='collapse' id='collapseExample288'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Use Amazon EC2 Auto Scaling to scale at certain periods based on previous traffic patterns.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 3%;" aria-valuenow="3" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_30><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 30</p><br/>A company is using various types of amazon EC&#8211;2 On&#8211;Demand instances.<br/><br/>The company suspects that these instances have greater CPU and memory capacity than its workloads require.<br/><br/>Which actions should the company take to obtain recommendation to optimize cost?<br/><br/>A. Use AWS Trusted Advisor for instance type recommendations.<br/>B. Use AWS Compute Optimizer for instance type recommendations.<br/>C. Use AWS Budgets for instance type recommendations.<br/>D. Use Cost Explorer rightsizing recommendations.<br/>E. Use Amazon Inspector to identify underutilized EC2 instances.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample520' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_31'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_762'>Random</a></p><div class='collapse' id='collapseExample520'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Use AWS Trusted Advisor for instance type recommendations.
<br><b>D. </b>Use Cost Explorer rightsizing recommendations.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 3%;" aria-valuenow="3" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_31><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 31</p><br/>A company has a hybrid application hosted on multiple on&#8211;premises servers with static IP addresses. There is already a VPN that provides connectivity between the VPC and the on&#8211;premises network. The company wants to distribute TCP traffic across the on&#8211;premises servers for internet users.<br/><br/>What should a solutions architect recommend to provide a highly available and scalable solution?<br/><br/>A. Launch an internet&#8211;facing Network Load Balancer (NLB) and register on&#8211;premises IP addresses with the NLB.<br/>B. Launch an internet&#8211;facing Application Load Balancer (ALB) and register on&#8211;premises IP addresses with the ALB.<br/>C. Launch an Amazon EC2 instance, attach an Elastic IP address, and distribute traffic to the on&#8211;premises servers.<br/>D. Launch an Amazon EC2 instance with public IP addresses in an Auto Scaling group and distribute traffic to the on&#8211;premises servers.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample381' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_32'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_49'>Random</a></p><div class='collapse' id='collapseExample381'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Launch an internet-facing Network Load Balancer (NLB) and register on-premises IP addresses with the NLB.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 3%;" aria-valuenow="3" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_32><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 32</p><br/>A company's website runs on Amazon EC2 instances behind an Application Load Balancer (ALB). The website has a mix of dynamic and static content. Users around the globe are reporting that the website is slow.<br/><br/>Which set of actions will improve website performance for users worldwide?<br/><br/>A. Create an Amazon CloudFront distribution and configure the ALB as an origin. Then update the Amazon Route 53 record to point to the CloudFront distribution.<br/>B. Create a latency&#8211;based Amazon Route 53 record for the ALB. Then launch new EC2 instances with larger instance sizes and register the instances with the ALB.<br/>C. Launch new EC2 instances hosting the same web application in different Regions closer to the users. Then register instances with the same ALB using cross&#8211;region VPC peering.<br/>D. Host the website in an Amazon S3 bucket in the Regions closest to the users and delete the ALB and EC2 instances. Then update an Amazon Route 53 record to point to the S3 buckets.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample261' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation261' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_33'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_29'>Random</a></p><div class='collapse' id='collapseExample261'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Create an Amazon CloudFront distribution and configure the ALB as an origin. Then update the Amazon Route 53 record to point to the CloudFront distribution.</div></div></div><div class='collapse' id='explanation261'><div class='card card&#45;body'><div>
What Is Amazon CloudFront?

Amazon CloudFront is a web service that speeds up distribution of your static and dynamic web content, such as .html, .css, .js, and image files, to your users. CloudFront delivers your content through a worldwide network of data centers called edge locations. When a user requests content that you're serving with CloudFront, the user is routed to the edge location that provides the lowest latency (time delay), so that content is delivered with the best possible performance.

Routing Traffic to an Amazon CloudFront web distribution by using your domain name.

If you want to speed up delivery of your web content, you can use Amazon CloudFront, the AWS content delivery network (CDN). CloudFront can deliver your entire website – including dynamic, static, streaming, and interactive content – by using a global network of edge locations. Requests for your content are automatically routed to the edge location that gives your users the lowest latency.

To use CloudFront to distribute your content, you create a web distribution and specify settings such as the Amazon S3 bucket or HTTP server that you want CloudFront to get your content from, whether you want only selected users to have access to your content, and whether you want to require users to use HTTPS.

When you create a web distribution, CloudFront assigns a domain name to the distribution, such asd111111abcdef8.cloudfront.net. You can use this domain name in the URLs for your content, for example:

http://d111111abcdef8.cloudfront.net/logo.jpg

Alternatively, you might prefer to use your own domain name in URLs, for example:

http://example.com/logo.jpg

If you want to use your own domain name, use Amazon Route 53 to create an alias record that points to your CloudFront distribution. An alias record is a Route 53 extension to DNS. It's similar to a CNAME record, but you can create an alias record both for the root domain, such as example.com, and for subdomains, such aswww.example.com. (You can create CNAME records only for subdomains.) When Route 53 receives a DNS query that matches the name and type of an alias record, Route 53 responds with the domain name that is associated with your distribution.

Amazon CloudFront is a content delivery network (CDN) that improves website performance by caching content at edge locations around the world. It can serve both dynamic and static content.

This is the best solution for improving the performance of the website.

CORRECT: "Create an Amazon CloudFront distribution and configure the ALB as an origin. Then update the Amazon Route 53 record to point to the CloudFront distribution" is the correct answer. INCORRECT: "Create a latency-based Amazon Route 53 record for the ALB. Then launch new EC2 instances with larger instance sizes and register the instances with the ALB" is incorrect.

Latency routing routes based on the latency between the client and AWS. There is no mention in the answer about creating the new instances in another region therefore the only advantage is in using larger instance sizes. For a dynamic site this adds complexity in keeping the instances in sync.

INCORRECT: "Launch new EC2 instances hosting the same web application in different Regions closer to the users. Use an AWS Transit Gateway to connect customers to the closest region" is incorrect as Transit Gateway is a service for connecting on-premises networks and VPCs to a single gateway.

INCORRECT: "Migrate the website to an Amazon S3 bucket in the Regions closest to the users. Then create an Amazon Route 53 geolocation record to point to the S3 buckets" is incorrect as with S3 you can only host static websites, not dynamic websites.

References:

Amazon CloudFront Dynamic Content Delivery

</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 4%;" aria-valuenow="4" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_33><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 33</p><br/>A medical records company is hosting an application on Amazon EC2 instances. The application processes customer data files that are stored on Amazon S3. The EC2 instances are hosted in public subnets. The EC2 instances access Amazon S3 over the internet, but they do not require any other network access.<br/><br/>A new requirement mandates that the network traffic for file transfers take a private route and not be sent over the internet.<br/><br/>Which change to the network architecture should a solutions architect recommend to meet this requirement?<br/><br/>A. Create a NAT gateway. Configure the route table for the public subnets to send traffic to Amazon S3 through the NAT gateway.<br/>B. Configure the security group for the EC2 instances to restrict outbound traffic so that only traffic to the S3 prefix list is permitted.<br/>C. Move the EC2 instances to private subnets. Create a VPC endpoint for Amazon S3, and link the endpoint to the route table for the private subnets<br/>D. Remove the internet gateway from the VP<br/>E. Set up an AWS Direct Connect connection, and route traffic to Amazon S3 over the Direct Connect connection.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample472' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_34'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_466'>Random</a></p><div class='collapse' id='collapseExample472'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Move the EC2 instances to private subnets. Create a VPC endpoint for Amazon S3, and link the endpoint to the route table for the private subnets</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 4%;" aria-valuenow="4" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_34><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 34</p><br/>A company wants to replicate its data to AWS to recover in the event of a disaster. Today, a system administrator has scripts that copy data to a NFS share Individual backup files need to be accessed with low latency by application administrators to deal with errors in processing.<br/><br/>What should a solutions architect recommend to meet these requirements?<br/><br/>A. Modify the script to copy data to an Amazon S3 bucket instead of the on&#8211;premises NFS share.<br/>B. Modify the script to copy data to an Amazon S3 Glacier Archive instead of the on&#8211;premises NFS share.<br/>C. Modify the script to copy data to an Amazon Elastic File System (Amazon EFS) volume instead of the on&#8211;premises NFS share.<br/>D. Modify the script to copy data to an AWS Storage Gateway for File Gateway virtual appliance instead of the on&#8211;premises NFS share.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample55' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_35'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_31'>Random</a></p><div class='collapse' id='collapseExample55'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Modify the script to copy data to an AWS Storage Gateway for File Gateway virtual appliance instead of the on-premises NFS share.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 4%;" aria-valuenow="4" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_35><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 35</p><br/>A company has a legacy application that processes data in two parts. The second part of the process takes longer than the first, so the company has decided to rewrite the application as two microservices running on Amazon ECS that can scale independently.<br/><br/>How should a solutions architect integrate the microservices?<br/><br/>A. Implement code in microservice 1 to send data to an Amazon S3 bucket. Use S3 event notifications to invoke microservice 2.<br/>B. Implement code in microservice 1 to publish data to an Amazon SNS topic. Implement code in microservice 2 to subscribe to this topic.<br/>C. Implement code in microservice 1 to send data to Amazon Kinesis Data Firehose. Implement code in microservice 2 to read from Kinesis Data Firehose.<br/>D. Implement code in microservice 1 to send data to an Amazon SQS queue. Implement code in microservice 2 to process messages from the queue.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample3' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation3' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_36'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_250'>Random</a></p><div class='collapse' id='collapseExample3'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Implement code in microservice 1 to send data to Amazon Kinesis Data Firehose. Implement code in microservice 2 to read from Kinesis Data Firehose.</div></div></div><div class='collapse' id='explanation3'><div class='card card&#45;body'><div>
This is a good use case for Amazon SQS. The microservices must be decoupled so they can scale independently. An Amazon SQS queue will enable microservice 1 to add messages to the queue. Microservice 2 can then pick up the messages and process them. This ensures that if there's a spike in traffic on the frontend, messages do not get lost due to the backend process not being ready to process them.

CORRECT: "Implement code in microservice 1 to send data to an Amazon SQS queue. Implement code in microservice 2 to process messages from the queue" is the correct answer. INCORRECT: "Implement code in microservice 1 to send data to an Amazon S3 bucket. Use S3 event notifications to invoke microservice 2" is incorrect as a message queue would be preferable to an S3 bucket.

INCORRECT: "Implement code in microservice 1 to publish data to an Amazon SNS topic. Implement code in microservice 2 to subscribe to this topic" is incorrect as notifications to topics are pushed to subscribers. In this case we want the second microservice to pickup the messages when ready (pull them).

INCORRECT: "Implement code in microservice 1 to send data to Amazon Kinesis Data Firehose. Implement code in microservice 2 to read from Kinesis Data Firehose" is incorrect as this is not how Firehose works. Firehose sends data directly to destinations, it is not a message queue.

References:

Amazon Simple Queue Service > Developer Guide > What is Amazon Simple Queue Service?</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 4%;" aria-valuenow="4" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_36><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 36</p><br/>A company needs to provide its employees with secure access to confidential and sensitive files. The company wants to ensure that the files can be accessed only by authorized users. The files must be downloaded securely to the employees' devices.<br/><br/>The files are stored in an on&#8211;premises Windows file server. However, due to an increase in remote usage, the file server is running out of capacity.<br/><br/>Which solution will meet these requirements?<br/><br/>A. Migrate the file server to an Amazon EC2 instance in a public subnet. Configure the security group to limit inbound traffic to the employees' IP addresses.<br/>B. Migrate the files to an Amazon FSx for Windows File Server file system. Integrate the Amazon FSx file system with the on&#8211;premises Active Directory. Configure AWS Client VPN.<br/>C. Migrate the files to Amazon S3, and create a private VPC endpoint. Create a signed URL to allow download.<br/>D. Migrate the files to Amazon S3, and create a public VPC endpoint. Allow employees to sign on with AWS Single Sign&#8211;On.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample417' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_37'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_698'>Random</a></p><div class='collapse' id='collapseExample417'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Migrate the files to Amazon S3, and create a private VPC endpoint. Create a signed URL to allow download.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 4%;" aria-valuenow="4" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_37><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 37</p><br/>A company has a mobile chat application with a data store based in Amazon DynamoDB. Users would like new messages to be read with as little latency as possible. A solutions architect needs to design an optimal solution that requires minimal application changes.<br/><br/>Which method should the solutions architect select?<br/><br/>A. Configure Amazon DynamoDB Accelerator (DAX) for the new messages table. Update the code to use the DAX endpoint.<br/>B. Add DynamoDB read replicas to handle the increased read load. Update the application to point to the read endpoint for the read replicas.<br/>C. Double the number of read capacity units for the new messages table in DynamoDB. Continue to use the existing DynamoDB endpoint.<br/>D. Add an Amazon ElastiCache for Redis cache to the application stack. Update the application to point to the Redis cache endpoint instead of DynamoDB.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample734' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation734' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_38'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_305'>Random</a></p><div class='collapse' id='collapseExample734'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Configure Amazon DynamoDB Accelerator (DAX) for the new messages table. Update the code to use the DAX endpoint.</div></div></div><div class='collapse' id='explanation734'><div class='card card&#45;body'><div>
Amazon DynamoDB Accelerator (DAX) is a fully managed, highly available, in-memory cache that can reduce Amazon DynamoDB response times from milliseconds to microseconds, even at millions of requests per second.

Amazon ElastiCache is incorrect because although you may use ElastiCache as your database cache, it will not reduce the DynamoDB response time from milliseconds to microseconds as compared with DynamoDB DAX.

AWS Device Farm is incorrect because this is an app testing service that lets you test and interact with your Android, iOS, and web apps on many devices at once, or reproduce issues on a device in real-time.

DynamoDB Read Replica is incorrect because this is primarily used to automate capacity management for your tables and global secondary indexes.

References:

Amazon DynamoDB Accelerator (DAX)
AWS Device Farm</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 4%;" aria-valuenow="4" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_38><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 38</p><br/>A company has implemented one of its microservices on AWS Lambda that accesses an Amazon DynamoDB table named Books. A solutions architect is designing an IAM policy to be attached to the Lambda function's IAM role, giving it access to put, update, and delete items in the Books table.<br/><br/>The IAM policy must prevent function from performing any other actions on the Books table or any other.<br/><br/>Which IAM policy would fulfill these needs and provide the LEAST privileged access?<br/><br/>A.<br/><br/>B.<br/><br/>C.<br/><br/>D.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample73' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_39'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_392'>Random</a></p><div class='collapse' id='collapseExample73'><div class='card card&#45;body'><div class=' border border&#45;success'></div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 4%;" aria-valuenow="4" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_39><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 39</p><br/>A solutions architect has created a new AWS account and must secure AWS account root user access.<br/><br/>Which combination of actions will accomplish this? (Choose two.)<br/><br/>A. Ensure the root user uses a strong password.<br/>B. Enable multi&#8211;factor authentication to the root user.<br/>C. Store root user access keys in an encrypted Amazon S3 bucket.<br/>D. Add the root user to a group containing administrative permissions.<br/>E. Apply the required permissions to the root user with an inline policy document.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample20' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation20' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_40'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_291'>Random</a></p><div class='collapse' id='collapseExample20'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Ensure the root user uses a strong password.
<br><b>B. </b>Enable multi-factor authentication to the root user.</div></div></div><div class='collapse' id='explanation20'><div class='card card&#45;body'><div>
"Enable MFA"
The AWS Account Root User – https://docs.aws.amazon.com/IAM/latest/UserGuide/id_root- user.html
"Choose a strong password"
Changing the AWS Account Root User Password –

References:

AWS Identity and Access Management > User Guide > Changing the AWS account root user password</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 4%;" aria-valuenow="4" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_40><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 40</p><br/>A company receives data from different sources and implements multiple applications to consume this data. There are many short&#8211;running jobs that run only on the weekend.<br/><br/>The data arrives in batches rather than throughout the entire weekend.<br/><br/>The company needs an environment on AWS to ingest and process this data while maintaining the order of the transactions.<br/><br/>Which combination of AWS services meets these requirements in the MOST cost&#8211;effective manner?<br/><br/>A. Amazon Kinesis Data Streams with AWS Lambda<br/>B. Amazon Kinesis Data Streams with Amazon EC2 Auto Scaling<br/>C. Amazon Simple Queue Service (Amazon SQS) with AWS Lambda<br/>D. Amazon Simple Queue Service (Amazon SQS) with Amazon EC2 Auto Scaling<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample565' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_41'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_504'>Random</a></p><div class='collapse' id='collapseExample565'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Amazon Kinesis Data Streams with AWS Lambda</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 5%;" aria-valuenow="5" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_41><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 41</p><br/>A company plans to store sensitive user data on Amazon S3. Internal security compliance requirement mandate encryption of data before sending it to Amazon S3.<br/><br/>What should a solutions architect recommend to satisfy these requirements?<br/><br/>A. Server&#8211;side encryption with customer&#8211;provided encryption keys<br/>B. Client&#8211;side encryption with Amazon S3 managed encryption keys<br/>C. Server&#8211;side encryption with keys stored in AWS Key Management Service (AWS KMS)<br/>D. Client&#8211;side encryption with a master key stored in AWS Key Management Service (AWS KMS)<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample267' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_42'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_371'>Random</a></p><div class='collapse' id='collapseExample267'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Client-side encryption with a master key stored in AWS Key Management Service (AWS KMS)

References:

Amazon Simple Storage Service > User Guide > Protecting data using client-side encryption</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 5%;" aria-valuenow="5" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_42><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 42</p><br/>A user wants to use an EBS&#8211;backed Amazon EC2 instance for a temporary job. Based on the input data, the job is most likely to finish within a week. Which of the following steps should be followed to terminate the instance automatically once the job is finished?<br/><br/>A. Configure the EC2 instance with a stop instance to terminate it.<br/>B. Configure the EC2 instance with ELB to terminate the instance when it remains idle.<br/>C. Configure the CloudWatch alarm on the instance that should perform the termination action once the instance is idle.<br/>D. Configure the Auto Scaling schedule activity that terminates the instance after 7 days.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample755' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation755' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_43'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_328'>Random</a></p><div class='collapse' id='collapseExample755'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Configure the CloudWatch alarm on the instance that should perform the termination action once the instance is idle.</div></div></div><div class='collapse' id='explanation755'><div class='card card&#45;body'><div>
Auto Scaling can start and stop the instance at a pre-defined time. Here, the total running time is unknown. Thus, the user has to use the CloudWatch alarm, which monitors the CPU utilization. The user can create an alarm that is triggered when the average CPU utilization percentage has been lower than 10 percent for 24 hours, signaling that it is idle and no longer in use. When the utilization is below the threshold limit, it will terminate the instance as a part of the instance action.

References:

Amazon CloudWatch > User Guide > Create alarms to stop, terminate, reboot, or recover an EC2 instance</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 5%;" aria-valuenow="5" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_43><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 43</p><br/>A company is planning to transfer multiple terabytes of data to AWS. The data is collected offline from ships. The company want to run complex transformation before transferring the data.<br/><br/>Which AWS service should a solutions architect recommend for this migration?<br/><br/>A. AWS Snowball<br/>B. AWS Snowmobile<br/>C. AWS Snowball Edge Storage Optimize<br/>D. AWS Snowball Edge Compute Optimize<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample343' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_44'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_619'>Random</a></p><div class='collapse' id='collapseExample343'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>AWS Snowball Edge Compute Optimize</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 5%;" aria-valuenow="5" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_44><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 44</p><br/>An environment has an Auto Scaling group across two Availability Zones to as AZ&#8211;a and AZ&#8211;b has four instances, and AZ&#8211;b has three EC2 instances.<br/><br/>The Auto Scaling group uses a default termination policies. None of the instances are protected from a scale&#8211;in event.<br/><br/>How will Auto Scaling processed if there is a scale&#8211;in event?<br/><br/>A. Auto Scaling selects an instance to terminate randomly.<br/>B. Auto Scaling terminates the instance with the oldest launch configuration of all instances.<br/>C. Auto Scaling selects the Availability Zone with four EC2 instances, and then continues to evaluate.<br/>D. Auto Scaling terminates the instance with the closed next billing hour of all instances.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample587' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_45'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_719'>Random</a></p><div class='collapse' id='collapseExample587'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Auto Scaling selects the Availability Zone with four EC2 instances, and then continues to evaluate.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 5%;" aria-valuenow="5" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_45><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 45</p><br/>A company is hosting its static website in an Amazon S3 bucket, which is the origin for Amazon CloudFront. The company has users in the United States, Canada, and Europe and wants to reduce.<br/><br/>What should a solutions architect recommend?<br/><br/>A. Adjust the CloudFront caching time to live (TTL) from the default to a longer timeframe<br/>B. Implement CloudFront events with Lambda@edge to run the website's data processing<br/>C. Modify the CloudFront price class to include only the locations of the countries that are served<br/>D. Implement a CloudFront Secure Socket Layer (SSL) certificate to push security closer to the locations of the countries that are served<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample713' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_46'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_588'>Random</a></p><div class='collapse' id='collapseExample713'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Modify the CloudFront price class to include only the locations of the countries that are served</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 5%;" aria-valuenow="5" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_46><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 46</p><br/>A company is creating an architecture for a mobile app that requires minimal latency for its users. The company's architecture consists of Amazon EC2 instances behind an Application Load Balancer running in an Auto Scaling group. The EC2 instances connect to Amazon RDS. Application beta testing showed there was a slowdown when reading the data. However the metrics indicate that the EC2 instances do not cross any CPU utilization thresholds.<br/><br/>How can this issue be addressed?<br/><br/>A. Reduce the threshold for CPU utilization in the Auto Scaling group.<br/>B. Replace the Application Load Balancer with a Network Load Balancer.<br/>C. Add read replicas for the RDS instances and direct read traffic to the replica.<br/>D. Add Multi&#8211;AZ support to the RDS instances and direct read traffic to the new EC2 instance.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample373' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_47'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_561'>Random</a></p><div class='collapse' id='collapseExample373'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Add read replicas for the RDS instances and direct read traffic to the replica.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 5%;" aria-valuenow="5" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_47><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 47</p><br/>An application running on an Amazon EC2 instance needs to securely access files on an Amazon Elastic File System (Amazon EFS) file system. The EFS files are stores using encryptions at rest.<br/><br/>Which solution for accessing the files in MOST secure?<br/><br/>A. Enable TLS when mounting Amazon EFS.<br/>B. Store the encryption key in the code of the application.<br/>C. Enable AWS Key Management Service (AKS KMS) when mounting Amazon EFS.<br/>D. Store the encryption key in an Amazon S3 bucket and use IAM roles to grand the EC2 instance access permission.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample697' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_48'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_520'>Random</a></p><div class='collapse' id='collapseExample697'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Enable AWS Key MAnagement Service (AKS KMS) when mounting Amazon EFS.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 5%;" aria-valuenow="5" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_48><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 48</p><br/>A company hosts its core network services, including directory services and DNS. in its on&#8211;premises data center. The data center is connected to the AWS Cloud using AWS Direct Connect (DX) Additional AWS accounts are planned that will require quick, cost&#8211;effective, and consistent access to these network services.<br/><br/>What should a solutions architect implement to meet these requirements with the LEAST amount of operational overhead?<br/><br/>A. Create a DX connection in each new account Route the network traffic to the on&#8211;premises servers<br/>B. Configure VPC endpoints in the DX VPC for all required services Route the network traffic to the on&#8211;premises servers.<br/>C. Create a VPN connection between each new account and the DX VPC, Route the network traffic to the on&#8211;premises servers<br/>D. Configure AWS Transit Gateway between the accounts Assign DX to the transit gateway and route network traffic to the on&#8211;premises servers<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample501' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_49'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_671'>Random</a></p><div class='collapse' id='collapseExample501'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Configure AWS Transit Gateway between the accounts Assign DX to the transit gateway and route network traffic to the on-premises servers</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 6%;" aria-valuenow="6" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_49><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 49</p><br/>Your supervisor has asked you to build a simple file synchronization service for your department. He doesn't want to spend too much money and he wants to be notified of any changes to files by email.<br/><br/>What do you think would be the best Amazon service to use for the email solution?<br/><br/>A. Amazon SES<br/>B. Amazon CloudSearch<br/>C. Amazon SWF<br/>D. Amazon AppStream<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample766' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation766' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_50'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_488'>Random</a></p><div class='collapse' id='collapseExample766'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Amazon SES</div></div></div><div class='collapse' id='explanation766'><div class='card card&#45;body'><div>
File change notifications can be sent via email to users following the resource with Amazon Simple Email Service (Amazon SES), an easy-to-use, cost-effective email solution.

References:

AWS File Synchronization Service</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 6%;" aria-valuenow="6" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_50><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 50</p><br/>A company has deployed a multiplayer game for mobile devices. The game requires live location tracking of players based on latitude and longitude. The data store for the game must support rapid updates and retrieval of locations.<br/><br/>The game uses an Amazon RDS for PostgreSQL DB instance with read replicas to store the location data. During peak usage periods, the database is unable to maintain the performance that is needed for reading and writing updates. The game's user base is increasing rapidly.<br/><br/>What should a solutions architect do to improve the performance of the data tier?<br/><br/>A. Take a snapshot of the existing DB instance. Restore the snapshot with Multi&#8211;AZ enabled.<br/>B. Migrate from Amazon RDS to Amazon Elasticsearch Service (Amazon ES) with Kibana.<br/>C. Deploy Amazon DynamoDB Accelerator (DAX) in front of the existing DB instance. Modify the game to use DA<br/>D. Deploy an Amazon ElastiCache for Redis cluster in front of the existing DB instance. Modify the game to use Redis.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample453' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_51'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_421'>Random</a></p><div class='collapse' id='collapseExample453'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Deploy an Amazon ElastiCache for Redis cluster in front of the existing DB instance. Modify the game to use Redis.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 6%;" aria-valuenow="6" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_51><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 51</p><br/>A company hosts its web application on AWS using seven Amazon EC2 instances.<br/><br/>The company requires that the IP addresses of all healthy EC2 instances be returned in response to DNS queries.<br/><br/>Which policy should be used to meet this requirement?<br/><br/>A. Simple routing policy<br/>B. Latency routing policy<br/>C. Multivalue routing policy<br/>D. Geolocation routing policy<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample672' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_52'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_221'>Random</a></p><div class='collapse' id='collapseExample672'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Multivalue routing policy</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 6%;" aria-valuenow="6" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_52><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 52</p><br/>An Amazon EC2 instance is located in a private subnet in a new VPC. This subnet does not have outbound internet access, but the EC2 instance needs the ability to download monthly security updates from an outside vendor.<br/><br/>What should a solutions architect do to meet these requirements?<br/><br/>A. Create an internet gateway, and attach it to the VPC. Configure the private subnet route table to use the internet gateway as the default route.<br/>B. Create a NAT gateway, and place it in a public subnet. Configure the private subnet route table to use the NAT gateway as the default route.<br/>C. Create a NAT instance, and place it in the same subnet where the EC2 instance is located. Configure the private subnet route table to use the NAT instance as the default route.<br/>D. Create an internet gateway, and attach it to the VPC. Create a NAT instance, and place it in the same subnet where the EC2 instance is located. Configure the private subnet route table to use the internet gateway as the default route.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample433' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_53'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_642'>Random</a></p><div class='collapse' id='collapseExample433'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Create an internet gateway, and attach it to the VP<br><b>C. </b>Configure the private subnet route table to use the internet gateway as the default route.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 6%;" aria-valuenow="6" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_53><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 53</p><br/>An online shopping application accesses an Amazon RDS Multi&#8211;AZ DB instance. Database performance is slowing down the application. After upgrading to the next&#8211;generation instance type, there was no significant performance improvement.<br/><br/>Analysis shows approximately 700 IOPS are sustained, common queries run for long durations and memory utilization is high.<br/><br/><br/><br/>Which application change should a solutions architect recommend to resolve these issues?<br/><br/>A. Migrate the RDS instance to an Amazon Redshift cluster and enable weekly garbage collection.<br/>B. Separate the long&#8211;running queries into a new Multi&#8211;AZ RDS database and modify the application to query whichever database is needed.<br/>C. Deploy a two&#8211;node Amazon ElastiCache cluster and modify the application to query the cluster first and query the database only if needed.<br/>D. Create an Amazon Simple Queue Service (Amazon SQS) FIFO queue for common queries and query it first and query the database only if needed.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample353' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_54'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_289'>Random</a></p><div class='collapse' id='collapseExample353'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Deploy a two-node Amazon ElastiCache cluster and modify the application to query the cluster first and query the database only if needed.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 6%;" aria-valuenow="6" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_54><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 54</p><br/>A company sells ringtones created from clips of popular songs. The files containing the ringtones are stored in Amazon S3 Standard and are at least 123 KB m size.<br/><br/>The company has millions of files but downloads are infrequent for ringtones older than 90 days. The company needs to save money on storage while keeping the most accessed files readily available for its users.<br/><br/>Which action should the company take to meet these requirements MOST cost&#8211;effectively?<br/><br/>A. Configure S3 Standard&#8211;infrequent Access (S3 Standard&#8211;IA) storage for the initial storage tier of the objects<br/>B. Move the files to S3 Intelligent&#8211;Tiering and configure it to move objects to a less expensive storage tier after 90 days<br/>C. Configure S3 inventory to manage objects and move them to S3 Standard&#8211;infrequent Access (S3 Standard&#8211;IA) after 90 days<br/>D. Implement an S3 Lifecycle policy that moves the objects from S3 Standard to S3 Standard&#8211; Infrequent Access (S3 Standard&#8211;IA) after 90 days<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample569' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_55'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_405'>Random</a></p><div class='collapse' id='collapseExample569'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Configure S3 Standard-infrequent Access (S3 Standard-IA) storage for the initial storage tier of the objects</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 6%;" aria-valuenow="6" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_55><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 55</p><br/>A company wants to share forensic accounting data that is stored in an Amazon RDS DB instance with an external auditor. The auditor has its own AWS account and requires its own copy of the database.<br/><br/>How should the company securely share the database with the auditor?<br/><br/>A. Create a read replica of the database and configure IAM standard database authentication to grant the auditor access.<br/>B. Copy a snapshot of the database to Amazon S3 and assign an IAM role to the auditor to grant access to the object in that bucket.<br/>C. Export the database contents to text files, store the files in Amazon S3, and create a new IAM user for the auditor with access to that bucket.<br/>D. Make an encrypted snapshot of the database, share the snapshot, and allow access to the AWS Key Management Service (AWS KMS) encryption key.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample278' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_56'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_165'>Random</a></p><div class='collapse' id='collapseExample278'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Create a read replica of the database and configure IAM standard database authentication to grant the auditor access.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 6%;" aria-valuenow="6" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_56><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 56</p><br/>A solutions architect is designing a system that will store personally identifiable information (Pll) in an Amazon S3 bucket.<br/><br/>Due to compliance and regulatory requirements, both the master keys and the unencrypted data should never be sent to AWS.<br/><br/>Which Amazon S3 encryption technique should the architect choose?<br/><br/>A. Amazon S3 client&#8211;side encryption with an AWS Key Management Service {AWS KMS) managed customer master key (CMK)<br/>B. Amazon S3 server&#8211;side encryption with AWS KMS managed encryption keys (SSE&#8211;KMS)<br/>C. Amazon S3 client&#8211;side encryption with a client&#8211;side master key<br/>D. Amazon S3 server&#8211;side encryption with customer&#8211;provided encryption keys (SSE&#8211;C)<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample624' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_57'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_74'>Random</a></p><div class='collapse' id='collapseExample624'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Amazon S3 server-side encryption with customer-provided encryption keys (SSE-C)</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 7%;" aria-valuenow="7" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_57><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 57</p><br/>A company hosts an application used to upload files to an Amazon S3 bucket. Once uploaded, the files are processed to extract metadata, which takes less than 5 seconds. The volume and frequency of the uploads varies from a few files each hour to hundreds of concurrent uploads. The company has asked a solutions architect to design a cost&#8211;effective architecture that will meet these requirements.<br/><br/>What should the solutions architect recommend?<br/><br/>A. Configure AWS CloudTrail trails to log S3 API calls. Use AWS AppSync to process the files.<br/>B. Configure an object&#8211;created event notification within the S3 bucket to invoke an AWS Lambda function to process the files.<br/>C. Configure Amazon Kinesis Data Streams to process and send data to Amazon S3. Invoke an AWS Lambda function to process the files.<br/>D. Configure an Amazon Simple Notification Service (Amazon SNS) topic to process the files uploaded to Amazon S3. Invoke an AWS Lambda function to process the files.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample276' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_58'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_257'>Random</a></p><div class='collapse' id='collapseExample276'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Configure an object-created event notification within the S3 bucket to invoke an AWS Lambda function to process the files.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 7%;" aria-valuenow="7" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_58><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 58</p><br/>An application running on an Amazon EC2 instance in VPC&#8211;A needs to access files in another EC2 instance in VPC&#8211;B. Both are in separate. AWS accounts. The network administrator needs to design a solution to enable secure access to EC2 instance in VPC&#8211;B from VPC&#8211;A. The connectivity should not have a single point of failure or bandwidth concerns.<br/><br/>Which solution will meet these requirements?<br/><br/>A. Set up a VPC peering connection between VPC&#8211;A and VPC&#8211;B.<br/>B. Set up VPC gateway endpoints for the EC2 instance running in VPC&#8211;B.<br/>C. Attach a virtual private gateway to VPC&#8211;B and enable routing from VPC&#8211;A.<br/>D. Create a private virtual interface (VIF) for the EC2 instance running in VPC&#8211;B and add appropriate routes from VPC&#8211;B.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample65' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation65' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_59'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_380'>Random</a></p><div class='collapse' id='collapseExample65'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Set up a VPC peering connection between VPC-A and VPC-B.</div></div></div><div class='collapse' id='explanation65'><div class='card card&#45;body'><div>
A VPC peering connection is a networking connection between two VPCs that enables you to route traffic between them using private IPv4 addresses or IPv6 addresses. Instances in either VPC can communicate with each other as if they are within the same network. You can create a VPC peering connection between your own VPCs, or with a VPC in another AWS account.

The traffic remains in the private IP space. All inter-region traffic is encrypted with no single point of failure, or bandwidth bottleneck.

References:
Amazon Virtual Private Cloud > VPC Peering > What is VPC peering?
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 7%;" aria-valuenow="7" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_59><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 59</p><br/>A company is running a media store across multiple Amazon EC2 instances distributed across multiple Availability Zones in a single VPC.<br/><br/>The company wants a high&#8211;performing solution to share data between all the EC2 instances, and prefers to keep the data within the VPC only.<br/><br/>What should a solutions architect recommend?<br/><br/>A. Create an Amazon S3 bucket and call the service APIs from each instance's application.<br/>B. Create an Amazon S3 bucket and configure all instances to access it as a mounted volume.<br/>C. Configure an Amazon Elastic Block Store (Amazon EBS) volume and mount it across all instances.<br/>D. Configure an Amazon Elastic File System (Amazon EFS) file system and mount it across all instances.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample684' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_60'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_739'>Random</a></p><div class='collapse' id='collapseExample684'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Configure an Amazon Elastic File System (Amazon EFS) file system and mount it across all instances.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 7%;" aria-valuenow="7" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_60><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 60</p><br/>A media company is using two video conversion tools that run on Amazon EC2 instances. One tool runs on Windows instances, and the other tool runs on Linux instances. Each video file is large in size and must be processed by both tools.<br/><br/>The company needs a storage solution that can provide a centralized file system that can be mounted on all the EC2 instances that are used in this process.<br/><br/>Which solution meets these requirements?<br/><br/>A. Use Amazon FSx for Windows File Server for the Windows instances. Use Amazon Elastic File System (Amazon EFS) with Max I/O performance mode for the Linux instances.<br/>B. Use Amazon FSx for Windows File Server for the Windows instances. Use Amazon FSx for Lustre for the Linux instances. Link both Amazon FSx file systems to the same Amazon S3 bucket.<br/>C. Use Amazon Elastic File System (Amazon EFS) with General Purpose performance mode for the Windows instances and the Linux instances<br/>D. Use Amazon FSx for Windows File Server for the Windows instances and the Linux instances.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample425' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_61'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_527'>Random</a></p><div class='collapse' id='collapseExample425'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Use Amazon Elastic File System (Amazon EFS) with General Purpose performance mode for the Windows instances and the Linux instances</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 7%;" aria-valuenow="7" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_61><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 61</p><br/>A company wants to run its critical applications in containers to meet requirements for scalability and availability. The company prefers to focus on maintenance of the critical applications. The company does not want to be responsible for provisioning and managing the underlying infrastructure that runs the containerized workload.<br/><br/>What should a solutions architect do to meet these requirements?<br/><br/>A. Use Amazon EC2 instances, and install Docker on the instances.<br/>B. Use Amazon Elastic Container Service (Amazon ECS) on Amazon EC2 worker nodes.<br/>C. Use Amazon Elastic Container Service (Amazon ECS) on AWS Fargate.<br/>D. Use Amazon EC2 instances from an Amazon Elastic Container Service (Amazon ECS)&#8211;optimized Amazon Machine Image (AMI).<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample414' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_62'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_564'>Random</a></p><div class='collapse' id='collapseExample414'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Use Amazon Elastic Container Service (Amazon ECS) on AWS Fargate.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 7%;" aria-valuenow="7" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_62><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 62</p><br/>A company wants to migrate a high performance computing (HPC) application and data from on&#8211;premises to the AWS Cloud. The company uses tiered storage on&#8211;premises with hot high&#8211;performance parallel storage to support the application during periodic runs of the application, and more economical cold storage to hold the data when the application is not actively running.<br/><br/>Which combination of solutions should a solutions architect recommend to support the storage needs of the application? (Choose two.)<br/><br/>A. Amazon S3 for cold data storage<br/>B. Amazon EFS for cold data storage<br/>C. Amazon S3 for high&#8211;performance parallel storage<br/>D. Amazon FSx for Lustre for high&#8211;performance parallel storage<br/>E. Amazon FSx for Windows for high&#8211;performance parallel storage<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample181' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation181' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_63'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_369'>Random</a></p><div class='collapse' id='collapseExample181'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Amazon S3 for cold data storage
<br><b>D. </b>Amazon FSx for Lustre for high-performance parallel storage</div></div></div><div class='collapse' id='explanation181'><div class='card card&#45;body'><div>
Amazon FSx for Lustre makes it easy and cost effective to launch and run the world's most popular high-performance file system. Use it for workloads where speed matters, such as machine learning, high performance computing (HPC), video processing, and financial modeling.

Amazon FSx for Lustre provides a high-performance file system optimized for fast processing of workloads such as machine learning, high-performance computing (HPC), video processing, financial modeling, and electronic design automation (EDA).

These workloads commonly require data to be presented via a fast and scalable file system interface, and typically have data sets stored on long-term data stores like Amazon S3.

Amazon FSx works natively with Amazon S3, making it easy to access your S3 data to run data processing workloads. Your S3 objects are presented as files in your file system, and you can write your results back to S3. This lets you run data processing workloads on FSx for Lustre and store your long-term data on S3 or on-premises data stores.

Therefore, the best combination for this scenario is to use S3 for cold data and FSx for Lustre for the parallel HPC job.

CORRECT: "Amazon S3 for cold data storage" is the correct answer.

CORRECT: "Amazon FSx for Lustre for high-performance parallel storage" is the correct answer. INCORRECT: "Amazon EFS for cold data storage" is incorrect as FSx works natively with S3 which is also more economical.

INCORRECT: "Amazon S3 for high-performance parallel storage" is incorrect as S3 is not suitable for running high-performance computing jobs.

INCORRECT: "Amazon FSx for Windows for high-performance parallel storage" is incorrect as FSx for Lustre should be used for HPC use cases and use cases that require storing data on S3.

References:

Amazon FSx for Lustre


</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 7%;" aria-valuenow="7" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_63><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 63</p><br/>You need to migrate a large amount of data into the cloud that you have stored on a hard disk and you decide that the best way to accomplish this is with AWS Import/Export and you mail the hard disk to AWS.<br/><br/>Which of the following statements is incorrect in regards to AWS Import/Export?<br/><br/>A. It can export from Amazon S3<br/>B. It can Import to Amazon Glacier<br/>C. It can export from Amazon Glacier.<br/>D. It can Import to Amazon EBS<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample757' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation757' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_64'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_522'>Random</a></p><div class='collapse' id='collapseExample757'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>It can export from Amazon Glacier.</div></div></div><div class='collapse' id='explanation757'><div class='card card&#45;body'><div>
AWS Import/Export supports: Import to Amazon S3 Export from Amazon S3 Import to Amazon EBS Import to Amazon Glacier
AWS Import/Export does not currently support export from Amazon EBS or Amazon Glacier.

References:

AWS Snowball</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 7%;" aria-valuenow="7" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_64><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 64</p><br/>A media company stores video content in an Amazon Elastic Block Store (Amazon EBS) volume. A certain video files has become popular and a large number of user across the world are accessing this content.<br/><br/>This has resulted in a cost increase.<br/><br/>Which action will DECREASE cost without compromising user accessibility?<br/><br/>A. Change the EBS volume to provisioned IOPS (PIOPS)<br/>B. Store the video in an Amazon S3 bucket and create an Amazon CloudFront distribution<br/>C. Split the video into multiple, smaller segments so users are routed to the requested video segments only<br/>D. Create an Amazon S3 bucket in each Region and upload the videos so users are routed to the nearest S3 bucket<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample712' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_65'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_636'>Random</a></p><div class='collapse' id='collapseExample712'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Store the video in an Amazon S3 bucket and create and Amazon CloudFront distribution</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 8%;" aria-valuenow="8" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_65><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 65</p><br/>A company receives inconsistent service from its data center provider because the company is headquartered in an area affected by natural disasters. The company is not ready to fully migrate to the AWS Cloud, but it wants a failure environment on AWS in case the on&#8211;premises data center fails.<br/><br/>The company runs web servers that connect to external vendors. The data available on AWS and on&#8211;premises must be uniform.<br/><br/>Which solution should a solutions architect recommend that has the LEAST amount of downtime?<br/><br/>A. Configure an Amazon Route 53 failover record. Run application servers on Amazon EC2 instances behind an Application Load Balancer in an Auto Scaling group. Set up AWS Storage Gateway with stored volumes to back up data to Amazon S3.<br/>B. Configure an Amazon Route 53 failover record. Execute an AWS CloudFormation template from a script to create Amazon EC2 instances behind an Application Load Balancer. Set up AWS Storage Gateway with stored volumes to back up data to Amazon S3.<br/>C. Configure an Amazon Route 53 failover record. Set up an AWS Direct Connect connection between a VPC and the data center. Run application servers on Amazon EC2 in an Auto Scaling group. Run an AWS Lambda function to execute an AWS CloudFormation template to create an Application Load Balancer.<br/>D. Configure an Amazon Route 53 failover record. Run an AWS Lambda function to execute an AWS CloudFormation template to launch two Amazon EC2 instances. Set up AWS Storage Gateway with stored volumes to back up data to Amazon S3. Set up an AWS Direct Connect connection between a VPC and the data center.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample140' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_66'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_160'>Random</a></p><div class='collapse' id='collapseExample140'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Configure an Amazon Route 53 failover record. Run application servers on Amazon EC2 instances behind an Application Load Balancer in an Auto Scaling group. Set up AWS Storage Gateway with stored volumes to back up data to Amazon S3.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 8%;" aria-valuenow="8" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_66><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 66</p><br/>In Amazon AWS, which of the following statements is true of key pairs?<br/><br/>A. Key pairs are used only for Amazon SDKs.<br/>B. Key pairs are used only for Amazon EC2 and Amazon CloudFront.<br/>C. Key pairs are used only for Elastic Load Balancing and AWS IAM.<br/>D. Key pairs are used for all Amazon services.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample762' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation762' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_67'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_404'>Random</a></p><div class='collapse' id='collapseExample762'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Key pairs are used only for Amazon EC2 and Amazon CloudFront.</div></div></div><div class='collapse' id='explanation762'><div class='card card&#45;body'><div>
Key pairs consist of a public and private key, where you use the private key to create a digital signature, and then AWS uses the corresponding public key to validate the signature. Key pairs are used only for Amazon EC2 and Amazon CloudFront.

References:

AWS General Reference > Reference guide > Understanding and getting your AWS credentials</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 8%;" aria-valuenow="8" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_67><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 67</p><br/>A company has an application hosted on Amazon EC2 instances in two VPCs across different AWS Regions. To communicate with each other, the instances use the internet for connectivity. The security team wants to ensure that no communication between the instances happens over the internet.<br/><br/>What should a solutions architect do to accomplish this?<br/><br/>A. Create a NAT gateway and update the route table of the EC2 instances' subnet.<br/>B. Create a VPC endpoint and update the route table of the EC2 instances' subnet.<br/>C. Create a VPN connection and update the route table of the EC2 instances' subnet.<br/>D. Create a VPC peering connection and update the route table of the EC2 instances' subnet.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample407' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_68'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_612'>Random</a></p><div class='collapse' id='collapseExample407'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Create a VPC peering connection and update the route table of the EC2 instances' subnet.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 8%;" aria-valuenow="8" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_68><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 68</p><br/>A company hosts its product information webpages on AWS. The existing solution uses multiple Amazon C2 instances behind an Application Load Balancer in an Auto Scaling group. The website also uses a custom DNS name and communicates with HTTPS only using a dedicated SSL certificate. The company is planning a new product launch and wants to be sure that users from around the world have the best possible experience on the new website.<br/><br/>What should a solutions architect do to meet these requirements?<br/><br/>A. Redesign the application to use Amazon CloudFront.<br/>B. Redesign the application to use AWS Elastic Beanstalk.<br/>C. Redesign the application to use a Network Load Balancer.<br/>D. Redesign the application to use Amazon S3 static website hosting.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample188' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation188' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_69'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_93'>Random</a></p><div class='collapse' id='collapseExample188'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Redesign the application to use Amazon CloudFront.</div></div></div><div class='collapse' id='explanation188'><div class='card card&#45;body'><div>
What Is Amazon CloudFront?
Amazon CloudFront is a web service that speeds up distribution of your static and dynamic web content, such as .html, .css, .js, and image files, to your users. CloudFront delivers your content through a worldwide network of data centers called edge locations. When a user requests content that you're serving with CloudFront, the user is routed to the edge location that provides the lowest latency (time delay), so that content is delivered with the best possible performance.

If the content is already in the edge location with the lowest latency, CloudFront delivers it immediately.

If the content is not in that edge location, CloudFront retrieves it from an origin that you've defined – such as an Amazon S3 bucket, a MediaPackage channel, or an HTTP server (for example, a web server) that you have identified as the source for the definitive version of your content.

As an example, suppose that you're serving an image from a traditional web server, not from CloudFront. For example, you might serve an image, sunsetphoto.png, using the URL http://example.com/sunsetphoto.png.

Your users can easily navigate to this URL and see the image. But they probably don't know that their request was routed from one network to another – through the complex collection of interconnected networks that comprise the internet – until the image was found.

CloudFront speeds up the distribution of your content by routing each user request through the AWS backbone network to the edge location that can best serve your content. Typically, this is a CloudFront edge server that provides the fastest delivery to the viewer. Using the AWS network dramatically reduces the number of networks that your users' requests must pass through, which improves performance. Users get lower latency – the time it takes to load the first byte of the file – and higher data transfer rates.

You also get increased reliability and availability because copies of your files (also known as objects) are now held (or cached) in multiple edge locations around the world.
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 8%;" aria-valuenow="8" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_69><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 69</p><br/>A team has an application that detects new objects being uploaded into an Amazon bucket. The upload a trigger AWS Lambda function to write metadata into an Amazon DynamoDB table and an Amazon RDS for PostgreSQL database.<br/><br/>Which action should the team take to ensure high availability?<br/><br/>A. Enable Cross&#8211;Region Replication to ensure high availability<br/>B. Create a Lambda function for each Availability Zone the application is deployed in<br/>C. Enable Multi&#8211;AZ on the RDS PostgreSQL database.<br/>D. Create a DynamoDB stream for the DynamoDB table<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample598' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_70'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_481'>Random</a></p><div class='collapse' id='collapseExample598'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Enable Multi-AZ on the RDS PostgreSQL database.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 8%;" aria-valuenow="8" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_70><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 70</p><br/>A company wants to use a custom distributed application that calculates various profit and loss scenarios. To achieve this goal, the company needs to provide a network connection between its Amazon EC2 instances. The connection must minimize latency and must maximize throughput<br/><br/>Which solution will meet these requirements?<br/><br/>A. Provision the application to use EC2 Dedicated Hosts of the same instance type.<br/>B. Configure a placement group for EC2 instances that have the same instance type.<br/>C. Use multiple AWS elastic network interfaces and link aggregation.<br/>D. Configure AWS PrivateLink for the EC2 instances.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample437' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_71'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_251'>Random</a></p><div class='collapse' id='collapseExample437'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Configure a placement group for EC2 instances that have the same instance type.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 8%;" aria-valuenow="8" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_71><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 71</p><br/>A company uses Amazon RDS for PostgreSQL databases for its data tier. The company must implement password rotation for the databases.<br/><br/>Which solution meets this requirement with the LEAST operational overhead?<br/><br/>A. Store the password in AWS Secrets Manager. Enable automatic rotation on the secret.<br/>B. Store the password in AWS Systems Manager Parameter Store. Enable automatic rotation on the parameter.<br/>C. Store the password in AWS Systems Manager Parameter Store. Write an AWS Lambda function that rotates the password.<br/>D. Store the password in AWS Key Management Service (AWS KMS). Enable automatic rotation on the customer master key (CMK).<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample431' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_72'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_1'>Random</a></p><div class='collapse' id='collapseExample431'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Store the password in AWS Secrets Manager. Enable automatic rotation on the secret.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 8%;" aria-valuenow="8" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_72><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 72</p><br/>The application's traffic is often low. but it occasionally grows significantly. During these sudden increases in traffic, DynamoDB returns throttling errors. The result is that error pages are displayed to end users.<br/><br/>What should a solutions architect do to reduce these errors?<br/><br/>A. Change the DynamoDB table to use on&#8211;demand capacity mode.<br/>B. Create a DynamoDB read replica to scale the read traffic horizontally.<br/>C. Purchase DynamoDB reserved capacity of 1,000 RCUs and 500 WCUs.<br/>D. Configure the application to use strongly consistent reads for DynamoDB queries.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample465' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_73'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_772'>Random</a></p><div class='collapse' id='collapseExample465'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Configure the application to use strongly consistent reads for DynamoDB queries.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 9%;" aria-valuenow="9" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_73><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 73</p><br/>A company Is designing an internet&#8211;facing web application. The application runs on Amazon EC2 for Linux&#8211;based instances that store sensitive user data in Amazon RDS MySQL Multi&#8211;AZ DB instances.<br/><br/>The EC2 instances are in public subnets, and the RDS DB instances are in private subnets. The security team has mandated that the DB instances be secured against web&#8211;based attacks.<br/><br/>What should a solutions architect recommend?<br/><br/>A. Ensure the EC2 instances are part of an Auto Scaling group and are behind an Application Load Balancer. Configure the EC2 instance iptables rules to drop suspicious web traffic. Create a security group for the DB instances. Configure the RDS security group to only allow port 3306 inbound from the individual EC2 instances.<br/>B. Ensure the EC2 instances are part of an Auto Scaling group and are behind an Application Load Balancer. Move DB instances to the same subnets that EC2 instances are located in. Create a security group for the DB instances. Configure the RDS security group to only allow port 3306 inbound from the individual EC2 instances.<br/>C. Ensure the EC2 instances are part of an Auto Scaling group and are behind an Application Load Balancer. Use AWS WAF to monitor inbound web traffic for threats. Create a security group for the web application servers and a security group for the DB instances. Configure the RDS security group to only allow port 3306 inbound from the web application server security group.<br/>D. Ensure the EC2 instances are part of an Auto Scaling group and are behind an Application Load Balancer. Use AWS WAF to monitor inbound web traffic for threats. Configure the Auto Scaling group to automatically create new DB instances under heavy traffic. Create a security group for the RDS DB instances. Configure the RDS security group to only allow port 3306 inbound.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample680' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_74'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_473'>Random</a></p><div class='collapse' id='collapseExample680'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Ensure the EC2 instances are part of an Auto Scaling group and are behind an Application Load Balancer. Use AWS WAF to monitor inbound web traffic for threats. Configure the Auto Scaling group to automatically create new DB instances under heavy traffic. Create a security group for the RDS DB instances. Configure the RDS security group to only allow port 3306 inbound.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 9%;" aria-valuenow="9" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_74><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 74</p><br/>A company has an on&#8211;premises MySQL database used by the global sales team with infrequent access patterns. The sales team requires the database to have minimal downtime. A database administrator wants to migrate this database to AWS without selecting a particular instance type in anticipation of more users in the future.<br/><br/>Which service should a solutions architect recommend?<br/><br/>A. Amazon Aurora MySQL<br/>B. Amazon Aurora Serverless for MySQL<br/>C. Amazon Redshift Spectrum<br/>D. Amazon RDS for MySQL<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample281' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation281' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_75'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_336'>Random</a></p><div class='collapse' id='collapseExample281'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Amazon Aurora Serverless for MySQL</div></div></div><div class='collapse' id='explanation281'><div class='card card&#45;body'><div>
A database administrator wants to migrate this database to AWS without selecting a particular instance type in anticipation of more users in the future" Serverless sounds right, and it's compatible with MySQL and PostgreSQL.

</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 9%;" aria-valuenow="9" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_75><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 75</p><br/>An eCommerce company is creating an application that requires a connection to a third&#8211;party payment service to process payments. The payment service needs to explicitly allow the public IP address of the server that is making the payment request. However, the company's security policies do not allow any server to be exposed directly to the public internet.<br/><br/>Which solution will meet these requirements?<br/><br/>A. Provision an Elastic IP address. Host the application servers on Amazon EC2 instances in a private subnet. Assign the public IP address to the application servers.<br/>B. Create a NAT gateway in a public subnet. Host the application servers on Amazon EC2 instances in a private subnet. Route payment requests through the NAT gateway.<br/>C. Deploy an Application Load Balancer (ALB). Host the application servers on Amazon EC2 instances in a private subnet. Route the payment requests through the ALB.<br/>D. Set up an AWS Client VPN connection to the payment service. Host the application servers on Amazon EC2 instances in a private subnet. Route the payment requests through the VPN.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample428' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_76'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_559'>Random</a></p><div class='collapse' id='collapseExample428'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Create a NAT gateway in a public subnet. Host the application servers on Amazon EC2 instances in a private subnet. Route payment requests through the NAT gateway.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 9%;" aria-valuenow="9" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_76><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 76</p><br/>A company requires a durable backup storage solution for its on&#8211;premises database servers while ensuring on&#8211;premises applications maintain access to these backups for quick recovery. The company will use AWS storage services as the destination for these backups. A solutions architect is designing a solution with minimal operational overhead.<br/><br/>Which solution should the solutions architect implement?<br/><br/>A. Deploy an AWS Storage Gateway file gateway on&#8211;premises and associate it with an Amazon S3 bucket.<br/>B. Back up the databases to an AWS Storage Gateway volume gateway and access it using the Amazon S3 API.<br/>C. Transfer the database backup files to an Amazon Elastic Block Store (Amazon EBS) volume attached to an Amazon EC2 instance.<br/>D. Back up the database directly to an AWS Snowball device and use lifecycle rules to move the data to Amazon S3 Glacier Deep Archive.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample93' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation93' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_77'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_712'>Random</a></p><div class='collapse' id='collapseExample93'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Deploy an AWS Storage Gateway file gateway on-premises and associate it with an Amazon S3 bucket.</div></div></div><div class='collapse' id='explanation93'><div class='card card&#45;body'><div>
Network Load Balancer overview

A Network Load Balancer functions at the fourth layer of the Open Systems Interconnection (OSI) model. It can handle millions of requests per second. After the load balancer receives a connection request, it selects a target from the target group for the default rule. It attempts to open a TCP connection to the selected target on the port specified in the listener configuration.

When you enable an Availability Zone for the load balancer, Elastic Load Balancing creates a load balancer node in the Availability Zone. By default, each load balancer node distributes traffic across the registered targets in its Availability Zone only. If you enable cross-zone load balancing, each load balancer node distributes traffic across the registered targets in all enabled Availability Zones. For more information, see Availability Zones.

If you enable multiple Availability Zones for your load balancer and ensure that each target group has at least one target in each enabled Availability Zone, this increases the fault tolerance of your applications. For example, if one or more target groups does not have a healthy target in an Availability Zone, we remove the IP address for the corresponding subnet from DNS, but the load balancer nodes in the other Availability Zones are still available to route traffic. If a client doesn't honor the time-to-live (TTL) and sends requests to the IP address after it is removed from DNS, the requests fail.

For TCP traffic, the load balancer selects a target using a flow hash algorithm based on the protocol, source IP address, source port, destination IP address, destination port, and TCP sequence number. The TCP connections from a client have different source ports and sequence numbers, and can be routed to different targets. Each individual TCP connection is routed to a single target for the life of the connection.

For UDP traffic, the load balancer selects a target using a flow hash algorithm based on the protocol, source IP address, source port, destination IP address, and destination port. A UDP flow has the same source and destination, so it is consistently routed to a single target throughout its lifetime. Different UDP flows have different source IP addresses and ports, so they can be routed to different targets.

An Auto Scaling group contains a collection of Amazon EC2 instances that are treated as a logical grouping for the purposes of automatic scaling and management. An Auto Scaling group also enables you to use Amazon EC2 Auto Scaling features such as health check replacements and scaling policies. Both maintaining the number of instances in an Auto Scaling group and automatic scaling are the core functionality of the Amazon EC2 Auto Scaling service.

The size of an Auto Scaling group depends on the number of instances that you set as the desired capacity. You can adjust its size to meet demand, either manually or by using automatic scaling.

An Auto Scaling group starts by launching enough instances to meet its desired capacity. It maintains this number of instances by performing periodic health checks on the instances in the group. The Auto Scaling group continues to maintain a fixed number of instances even if an instance becomes unhealthy. If an instance becomes unhealthy, the group terminates the unhealthy instance and launches another instance to replace it.
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 9%;" aria-valuenow="9" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_77><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 77</p><br/>A company sells datasets to customers who do research in artificial intelligence and machine learning (AIMU).<br/><br/>The datasets are large formatted files met are stored in an Amazon S3 bucket in the us&#8211;east&#8211;1 Region.<br/><br/>The company hosts a web application that the customers use o purchase access to a given dataset.<br/><br/>The web application Is deployed on mutate Amazon EC2 instances behind an Application Load Balancer.<br/><br/>After a purchase is made customers receive an S3 signed URL that allows access to the files. The customers are distributed across North America and Europe.<br/><br/>The company wants to reduce the cost that is associated with data transfers and wants to maintain or improve performance.<br/><br/>What should a solutions architect do to meet these requirements?<br/><br/>A. Configure S3 Transfer Accelerator on the ex sting S3 bucket. Direct customer requests to the S3 Transfer Acceleration endpoint Continue to use S3 signed URLs to access control<br/>B. Deploy an Amazon CloudFront distribution with the existing S3 bucket as the origin Direct customer requests to the CloudFront URL. Switch to CloudFront signed URLs for access control<br/>C. Set up a second S3 Ducket in the eu&#8211;central&#8211;1 Region with S3 Cross&#8211;Region Replication between lite Duckets. Direct customer requests to the closest Region. Continue to use S3 signed URLs for access control<br/>D. Modify the web application to enable streaming of the datasets to and users. Configure the web application to read the data from the existing S3 bucket implement access control directly in the application<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample597' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_78'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_318'>Random</a></p><div class='collapse' id='collapseExample597'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Configure S3 Transfer Accelerator on the ex sting S3 bucket. Direct customer requests to the S3 Transfer Acceleration endpoint Continue to use S3 signed URLs for access control</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 9%;" aria-valuenow="9" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_78><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 78</p><br/>A company needs to store data in Amazon S3 A compliance requirement states that when any changes are made to objects the previous state of the object with any changes must be preserved Additionally files older than 5 years should not be accessed but need to be archived for auditing<br/><br/>What should a solutions architect recommend that is MOST cost&#8211;effective?<br/><br/>A. Enable object&#8211;level versioning and S3 Object Lock in governance mode<br/>B. Enable object&#8211;level versioning and S3 Object Lock in compliance mode<br/>C. Enable object&#8211;level versioning Enable a lifecycle policy to move data older than 5 years to S3 Glacier Deep Archive<br/>D. Enable object&#8211;level versioning Enable a lifecycle policy to move data older than 5 years to S3 Standard&#8211;Infrequent Access (S3 Standard&#8211;IA)<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample499' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_79'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_266'>Random</a></p><div class='collapse' id='collapseExample499'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Enable object-level versioning Enable a lifecycle policy to move data older than 5 years to S3 Glacier Deep Archive</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 9%;" aria-valuenow="9" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_79><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 79</p><br/>An organization has three separate AWS accounts, one each for development, testing, and production. The organization wants the testing team to have access to certain AWS resources in the production account. How can the organization achieve this?<br/><br/>A. It is not possible to access resources of one account with another account.<br/>B. Create the IAM roles with cross account access.<br/>C. Create the IAM user in a test account, and allow it access to the production environment with the IAM policy.<br/>D. Create the IAM users with cross account access.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample760' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation760' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_80'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_43'>Random</a></p><div class='collapse' id='collapseExample760'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Create the IAM roles with cross account access.</div></div></div><div class='collapse' id='explanation760'><div class='card card&#45;body'><div>
An organization has multiple AWS accounts to isolate a development environment from a testing or production environment. At times the users from one account need to access resources in the other account, such as promoting an update from the development environment to the production environment. In this case the IAM role with cross account access will provide a solution. Cross account access lets one account share access to their resources with users in the other AWS accounts.

References:

AWS Security Best Practices</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 10%;" aria-valuenow="10" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_80><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 80</p><br/>A company needs to use its on&#8211;premises LDAP directory service to authenticate its users to the AWS Management Console.<br/><br/>The directory service is not compatible with Security Assertion Markup Language (SAML).<br/><br/>Which solution meets these requirements?<br/><br/>A. Enable AWS Single Sign&#8211;On between AWS and the on&#8211;premises LDAP<br/>B. Create an 1AM policy mat uses AWS credentials and integrate the policy into LDAP<br/>C. Set up a process that rotates the IAM credentials whenever LDAP credentials are updated.<br/>D. Develop an on&#8211;premises custom identity broker application of process mat uses AWS Security Token Service (AWS STS) to get short&#8211;lived credentials<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample566' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_81'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_321'>Random</a></p><div class='collapse' id='collapseExample566'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Enable AWS Single Sign-On between AWS and the on-premises LDAP</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 10%;" aria-valuenow="10" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_81><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 81</p><br/>A company is developing a real&#8211;time multiplier game that uses UDP for communications between client and servers in an Auto Scaling group. Spikes in demand are anticipated during the day, so the game server platform must adapt accordingly. Developers want to store gamer scores and other non&#8211;relational data in a database solution that will scale without intervention.<br/><br/>Which solution should a solutions architect recommend?<br/><br/>A. Use Amazon Route 53 for traffic distribution and Amazon Aurora Serverless for data storage.<br/>B. Use a Network Load Balancer for traffic distribution and Amazon DynamoDB on&#8211;demand for data storage.<br/>C. Use a Network Load Balancer for traffic distribution and Amazon Aurora Global Database for data storage.<br/>D. Use an Application Load Balancer for traffic distribution and Amazon DynamoDB global tables for data storage.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample210' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_82'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_658'>Random</a></p><div class='collapse' id='collapseExample210'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Use a Network Load Balancer for traffic distribution and Amazon DynamoDB on-demand for data storage.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 10%;" aria-valuenow="10" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_82><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 82</p><br/>A company has been storing analytics data in an Amazon RDS instance for the past few years. The company asked a solutions architect to find a solution that allows users to access this data using an API.<br/><br/>The expectation is that the application will experience periods of inactivity but could receive bursts of traffic within seconds.<br/><br/>Which solution should the solution architect suggest?<br/><br/>A. Set up an Amazon API Gateway and use Amazon ECS.<br/>B. Set up an Amazon API Gateway and use AWS Elastic Beanstalk.<br/>C. Set up an Amazon API Gateway and use AWS Lambda functions.<br/>D. Set up an Amazon API Gateway and use Amazon EC2 with Auto Scaling.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample17' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation17' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_83'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_446'>Random</a></p><div class='collapse' id='collapseExample17'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Set up an Amazon API Gateway and use AWS Lambda functions.</div></div></div><div class='collapse' id='explanation17'><div class='card card&#45;body'><div>
AWS Lambda: With Lambda, you can run code for virtually any type of application or backend service – all with zero administration. Just upload your code and Lambda takes care of everything required to run and scale your code with high availability. You can set up your code to automatically trigger from other AWS services or call it directly from any web or mobile app.

How it works

Amazon API Gateway: Amazon API Gateway is a fully managed service that makes it easy for developers to create, publish, maintain, monitor, and secure APIs at any scale. APIs act as the "front door" for applications to access data, business logic, or functionality from your backend services. Using API Gateway, you can create RESTful APIs and WebSocket APIs that enable real-time two-way communication applications. API Gateway supports containerized and serverless workloads, as well as web applications.

API Gateway handles all the tasks involved in accepting and processing up to hundreds of thousands of concurrent API calls, including traffic management, CORS support, authorization and access control, throttling, monitoring, and API version management. API Gateway has no minimum fees or startup costs.

You pay for the API calls you receive and the amount of data transferred out and, with the API Gateway tiered pricing model, you can reduce your cost as your API usage scales.

This question is simply asking you to work out the best compute service for the stated requirements. The key requirements are that the compute service should be suitable for a workload that can range quite broadly in demand from no requests to large bursts of traffic. AWS Lambda is an ideal solution as you pay only when requests are made and it can easily scale to accommodate the large bursts in traffic. Lambda works well with both API Gateway and Amazon RDS.

CORRECT: "Set up an Amazon API Gateway and use AWS Lambda functions" is the correct answer.

INCORRECT: "Set up an Amazon API Gateway and use Amazon ECS" is incorrect as Lambda is a better fit for this use case as the traffic patterns are highly dynamic.

INCORRECT: "Set up an Amazon API Gateway and use AWS Elastic Beanstalk" is incorrect as Lambda is a better fit for this use case as the traffic patterns are highly dynamic.

INCORRECT: "Set up an Amazon API Gateway and use Amazon EC2 with Auto Scaling" is incorrect as Lambda is a better fit for this use case as the traffic patterns are highly dynamic.

References:

AWS Lambda > Developer Guide > Lambda function scaling
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 10%;" aria-valuenow="10" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_83><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 83</p><br/>A company has developed a database in Amazon RDS for MySQL.<br/><br/>Due to increased support team is reporting slow reads against the DB instance and recommends adding a read replica.<br/><br/>Which combination of actions should a solutions architect take before implementing this change? (Select TWO.)<br/><br/>A. Enable binlog replication on the RDS master.<br/>B. Choose a failover priority for the source DB instance.<br/>C. Allow long&#8211;running transactions to complete on the source DB instance.<br/>D. Create a global table and specify the AWS Regions where the table will be available.<br/>E. Enable automatic backups on the source instance by settings the backup retention period to a value other than 0.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample605' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_84'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_130'>Random</a></p><div class='collapse' id='collapseExample605'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Allow long-running transactions to complete on the source DB instance.
<br><b>E. </b>Enable automatic backups on the source instance by settings the backup retention period to a value other than 0.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 10%;" aria-valuenow="10" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_84><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 84</p><br/>A company has media and application files that need to be shared internally. Users currently are authenticated using Active Directory and access files from a Microsoft Windows platform. The chief executive officer wants to keep the same user permissions, but wants the company to improve the process as the company is reaching its storage capacity limit.<br/><br/>What should a solutions architect recommend?<br/><br/>A. Set up a corporate Amazon S3 bucket and move all media and application files.<br/>B. Configure Amazon FSx for Windows File Server and move all the media and application files.<br/>C. Configure Amazon Elastic File System (Amazon EFS) and move all media and application files.<br/>D. Set up Amazon EC2 on Windows, attach multiple Amazon Elastic Block Store (Amazon EBS) volumes, and move all media and application files.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample275' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_85'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_354'>Random</a></p><div class='collapse' id='collapseExample275'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Configure Amazon FSx for Windows File Server and move all the media and application files.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 10%;" aria-valuenow="10" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_85><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 85</p><br/>A company wants to migrate its web application to AWS. The legacy web application consists of a web tier, an application tier, and a MySQL database. The re&#8211;architected application must consist of technologies that do not require the administration team to manage instances or clusters.<br/><br/>Which combination of services should a solutions architect include in the overall architecture? (Choose two.)<br/><br/>A. Amazon Aurora Serverless<br/>B. Amazon EC2 Spot Instances<br/>C. Amazon Elasticsearch Service (Amazon ES)<br/>D. Amazon RDS for MySQL<br/>E. AWS Fargate<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample304' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_86'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_356'>Random</a></p><div class='collapse' id='collapseExample304'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Amazon RDS for MySQL
<br><b>E. </b>AWS Fargate</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 10%;" aria-valuenow="10" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_86><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 86</p><br/>A company currently stores symmetric encryption keys in a hardware security module (HSM). A solutions architect must design a solution to migrate key management to AWS. The solution should allow for key rotation and support the use of customer provided keys.<br/><br/>Where should the key material be stored to meet these requirements?<br/><br/>A. Amazon S3<br/>B. AWS Secrets Manager<br/>C. AWS Systems Manager Parameter store<br/>D. AWS Key Management Service (AWS KMS)<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample197' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation197' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_87'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_648'>Random</a></p><div class='collapse' id='collapseExample197'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>AWS Secrets Manager</div></div></div><div class='collapse' id='explanation197'><div class='card card&#45;body'><div>
AWS Secrets Manager helps you protect secrets needed to access your applications, services, and IT resources. The service enables you to easily rotate, manage, and retrieve database credentials, API keys, and other secrets throughout their lifecycle.

References:

AWS Secrets Manager</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 10%;" aria-valuenow="10" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_87><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 87</p><br/>A solutions architect is designing a mission&#8211;critical web application. It will consist of Amazon EC2 instances behind an Application Load Balancer and a relational database. The database should be highly available and fault tolerant.<br/><br/>Which database implementations will meet these requirements? (Choose two.)<br/><br/>A. Amazon Redshift<br/>B. Amazon DynamoDB<br/>C. Amazon RDS for MySQL<br/>D. MySQL&#8211;compatible Amazon Aurora Multi&#8211;AZ<br/>E. Amazon RDS for SQL Server Standard Edition Multi&#8211;AZ<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample56' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_88'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_308'>Random</a></p><div class='collapse' id='collapseExample56'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>MySQL-compatible Amazon Aurora Multi-AZ
<br><b>E. </b>Amazon RDS for SQL Server Standard Edition Multi-AZ</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 11%;" aria-valuenow="11" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_88><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 88</p><br/>You are looking at ways to improve some existing infrastructure as it seems a lot of engineering resources are being taken up with basic management and monitoring tasks and the costs seem to be excessive. You are thinking of deploying Amazon ElasticCache to help.<br/><br/>Which of the following statements is true in regards to ElasticCache?<br/><br/>A. You can improve load and response times to user actions and queries however the cost associated with scaling web applications will be more.<br/>B. You can't improve load and response times to user actions and queries but you can reduce the cost associated with scaling web applications.<br/>C. You can improve load and response times to user actions and queries however the cost associated with scaling web applications will remain the same.<br/>D. You can improve load and response times to user actions and queries and also reduce the cost associated with scaling web applications.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample768' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation768' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_89'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_278'>Random</a></p><div class='collapse' id='collapseExample768'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>You can improve load and response times to user actions and queries and also reduce the cost associated with scaling web applications.</div></div></div><div class='collapse' id='explanation768'><div class='card card&#45;body'><div>
Amazon ElastiCache is a web service that makes it easy to deploy and run Memcached or Redis protocol-compliant server nodes in the cloud. Amazon ElastiCache improves the performance of web applications by allowing you to retrieve information from a fast, managed, in-memory caching system, instead of relying entirely on slower disk-based databases. The service simplifies and offloads the management, monitoring and operation of in-memory cache environments, enabling your engineering resources to focus on developing applications. Using Amazon ElastiCache, you can not only improve load and response times to user actions and queries, but also reduce the cost associated with scaling web applications.

References:

Amazon ElastiCache FAQs</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 11%;" aria-valuenow="11" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_89><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 89</p><br/>A solutions architect needs to ensure that API calls to Amazon DynamoDB from Amazon EC2 instances in a VPC do not traverse the internet.<br/><br/>What should the solutions architect do to accomplish this? (Choose two.)<br/><br/>A. Create a route table entry for the endpoint.<br/>B. Create a gateway endpoint for DynamoDB.<br/>C. Create a new DynamoDB table that uses the endpoint.<br/>D. Create an ENI for the endpoint in each of the subnets of the VPC.<br/>E. Create a security group entry in the default security group to provide access.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample16' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation16' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_90'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_691'>Random</a></p><div class='collapse' id='collapseExample16'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Create a route table entry for the endpoint.
<br><b>B. </b>Create a gateway endpoint for DynamoDB.</div></div></div><div class='collapse' id='explanation16'><div class='card card&#45;body'><div>
A VPC endpoint enables you to privately connect your VPC to supported AWS services and VPC endpoint services powered by AWS PrivateLink without requiring an internet gateway, NAT device, VPN connection, or AWS Direct Connect connection.

Instances in your VPC do not require public IP addresses to communicate with resources in the service. Traffic between your VPC and the other service does not leave the Amazon network.

Gateway endpoints: A gateway endpoint is a gateway that you specify as a target for a route in your route table for traffic destined to a supported AWS service. The following AWS services are supported:
Amazon S3
DynamoDB

Amazon DynamoDB and Amazon S3 support gateway endpoints, not interface endpoints. With a gateway endpoint you create the endpoint in the VPC, attach a policy allowing access to the service, and then specify the route table to create a route table entry in.

CORRECT: "Create a route table entry for the endpoint" is a correct answer. CORRECT: "Create a gateway endpoint for DynamoDB" is also a correct answer.

INCORRECT: "Create a new DynamoDB table that uses the endpoint" is incorrect as it is not necessary to create a new DynamoDB table.

INCORRECT: "Create an ENI for the endpoint in each of the subnets of the VPC" is incorrect as an ENI is used by an interface endpoint, not a gateway endpoint.

INCORRECT: "Create a VPC peering connection between the VPC and DynamoDB" is incorrect as you cannot create a VPC peering connection between a VPC and a public AWS service as public services are outside of VPCs.

References:

Amazon Virtual Private Cloud > AWS PrivateLink > Gateway VPC endpoints</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 11%;" aria-valuenow="11" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_90><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 90</p><br/>A solutions architect is designing an application for a two&#8211;step order process. The first step is synchronous and must return to the user with little latency. The second step takes longer, so it will be implemented in a separate component. Orders must be processed exactly once and in the order in which they are received.<br/><br/>How should the solutions architect integrate these components?<br/><br/>A. Use Amazon SQS FIFO queues.<br/>B. Use an AWS Lambda function along with Amazon SQS standard queues.<br/>C. Create an SNS topic and subscribe an Amazon SQS FIFO queue to that topic.<br/>D. Create an SNS topic and subscribe an Amazon SQS Standard queue to that topic.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample372' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation372' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_91'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_344'>Random</a></p><div class='collapse' id='collapseExample372'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Use Amazon SQS FIFO queues.</div></div></div><div class='collapse' id='explanation372'><div class='card card&#45;body'><div>
"Standard queues provide at-least-once delivery, which means that each message is delivered at least once.

FIFO queues provide exactly-once processing, which means that each message is delivered once and remains available until a consumer processes it and deletes it. Duplicates are not introduced into the queue."

References:

Amazon Simple Queue Service > Developer Guide > What is Amazon Simple Queue Service?</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 11%;" aria-valuenow="11" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_91><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 91</p><br/>A company that recently started using AWS establishes a Site&#8211;to&#8211;Site VPN between its on&#8211;premises datacenter and AWS. The company's security mandate states that traffic originating from on&#8211;premises should stay within the company's private IP space when communicating with an Amazon Elastic Container Service (Amazon ECS) cluster that is hosting a sample web application.<br/><br/>Which solution meets this requirement?<br/><br/>A. Configure a gateway endpoint for Amazon ECS. Modify the route table to include an entry pointing to the ECS cluster.<br/>B. Create a Network Load Balancer and AWS PrivateLink endpoint for Amazon ECS in the same VPC that is hosting the ECS cluster.<br/>C. Create a Network Load Balancer in one VPC and an AWS PrivateLink endpoint for Amazon ECS in another VPC. Connect the two VPCs by using VPC peering.<br/>D. Configure an Amazon Route 53 record with Amazon ECS as the target. Apply a server certificate to Route 53 from AWS Certificate Manager (ACM) for SSL offloading.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample394' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_92'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_406'>Random</a></p><div class='collapse' id='collapseExample394'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Create a Network Load Balancer in one VPC and an AWS PrivateLink endpoint for Amazon ECS in another VP<b>C. </b>Connect the two VPCs by using VPC peering.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 11%;" aria-valuenow="11" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_92><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 92</p><br/>A company has a 10 Gbps AWS Direct Connect connection from its on&#8211;premises servers to AWS. The workloads using the connection are critical. The company requires a disaster recovery strategy with maximum resiliency that maintains the current connection bandwidth at a minimum.<br/><br/>What should a solutions architect recommend?<br/><br/>A. Set up a new Direct Connect connection in another AWS Region.<br/>B. Set up a new AWS managed VPN connection in another AWS Region.<br/>C. Set up two new Direct Connect connections: one in the current AWS Region and one in another Region.<br/>D. Set up two new AWS managed VPN connections: one in the current AWS Region and one in another Region.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample132' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_93'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_276'>Random</a></p><div class='collapse' id='collapseExample132'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Set up two new Direct Connect connections: one in the current AWS Region and one in another Region.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 11%;" aria-valuenow="11" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_93><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 93</p><br/>A company wants to move its on&#8211;premises network, attached storage (NAS) to AWS. The company wants to make the data available to any Linux instances within its VPC and ensure changes are automatically synchronized across all instances accessing the data store. The majority of the data is accessed very rarely, and some files are accessed by multiple users at the same time.<br/>Which solution meets these requirements and is MOST cost&#8211;effective?<br/><br/>A. Create an Amazon Elastic Block Store (Amazon EBS) snapshot containing the data. Share it with users within the VPC.<br/>B. Create an Amazon S3 bucket that has a lifecycle policy set to transition the data to S3 Standard Infrequent Access (S3 Standard&#8211;IA) after the appropriate number of days.<br/>C. Create an Amazon Elastic File System (Amazon EFS) file system within the VPC. Set the throughput mode to Provisioned and to the required amount of IOPS to support concurrent usage.<br/>D. Create an Amazon Elastic File System (Amazon EFS) file system within the VPC. Set the lifecycle policy to transition the data to EFS Infrequent Access (EFS IA) after the appropriate number of days.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample393' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_94'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_48'>Random</a></p><div class='collapse' id='collapseExample393'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Create an Amazon Elastic File System (Amazon EFS) file system within the VP<br><b>C. </b>Set the lifecycle policy to transition the data to EFS Infrequent Access (EFS IA) after the appropriate number of days.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 11%;" aria-valuenow="11" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_94><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 94</p><br/>A company runs an online media site, hosted on&#8211;premises. An employee posted a product review that contained videos and pictures. The review went viral and the company needs to handle the resulting spike in website traffic.<br/><br/>What action would provide an immediate solution?<br/><br/>A. Redesign the website to use Amazon API Gateway, and use AWS Lambda to deliver content<br/>B. Add server instances using Amazon EC2 and use Amazon Route 53 with a failover routing policy<br/>C. Serve the images and videos using an Amazon CloudFront distribution created using the news site as the origin<br/>D. Use Amazon ElasbCache for Redis for caching and reducing the load requests from the origin<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample544' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_95'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_397'>Random</a></p><div class='collapse' id='collapseExample544'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Serve the images and videos using an Amazon CloudFront distribution created using the news site as the origin</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 11%;" aria-valuenow="11" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_95><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 95</p><br/>A company's website hosted on Amazon EC2 instances processes classified data stored in Amazon S3. Due to security concerns, the company requires a private and secure connection between its EC2 resources and Amazon S3.<br/><br/>Which solution meets these requirements?<br/><br/>A. Set up S3 bucket policies to allow access from a VPC endpoint.<br/>B. Set up an IAM policy to grant read&#8211;write access to the S3 bucket.<br/>C. Set up a NAT gateway to access resources outside the private subnet.<br/>D. Set up an access key ID and a secret access key to access the S3 bucket.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample678' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_96'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_127'>Random</a></p><div class='collapse' id='collapseExample678'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Set up S3 bucket policies to allow access from a VPC endpoint.

References:

Amazon Simple Storage Service > User Guide > Controlling access from VPC endpoints with bucket policies</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 12%;" aria-valuenow="12" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_96><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 96</p><br/>A marketing company is storing CSV files in an Amazon S3 bucket for statistical analysis. An application on an Amazon EC2 instance needs permission to efficiently process the CSV data stored in the S3 bucket.<br/><br/>Which action will MOST securely grant the EC2 instance access to the S3 bucket?<br/><br/>A. Attach a resource&#8211;based policy to the S3 bucket.<br/>B. Create an IAM user for the application with specific permissions to the S3 bucket.<br/>C. Associate an IAM role with least privilege permissions to the EC2 instance profile.<br/>D. Store AWS credentials directly on the EC2 instance for applications on the instance to use for API calls.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample153' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation153' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_97'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_553'>Random</a></p><div class='collapse' id='collapseExample153'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Associate an IAM role with least privilege permissions to the EC2 instance profile.</div></div></div><div class='collapse' id='explanation153'><div class='card card&#45;body'><div>
Keyword: Privilege Permission + IAM Role

AWS Identity and Access Management (IAM) enables you to manage access to AWS services and resources securely. Using IAM, you can create and manage AWS users and groups, and use permissions to allow and deny their access to AWS resources.

IAM is a feature of your AWS account offered at no additional charge. You will be charged only for use of other AWS services by your users.

IAM roles for Amazon EC2
Applications must sign their API requests with AWS credentials. Therefore, if you are an application developer, you need a strategy for managing credentials for your applications that run on EC2 instances. For example, you can securely distribute your AWS credentials to the instances, enabling the applications on those instances to use your credentials to sign requests, while protecting your credentials from other users. However, it's challenging to securely distribute credentials to each instance, especially those that AWS creates on your behalf, such as Spot Instances or instances in Auto Scaling groups. You must also be able to update the credentials on each instance when you rotate your AWS credentials.

We designed IAM roles so that your applications can securely make API requests from your instances, without requiring you to manage the security credentials that the applications use.

Instead of creating and distributing your AWS credentials, you can delegate permission to make API requests using IAM roles as follows:

Create an IAM role.

Define which accounts or AWS services can assume the role.

Define which API actions and resources the application can use after assuming the role. Specify the role when you launch your instance, or attach the role to an existing instance. Have the application retrieve a set of temporary credentials and use them.

For example, you can use IAM roles to grant permissions to applications running on your instances that need to use a bucket in Amazon S3. You can specify permissions for IAM roles by creating a policy in JSON format. These are similar to the policies that you create for IAM users. If you change a role, the change is propagated to all instances.

When creating IAM roles, associate least privilege IAM policies that restrict access to the specific API calls the application requires.

References:

AWS Identity and Access Management (IAM) FAQs
Amazon Elastic Compute Cloud > User Guide for Linux Instances > IAM roles for Amazon EC2

</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 12%;" aria-valuenow="12" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_97><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 97</p><br/>A company is hosting its website by using Amazon EC2 instance behind an Elastic Load Balancer across multiple Availability Zones.<br/><br/>The instance run in an EC2 Auto Scaling group.<br/><br/>The website uses Amazon Elastic Block Store (Amazon EBS) volumes to store product manuals for users to download.<br/><br/>The company updates the product content often, so new instance launched by the Auto Scaling group often have old data.<br/><br/>It can take up to 30 minutes for the new instances to receive all the updates.<br/><br/>The updates also requires the EBS volumes to be resized during business hours.<br/><br/>The company wants to ensure that the product manuals are always up to date on all that the architecture adjusts quickly to increased user demand.<br/><br/>A solutions architect needs to meet these requirements without causing the company to update its application code or adjust its website.<br/><br/>What should the solution architect do to accomplish this goal?<br/><br/>A. Store the product manuals in an EBS volume. Mount that volume to the EC2 instances.<br/>B. Store the product manuals in an Amazon S3 bucket. Redirect the downloads to this bucket.<br/>C. Store the product manual in an Amazon Elastic File System (Amazon EFS) volume. Mount that volume to the EC2 instances.<br/>D. Store the product manual in an Amazon S3 Standard&#8211;infrequent Access (S3 Standard&#8211;IA) bucket. Redirect the downloads to this bucket.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample617' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_98'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_290'>Random</a></p><div class='collapse' id='collapseExample617'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Store the product manual in an Amazon S3 Standard-infrequent Access (S3 Standard-IA) bucket. Redirect the downloads to this bucket.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 12%;" aria-valuenow="12" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_98><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 98</p><br/>Your manager has just given you access to multiple VPN connections that someone else has recently set up between all your company's offices. She needs you to make sure that the communication between the VPNs is secure.<br/><br/>Which of the following services would be best for providing a low&#8211;cost hub&#8211;and&#8211;spoke model for primary or backup connectivity between these remote offices?<br/><br/>A. Amazon CloudFront<br/>B. AWS Direct Connect<br/>C. AWS CloudHSM<br/>D. AWS VPN CloudHub<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample764' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation764' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_99'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_607'>Random</a></p><div class='collapse' id='collapseExample764'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>AWS VPN CloudHub</div></div></div><div class='collapse' id='explanation764'><div class='card card&#45;body'><div>
If you have multiple VPN connections, you can provide secure communication between sites using the AWS VPN CloudHub. The VPN CloudHub operates on a simple hub-and-spoke model that you can use with or without a VPC. This design is suitable for customers with multiple branch offices and existing Internet connections who would like to implement a convenient, potentially low-cost hub-and-spoke model for primary or backup connectivity between these remote offices.

References:

AWS Site-to-Site VPN > User Guide > Providing secure communication between sites using VPN CloudHub</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 12%;" aria-valuenow="12" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_99><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 99</p><br/>A company allows its developers to attach existing IAM policies to existing IAM roles to enable faster experimentation and agility. However, the security operations team is concerned that the developers could attach the existing administrator policy, which would allow the developers to circumvent any other security policies.<br/><br/>How should a solutions architect address this issue?<br/><br/>A. Create an Amazon SNS topic to send an alert every time a developer creates a new policy.<br/>B. Use service control policies to disable IAM activity across all account in the organizational unit.<br/>C. Prevent the developers from attaching any policies and assign all IAM duties to the security operations team.<br/>D. Set an IAM permissions boundary on the developer IAM role that explicitly denies attaching the administrator policy.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample35' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation35' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_100'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_568'>Random</a></p><div class='collapse' id='collapseExample35'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Set an IAM permissions boundary on the developer IAM role that explicitly denies attaching the administrator policy.</div></div></div><div class='collapse' id='explanation35'><div class='card card&#45;body'><div>
The permissions boundary for an IAM entity (user or role) sets the maximum permissions that the entity can have. This can change the effective permissions for that user or role. The effective permissions for an entity are the permissions that are granted by all the policies that affect the user or role. Within an account, the permissions for an entity can be affected by identity-based policies, resource-based policies, permissions boundaries, Organizations SCPs, or session policies.

Therefore, the solutions architect can set an IAM permissions boundary on the developer IAM role that explicitly denies attaching the administrator policy.

CORRECT: "Set an IAM permissions boundary on the developer IAM role that explicitly denies attaching the administrator policy" is the correct answer.

INCORRECT: "Create an Amazon SNS topic to send an alert every time a developer creates a new policy" is incorrect as this would mean investigating every incident which is not an efficient solution.

INCORRECT: "Use service control policies to disable IAM activity across all accounts in the organizational unit" is incorrect as this would prevent the developers from being able to work with IAM completely.

INCORRECT: "Prevent the developers from attaching any policies and assign all IAM duties to the security operations team" is incorrect as this is not necessary. The requirement is to allow developers to work with policies, the solution needs to find a secure way of achieving this.

References:
AWS Identity and Access Management > User Guide > Permissions boundaries for IAM entities
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 12%;" aria-valuenow="12" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_100><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 100</p><br/>A solutions architect is designing an architecture for a new application that requires low network latency and high network throughput between Amazon EC2 instances. Which component should be included in the architectural design?<br/><br/>A. An Auto Scaling group with Spot Instance types.<br/>B. A placement group using a cluster placement strategy.<br/>C. A placement group using a partition placement strategy.<br/>D. An Auto Scaling group with On&#8211;Demand instance types.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample80' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_101'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_741'>Random</a></p><div class='collapse' id='collapseExample80'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>A placement group using a cluster placement strategy.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 12%;" aria-valuenow="12" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_101><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 101</p><br/>A company wants to build an online marketplace application on AWS as a set of loosely coupled microservices. For this application, when a customer submits a new order, two microservices should handle the event simultaneously. The Email microservice will send a confirmation email, and the order processing microservice will start the order delivery process. If a customer cancels an order, the OrderCancelation and Email microservices should handle the event simultaneously.<br/><br/>A solutions architect wants to use Amazon Simple Queue Service (Amazon SQS) and Amazon Simple<br/><br/>Notification Service (Amazon SNS) to design the messaging between the microservices.<br/><br/>How should the solutions architect design the solution?<br/><br/>A. Create a single SQS queue and publish order events to it. The Email OrderProcessing and Order Cancellation microservices can then consume messages of the queue.<br/>B. Create three SNS topics for each microservice. Publish order events to the three topics. Subscribe each of the Email OrderProcessing and Order Cancellation microservices to its own topic.<br/>C. Create an SNS topic and publish order events to it. Create three SQS queues for the Email OrderProcessing and Order Cancellation microservices. Subscribe all SQS queues to the SNS topic with message filtering.<br/>D. Create two SQS queues and publish order events to both queues simultaneously. One queue is for the Email and OrderProcessing microservices. The second queue is for the Email and Order Cancellation microservices.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample300' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_102'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_244'>Random</a></p><div class='collapse' id='collapseExample300'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Create two SQS queues and publish order events to both queues simultaneously. One queue is for the Email and OrderProcessing microservices. The second queue is for the Email and Order Cancellation microservices.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 12%;" aria-valuenow="12" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_102><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 102</p><br/>A company has an application running as a service in Amazon Elastic Container Service (Amazon EC2) using the Amazon launch type.<br/><br/>The application code makes AWS API calls to publish messages to Amazon Simple Queue Service (Amazon SQS).<br/><br/>What is the MOST secure method of giving the application permission to publish messages to Amazon SQS?<br/><br/>A. Use AWS Identity and Access Management (IAM) to grant SQS permissions to the role used by the launch configuration for the Auto Scaling group of the ECS cluster.<br/>B. Create a new IAM user with SQS permissions. The update the task definition to declare the access key ID and secret access key as environment variables.<br/>C. Create a new IAM role with SQS permissions. The update the task definition to use this role for the task role setting.<br/>D. Update the security group used by the ECS cluster to allow access to Amazon SQS<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample536' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_103'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_366'>Random</a></p><div class='collapse' id='collapseExample536'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Create a new IAM user with SQS permissions. The update the task definition to declare the access key ID and secret access key as environment variables.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 12%;" aria-valuenow="12" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_103><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 103</p><br/>A company uses on&#8211;premises servers to host its applications. The company is running out of storage capacity. The applications use both block storage and NFS storage. The company needs a high&#8211;performing solution that supports local caching without re&#8211;architecting its existing applications.<br/><br/>Which combination of actions should a solutions architect take to meet these requirements? (Choose two.)<br/><br/>A. Mount Amazon S3 as a file system to the on&#8211;premises servers.<br/>B. Deploy an AWS Storage Gateway file gateway to replace NFS storage.<br/>C. Deploy AWS Snowball Edge to provision NFS mounts to on&#8211;premises servers.<br/>D. Deploy an AWS Storage Gateway volume gateway to replace the block storage.<br/>E. Deploy Amazon Elastic Fife System (Amazon EFS) volumes and mount them to on&#8211;premises servers.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample313' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_104'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_681'>Random</a></p><div class='collapse' id='collapseExample313'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Deploy an AWS Storage Gateway volume gateway to replace the block storage.
<br><b>E. </b>Deploy Amazon Elastic Fife System (Amazon EFS) volumes and mount them to on-premises servers.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 13%;" aria-valuenow="13" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_104><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 104</p><br/>A company runs its production workload on an Amazon Aurora MySQL DB cluster that includes six Aurora Replicas. The company wants near&#8211;real&#8211;time reporting queries from one of its departments to be automatically distributed across three of the Aurora Replicas. Those three replicas have a different compute and memory specification from the rest of the DB cluster.<br/>Which solution meets these requirements?<br/><br/>A. Create and use a custom endpoint for the workload.<br/>B. Create a three&#8211;node cluster clone and use the reader endpoint.<br/>C. Use any of the instance endpoints for the selected three nodes.<br/>D. Use the reader endpoint to automatically distribute the read&#8211;only workload.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample392' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_105'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_467'>Random</a></p><div class='collapse' id='collapseExample392'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Create a three-node cluster clone and use the reader endpoint.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 13%;" aria-valuenow="13" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_105><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 105</p><br/>A company hosts its website on Amazon S3. The website serves petabytes of outbound traffic monthly, which accounts for most of the company's AWS costs. What should a solutions architect do to reduce costs?<br/><br/>A. Configure Amazon CloudFront with the existing website as the origin.<br/>B. Move the website to Amazon EC2 with Amazon EBS volumes for storage.<br/>C. Use AWS Global Accelerator and specify the existing website as the endpoint.<br/>D. Rearchitect the website to run on a combination of Amazon API Gateway and AWS Lambda.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample201' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation201' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_106'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_341'>Random</a></p><div class='collapse' id='collapseExample201'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Configure Amazon CloudFront with the existing website as the origin.</div></div></div><div class='collapse' id='explanation201'><div class='card card&#45;body'><div>
A textbook case for CloudFront. The data transfer cost in CloudFront is lower than in S3. With heavy read operations of static content, it's more economical to add CloudFront in front of your S3 bucket.
https://pupuweb.com/aws-saa-c02-actual-exam-question-answer-dumps-2/10/3
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 13%;" aria-valuenow="13" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_106><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 106</p><br/>You are migrating an internal server on your DC to an EC2 instance with EBS volume. Your server disk usage is around 500GB so you just copied all your data to a 2TB disk to be used with AWS Import/Export.<br/><br/>Where will the data be imported once it arrives at Amazon?<br/><br/>A. to a 2TB EBS volume<br/>B. to an S3 bucket with 2 objects of 1TB<br/>C. to an 500GB EBS volume<br/>D. to an S3 bucket as a 2TB snapshot<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample772' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation772' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_107'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_259'>Random</a></p><div class='collapse' id='collapseExample772'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>to an S3 bucket with 2 objects of 1TB</div></div></div><div class='collapse' id='explanation772'><div class='card card&#45;body'><div>
An import to Amazon EBS will have different results depending on whether the capacity of your storage device is less than or equal to 1 TB or greater than 1 TB. The maximum size of an Amazon EBS snapshot is 1 TB, so if the device image is larger than 1 TB, the image is chunked and stored on Amazon S3. The target location is determined based on the total capacity of the device, not the amount of data on the device.

References:

AWS Snowball</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 13%;" aria-valuenow="13" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_107><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 107</p><br/>A company wants to use Amazon S3 for the secondary copy of its on&#8211;premises dataset. The company would rarely need to access this copy. The storage solution's cost should be minimal.<br/><br/>Which storage solution meets these requirements?<br/><br/>A. S3 Standard<br/>B. S3 Intelligent&#8211;Tiering<br/>C. S3 Standard&#8211;Infrequent Access (S3 Standard&#8211;IA)<br/>D. S3 One Zone&#8211;Infrequent Access (S3 One Zone&#8211;IA)<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample46' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_108'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_655'>Random</a></p><div class='collapse' id='collapseExample46'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>S3 One Zone-Infrequent Access (S3 One Zone-IA)</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 13%;" aria-valuenow="13" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_108><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 108</p><br/>A company is reviewing a recent migration of a three&#8211;tier application to a VPC. The security team discovers that the principle of least privilege is not being applied to Amazon EC2 security group ingress and egress rules between the application tiers.<br/><br/>What should a solutions architect do to correct this issue?<br/><br/>A. Create security group rules using the instance ID as the source or destination.<br/>B. Create security group rules using the security group ID as the source or destination.<br/>C. Create security group rules using the VPC CIDR blocks as the source or destination.<br/>D. Create security group rules using the subnet CIDR blocks as the source or destination.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample332' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_109'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_150'>Random</a></p><div class='collapse' id='collapseExample332'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Create security group rules using the security group ID as the source or destination.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 13%;" aria-valuenow="13" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_109><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 109</p><br/>A website runs a web application that receives a burst of traffic each day at noon. The users upload new pictures and content daily, but have been complaining of timeouts. The architecture uses Amazon EC2 Auto Scaling groups, and the custom application consistently takes 1 minute to initiate upon boot up before responding to user requests.<br/><br/>How should a solutions architect redesign the architecture to better respond to changing traffic?<br/><br/>A. Configure a Network Load Balancer with a slow start configuration.<br/>B. Configure AWS ElastiCache for Redis to offload direct requests to the servers.<br/>C. Configure an Auto Scaling step scaling policy with an instance warmup condition.<br/>D. Configure Amazon CloudFront to use an Application Load Balancer as the origin.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample117' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation117' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_110'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_695'>Random</a></p><div class='collapse' id='collapseExample117'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Configure an Auto Scaling step scaling policy with an instance warmup condition.</div></div></div><div class='collapse' id='explanation117'><div class='card card&#45;body'><div>
If you are creating a step policy, you can specify the number of seconds that it takes for a newly launched instance to warm up. Until its specified warm-up time has expired, an instance is not counted toward the aggregated metrics of the Auto Scaling group. Using the example in the Step Adjustments section, suppose that the metric gets to 60, and then it gets to 62 while the new instance is still warming up. The current capacity is still 10 instances, so 1 instance is added (10 percent of 10 instances). However, the desired capacity of the group is already 11 instances, so the scaling policy does not increase the desired capacity further. If the metric gets to 70 while the new instance is still warming up, we should add 3 instances (30 percent of 10 instances). However, the desired capacity of the group is already 11, so we add only 2 instances, for a new desired capacity of 13 instances.

References:
Amazon EC2 Auto Scaling > User Guide > Step and simple scaling policies for Amazon EC2 Auto Scaling
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 13%;" aria-valuenow="13" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_110><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 110</p><br/>A company creates business&#8211;critical 3D images every night. The images are batch&#8211;processed every Friday and require an uninterrupted 48 hours to complete.<br/><br/>What is the MOST cost&#8211;effective Amazon EC2 pricing model for this scenario?<br/><br/>A. On&#8211;Demand Instances<br/>B. Scheduled Reserved Instances<br/>C. Reserved Instances<br/>D. Spot Instances<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample791' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation791' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_111'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_234'>Random</a></p><div class='collapse' id='collapseExample791'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Scheduled Reserved Instances</div></div></div><div class='collapse' id='explanation791'><div class='card card&#45;body'><div>
Scheduled Reserved Instances (Scheduled Instances) enable you to purchase capacity reservations that recur on a daily, weekly, or monthly basis, with a specified start time and duration, for a one-year term. You reserve the capacity in advance, so that you know it is available when you need it. You pay for the time that the instances are scheduled, even if you do not use them.

Scheduled Instances are a good choice for workloads that do not run continuously, but do run on a regular schedule. For example, you can use Scheduled Instances for an application that runs during business hours or for batch processing that runs at the end of the week.

CORRECT: "Scheduled Reserved Instances" is the correct answer.

INCORRECT: "Standard Reserved Instances" is incorrect as the workload only runs for 4 hours a day this would be more expensive.

INCORRECT: "On-Demand Instances" is incorrect as this would be much more expensive as there is no discount applied.

INCORRECT: "Spot Instances" is incorrect as the workload cannot be interrupted once started. With Spot instances workloads can be terminated if the Spot price changes or capacity is required.

References:

Amazon Elastic Compute Cloud > User Guide for Linux Instances > Scheduled Reserved Instances
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 13%;" aria-valuenow="13" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_111><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 111</p><br/>An eCommerce company has noticed performance degradation of its Amazon RDS based web application.<br/><br/>The performance degradation is attributed to an increase in the number of read&#8211;only SQL queries triggered by business analysts. A solutions architect needs to solve the problem with minimal changes to the existing web application. What should the solutions architect recommend?<br/><br/>A. Export the data to Amazon DynamoDB and have the business analysts run their queries.<br/>B. Load the data into Amazon ElastiCache and have the business analysts run their queries.<br/>C. Create a read replica of the primary database and have the business analysts run their queries.<br/>D. Copy the data into an Amazon Redshift cluster and have the business analysts run their queries.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample68' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_112'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_330'>Random</a></p><div class='collapse' id='collapseExample68'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Create a read replica of the primary database and have the business analysts run their queries.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 14%;" aria-valuenow="14" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_112><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 112</p><br/>A company is seeing access requests by some suspicious IP addresses. The security team discovers the requests are from different IP addresses under the same CIDR range.<br/><br/>What should a solutions architect recommend to the team?<br/><br/>A. Add a rule in the inbound table of the security to deny the traffic from that CIDR range.<br/>B. Add a rule in the outbound table of the security group to deny the traffic from that CIDR range.<br/>C. Add a deny rule in the inbound table of the network ACL with a lower number than other rules.<br/>D. Add a deny rule in the outbound table of the network ACL with a lower rule number than other rules.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample53' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation53' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_113'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_516'>Random</a></p><div class='collapse' id='collapseExample53'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Add a deny rule in the inbound table of the network ACL with a lower number than other rules.</div></div></div><div class='collapse' id='explanation53'><div class='card card&#45;body'><div>
You can only create deny rules with network ACLs, it is not possible with security groups. Network ACLs process rules in order from the lowest numbered rules to the highest until they reach and allow or deny. The following table describes some of the differences between security groups and network ACLs:

Therefore, the solutions architect should add a deny rule in the inbound table of the network ACL with a lower rule number than other rules.

CORRECT: "Add a deny rule in the inbound table of the network ACL with a lower rule number than other rules" is the correct answer.

INCORRECT: "Add a deny rule in the outbound table of the network ACL with a lower rule number than other rules" is incorrect as this will only block outbound traffic.

INCORRECT: "Add a rule in the inbound table of the security group to deny the traffic from that CIDR range" is incorrect as you cannot create a deny rule with a security group.

INCORRECT: "Add a rule in the outbound table of the security group to deny the traffic from that CIDR range" is incorrect as you cannot create a deny rule with a security group.

References:
Amazon Virtual Private Cloud > User Guide > Network ACLs
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 14%;" aria-valuenow="14" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_113><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 113</p><br/>A company has a three&#8211;tier, stateless web application. The company's web and application tiers run on Amazon BC2 instances in an Auto Scaling group with an Amazon Elastic Block Store (Amazon EBS) root volume, and the database tier runs on Amazon RDS for PostgreSQL.<br/><br/>The company's recovery point objective (RPO) is 2 hours.<br/><br/>What should a solutions architect recommend to enable backups for this environment?<br/><br/>A. Take snapshots of EBS volumes of the EC2 instances and database every 2 hours<br/>B. Configure a snapshot lifecycle policy to take EBS snapshots and configure an automated database backup in Amazon RDS to meet the RPO<br/>C. Take snapshots of EBS volumes of the EC2 instances every 2 hours. Configure automated database backup in Amazon RDS so that it runs every 2 hours<br/>D. Retain the latest Amazon Machine Images (AMIs) of the web and application tiers Configure daily Amazon RDS snapshots and use point&#8211;in&#8211;time recovery to meet the RPO.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample662' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_114'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_137'>Random</a></p><div class='collapse' id='collapseExample662'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Retain the latest Amazon Machine Images (AMIs) of the web and application tiers Configure daily Amazon RDS snapshots and use point-in-time recovery to meet the RPO.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 14%;" aria-valuenow="14" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_114><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 114</p><br/>A company's application hosted on Amazon EC2 instances needs to access an Amazon S3 bucket. Due to data sensitivity, traffic cannot traverse the internet.<br/><br/>How should a solutions architect configure access?<br/><br/>A. Create a private hosted zone using Amazon Route 53.<br/>B. Configure a VPC gateway endpoint for Amazon S3 in the VPC.<br/>C. Configure AWS PrivateLink between the EC2 instance and the S3 bucket.<br/>D. Set up a site&#8211;to&#8211;site VPN connection between the VPC and the S3 bucket.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample66' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_115'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_475'>Random</a></p><div class='collapse' id='collapseExample66'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Configure a VPC gateway endpoint for Amazon S3 in the VPC.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 14%;" aria-valuenow="14" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_115><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 115</p><br/>A company is moving its on&#8211;premises applications to Amazon EC2 instances. However, as a result of fluctuating compute requirements, the EC2 instances must always be ready to use between 8 AM and 5 PM in specific Availability Zones.<br/><br/>Which EC2 instances should the company choose to run the applications?<br/><br/>A. Scheduled Reserved Instances<br/>B. On&#8211;Demand Instances<br/>C. Spot Instances as part of a Spot Fleet<br/>D. EC2 instances in an Auto Scaling group<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample252' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_116'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_395'>Random</a></p><div class='collapse' id='collapseExample252'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Scheduled Reserved Instances</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 14%;" aria-valuenow="14" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_116><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 116</p><br/>A company has 700 TB of backup data stored in network attached storage (NAS) in its data center This backup data need to be accessible for infrequent regulatory requests and must be retained 7 years. The company has decided to migrate this backup data from its data center to AWS. The migration must be complete within 1 month. The company has 500 Mbps of dedicated bandwidth on its public internet connection available for data transfer.<br/><br/>What should a solutions architect do to migrate and store the data at the LOWEST cost?<br/><br/>A. Order AWS Snowball devices to transfer the data. Use a lifecycle policy to transition the files to Amazon S3 Glacier Deep Archive.<br/>B. Deploy a VPN connection between the data center and Amazon VPC. Use the AWS CLI to copy the data from on&#8211;premises to Amazon S3 Glacier.<br/>C. Provision a 500 Mbps AWS Direct Connect connection and transfer the data to Amazon S3. Use a lifecycle policy to transition the files to Amazon S3 Glacier Deep Archive.<br/>D. Use AWS DataSync to transfer the data and deploy a DataSync agent on&#8211;premises. Use the DataSync task to copy files from the on&#8211;premises NAS storage to Amazon S3 Glacier.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample345' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_117'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_323'>Random</a></p><div class='collapse' id='collapseExample345'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Order AWS Snowball devices to transfer the data. Use a lifecycle policy to transition the files to Amazon S3 Glacier Deep Archive.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 14%;" aria-valuenow="14" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_117><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 117</p><br/>A company hosts its web application on AWS using server Amazon EC2 instances. The company requires that the IP addresses of all healthy EC2 instances be refused in response to DNS queries.<br/><br/>Which policy should be used to meet this requirement?<br/><br/>A. Simple routing policy.<br/>B. Latency routing policy.<br/>C. Multivalue routing policy.<br/>D. Geolocation routing policy.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample699' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_118'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_437'>Random</a></p><div class='collapse' id='collapseExample699'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Multivalue routing policy.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 14%;" aria-valuenow="14" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_118><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 118</p><br/>A company has an on&#8211;premises business application that generates hundreds of files each day. These files are stored on an SMB file share and require a low&#8211;latency connection to the application servers. A new company policy states all application&#8211;generated files must be copied to AWS. There is already a VPN connection to AWS.<br/><br/>The application development team does not have time to make the necessary code modifications to move the application to AWS.<br/><br/>Which service should a solutions architect recommend to allow the application to copy files to AWS?<br/><br/>A. Amazon Elastic File System (Amazon EFS)<br/>B. Amazon FSx for Windows File Server<br/>C. AWS Snowball<br/>D. AWS Storage Gateway<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample363' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation363' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_119'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_101'>Random</a></p><div class='collapse' id='collapseExample363'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>AWS Storage Gateway</div></div></div><div class='collapse' id='explanation363'><div class='card card&#45;body'><div>
The files will be on the storage gateway with low latency and copied to AWS as a second copy. FSx in AWS will not provide low latency for the on-prem apps over a VPN to the FSx file system.
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 14%;" aria-valuenow="14" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_119><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 119</p><br/>A company is hosting multiple websites for several lines of business under its registered parent domain.<br/><br/>Users accessing these websites will be routed to appropriate backend Amazon EC2 instances based on the subdomain. The websites host static webpages, images, and server&#8211;side scripts like PHP and JavaScript. Some of the websites experience peak access during the first two hours of business with constant usage throughout the rest of the day. A solutions architect needs to design a solution that will automatically adjust capacity to these traffic patterns while keeping costs low.<br/><br/>Which combination of AWS services or features will meet these requirements? (Choose two.)<br/><br/>A. AWS Batch<br/>B. Network Load Balancer<br/>C. Application Load Balancer<br/>D. Amazon EC2 Auto Scaling<br/>E. Amazon S3 website hosting<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample107' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_120'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_591'>Random</a></p><div class='collapse' id='collapseExample107'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Application Load Balancer
<br><b>D. </b>Amazon EC2 Auto Scaling

References:

Amazon Simple Storage Service > User Guide > Hosting a static website using Amazon S3</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 15%;" aria-valuenow="15" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_120><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 120</p><br/>A recently acquired company is required to build its own infrastructure on AWS and migrate multiple applications to the cloud within a month. Each application has approximately 50 TB of data to be transferred. After the migration is complete, this company and its parent company will both require secure network connectivity with consistent throughput from their data centers to the applications. A solutions architect must ensure one&#8211;time data migration and ongoing network connectivity.<br/><br/>Which solution will meet these requirements?<br/><br/>A. AWS Direct Connect for both the initial transfer and ongoing connectivity.<br/>B. AWS Site&#8211;to&#8211;Site VPN for both the initial transfer and ongoing connectivity.<br/>C. AWS Snowball for the initial transfer and AWS Direct Connect for ongoing connectivity.<br/>D. AWS Snowball for the initial transfer and AWS Site&#8211;to&#8211;Site VPN for ongoing connectivity.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample179' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation179' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_121'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_764'>Random</a></p><div class='collapse' id='collapseExample179'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>AWS Snowball for the initial transfer and AWS Direct Connect for ongoing connectivity.</div></div></div><div class='collapse' id='explanation179'><div class='card card&#45;body'><div>
"Each application has approximately 50 TB of data to be transferred" = AWS Snowball; "secure network connectivity with consistent throughput from their data centers to the applications"

What are the benefits of using AWS Direct Connect and private network connections? In many circumstances, private network connections can reduce costs, increase bandwidth, and provide a more consistent network experience than Internet-based connections. "more consistent network experience", hence AWS Direct Connect.

Direct Connect is better than VPN; reduced cost+increased bandwith+(remain connection or consistent network) = direct connect
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 15%;" aria-valuenow="15" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_121><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 121</p><br/>A company has application running on Amazon EC2 instances in a VPC. One of the applications needs to call an Amazon S3 API to store and read objects. The company's security policies restrict any internet&#8211;bound traffic from the applications.<br/><br/>Which action will fulfill these requirements and maintain security?<br/><br/>A. Configure an S3 interface endpoint.<br/>B. Configure an S3 gateway endpoint.<br/>C. Create an S3 bucket in a private subnet.<br/>D. Create an S3 bucket in the same Region as the EC2 instance.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample14' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation14' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_122'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_138'>Random</a></p><div class='collapse' id='collapseExample14'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Configure an S3 gateway endpoint.</div></div></div><div class='collapse' id='explanation14'><div class='card card&#45;body'><div>
VPC endpoints: A VPC endpoint enables you to privately connect your VPC to supported AWS services and VPC endpoint services powered by AWS PrivateLink without requiring an internet gateway, NAT device, VPN connection, or AWS Direct Connect connection. Instances in your VPC do not require public IP addresses to communicate with resources in the service. Traffic between your VPC and the other service does not leave the Amazon network.

An interface endpoint is an elastic network interface with a private IP address from the IP address range of your subnet that serves as an entry point for traffic destined to a supported service. Interface endpoints are powered by AWS PrivateLink, a technology that enables you to privately access services by using private IP addresses. AWS PrivateLink restricts all network traffic between your VPC and services to the Amazon network. You do not need an internet gateway, a NAT device, or a virtual private gateway.

References:

Amazon Virtual Private Cloud > AWS PrivateLink > Endpoints for Amazon S3
Amazon Virtual Private Cloud > AWS PrivateLink > Gateway VPC endpoints</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 15%;" aria-valuenow="15" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_122><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 122</p><br/>A company is reviewing a recent migration of a three&#8211;tier application to a VPC. The security team discovers that the principle of least privilege is not being applied to Amazon EC2 security group ingress and egress rules between the application tiers.<br/><br/>What should a solutions architect do to correct this issue?<br/><br/>A. Create security group rules using the instance ID as the source or destination.<br/>B. Create security group rules using the security group ID as the source or destination.<br/>C. Create security group rules using the VPC CIDR block as the source or destination.<br/>D. Create security group rules using the subnet CIDR block as the source or destination.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample695' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_123'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_611'>Random</a></p><div class='collapse' id='collapseExample695'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Create security group rules using the security group ID as the source or destination.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 15%;" aria-valuenow="15" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_123><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 123</p><br/>A solutions architect needs to design a resilient solution for Windows users' home directories. The solution must provide fault tolerance, file&#8211;level backup and recovery, and access control, based upon the company's Active Directory.<br/><br/>Which storage solution meets these requirements?<br/><br/>A. Configure Amazon S3 to store the users' home directories. Join Amazon S3 to Active Directory.<br/>B. Configure a Multi&#8211;AZ file system with Amazon FSx for Windows File Server Join Amazon FSx to Active Directory.<br/>C. Configure Amazon Elastic File System (Amazon EFS) for the users' home directories. Configure AWS Single Sign&#8211;On with Active Directory.<br/>D. Configure Amazon Elastic Block Store (Amazon EBS) to store the users' home directories Configure AWS Single Sign&#8211;On with Active Directory.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample485' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_124'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_535'>Random</a></p><div class='collapse' id='collapseExample485'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Configure Amazon Elastic File System (Amazon EFS) for the users' home directories. Configure AWS Single Sign-On with Active Directory.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 15%;" aria-valuenow="15" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_124><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 124</p><br/>A solution architect must migrate a Windows internet information Services (IIS) web application to AWS. The application currently relies on a file share hosted in the user's on&#8211;premises network&#8211;attached storage (NAS). The solution architected has proposed migrating the IIS web servers.<br/><br/>Which replacement to the on&#8211;promises filo share is MOST resilient and durable?<br/><br/>A. Migrate the file Share to Amazon RDS.<br/>B. Migrate the tile Share to AWS Storage Gateway<br/>C. Migrate the file Share to Amazon FSx dor Windows File Server.<br/>D. Migrate the tile share to Amazon Elastic File System (Amazon EFS)<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample728' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_125'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_511'>Random</a></p><div class='collapse' id='collapseExample728'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Migrate the file Share to Amazon FSx dor Windows File Server.

References:

Amazon FSx for Windows File Server</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 15%;" aria-valuenow="15" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_125><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 125</p><br/>A solutions architect is using Amazon S3 to design the storage architecture of a new digital media application. The media files must be resilient to the loss of an Availability Zone. Some files are accessed frequently while other files are rarely accessed in an unpredictable pattern. The solutions architect must minimize the costs of storing and retrieving the media files.<br/><br/>Which storage option meets these requirements?<br/><br/>A. S3 Standard<br/>B. S3 Intelligent&#8211;Tiering<br/>C. S3 Standard&#8211;Infrequent Access (S3 Standard&#8211;IA)<br/>D. S3 One Zone&#8211;Infrequent Access (S3 One Zone&#8211;IA)<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample102' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation102' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_126'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_381'>Random</a></p><div class='collapse' id='collapseExample102'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>S3 Intelligent-Tiering</div></div></div><div class='collapse' id='explanation102'><div class='card card&#45;body'><div>
S3 Intelligent-Tiering is a new Amazon S3 storage class designed for customers who want to optimize storage costs automatically when data access patterns change, without performance impact or operational overhead. S3 Intelligent-Tiering is the first cloud object storage class that delivers automatic cost savings by moving data between two access tiers – frequent access and infrequent access – when access patterns change, and is ideal for data with unknown or changing access patterns.

S3 Intelligent-Tiering stores objects in two access tiers: one tier that is optimized for frequent access and another lower-cost tier that is optimized for infrequent access. For a small monthly monitoring and automation fee per object, S3 Intelligent-Tiering monitors access patterns and moves objects that have not been accessed for 30 consecutive days to the infrequent access tier. There are no retrieval fees in S3 Intelligent-Tiering. If an object in the infrequent access tier is accessed later, it is automatically moved back to the frequent access tier. No additional tiering fees apply when objects are moved between access tiers within the S3 Intelligent-Tiering storage class. S3 Intelligent-Tiering is designed for 99.9% availability and 99.999999999% durability, and offers the same low latency and high throughput performance of S3 Standard.
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 15%;" aria-valuenow="15" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_126><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 126</p><br/>A solutions architect must provide a fully managed replacement for an on&#8211;premises solution that allows employees and partners to exchange files The solution must be easily accessible to employees connecting from on&#8211;premises systems, remote employees, and external partners.<br/><br/>Which solution meets these requirements?<br/><br/>A. Use AWS Transfer for SFTP to transfer files into and out of Amazon S3<br/>B. Use AWS Snowball Edge for local storage and large&#8211;scale data transfers<br/>C. Use Amazon FSx to store and transfer files to make them available remotely<br/>D. Use AWS Storage Gateway to create a volume gateway to store and transfer files to Amazon S3.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample666' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_127'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_109'>Random</a></p><div class='collapse' id='collapseExample666'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Use AWS Snowball Edge for local storage and large-scale data transfers</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 15%;" aria-valuenow="15" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_127><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 127</p><br/>A company's website handles millions of requests each day. and the number of requests continues to increase. A solutions architect needs to improve the response time of the web application. The solutions architect determines that the application needs to decrease latency.<br/><br/>When retrieving product details from the Amazon DynamoDB table?<br/><br/>A. Set up a DynamoOB Accelerator (DAX) cluster. Route all read requests through DAX.<br/>B. Set up Amazon ElasliCache (or Redis between the DynamoOB table and the web application. Route all read requests through Redis.<br/>C. Set up Amazon ElasliCache for Memcached between the DynamoOB table and the web application. Route all read requests through Memcached.<br/>D. Set up Amazon DynamoOB Streams on the table, and have AWS Lambda read from the table and populate Amazon ElastiCache. Route all read requests through ElasliCache.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample548' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_128'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_350'>Random</a></p><div class='collapse' id='collapseExample548'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Set up a DynamoOB Accelerator (DAX) cluster. Route all read requests through DAX.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 16%;" aria-valuenow="16" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_128><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 128</p><br/>An application running on AWS Lambda requires an API key to access a third&#8211;party service. The key must be stored securely with audited access to the Lambda function only.<br/><br/>What is the MOST secure way to store the key?<br/><br/>A. As an object in Amazon S3.<br/>B. As a secure siring in AWS Systems Manager Parameter Store.<br/>C. Inside a file on an Amazon EBS volume attached to the Lambda function<br/>D. Inside a secrets file stored on Amazon EFS<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample576' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_129'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_476'>Random</a></p><div class='collapse' id='collapseExample576'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>As a secure siring in AWS Systems Manager Parameter Store.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 16%;" aria-valuenow="16" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_129><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 129</p><br/>A company is using a third&#8211;party vendor to manage its marketplace analytics. The vendor needs limited programmatic access to resources in the company's account. All the needed policies have been created to grant appropriate access.<br/><br/>Which additional component will provide the vendor with the MOST secure access to the account?<br/><br/>A. Create an IAM user.<br/>B. Implement a service control policy (SCP)<br/>C. Use a cross&#8211;account role with an external ID.<br/>D. Configure a single sign&#8211;on (SSO) identity provider.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample242' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_130'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_549'>Random</a></p><div class='collapse' id='collapseExample242'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Implement a service control policy (SCP)</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 16%;" aria-valuenow="16" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_130><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 130</p><br/>A meteorological startup company has a custom web application to sell weather data to its users online.<br/><br/>The company uses Amazon DynamoDB to store its data and wants to build a new service that sends an alert to the managers of four internal teams every time a new weather event is recorded. The company does not want this new service to affect the performance of the current application.<br/><br/>What should a solutions architect do to meet these requirements with the LEAST amount of operational overhead?<br/><br/>A. Use DynamoDB transactions to write new event data to the table. Configure the transactions to notify internal teams.<br/>B. Have the current application publish a message to four Amazon Simple Notification Service (Amazon SNS) topics. Have each team subscribe to one topic.<br/>C. Enable Amazon DynamoDB Streams on the table. Use triggers to write to a single Amazon Simple Notification Service (Amazon SNS) topic to which the teams can subscribe.<br/>D. Add a custom attribute to each record to flag new items. Write a cron job that scans the table every minute for items that are new and notifies an Amazon Simple Queue Service (Amazon SQS) queue to which the teams can subscribe.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample320' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_131'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_196'>Random</a></p><div class='collapse' id='collapseExample320'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Use DynamoDB transactions to write new event data to the table. Configure the transactions to notify internal teams.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 16%;" aria-valuenow="16" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_131><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 131</p><br/>A company is using a fleet of Amazon EC2 instances to ingest data from on&#8211;premises data sources. The data is in JSON format and ingestion rates can be as high as 1 MB/s. When an EC2 instance is rebooted, the data in&#8211;flight is lost. The company's data science team wants to query ingested data in near&#8211;real time.<br/><br/>Which solution provides near&#8211;real&#8211;time data querying that is scalable with minimal data loss?<br/><br/>A. Publish data to Amazon Kinesis Data Streams. Use Kinesis Data Analytics to query the data.<br/>B. Publish data to Amazon Kinesis Data Firehose with Amazon Redshift as the destination. Use Amazon Redshift to query the data.<br/>C. Store ingested data in an EC2 instance store. Publish data to Amazon Kinesis Data Firehose with Amazon S3 as the destination. Use Amazon Athena to query the data.<br/>D. Store ingested data in an Amazon Elastic Block Store (Amazon EBS) volume. Publish data to Amazon ElastiCache for Redis. Subscribe to the Redis channel to query the data.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample222' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation222' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_132'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_378'>Random</a></p><div class='collapse' id='collapseExample222'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Publish data to Amazon Kinesis Data Firehose with Amazon Redshift as the destination. Use Amazon Redshift to query the data.</div></div></div><div class='collapse' id='explanation222'><div class='card card&#45;body'><div>
Kinesis data streams consists of shards. The more throughput is needed, the more shards you add, the less throughput, the more shards you remove, so it's scalable. Each shard can handle up to 1MB/s of writes.

However Kinesis data streams stores ingested data for only 1 to 7 days so there is a chance of data loss. Additionally,

Kinesis data analytics and kinesis data streams are both for real-time ingestion and analytics. Firehouse on the other hand is also scalable and processes data in near real time as per the requirement. It also transfers data into Redshift which is a data warehouse so data won't be lost. Redshift also has a SQL interface for performing queries for data analytics.
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 16%;" aria-valuenow="16" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_132><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 132</p><br/>An engineering team is developing and deploying AWS Lambda functions. The team needs to create roles and manage policies in AWS IAM to configure the permissions of the Lambda functions.<br/><br/>How should the permissions for the team be configured so they also adhere to the concept of least privilege?<br/><br/>A. Create an IAM role with a managed policy attached. Allow the engineering team and the Lambda functions to assume this role.<br/>B. Create an IAM group for the engineering team with an IAMFullAccess policy attached. Add all the users from the team to this IAM group.<br/>C. Create an execution role for the Lambda functions. Attach a managed policy that has permission boundaries specific to these Lambda functions.<br/>D. Create an IAM role with a managed policy attached that has permission boundaries specific to the Lambda functions. Allow the engineering team to assume this role.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample361' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_133'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_326'>Random</a></p><div class='collapse' id='collapseExample361'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Create an IAM role with a managed policy attached. Allow the engineering team and the Lambda functions to assume this role.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 16%;" aria-valuenow="16" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_133><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 133</p><br/>A company has an application workflow that uses an AWS Lambda function to download and decrypt files from Amazon S3. These files are encrypted using AWS Key Management Service Customer Master Keys (AWS KMS CMKs). A solutions architect needs to design a solution that will ensure the required permissions are set correctly.<br/><br/>Which combination of actions accomplish this? (Choose two.)<br/><br/>A. Attach the kms:decrypt permission to the Lambda function's resource policy.<br/>B. Grant the decrypt permission for the Lambda IAM role in the KMS key's policy.<br/>C. Grant the decrypt permission for the Lambda resource policy in the KMS key's policy.<br/>D. Create a new IAM policy with the kms:decrypt permission and attach the policy to the Lambda function.<br/>E. Create a new IAM role with the kms:decrypt permission and attach the execution role to the Lambda function.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample358' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_134'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_72'>Random</a></p><div class='collapse' id='collapseExample358'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Grant the decrypt permission for the Lambda IAM role in the KMS key's policy.
<br><b>E. </b>Create a new IAM role with the kms:decrypt permission and attach the execution role to the Lambda function.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 16%;" aria-valuenow="16" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_134><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 134</p><br/>Application developers have noticed that a production application is very slow when business reporting users run large production reports against the Amazon RDS instance backing the application. the CPU and memory utilization metrics for the RDS instanced not exceed 60% while the reporting queries are running. The business reporting users must be able to generate reports without affecting the applications performance.<br/><br/>Which action will accomplish this?<br/><br/>A. Increase the size of the RDS instance<br/>B. Create a read replica and connect the application to it.<br/>C. Enable multiple Availability Zones on the RDS instance<br/>D. Create a read replication and connect the business reports to it.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample725' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_135'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_448'>Random</a></p><div class='collapse' id='collapseExample725'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Create a read replication and connect the business reports to it.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 16%;" aria-valuenow="16" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_135><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 135</p><br/>A solutions architect is designing a system to analyze the performance of financial markets while the markets are closed. The system will run a series of compute&#8211;intensive jobs for 4 hours every night. The time to complete the compute jobs is expected to remain constant, and jobs cannot be interrupted once started. Once completed, the system is expected to run for a minimum of 1 year.<br/><br/>Which type of Amazon EC2 instances should be used to reduce the cost of the system?<br/><br/>A. Spot Instances<br/>B. On&#8211;Demand Instances<br/>C. Standard Reserved Instances<br/>D. Scheduled Reserved Instances<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample156' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation156' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_136'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_645'>Random</a></p><div class='collapse' id='collapseExample156'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Scheduled Reserved Instances</div></div></div><div class='collapse' id='explanation156'><div class='card card&#45;body'><div>
Scheduled Reserved Instances (Scheduled Instances) enable you to purchase capacity reservations that recur on a daily, weekly, or monthly basis, with a specified start time and duration, for a one-year term. You reserve the capacity in advance, so that you know it is available when you need it. You pay for the time that the instances are scheduled, even if you do not use them.

Scheduled Instances are a good choice for workloads that do not run continuously, but do run on a regular schedule. For example, you can use Scheduled Instances for an application that runs during business hours or for batch processing that runs at the end of the week.

CORRECT: "Scheduled Reserved Instances" is the correct answer.

INCORRECT: "Standard Reserved Instances" is incorrect as the workload only runs for 4 hours a day this would be more expensive.

INCORRECT: "On-Demand Instances" is incorrect as this would be much more expensive as there is no discount applied.

INCORRECT: "Spot Instances" is incorrect as the workload cannot be interrupted once started. With Spot instances workloads can be terminated if the Spot price changes or capacity is required.

References:

Amazon Elastic Compute Cloud > User Guide for Linux Instances > Scheduled Reserved Instances</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 17%;" aria-valuenow="17" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_136><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 136</p><br/>A company that develops web applications has launched hundreds of Application Load Balancers (ALBs) in multiple Regions. The company wants to create an allow list (or the IPs of all the load balancers on its firewall device. A solutions architect is looking for a one&#8211;time, highly available solution to address this request, which will also help reduce the number of IPs that need to be allowed by the firewall.<br/><br/>What should the solutions architect recommend to meet these requirements?<br/><br/>A. Create a AWS Lambda function to keep track of the IPs for all the ALBs in different Regions. Keep refreshing this list.<br/>B. Set up a Network Load Balancer (NLB) with Elastic IPs. Register the private IPs of all the ALBs as targets to this NLB.<br/>C. Launch AWS Global Accelerator and create endpoints for all the Regions. Register all the ALBs in different Regions to the corresponding endpoints.<br/>D. Set up an Amazon EC2 instance, assign an Elastic IP to this EC2 instance, and configure the instance as a proxy to forward traffic to all the ALBs.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample90' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_137'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_232'>Random</a></p><div class='collapse' id='collapseExample90'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Launch AWS Global Accelerator and create endpoints for all the Regions. Register all the ALBs in different Regions to the corresponding endpoints.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 17%;" aria-valuenow="17" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_137><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 137</p><br/>A company uses a payment processing system that requires messages for a particular payment ID to be received in the same order that they were sent Otherwise, the payments might be processed incorrectly.<br/><br/>Which actions should a solutions architect take to meet this requirement? (Select TWO.)<br/><br/>A. Write the messages to an Amazon DynamoDB table with the payment ID as the partition key<br/>B. Write the messages to an Amazon Kinesis data stream with the payment ID as the partition key.<br/>C. Write the messages to an Amazon ElastiCache for Memcached cluster with the payment ID as the key<br/>D. Write the messages to an Amazon Simple Queue Service (Amazon SQS) queue Set the message attribute to use the payment ID<br/>E. Write the messages to an Amazon Simple Queue Service (Amazon SQS) FIFO queue. Set the message group to use the payment ID<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample450' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_138'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_208'>Random</a></p><div class='collapse' id='collapseExample450'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Write the messages to an Amazon DynamoDB table with the payment ID as the partition key
<br><b>E. </b>Write the messages to an Amazon Simple Queue Service (Amazon SQS) FIFO queue. Set the message group to use the payment ID</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 17%;" aria-valuenow="17" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_138><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 138</p><br/>A company has global users accessing an application deployed in different AWS Regions, exposing public static IP addresses. The users are experiencing poor performance when accessing the application over the internet.<br/><br/>What should a solutions architect recommend to reduce internet latency?<br/><br/>A. Set up AWS Global Accelerator and add endpoints.<br/>B. Set up AWS Direct Connect locations in multiple Regions.<br/>C. Set up an Amazon CloudFront distribution to access an application.<br/>D. Set up an Amazon Route 53 geoproximity routing policy to route traffic.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample81' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation81' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_139'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_178'>Random</a></p><div class='collapse' id='collapseExample81'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Set up AWS Global Accelerator and add endpoints.</div></div></div><div class='collapse' id='explanation81'><div class='card card&#45;body'><div>
AWS Global Accelerator is a service in which you create accelerators to improve availability and performance of your applications for local and global users. Global Accelerator directs traffic to optimal endpoints over the AWS global network. This improves the availability and performance of your internet applications that are used by a global audience. Global Accelerator is a global service that supports endpoints in multiple AWS Regions, which are listed in the AWS Region Table.

By default, Global Accelerator provides you with two static IP addresses that you associate with your accelerator. (Or, instead of using the IP addresses that Global Accelerator provides, you can configure these entry points to be IPv4 addresses from your own IP address ranges that you bring to Global Accelerator.)

The static IP addresses are anycast from the AWS edge network and distribute incoming application traffic across multiple endpoint resources in multiple AWS Regions, which increases the availability of your applications. Endpoints can be Network Load Balancers, Application Load Balancers, EC2 instances, or Elastic IP addresses that are located in one AWS Region or multiple Regions.

CORRECT: "Set up AWS Global Accelerator and add endpoints" is the correct answer. INCORRECT: "Set up AWS Direct Connect locations in multiple Regions" is incorrect as this is used to connect from an on-premises data center to AWS. It does not improve performance for users who are not connected to the on-premises data center.

INCORRECT: "Set up an Amazon CloudFront distribution to access an application" is incorrect as CloudFront cannot expose static public IP addresses.

INCORRECT: "Set up an Amazon Route 53 geoproximity routing policy to route traffic" is incorrect as this does not reduce internet latency as well as using Global Accelerator. GA will direct users to the closest edge location and then use the AWS global network.

References:

AWS Global Accelerator > Developer Guide > What is AWS Global Accelerator?
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 17%;" aria-valuenow="17" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_139><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 139</p><br/>A company hosts its multi&#8211;tier public web application in the AWS Cloud. The web application runs on Amazon EC2 instances and its database runs on Amazon RDS. The company is anticipating a large increase in sales during an upcoming holiday weekend. A solutions architect needs to build a solution to analyze the performance of the web application with a granularity of no more than 2 minutes.<br/><br/>What should the solutions architect do to meet this requirement?<br/><br/>A. Send Amazon CloudWatch logs to Amazon Redshift. Use Amazon QuickSight to perform further analysis.<br/>B. Enable detailed monitoring on all EC2 instances. Use Amazon CloudWatch metrics to perform further analysis.<br/>C. Create an AWS Lambda function to fetch EC2 logs from Amazon CloudWatch Logs. Use Amazon CloudWatch metrics to perform further analysis.<br/>D. Send EC2 logs to Amazon S3. Use Amazon Redshift to fetch logs from the S3 bucket to process raw data for further analysis with Amazon QuickSight.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample370' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_140'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_766'>Random</a></p><div class='collapse' id='collapseExample370'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Enable detailed monitoring on all EC2 instances. Use Amazon CloudWatch metrics to perform further analysis.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 17%;" aria-valuenow="17" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_140><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 140</p><br/>A company has several web servers that need to frequently access a common Amazon RDS MySQL Multi&#8211;AZ instance.<br/><br/>The company wants a secure method for the web servers to connect to the database while meeting a security requirement to rotate user credentials frequently.<br/><br/>A company has several web servers that need to frequently access a common Amazon ROS MySQL Muto&#8211;AZ DB instance.<br/><br/>The company wants a secure method for the web servers to connect to the database while meeting a security requirement to rotate user credentials frequently.<br/><br/>Which solution meets these requirements?<br/><br/>A. Store the database user credentials in AWS Secrets Manager. Grant the necessary IAM permissions to allow the web servers to access AWS Secrets Manager<br/>B. Store the database user credentials m AWS Systems Manager OpsCenter. Grant the necessary IAM permissions to allow the web servers to access OpsCenter<br/>C. Store the database user credentials in a secure Amazon S3 bucket. Grant the necessary IAM permissions to allow the web servers to retrieve credentials and access the database<br/>D. Store the database user credentials in fries encrypted with AWS Key Management Service (AWS KMS) on the web server file system. The web server should be able to decrypt the files and access the database<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample517' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_141'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_117'>Random</a></p><div class='collapse' id='collapseExample517'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Store the database user credentials in AWS Secrets Manager. Grant the necessary IAM permissions to allow the web servers to access AWS Secrets Manager</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 17%;" aria-valuenow="17" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_141><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 141</p><br/>A company maintains a searchable repository of items on its website. The data is stored in an Amazon RDS for MySQL database table that contains over 10 million rows. The database has 2 TB of General Purpose SSD (gp2) storage. There are millions of updates against this data every day through the company's website. The company has noticed some operations are taking 10 seconds or longer, and has determined that the database storage performance is bottleneck.<br/><br/>Which solution addresses the performance issues?<br/><br/>A. Change the storage type to Provisioned IOPS SSD (io1).<br/>B. Change the instance to a memory&#8211;optimized instance class.<br/>C. Change the instance to a burstable performance DB instance class.<br/>D. Enable Multi&#8211;AZ RDS read replicas with MySQL native asynchronous replication.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample701' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_142'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_153'>Random</a></p><div class='collapse' id='collapseExample701'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Change the storage type to Provissioned IOPS SSD (io1).</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 17%;" aria-valuenow="17" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_142><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 142</p><br/>A company provides an online service for posting video content and transcoding it for use by any mobile platform.<br/><br/>The application architecture uses Amazon Elastic File System (Amazon EFS) Standard to collect and store the videos so that multiple Amazon EC2 Linux instances can access the video content for processing.<br/><br/>As the popularity of the service has grown over time, the storage costs have become too expensive.<br/><br/>Which storage solution is MOST cost&#8211;effective?<br/><br/>A. Use AWS Storage Gateway for files to store and process the video content<br/>B. Use AWS Storage Gateway for volumes to store and process the video content<br/>C. Use Amazon EFS for storing the video content. Once processing is complete, transfer the files to Amazon Elastic Block Store (Amazon EBS)<br/>D. Use Amazon S3 for storing the video content. Move the files temporarily over to an Amazon Elastic Block Store (Amazon EBS) volume attached to the server for processing<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample665' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_143'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_412'>Random</a></p><div class='collapse' id='collapseExample665'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Use AWS Storage Gateway for files to store and process the video content</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 17%;" aria-valuenow="17" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_143><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 143</p><br/>A company is designing an internet&#8211;facing web application. The application runs on Amazon EC2 for Linux&#8211;based instances that store sensitive user data in Amazon RDS MySQL Multi&#8211;AZ DB instances. The EC2 instances are in public subnets, and the RDS DB instances are in private subnets. The security team has mandated that the DB instances be secured against web&#8211;based attacks.<br/><br/>What should a solutions architect recommend?<br/><br/>A. Ensure the EC2 instances are part of an Auto Scaling group and are behind an Application Load Balancer. Configure the EC2 instance iptables rules to drop suspicious web traffic. Create a security group for the DB instances. Configure the RDS security group to only allow port 3306 inbound from the individual EC2 instances.<br/>B. Ensure the EC2 instances are part of an Auto Scaling group and are behind an Application Load Balancer. Move DB instances to the same subnets that EC2 instances are located in. Create a security group for the DB instances. Configure the RDS security group to only allow port 3306 inbound from the individual EC2 instances.<br/>C. Ensure the EC2 instances are part of an Auto Scaling group and are behind an Application Load Balancer. Use AWS WAF to monitor inbound web traffic for threats. Create a security group for the web application servers and a security group for the DB instances. Configure the RDS security group to only allow port 3306 inbound from the web application server security group.<br/>D. Ensure the EC2 instances are part of an Auto Scaling group and are behind an Application Load Balancer. Use AWS WAF to monitor inbound web traffic for threats. Configure the Auto Scaling group to automatically create new DB instances under heavy traffic. Create a security group for the RDS DB instances. Configure the RDS security group to only allow port 3306 inbound.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample385' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_144'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_357'>Random</a></p><div class='collapse' id='collapseExample385'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Ensure the EC2 instances are part of an Auto Scaling group and are behind an Application Load Balancer. Use AWS WAF to monitor inbound web traffic for threats. Create a security group for the web application servers and a security group for the DB instances. Configure the RDS security group to only allow port 3306 inbound from the web application server security group.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 18%;" aria-valuenow="18" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_144><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 144</p><br/>A company wants to use high performance computing (HPC) infrastructure on AWS for financial risk modeling. The company's HPC workloads run on Linux. Each HPC workflow runs on hundreds of AmazonEC2 Spot Instances, is short&#8211;lived, and generates thousands of output files that are ultimately stored in persistent storage for analytics and long&#8211;term future use.<br/><br/>The company seeks a cloud storage solution that permits the copying of on&#8211;premises data to long&#8211;term persistent storage to make data available for processing by all EC2 instances. The solution should also be a high performance file system that is integrated with persistent storage to read and write datasets and output files.<br/><br/>Which combination of AWS services meets these requirements?<br/><br/>A. Amazon FSx for Lustre integrated with Amazon S3<br/>B. Amazon FSx for Windows File Server integrated with Amazon S3<br/>C. Amazon S3 Glacier integrated with Amazon Elastic Block Store (Amazon EBS)<br/>D. Amazon S3 bucket with a VPC endpoint integrated with an Amazon Elastic Block Store (Amazon EBS) General Purpose SSD (gp2) volume<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample317' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_145'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_704'>Random</a></p><div class='collapse' id='collapseExample317'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Amazon FSx for Lustre integrated with Amazon S3</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 18%;" aria-valuenow="18" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_145><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 145</p><br/>A company is planning to migrate a business&#8211;critical dataset to Amazon S3. The current solution design uses a single S3 bucket in the us&#8211;east&#8211;1 Region with versioning enabled to store the dataset. The company's disaster recovery policy states that all data multiple AWS Regions.<br/><br/>How should a solutions architect design the S3 solution?<br/><br/>A. Create an additional S3 bucket in another Region and configure cross&#8211;Region replication.<br/>B. Create an additional S3 bucket in another Region and configure cross&#8211;origin resource sharing (CORS).<br/>C. Create an additional S3 bucket with versioning in another Region and configure cross&#8211;Region replication.<br/>D. Create an additional S3 bucket with versioning in another Region and configure cross&#8211;origin resource (CORS).<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample13' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation13' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_146'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_108'>Random</a></p><div class='collapse' id='collapseExample13'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Create an additional S3 bucket with versioning in another Region and configure cross-Region replication.</div></div></div><div class='collapse' id='explanation13'><div class='card card&#45;body'><div>
Replication enables automatic, asynchronous copying of objects across Amazon S3 buckets. Buckets that are configured for object replication can be owned by the same AWS account or by different accounts. You can copy objects between different AWS Regions or within the same Region. Both source and destination buckets must have versioning enabled.

CORRECT: "Create an additional S3 bucket with versioning in another Region and configure cross-Region replication" is the correct answer.

INCORRECT: "Create an additional S3 bucket in another Region and configure cross-Region replication" is incorrect as the destination bucket must also have versioning enabled.

INCORRECT: "Create an additional S3 bucket in another Region and configure cross-origin resource sharing (CORS)" is incorrect as CORS is not related to replication.

INCORRECT: "Create an additional S3 bucket with versioning in another Region and configure cross-origin resource sharing (CORS)" is incorrect as CORS is not related to replication.

References:
Amazon Simple Storage Service > User Guide > Replicating objects
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 18%;" aria-valuenow="18" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_146><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 146</p><br/>company owns an asynchronous API that is used to ingest user requests and, based on the request type, dispatch requests to the appropriate microservice for processing. The company is using Amazon API Gateway to deploy the API front end, and an AWS Lambda function that invokes Amazon DynamoDB to store user requests before dispatching them to the processing microservices.<br/><br/>The company provisioned as much DynamoDB throughput as its budget allows, but the company is still experiencing availability issues and is losing user requests.<br/><br/>What should a solutions architect do to address this issue without impacting existing users?<br/><br/>A. Add throttling on the API Gateway with server&#8211;side throttling limits.<br/>B. Use DynamoDB Accelerator (DAX) and Lambda to buffer writes to DynamoDB.<br/>C. Create a secondary index in DynamoDB for the table with the user requests.<br/>D. Use the Amazon Simple Queue Service (Amazon SQS) queue and Lambda to buffer writes to DynamoDB.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample251' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_147'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_492'>Random</a></p><div class='collapse' id='collapseExample251'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Use DynamoDB Accelerator (DAX) and Lambda to buffer writes to DynamoDB.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 18%;" aria-valuenow="18" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_147><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 147</p><br/>A solutions architect needs to allow developers to have SSH connectivity to web servers The requirements are as follows:<br/><br/>Limit access to users originating from the corporate<br/>Web servers cannot have SSH access directly from the<br/>Web servers reside in a private<br/>Which combination of steps must the architect complete to meet these requirements? (Select TWO.)<br/><br/>A. Create a bastion host that authenticates users against the corporate directory<br/>B. Create a bastion host with security group rules that only allow traffic from the corporate network.<br/>C. Attach an 1AM role to the bastion host with relevant permissions<br/>D. Configure the web servers' security group to allow SSH traffic from a bastion host.<br/>E. Deny all SSH traffic from the corporate network in the inbound network ACL.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample649' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_148'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_666'>Random</a></p><div class='collapse' id='collapseExample649'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Create a bastion host that authenticates users against the corporate directory
<br><b>E. </b>Deny all SSH traffic from the corporate network in the inbound network ACL.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 18%;" aria-valuenow="18" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_148><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 148</p><br/>A company runs an application that uses multiple Amazon EC2 instances to gather data from its users. The data is then processed and transferred to Amazon S3 for long&#8211;term storage. A review of the application shows that there were long periods of time when the EC2 instances were not being used. A solutions architect needs to design a solution that optimizes utilization and reduces costs.<br/><br/>Which solution meets these requirements?<br/><br/>A. Use Amazon EC2 in an Auto Scaling group with On&#8211;Demand instances.<br/>B. Build the application to use Amazon Lightsail with On&#8211;Demand Instances.<br/>C. Create an Amazon CloudWatch cron job to automatically stop the EC2 instances when there is no activity.<br/>D. Redesign the application to use an event&#8211;driven design with Amazon Simple Queue Service (Amazon SQS) and AWS Lambda.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample356' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_149'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_403'>Random</a></p><div class='collapse' id='collapseExample356'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Redesign the application to use an event-driven design with Amazon Simple Queue Service (Amazon SQS) and AWS Lambda.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 18%;" aria-valuenow="18" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_149><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 149</p><br/>A company collects temperature, humidity, and atmospheric pressure data in cities across multiple continents. The average volume of data collected per site each day is 500 GB. Each site has a high&#8211;speed internet connection. The company's weather forecasting applications are based in a single Region and analyze the data daily.<br/><br/>What is the FASTEST way to aggregate data from all of these global sites?<br/><br/>A. Enable Amazon S3 Transfer Acceleration on the destination bucket. Use multipart uploads to directly upload site data to the destination bucket.<br/>B. Upload site data to an Amazon S3 bucket in the closest AWS Region. Use S3 cross&#8211;Region replication to copy objects to the destination bucket.<br/>C. Schedule AWS Snowball jobs daily to transfer data to the closest AWS Region. Use S3 cross&#8211;Region replication to copy objects to the destination bucket.<br/>D. Upload the data to an Amazon EC2 instance in the closest Region. Store the data in an Amazon EBS volume. Once a day take an EBS snapshot and copy it to the centralized Region. Restore the EBS volume in the centralized Region and run an analysis on the data daily.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample173' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_150'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_66'>Random</a></p><div class='collapse' id='collapseExample173'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Upload site data to an Amazon S3 bucket in the closest AWS Region. Use S3 cross-Region replication to copy objects to the destination bucket.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 18%;" aria-valuenow="18" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_150><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 150</p><br/>An Amazon EC2 administrator created the following policy associated with an IAM group containing several users:<br/><br/>An Amazon EC2 administrator created the following policy associated with an IAM group containing several users.<br/><br/>What is the effect of this policy?<br/><br/>A. Users can terminate an EC2 instance in any AWS Region except us&#8211;east&#8211;1.<br/>B. Users can terminate an EC2 instance with the IP address 10.100.100.1 in the us&#8211;east&#8211;1 Region.<br/>C. Users can terminate an EC2 instance in the us&#8211;east&#8211;1 Region when the user's source IP is 10.100.100.254.<br/>D. Users cannot terminate an EC2 instance in the us&#8211;east&#8211;1 Region when the user's source IP is 10.100.100.254.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample41' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation41' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_151'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_491'>Random</a></p><div class='collapse' id='collapseExample41'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Users can terminate an EC2 instance in the us-east-1 Region when the user's source IP is 10.100.100.254.</div></div></div><div class='collapse' id='explanation41'><div class='card card&#45;body'><div>
What the policy means:
1. Allow termination of any instance if user's source IP address is 100.100.254.
2. Deny termination of instances that are not in the us-east-1 Combining this two, you get:
"Allow instance termination in the us-east-1 region if the user's source IP address is 10.100.100.254. Deny termination operation on other regions."


</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 18%;" aria-valuenow="18" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_151><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 151</p><br/>A company is planning on deploying a newly built application on AWS in a default VPC. The application will consist of a web layer and database layer. The web server was created in public subnets, and the MySQL database was created in private subnets. All subnets are created with the default network ACL settings, and the default security group in the VPC will be replaced with new custom security groups.<br/>The following are the key requirements:<br/><br/>The web servers must be accessible only to users on an SSL connection.<br/>The database should be accessible to the web layer, which is created in a public subnet only.<br/>All traffic to and from the IP range 182.20.0.0/16 subnet should be blocked.<br/>Which combination of steps meets these requirements? (Select two.)<br/><br/>A. Create a database server security group with inbound and outbound rules for MySQL port 3306 traffic to and from anywhere (0 0.0.0/0).<br/>B. Create a database server security group with an inbound rule for MySQL port 3306 and specify the source as a web server security group.<br/>C. Create a web server security group with an inbound allow rule for HTTPS port 443 traffic from anywhere (0.0.0.0/0) and an inbound deny rule for IP range 182.20.0.0/16.<br/>D. Create a web server security group with an inbound rule for HTTPS port 443 traffic from anywhere (0.0.0.0/0). Create network ACL inbound and outbound deny rules for IP range 182.20.0.0/16.<br/>E. Create a web server security group with inbound and outbound rules for HTTPS port 443 traffic to and from anywhere (0.0.0.0/0). Create a network ACL inbound deny rule for IP range 182.20.0.0/16.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample382' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_152'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_21'>Random</a></p><div class='collapse' id='collapseExample382'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Create a database server security group with an inbound rule for MySQL port 3306 and specify the source as a web server security group.
<br><b>D. </b>Create a web server security group with an inbound rule for HTTPS port 443 traffic from anywhere (0.0.0.0/0). Create network ACL inbound and outbound deny rules for IP range 182.20.0.0/16.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 19%;" aria-valuenow="19" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_152><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 152</p><br/>A company is developing a new machine learning model solution in AWS. The models are developed as independent microservices that fetch about 1 GB of model data from Amazon S3 at startup and load the data into memory. users access the models through an asynchronous API. Users can send a request or a batch of requests and specify where the result should be sent.<br/><br/>The company provides models to hundreds of users. The usage patterns for the models are irregular. somes models could be unused for days or weeks. other models could receive batches of thousands of requests at a time.<br/><br/>Which solution meets these requirements?<br/><br/>A. The requests from the API are sent to an Application Load Balancer (ALB). Models are deployed as AWS lambda functions invoked by the ALB<br/>B. The requests from the API are sent to the models Amazon Simple Queue Service (Amazon SOS) queue. Models are deployed as AWS Lambda functions triggered by SOS events. AWS auto scaling is enabled on Lambda to increase the number vCPUSs based on the SQS queue size.<br/>C. The requests from the API are sent to the model's Amazon simple Queue Service (Amazon SQS) queue. Model are deployed as Amazon Elastic container service ( AMAzon ECS) service reading from the queue. AWS App Mesh scales the instances of the ECS cluster based on the SQS queue size.<br/>D. The requests from the API are sent to the model's Amazon simple Queue Service (Amazon SQS) queue. Models are deployed as Amazon Elastics container service ( Amazon ECS) services reading from the queue. AWS Auto Scaling is enabled ECS for both the cluster and copies the service based on the queue size.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample709' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_153'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_659'>Random</a></p><div class='collapse' id='collapseExample709'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>The requests from the API are sent to the model's Amazon simple Queue Service (Amazon SQS) queue. Models are deployed as Amazon Elastics container service ( Amazon ECS) services reading from the queue. AWS Auto Scaling is enabled ECS for both the cluster and copies the service based on the queue size.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 19%;" aria-valuenow="19" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_153><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 153</p><br/>Does Amazon DynamoDB support both increment and decrement atomic operations?<br/><br/>A. Only increment, since decrement are inherently impossible with DynamoDB's data model.<br/>B. No, neither increment nor decrement operations.<br/>C. Yes, both increment and decrement operations.<br/>D. Only decrement, since increment are inherently impossible with DynamoDB's data model.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample761' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation761' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_154'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_721'>Random</a></p><div class='collapse' id='collapseExample761'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Yes, both increment and decrement operations.</div></div></div><div class='collapse' id='explanation761'><div class='card card&#45;body'><div>
Amazon DynamoDB supports increment and decrement atomic operations.

References:

Amazon DynamoDB > Developer Guide > DynamoDB API
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 19%;" aria-valuenow="19" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_154><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 154</p><br/>A company is building its web application using containers on AWS. The company requires three instances of the web application to run at all times. The application must be able to scale to meet increases in demand. Management is extremely sensitive to cost but agrees that the application should be highly available.<br/><br/>What should a solutions architect recommend?<br/><br/>A. Create an Amazon Elastic Container Service (Amazon ECS) cluster using the Fargate launch type. Create a task definition for the web application. Create an ECS service with a desired count of three tasks.<br/>B. Create an Amazon Elastic Container Service (Amazon ECS) cluster using the Amazon EC2 launch type with three container instances in one Availability Zone. Create a task definition for the web application. Place one task for each container instance.<br/>C. Create an Amazon Elastic Container Service (Amazon ECS) cluster using the Fargate launch type with one container instance in three different Availability Zones. Create a task definition for the web application. Create an ECS service with a desired count of three tasks.<br/>D. Create an Amazon Elastic Container Service (Amazon ECS) cluster using the Amazon EC2 launch type with one container instance in two different Availability Zones. Create a task definition for the web application. Place two tasks on one container instance and one task on the remaining container instance.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample322' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_155'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_361'>Random</a></p><div class='collapse' id='collapseExample322'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Create an Amazon Elastic Container Service (Amazon ECS) cluster using the Amazon EC2 launch type with one container instance in two different Availability Zones. Create a task definition for the web application. Place two tasks on one container instance and one task on the remaining container instance.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 19%;" aria-valuenow="19" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_155><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 155</p><br/>A solutions architect is designing the architecture of a new application being deployed to the AWS Cloud.<br/><br/>The application will run on Amazon EC2 On&#8211;Demand Instances and will automatically scale across multiple Availability Zones. The EC2 instances will scale up and down frequently throughout the day. An Application Load Balancer (ALB) will handle the load distribution. The architecture needs to support distributed session data management. The company is willing to make changes to code if needed.<br/><br/>What should the solutions architect do to ensure that the architecture supports distributed session data management?<br/><br/>A. Use Amazon ElastiCache to manage and store session data.<br/>B. Use session affinity (sticky sessions) of the ALB to manage session data.<br/>C. Use Session Manager from AWS Systems Manager to manage the session.<br/>D. Use the GetSessionToken API operation in AWS Security Token Service (AWS STS) to manage the session.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample295' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_156'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_255'>Random</a></p><div class='collapse' id='collapseExample295'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Use Amazon ElastiCache to manage and store session data.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 19%;" aria-valuenow="19" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_156><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 156</p><br/>A web application runs on Amazon EC2 instances behind an Application Load Balancer. The application allows users to create custom reports of historical weather data. Generating a report can take up to 5 minutes. These long&#8211;running requests use many of the available incoming connections, making the system unresponsive to other users.<br/><br/>How can a solutions architect make the system more responsive?<br/><br/>A. Use Amazon SQS with AWS Lambda to generate reports.<br/>B. Increase the idle timeout on the Application Load Balancer to 5 minutes.<br/>C. Update the client&#8211;side application code to increase its request timeout to 5 minutes.<br/>D. Publish the reports to Amazon S3 and use Amazon CloudFront for downloading to the user.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample77' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_157'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_558'>Random</a></p><div class='collapse' id='collapseExample77'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Use Amazon SQS with AWS Lambda to generate reports.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 19%;" aria-valuenow="19" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_157><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 157</p><br/>A solutions architect needs to deploy a node js&#8211;based web application that is highly available and scales automatically.<br/><br/>The marketing team needs to roll back on application releases quickly and they need to have an operational dashboard.<br/><br/>The Marketing team does not want to manage deployment of operating system patches to the Linux servers.<br/><br/>Which AWS service satisfies these requirements?<br/><br/>A. Amazon EC2<br/>B. Amazon API Gateway<br/>C. AWS Elastic Beanstalk<br/>D. Amazon EC2<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample633' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_158'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_191'>Random</a></p><div class='collapse' id='collapseExample633'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>AWS Elastic Beanstalk</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 19%;" aria-valuenow="19" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_158><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 158</p><br/>A company wants to host a web application on AWS that will communicate to a database within a VPC. The application should be highly available.<br/><br/>What should a solutions architect recommend?<br/><br/>A. Create two Amazon EC2 instances to host the web servers behind a load balancer, and then deploy the database on a large instance.<br/>B. Deploy a load balancer in multiple Availability Zones with an Auto Scaling group for the web servers, and then deploy Amazon RDS in multiple Availability Zones.<br/>C. Deploy a load balancer in the public subnet with an Auto Scaling group for the web servers, and then deploy the database on an Amazon EC2 instance in the private subnet.<br/>D. Deploy two web servers with an Auto Scaling group, configure a domain that points to the two web servers, and then deploy a database architecture in multiple Availability Zones.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample377' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_159'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_782'>Random</a></p><div class='collapse' id='collapseExample377'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Deploy a load balancer in multiple Availability Zones with an Auto Scaling group for the web servers, and then deploy Amazon RDS in multiple Availability Zones.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 20%;" aria-valuenow="20" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_159><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 159</p><br/>A company wants to move its on&#8211;premises network, attached storage (NAS) to AWS. The company wants to make the data available to any Linux instances within its VPC and ensure changes are automatically synchronized across all instances accessing the data store. The majority of the data is accessed very rarely, and some files are accessed by multiple users at the same time.<br/>Which solution meets these requirements and is MOST cost&#8211;effective?<br/><br/>A. Create an Amazon Elastic Block Store (Amazon EBS) snapshot containing the data. Share it with users within the VP<br/>B. Create an Amazon S3 bucket that has a lifecycle policy set to transition the data to S3 Standard&#8211;Infrequent Access (S3 Standard&#8211;IA) after the appropriate number of days.<br/>C. Create an Amazon Elastic File System (Amazon EFS) file system within the VP<br/>D. Set the throughput mode to Provisioned and to the required amount of IOPS to support concurrent usage.<br/>E. Create an Amazon Elastic File System (Amazon EFS) file system within the VP<br/>F. Set the lifecycle policy to transition the data to £FS Infrequent Access (EFS IA) after the appropriate number of days.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample508' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_160'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_236'>Random</a></p><div class='collapse' id='collapseExample508'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Create an Amazon Elastic File System (Amazon EFS) file system within the VP</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 20%;" aria-valuenow="20" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_160><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 160</p><br/>A company is running a highly sensitive application on Amazon EC2 backed by an Amazon RDS database Compliance regulations mandate that all personally identifiable information (Pll) be encrypted at rest.<br/><br/>Which solution should a solutions architect recommend to meet this requirement with the LEAST amount of changes to the infrastructure"<br/><br/>A. Deploy AWS Certificate Manager to generate certificates Use the certificates to encrypt the database volume<br/>B. Deploy AWS CloudHS<br/>C. generate encryption keys, and use the customer master key (CMK) to encrypt database volumes.<br/>D. Configure SSL encryption using AWS Key Management Service customer master keys (AWS KMS CMKs) to encrypt database volumes<br/>E. Configure Amazon Elastic Block Store {Amazon EBS) encryption and Amazon RDS encryption with AWS Key Management Service (AWS KMS) keys to encrypt instance and database volumes.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample492' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_161'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_727'>Random</a></p><div class='collapse' id='collapseExample492'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Configure SSL encryption using AWS Key Management Service customer master keys (AWS KMS CMKs) to encrypt database volumes</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 20%;" aria-valuenow="20" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_161><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 161</p><br/>A solutions architect has created two IAM policies: Policy1 and Policy2. Both policies are attached to an IAM group.<br/><br/>A solutions architect has created two IAM policies: Policy1 and Policy2. Both policies are attached to an IAM group.<br/><br/>A cloud engineer is added as an IAM user to the IAM group. Which action will the cloud engineer be able to perform?<br/><br/>A. Deleting IAM users<br/>B. Deleting directories<br/>C. Deleting Amazon EC2 instances<br/>D. Deleting logs from Amazon CloudWatch Logs<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample58' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_162'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_662'>Random</a></p><div class='collapse' id='collapseExample58'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Deleting Amazon EC2 instances</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 20%;" aria-valuenow="20" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_162><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 162</p><br/>A company's dynamic website is hosted using on&#8211;premises servers in the United States. The company is launching its product in Europe, and it wants to optimize site loading times for new European users. The site's backend must remain in the United States. The product is being launched in a few days, and an immediate solution is needed.<br/><br/>What should the solutions architect recommend?<br/><br/>A. Launch an Amazon EC2 instance in us&#8211;east&#8211;1 and migrate the site to it.<br/>B. Move the website to Amazon S3. Use cross&#8211;Region replication between Regions.<br/>C. Use Amazon CloudFront with a custom origin pointing to the on&#8211;premises servers.<br/>D. Use an Amazon Route 53 geo&#8211;proximity routing policy pointing to on&#8211;premises servers.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample106' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_163'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_50'>Random</a></p><div class='collapse' id='collapseExample106'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Use Amazon CloudFront with a custom origin pointing to the on-premises servers.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 20%;" aria-valuenow="20" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_163><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 163</p><br/>In Amazon EC2 Container Service components, what is the name of a logical grouping of container instances on which you can place tasks?<br/><br/>A. A cluster<br/>B. A container instance<br/>C. A container<br/>D. A task definition<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample783' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation783' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_164'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_375'>Random</a></p><div class='collapse' id='collapseExample783'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>A cluster</div></div></div><div class='collapse' id='explanation783'><div class='card card&#45;body'><div>
Amazon ECS contains the following components:

A Cluster is a logical grouping of container instances that you can place tasks on. A Container instance is an Amazon EC2 instance that is running the Amazon ECS agent and has been registered into a cluster.

A Task definition is a description of an application that contains one or more container definitions. A Scheduler is the method used for placing tasks on container instances. A Service is an Amazon ECS service that allows you to run and maintain a specified number of instances of a task definition simultaneously.

A Task is an instantiation of a task definition that is running on a container instance. A Container is a Linux container that was created as part of a task.
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 20%;" aria-valuenow="20" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_164><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 164</p><br/>A data science team requires storage for nightly log processing. The size and number of logs is unknown and will persist for 24 hours only.<br/><br/>What is the MOST cost&#8211;effective solution?<br/><br/>A. Amazon S3 Glacier<br/>B. Amazon S3 Standard<br/>C. Amazon S3 Intelligent&#8211;Tiering<br/>D. Amazon S3 One Zone&#8211;Infrequent Access (S3 One Zone&#8211;IA)<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample30' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation30' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_165'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_214'>Random</a></p><div class='collapse' id='collapseExample30'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Amazon S3 Standard</div></div></div><div class='collapse' id='explanation30'><div class='card card&#45;body'><div>
The S3 Intelligent-Tiering storage class is designed to optimize costs by automatically moving data to the most cost-effective access tier, without performance impact or operational overhead. It works by storing objects in two access tiers: one tier that is optimized for frequent access and another lower-cost tier that is optimized for infrequent access. This is an ideal use case for intelligent-tiering as the access patterns for the log files are not known.

CORRECT: "S3 Intelligent-Tiering" is the correct answer.

INCORRECT: "S3 Standard-Infrequent Access (S3 Standard-IA)" is incorrect as if the data is accessed often retrieval fees could become expensive.

INCORRECT: "S3 One Zone-Infrequent Access (S3 One Zone-IA)" is incorrect as if the data is accessed often retrieval fees could become expensive.

INCORRECT: "S3 Glacier" is incorrect as if the data is accessed often retrieval fees could become expensive. Glacier also requires more work in retrieving the data from the archive and quick access requirements can add further costs.

References:

Unknown or changing access</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 20%;" aria-valuenow="20" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_165><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 165</p><br/>A company is making a prototype of the infrastructure for its new website by manually provisioning the necessary infrastructure.<br/><br/>This infrastructure includes an Auto Scaling group an Application Load Balancer, and an Amazon RDS database.<br/><br/>After the configuration has been thoroughly validated the company wants the capability to immediately deploy the infrastructure for development and production use in two Availability Zones in an automated fashion.<br/><br/>What should a solutions architect recommend to meet these requirements?<br/><br/>A. Use AWS Systems Manager to replicate and provision the prototype infrastructure in two Availability Zones<br/>B. Define the infrastructure as a template by using the prototype infrastructure as a guide Deploy the infrastructure with AWS CloudFormation<br/>C. Use AWS Config to record the inventory of resources that are used in the prototype infrastructure Use AWS Config to deploy the prototype infrastructure into two Availability Zones.<br/>D. Use AWS Elastic Beanstalk and configure it to use an automated reference to the prototype infrastructure to automatically deploy new environments in two Availability Zones<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample625' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_166'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_114'>Random</a></p><div class='collapse' id='collapseExample625'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Define the infrastructure as a template by using the prototype infrastructure as a guide Deploy the infrastructure with AWS CloudFormation</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 20%;" aria-valuenow="20" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_166><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 166</p><br/>A company's production application runs online transaction processing (OLTP) transactions on an Amazon RDS MySQL DB instance. The company is launching a new reporting tool that will access the same data.<br/><br/>The reporting tool must be highly available and not impact the performance of the production application.<br/><br/>How can this be achieved?<br/><br/>A. Create hourly snapshots of the production RDS DB instance.<br/>B. Create a Multi&#8211;AZ RDS Read Replica of the production RDS DB instance.<br/>C. Create multiple RDS Read Replicas of the production RDS DB instance. Place the Read Replicas in an Auto Scaling group.<br/>D. Create a Single&#8211;AZ RDS Read Replica of the production RDS DB instance. Create a second Single&#8211;AZ RDS Read Replica from the replica.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample27' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation27' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_167'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_597'>Random</a></p><div class='collapse' id='collapseExample27'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Create a Multi-AZ RDS Read Replica of the production RDS DB instance.</div></div></div><div class='collapse' id='explanation27'><div class='card card&#45;body'><div>
Amazon RDS Read Replicas Now Support Multi-AZ Deployments

Amazon RDS Read Replicas enable you to create one or more read-only copies of your database instance within the same AWS Region or in a different AWS Region. Updates made to the source database are then asynchronously copied to your Read Replicas. In addition to providing scalability for read-heavy workloads, Read Replicas can be promoted to become a standalone database instance when needed.

Amazon RDS Multi-AZ deployments provide enhanced availability for database instances within a single AWS Region. With Multi-AZ, your data is synchronously replicated to a standby in a different Availability Zone (AZ). In the event of an infrastructure failure, Amazon RDS performs an automatic failover to the standby, minimizing disruption to your applications.

You can now use Read Replicas with Multi-AZ as part of a disaster recovery (DR) strategy for your production databases. A well-designed and tested DR plan is critical for maintaining business continuity after a disaster. A Read Replica in a different region than the source database can be used as a standby database and promoted to become the new production database in case of a regional disruption.

You can create a read replica as a Multi-AZ DB instance. Amazon RDS creates a standby of your replica in another Availability Zone for failover support for the replica. Creating your read replica as a Multi-AZ DB instance is independent of whether the source database is a Multi-AZ DB instance.

CORRECT: "Create a Multi-AZ RDS Read Replica of the production RDS DB instance" is the correct answer.

INCORRECT: "Create a Single-AZ RDS Read Replica of the production RDS DB instance. Create a second Single-AZ RDS Read Replica from the replica" is incorrect. Read replicas are primarily used for horizontal scaling. The best solution for high availability is to use a Multi-AZ read replica.

INCORRECT: "Create a cross-region Multi-AZ deployment and create a read replica in the second region" is incorrect as you cannot create a cross-region Multi-AZ deployment with RDS. INCORRECT: "Use Amazon Data Lifecycle Manager to automatically create and manage snapshots" is incorrect as using snapshots is not the best solution for high availability.

References:

Amazon Relational Database Service > User Guide > What is Amazon Relational Database Service (Amazon RDS)?</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 21%;" aria-valuenow="21" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_167><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 167</p><br/>A solutions architect must analyze and update a company's existing IAM policies prior to deploying a new workload. The solutions architect created the following policy:<br/><br/>A solutions architect must analyze and update a company's existing IAM policies prior to deploying a new workload.<br/><br/>What is the net effect of this policy?<br/><br/>A. Users will be allowed all actions except s3:PutObject if multi&#8211;factor authentication (MFA) is enabled.<br/>B. Users will be allowed all actions except s3:PutObject if multi&#8211;factor authentication (MFA) is not enabled.<br/>C. Users will be denied all actions except s3:PutObject if multi&#8211;factor authentication (MFA) is enabled.<br/>D. Users will be denied all actions except s3:PutObject if multi&#8211;factor authentication (MFA) is not enabled.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample330' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_168'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_652'>Random</a></p><div class='collapse' id='collapseExample330'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Users will be denied all actions except s3:PutObject if multi-factor authentication (MFA) is enabled.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 21%;" aria-valuenow="21" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_168><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 168</p><br/>A software vendor is deploying a new software&#8211;as&#8211;a&#8211;service (SaaS) solution that will be utilized by many AWS users. The service is hosted in a VPC behind a Network Load Balancer. The software vendor wants to provide access to this service to users with the least amount of administrative overhead and without exposing the service to the public internet.<br/><br/>What should a solutions architect do to accomplish this goal?<br/><br/>A. Create a peering VPC connection from each user's VPC to the software vendor's VPC.<br/>B. Deploy a transit VPC in the software vendor's AWS account. Create a VPN connection with each user account.<br/>C. Connect the service in the VPC with an AWS Private Link endpoint. Have users subscribe to the endpoint.<br/>D. Deploy a transit VPC in the software vendor's AWS account. Create an AWS Direct Connect connection with each user account.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample257' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_169'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_518'>Random</a></p><div class='collapse' id='collapseExample257'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Connect the service in the VPC with an AWS Private Link endpoint. Have users subscribe to the endpoint.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 21%;" aria-valuenow="21" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_169><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 169</p><br/>A company is hosting an election reporting website on AWS for users around the world. The website uses Amazon EC2 instances for the web and application tiers in an Auto Scaling group with Application Load Balancers. The database tier uses an Amazon RDS for MySQL database. The website is updated with election results once an hour and has historically observed hundreds of users accessing the reports.<br/><br/>The company is expecting a significant increase in demand because of upcoming elections in different countries. A solutions architect must improve the website's ability to handle additional demand while minimizing the need for additional EC2 instances.<br/><br/>Which solution will meet these requirements?<br/><br/>A. Launch an Amazon ElastiCache cluster to cache common database queries.<br/>B. Launch an Amazon CloudFront web distribution to cache commonly requested website content.<br/>C. Enable disk&#8211;based caching on the EC2 instances to cache commonly requested website content.<br/>D. Deploy a reverse proxy into the design using an EC2 instance with caching enabled for commonly requested website content.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample129' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_170'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_169'>Random</a></p><div class='collapse' id='collapseExample129'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Launch an Amazon CloudFront web distribution to cache commonly requested website content.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 21%;" aria-valuenow="21" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_170><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 170</p><br/>A company built an application that lets users check in to places they visit, rank the places, and add reviews about their experiences. The application is successful with a rapid increase in the number of users every month.<br/><br/>The chief technology officer fears the database supporting the current Infrastructure may not handle the new load the following month because the single Amazon RDS for MySQL instance has triggered alarms related to resource exhaustion due to read requests.<br/><br/>What can a solutions architect recommend to prevent service Interruptions at the database layer with minimal changes to code?<br/><br/>A. Create RDS read replicas and redirect read&#8211;only traffic to the read replica endpoints. Enable a Multi&#8211;AZ deployment.<br/>B. Create an Amazon EMR cluster and migrate the data to a Hadoop Distributed File System (HDFS) with a replication factor of 3.<br/>C. Create an Amazon ElastiCache cluster and redirect all read&#8211;only traffic to the cluster. Set up the cluster to be deployed in three Availability Zones.<br/>D. Create an Amazon DynamoDB table to replace the RDS instance and redirect all read&#8211;only traffic to the DynamoDB table. Enable DynamoDB Accelerator to offload traffic from the main table.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample191' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_171'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_319'>Random</a></p><div class='collapse' id='collapseExample191'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Create RDS read replicas and redirect read-only traffic to the read replica endpoints. Enable a Multi-AZ deployment.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 21%;" aria-valuenow="21" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_171><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 171</p><br/>A solutions architect is creating a new Amazon CloudFront distribution for an application. Some of the information submitted by users is sensitive. The application uses HTTPS but needs another layer of security. The sensitive information should be protected throughout the entire application stack, and access to the information should be restricted to certain applications.<br/><br/>Which action should the solutions architect take?<br/><br/>A. Configure a CloudFront signed URL<br/>B. Configure a CloudFront signed cookie.<br/>C. Configure a CloudFront field&#8211;level encryption profile.<br/>D. Configure a CloudFront and set the Origin Protocol Policy setting to HTTPS. Only for the Viewer Protocol Pokey.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample324' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_172'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_247'>Random</a></p><div class='collapse' id='collapseExample324'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Configure a CloudFront signed URL</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 21%;" aria-valuenow="21" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_172><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 172</p><br/>A computer is reviewing a recent migration of a three&#8211;tier application to a VPC. The security team discover that the principle of least privilege is not being applied to Amazon EC2 security group ingress and egress rules between the application tiers.<br/><br/>What should a solution architect do to connect issue?<br/><br/>A. Create security group rules using the instance ID as the source destination.<br/>B. Create security group rules using the security ID as the source or destination.<br/>C. Create security group rules using the VPC CDR blocks as the source or destination<br/>D. Create security group rules using the subnet CDR blocks as the source or destination<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample441' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_173'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_273'>Random</a></p><div class='collapse' id='collapseExample441'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Create security group rules using the instance ID as the source destination.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 21%;" aria-valuenow="21" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_173><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 173</p><br/>A company has a custom application running on an Amazon EC instance that:<br/><br/>Reads a large amount of data from Amazon S3<br/>Performs a multi&#8211;stage analysis<br/>Writes the results to Amazon DynamoDB<br/>The application writes a significant number of large, temporary files during the multi&#8211;stage analysis. The process performance depends on the temporary storage performance.<br/><br/>What would be the fastest storage option for holding the temporary files?<br/><br/>A. Multiple Amazon S3 buckets with Transfer Acceleration for storage.<br/>B. Multiple Amazon EBS drives with Provisioned IOPS and EBS optimization.<br/>C. Multiple Amazon EFS volumes using the Network File System version 4.1 (NFSv4.1) protocol.<br/>D. Multiple instance store volumes with software RAID 0.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample114' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_174'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_506'>Random</a></p><div class='collapse' id='collapseExample114'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Multiple Amazon S3 buckets with Transfer Acceleration for storage.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 21%;" aria-valuenow="21" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_174><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 174</p><br/>A company Is seeing access requests by some suspicious IP addresses. The security team discovers the requests are horn different IP addresses under the same CIDR range.<br/><br/>What should a solutions architect recommend to the team?<br/><br/>A. Add a deny rule in the outbound table of the network ACL with a tower rule number than other rules.<br/>B. Add a rule In the outbound table of the security group to deny the traffic from that CIDR range.<br/>C. Add a deny rule in the Inbound table of the network ACL with a lower rule number than other rules.<br/>D. Add a rule in the inbound table of the security group to deny the traffic from that CIDR range.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample512' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_175'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_480'>Random</a></p><div class='collapse' id='collapseExample512'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Add a deny rule in the Inbound table of the network ACL with a lower rule number than other rules.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 22%;" aria-valuenow="22" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_175><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 175</p><br/>A company hosts a multi&#8211;tier web application that uses an Amazon Aurora MySQL DB cluster for storage. The application tier is hosted on Amazon EC2 instances. The company's IT security guidelines mandate that the database credentials be encrypted and rotated every 14 days.<br/><br/>What should a solutions architect do to meet this requirement with the LEAST operational effort?<br/><br/>A. Create a new AWS Key Management Service (AWS KMS) encryption key. Use AWS Secrets Manager to create a new secret that uses the KMS key with the appropriate credentials. Associate the secret with the Aurora DB cluster. Configure a custom rotation period of 14 days.<br/>B. Create two parameters in AWS Systems Manager Parameter Store: one for the user name as a string parameter and one that uses the SecureString type for the password. Select AWS Key Management Service (AWS KMS) encryption for the password parameter, and load these parameters in the application tier. Implement an AWS Lambda function that rotates the password every 14 days.<br/>C. Store a file that contains the credentials in an AWS Key Management Service (AWS KMS) encrypted Amazon Elastic File System (Amazon EFS) file system. Mount the EFS file system in all EC2 instances of the application tier. Restrict the access to the file on the file system so that the application can read the file and that only super users can modify the file. Implement an AWS Lambda function that rotates the key in Aurora every 14 days and writes new credentials into the file.<br/>D. Store a file that contains the credentials in an AWS Key Management Service (AWS KMS) encrypted Amazon S3 bucket that the application uses to load the credentials. Download the file to the application regularly to ensure that the correct credentials are used. Implement an AWS Lambda function that rotates the Aurora credentials every 14 days and uploads these credentials to the file in the S3 bucket.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample418' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_176'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_61'>Random</a></p><div class='collapse' id='collapseExample418'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Create two parameters in AWS Systems Manager Parameter Store: one for the user name as a string parameter and one that uses the SecureString type for the password. Select AWS Key Management Service (AWS KMS) encryption for the password parameter, and load these parameters in the application tier. Implement an AWS Lambda function that rotates the password every 14 days.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 22%;" aria-valuenow="22" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_176><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 176</p><br/>A solutions architect must migrate a Windows internet information Services (IIS) web application to AWS.<br/><br/>The application currently relies on a file share hosted in the user's on&#8211;premises network&#8211;attached storage (NAS). The solutions architected has proposed migrating the IIS web servers.<br/><br/>Which replacement to the on&#8211;premises file share is MOST resilient and durable?<br/><br/>A. Migrate the file Share to Amazon RDS.<br/>B. Migrate the file Share to AWS Storage Gateway<br/>C. Migrate the file Share to Amazon FSx for Windows File Server.<br/>D. Migrate the file share to Amazon Elastic File System (Amazon EFS)<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample97' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_177'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_554'>Random</a></p><div class='collapse' id='collapseExample97'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Migrate the file Share to Amazon FSx for Windows File Server.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 22%;" aria-valuenow="22" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_177><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 177</p><br/>A mobile gaming company runs application servers on Amazon EC2 instances. The servers receive updates from players every 15 minutes. The mobile game creates a JSON object of the progress made in the game since the last update, and sends the JSON object to an Application Load Balancer. As the mobile game is played, game updates are being lost. The company wants to create a durable way to get the updates in older.<br/><br/>What should a solutions architect recommend to decouple the system?<br/><br/>A. Use Amazon Kinesis Data Streams to capture the data and store the JSON object in Amazon S3.<br/>B. Use Amazon Kinesis Data Firehose to capture the data and store the JSON object in Amazon S3.<br/>C. Use Amazon Simple Queue Service (Amazon SQS) FIFO queues to capture the data and EC2 instances to process the messages in the queue.<br/>D. Use Amazon Simple Notification Service (Amazon SNS) to capture the data and EC2 instances to process the messages sent to the Application Load Balancer.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample404' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_178'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_630'>Random</a></p><div class='collapse' id='collapseExample404'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Use Amazon Simple Queue Service (Amazon SQS) FIFO queues to capture the data and EC2 instances to process the messages in the queue.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 22%;" aria-valuenow="22" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_178><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 178</p><br/>A development team is collaborating with another company to create an integrated product. The other company needs to access an Amazon Simple Queue Service (Amazon SQS) queue that is contained in the development team's account. The other company wants to poll the queue without giving up its own account permissions to do so.<br/><br/>How should a solutions architect provide access to the SQS queue?<br/><br/>A. Create an instance profile that provides the other company access to the SQS queue.<br/>B. Create an IAM policy that provides the other company access to the SQS queue.<br/>C. Create an SQS access policy that provides the other company access to the SQS queue.<br/>D. Create an Amazon Simple Notification Service (Amazon SNS) access policy that provides the other company access to the SQS queue.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample333' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_179'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_262'>Random</a></p><div class='collapse' id='collapseExample333'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Create an SQS access policy that provides the other company access to the SQS queue.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 22%;" aria-valuenow="22" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_179><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 179</p><br/>An ecommerce company is running a multi&#8211;tier application on AWS. The front&#8211;end and backend tiers both run on Amazon EC2, and the database runs on Amazon RDS for MySQL. The backend tier communicates with the RDS instance. There are frequent calls to return identical datasets from the database that are causing performance slowdowns.<br/><br/>Which action should be taken to improve the performance of the backend?<br/><br/>A. Implement Amazon SNS to store the database calls.<br/>B. Implement Amazon ElastiCache to cache the large datasets.<br/>C. Implement an RDS for MySQL read replica to cache database calls.<br/>D. Implement Amazon Kinesis Data Firehose to stream the calls to the database.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample196' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_180'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_550'>Random</a></p><div class='collapse' id='collapseExample196'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Implement Amazon ElastiCache to cache the large datasets.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 22%;" aria-valuenow="22" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_180><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 180</p><br/>A company mandates that an Amazon S3 gateway endpoint must allow traffic to trusted buckets only.<br/><br/>Which method should a solutions architect implement to meet this requirement?<br/><br/>A. Create a bucket policy for each of the company's trusted S3 buckets that allows traffic only from the company's trusted VPCs.<br/>B. Create a bucket policy for each of the company's trusted S3 buckets that allows traffic only from the company's S3 gateway endpoint IDs.<br/>C. Create an S3 endpoint policy for each of the company's S3 gateway endpoints that blocks access from any VPC other than the company's trusted VPCs.<br/>D. Create an S3 endpoint policy for each of the company's S3 gateway endpoints that provides access to the Amazon Resource Name (ARN) of the trusted S3 buckets.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample205' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_181'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_440'>Random</a></p><div class='collapse' id='collapseExample205'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Create an S3 endpoint policy for each of the company's S3 gateway endpoints that provides access to the Amazon Resource Name (ARN) of the trusted S3 buckets.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 22%;" aria-valuenow="22" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_181><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 181</p><br/>A company is planning to build a new web application on AWS. The company expects predictable traffic most of the year and very high traffic on occasion. The web application needs to be highly available and fault tolerant with minimal latency.<br/><br/>What should a solutions architect recommend to meet these requirements?<br/><br/>A. Use an Amazon Route 53 routing policy to distribute requests to two AWS Regions, each with one Amazon EC2 instance.<br/>B. Use Amazon EC2 instances in an Auto Scaling group with an Application Load Balancer across multiple Availability Zones.<br/>C. Use Amazon EC2 instances in a cluster placement group with an Application Load Balancer across multiple Availability Zones.<br/>D. Use Amazon EC2 instances in a cluster placement group and include the cluster placement group within a new Auto Scaling group.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample100' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_182'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_675'>Random</a></p><div class='collapse' id='collapseExample100'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Use Amazon EC2 instances in an Auto Scaling group with an Application Load Balancer across multiple Availability Zones.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 22%;" aria-valuenow="22" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_182><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 182</p><br/>A three&#8211;tier web application processes orders from customers. The web tier consists of Amazon EC2 instances behind an Application Load Balancer, a middle tier of three EC2 instances decoupled from the web tier using Amazon SQS. and an Amazon DynamoDB backend. At peak times, customers who submit orders using the site have to wait much longer than normal to receive confirmations due to lengthy processing times. A solutions architect needs to reduce these processing times.<br/><br/>Which action will be MOST effective in accomplishing this?<br/><br/>A. Replace the SQS queue with Amazon Kinesis Data Firehose.<br/>B. Use Amazon ElastiCache for Redis in front of the DynamoDB backend tier.<br/>C. Add an Amazon CloudFront distribution to cache the responses for the web tier.<br/>D. Use Amazon EC2 Auto Scaling to scale out the middle tier instances based on the SOS queue depth.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample497' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_183'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_781'>Random</a></p><div class='collapse' id='collapseExample497'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Use Amazon EC2 Auto Scaling to scale out the middle tier instances based on the SOS queue depth.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 23%;" aria-valuenow="23" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_183><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 183</p><br/>A company receives 10 TB of instrumentation data each day from several machines located at a single factory. The data consists of JSON files stored on a storage area network (SAN) in an on&#8211;premises data center located within the factory. The company wants to send this data to Amazon S3 where it can be accessed by several additional systems that provide critical near&#8211;real&#8211;lime analytics. A secure transfer is important because the data is considered sensitive.<br/><br/>Which solution offers the MOST reliable data transfer?<br/><br/>A. AWS DataSync over public internet<br/>B. AWS DataSync over AWS Direct Connect<br/>C. AWS Database Migration Service (AWS DMS) over public internet<br/>D. AWS Database Migration Service (AWS DMS) over AWS Direct Connect<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample298' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_184'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_212'>Random</a></p><div class='collapse' id='collapseExample298'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>AWS Database Migration Service (AWS DMS) over AWS Direct Connect</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 23%;" aria-valuenow="23" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_184><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 184</p><br/>A company has an eCommerce application that stores data in an on&#8211;premises SQL database. The company has decided to migrate this database to AWS. However, as part of the migration, the company wants to find a way to attain sub&#8211;millisecond responses to common read requests.<br/><br/>A solutions architect knows that the increase in speed is paramount and that a small percentage of stale data returned in the database reads is acceptable.<br/><br/>What should the solutions architect recommend?<br/><br/>A. Build Amazon RDS read replicas.<br/>B. Build the database as a larger instance type.<br/>C. Build a database cache using Amazon ElastiCache.<br/>D. Build a database cache using Amazon Elasticsearch Service (Amazon ES).<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample282' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation282' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_185'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_670'>Random</a></p><div class='collapse' id='collapseExample282'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Build a database cache using Amazon ElastiCache.</div></div></div><div class='collapse' id='explanation282'><div class='card card&#45;body'><div>
To attain sub-millisecond responses to common read requests. REDIS (REmote DIctionary Server) delivers sub-millisecond response times enabling millions of requests per second for real-time applications.
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 23%;" aria-valuenow="23" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_185><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 185</p><br/>A company wants to automate the security assessment of its Amazon EC2 instances. The company needs to validate and demonstrate that security and compliance standards are being followed throughout the development process.<br/><br/>What should a solutions architect do to meet these requirements?<br/><br/>A. Use Amazon Macie to automatically discover, classify and protect the EC2 instances.<br/>B. Use Amazon GuardDuty to publish Amazon Simple Notification Service (Amazon SNS) notifications.<br/>C. Use Amazon Inspector with Amazon CloudWatch to publish Amazon Simple Notification Service (Amazon SNS) notifications<br/>D. Use Amazon EventBridge (Amazon CloudWatch Events) to detect and react to changes in the status of AWS Trusted Advisor checks.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample327' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_186'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_472'>Random</a></p><div class='collapse' id='collapseExample327'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Use Amazon Inspector with Amazon CloudWatch to publish Amazon Simple Notification Service (Amazon SNS) notifications</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 23%;" aria-valuenow="23" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_186><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 186</p><br/>A three&#8211;tier web application processes orders from customers. The web tier consists of Amazon EC2 instances behind an Application Load Balancer, a middle tier of three EC2 instances decoupled from the web tier using Amazon SQS, and an Amazon DynamoDB backend. At peak times, customers who submit orders using the site have to wait much longer than normal to receive confirmations due to lengthy processing times. A solutions architect needs to reduce these processing times.<br/><br/>Which action will be MOST effective in accomplishing this?<br/><br/>A. Replace the SQS queue with Amazon Kinesis Data Firehose.<br/>B. Use Amazon ElastiCache for Redis in front of the DynamoDB backend tier.<br/>C. Add an Amazon CloudFront distribution to cache the responses for the web tier.<br/>D. Use Amazon EC2 Auto Scaling to scale out the middle tier instances based on the SQS queue depth.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample79' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_187'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_215'>Random</a></p><div class='collapse' id='collapseExample79'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Use Amazon EC2 Auto Scaling to scale out the middle tier instances based on the SQS queue depth.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 23%;" aria-valuenow="23" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_187><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 187</p><br/>A solutions architect must design a solution for a persistent database that is being migrated from on&#8211;premises to AWS. The database requires 64,000 IOPS according to the database administrator. If possible, the database administrator wants to use a single Amazon Elastic Block Store (Amazon EBS) volume to host the database instance.<br/><br/>Which solution effectively meets the database administrator's criteria?<br/><br/>A. Use an instance from the I3 I/O optimized family and leverage local ephemeral storage to achieve the IOPS requirement.<br/>B. Create an Nitro&#8211;based Amazon EC2 instance with an Amazon EBS Provisioned IOPS SSD (io1) volume attached. Configure the volume to have 64,000 IOPS.<br/>C. Create and map an Amazon Elastic File System (Amazon EFS) volume to the database instance and use the volume to achieve the required IOPS for the database.<br/>D. Provision two volumes and assign 32,000 IOPS to each. Create a logical volume at the operating system level that aggregates both volumes to achieve the IOPS requirements.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample166' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_188'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_569'>Random</a></p><div class='collapse' id='collapseExample166'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Create an Nitro-based Amazon EC2 instance with an Amazon EBS Provisioned IOPS SSD (io1) volume attached. Configure the volume to have 64,000 IOPS.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 23%;" aria-valuenow="23" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_188><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 188</p><br/>A solutions architect is designing the cloud architecture for a new application being deployed on AWS. The process should run in parallel while adding and removing application nodes as needed based on the number of jobs to be processed. The processor application is stateless. The solutions architect must ensure that the application is loosely coupled and the job items are durably stored.<br/><br/>Which design should the solutions architect use?<br/><br/>A. Create an Amazon SNS topic to send the jobs that need to be processed. Create an Amazon Machine Image (AMI) that consists of the processor application. Create a launch configuration that uses the AMI. Create an Auto Scaling group using the launch configuration. Set the scaling policy for the Auto Scaling group to add and remove nodes based on CPU usage.<br/>B. Create an Amazon SQS queue to hold the jobs that need to be processed. Create an Amazon Machine Image (AMI) that consists of the processor application. Create a launch configuration that uses the AMI. Create an Auto Scaling group using the launch configuration. Set the scaling policy for the Auto Scaling group to add and remove nodes based on network usage.<br/>C. Create an Amazon SQS queue to hold the jobs that need to be processed. Create an Amazon Machine Image (AMI) that consists of the processor application. Create a launch template that uses the AMI. Create an Auto Scaling group using the launch template. Set the scaling policy for the Auto Scaling group to add and remove nodes based on the number of items in the SQS queue.<br/>D. Create an Amazon SNS topic to send the jobs that need to be processed. Create an Amazon Machine Image (AMI) that consists of the processor application. Create a launch template that uses the AMI. Create an Auto Scaling group using the launch template. Set the scaling policy for the Auto Scaling group to add and remove nodes based on the number of messages published to the SNS topic.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample189' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation189' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_189'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_657'>Random</a></p><div class='collapse' id='collapseExample189'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Create an Amazon SQS queue to hold the jobs that need to be processed. Create an Amazon Machine Image (AMI) that consists of the processor application. Create a launch template that uses the AMI. Create an Auto Scaling group using the launch template. Set the scaling policy for the Auto Scaling group to add and remove nodes based on the number of items in the SQS queue.</div></div></div><div class='collapse' id='explanation189'><div class='card card&#45;body'><div>
Amazon Simple Queue Service (SQS) is a fully managed message queuing service that enables you to decouple and scale microservices, distributed systems, and serverless applications. SQS eliminates the complexity and overhead associated with managing and operating message oriented middleware, and empowers developers to focus on differentiating work. Using SQS, you can send, store, and receive messages between software components at any volume, without losing messages or requiring other services to be available. Get started with SQS in minutes using the AWS console, Command Line Interface or SDK of your choice, and three simple commands.

SQS offers two types of message queues. Standard queues offer maximum throughput, best-effort ordering, and at-least-once delivery. SQS FIFO queues are designed to guarantee that messages are processed exactly once, in the exact order that they are sent.

Scaling Based on Amazon SQS
There are some scenarios where you might think about scaling in response to activity in an Amazon SQS queue. For example, suppose that you have a web app that lets users upload images and use them online. In this scenario, each image requires resizing and encoding before it can be published. The app runs on EC2 instances in an Auto Scaling group, and it's configured to handle your typical upload rates. Unhealthy instances are terminated and replaced to maintain current instance levels at all times. The app places the raw bitmap data of the images in an SQS queue for processing. It processes the images and then publishes the processed images where they can be viewed by users. The architecture for this scenario works well if the number of image uploads doesn't vary over time. But if the number of uploads changes over time, you might consider using dynamic scaling to scale the capacity of your Auto Scaling group.

In this case we need to find a durable and loosely coupled solution for storing jobs. Amazon SQS is ideal for this use case and can be configured to use dynamic scaling based on the number of jobs waiting in the queue.

To configure this scaling you can use the backlog per instance metric with the target value being the acceptable backlog per instance to maintain. You can calculate these numbers as follows: Backlog per instance: To calculate your backlog per instance, start with the ApproximateNumberOfMessages queue attribute to determine the length of the SQS queue (number of messages available for retrieval from the queue). Divide that number by the fleet's running capacity, which for an Auto Scaling group is the number of instances in the InService state, to get the backlog per instance.

Acceptable backlog per instance: To calculate your target value, first determine what your application can accept in terms of latency. Then, take the acceptable latency value and divide it by the average time that an EC2 instance takes to process a message.

This solution will scale EC2 instances using Auto Scaling based on the number of jobs waiting in the SQS queue.

CORRECT: "Create an Amazon SQS queue to hold the jobs that needs to be processed. Create an Amazon EC2 Auto Scaling group for the compute application. Set the scaling policy for the Auto Scaling group to add and remove nodes based on the number of items in the SQS queue" is the correct answer.

INCORRECT: "Create an Amazon SQS queue to hold the jobs that need to be processed. Create an Amazon EC2 Auto Scaling group for the compute application. Set the scaling policy for the Auto Scaling group to add and remove nodes based on network usage" is incorrect as scaling on network usage does not relate to the number of jobs waiting to be processed.

INCORRECT: "Create an Amazon SNS topic to send the jobs that need to be processed. Create an Amazon EC2 Auto Scaling group for the compute application. Set the scaling policy for the

Auto Scaling group to add and remove nodes based on CPU usage" is incorrect. Amazon SNS is a notification service so it delivers notifications to subscribers. It does store data durably but is less suitable than SQS for this use case. Scaling on CPU usage is not the best solution as it does not relate to the number of jobs waiting to be processed.

INCORRECT: "Create an Amazon SNS topic to send the jobs that need to be processed. Create an Amazon EC2 Auto Scaling group for the compute application. Set the scaling policy for the Auto Scaling group to add and remove nodes based on the number of messages published to the SNS topic" is incorrect. Amazon SNS is a notification service so it delivers notifications to subscribers. It does store data durably but is less suitable than SQS for this use case. Scaling on the number of notifications in SNS is not possible.

References:

Amazon EC2 Auto Scaling > User Guide > Scaling based on Amazon SQS</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 23%;" aria-valuenow="23" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_189><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 189</p><br/>A company experienced a breach from an attacker on its on&#8211;premises network.<br/><br/>The attacker launched port scanning, waged on outbound Dos attack, and performed crypto currency mining.<br/><br/>The company is moving to AWS to build a more resilient architecture that monitors and remediate this type the attack on the account level.<br/><br/>How should the company use AWS services to meet these requirements?<br/><br/>A. Enable Amazon GuardDuty to generate findings. Trigger AWS Lambda for automated remediation of identified threats.<br/>B. Enable AWS Config and configure policies to monitor against breaches. Trigger AWS Lambda for automated remediation of non&#8211;compliant resources<br/>C. Enable Amazon Macie to identify and classify security threats. Configure events in Amazon EventBridge (Amazon CloudWatch Events) to trigger actions based on the severity of threats.<br/>D. Enable Amazon inspector to generate assessment reports. Configure events in Amazon EventBridge (Amazon CloudWatch Events) to trigger actions based on identified threat.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample607' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_190'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_44'>Random</a></p><div class='collapse' id='collapseExample607'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Enable Amazon GuardDuty to generate findings. Trigger AWS Lambda for automated remediation of identified threats.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 23%;" aria-valuenow="23" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_190><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 190</p><br/>A company hosts an application on an Amazon EC2 instance that requires a maximum of 200 GB storage space. The application is used infrequently, with peaks during mornings and evenings. Disk I/O varies, but peaks at 3,000 IOPS. The chief financial officer of the company is concerned about costs and has asked a solutions architect to recommend the most cost&#8211;effective storage option that does not sacrifice performance.<br/><br/>Which solution should the solutions architect recommend?<br/><br/>A. Amazon EBS Cold HDD (sc1)<br/>B. Amazon EBS General Purpose SSD (gp2)<br/>C. Amazon EBS Provisioned IOPS SSD (io1)<br/>D. Amazon EBS Throughput Optimized HDD (st1)<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample199' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation199' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_191'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_217'>Random</a></p><div class='collapse' id='collapseExample199'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Amazon EBS General Purpose SSD (gp2)</div></div></div><div class='collapse' id='explanation199'><div class='card card&#45;body'><div>
General Purpose SSD (gp2) volumes offer cost-effective storage that is ideal for a broad range of workloads. These volumes deliver single-digit millisecond latencies and the ability to burst to 3,000 IOPS for extended periods of time.

Between a minimum of 100 IOPS (at 33.33 GiB and below) and a maximum of 16,000 IOPS (at 5,334 GiB and above), baseline performance scales linearly at 3 IOPS per GiB of volume size. AWS designs gp2 volumes to deliver their provisioned performance 99% of the time. A gp2 volume can range in size from 1 GiB to 16 TiB.

In this case the volume would have a baseline performance of 3 x 200 = 600 IOPS. The volume could also burst to 3,000 IOPS for extended periods. As the I/O varies, this should be suitable. CORRECT: "Amazon EBS General Purpose SSD (gp2)" is the correct answer.

INCORRECT: "Amazon EBS Provisioned IOPS SSD (io1) " is incorrect as this would be a more expensive option and is not required for the performance characteristics of this workload.

INCORRECT: "Amazon EBS Cold HDD (sc1)" is incorrect as there is no IOPS SLA for HDD volumes and they would likely not perform well enough for this workload.

INCORRECT: "Amazon EBS Throughput Optimized HDD (st1)" is incorrect as there is no IOPS SLA for HDD volumes and they would likely not perform well enough for this workload.

References:
Amazon Elastic Compute Cloud > User Guide for Linux Instances > Amazon EBS volume types
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 24%;" aria-valuenow="24" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_191><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 191</p><br/>A company's lease of a co&#8211;located storage facility will expire in 90 days. The company wants to move to AWS to avoid signing a contract extension. The company's environment consists of 200 virtual machines and a NAS with 40 TB of data. Most of the data is archival, yet instant access is required when data is requested.<br/><br/>Leadership wants to ensure minimal downtime during the migration. Each virtual machine has a number of customized configurations. The company's existing 1 Gbps network connection is mostly idle, especially after business hours.<br/><br/>Which combination of steps should the company take to migrate to AWS while minimizing downtime and operational impact? (Select TWO)<br/><br/>A. Use new Amazon EC2 instances and reinstall all application code.<br/>B. Use AWS SMS to migrate the virtual machines.<br/>C. Use AWS Storage Gateway to migrate the data to cloud&#8211;native storage.<br/>D. Use AWS Snowball to migrate the data.<br/>E. Use AWS SMS to copy the infrequently accessed data from the NAS.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample687' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_192'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_720'>Random</a></p><div class='collapse' id='collapseExample687'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Use AWS SMS to migrate the virtual machines.
<br><b>C. </b>Use AWS Storage Gateway to migrate the data to cloud-native storage.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 24%;" aria-valuenow="24" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_192><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 192</p><br/>A company is using Amazon DynamoDB with provisioned throughput for the database tier of its eCommerce website. During flash sales, customers experience periods of time when the database cannot handle the high number of transactions taking place. This causes the company to lose transactions. During normal periods, the database performs appropriately.<br/><br/>Which solution solves the performance problem the company faces?<br/><br/>A. Switch DynamoDB to on&#8211;demand mode during flash sales.<br/>B. Implement DynamoDB Accelerator for fast in memory performance.<br/>C. Use Amazon Kinesis to queue transactions for processing to DynamoDB.<br/>D. Use Amazon Simple Queue Service (Amazon SQS) to queue transactions to DynamoDB.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample331' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_193'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_783'>Random</a></p><div class='collapse' id='collapseExample331'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Switch DynamoDB to on-demand mode during flash sales.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 24%;" aria-valuenow="24" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_193><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 193</p><br/>As part of budget planning, management wants a report of AWS billed items listed by user. The data will be used to create department budgets. A solutions architect needs to determine the most efficient way to obtain this report information.<br/><br/>Which solution meets these requirements?<br/><br/>A. Run a query with Amazon Athena to generate the report.<br/>B. Create a report in Cost Explorer and download the report.<br/>C. Access the bill details from the billing dashboard and download the bill.<br/>D. Modify a cost budget in AWS Budgets to alert with Amazon Simple Email Service (Amazon SES).<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample272' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_194'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_81'>Random</a></p><div class='collapse' id='collapseExample272'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Create a report in Cost Explorer and download the report.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 24%;" aria-valuenow="24" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_194><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 194</p><br/>A solutions architect is developing a multiple&#8211;subnet VPC architecture. The solution will consist of six subnets in two Availability Zones. The subnets are defined as public, private and dedicated for databases.<br/><br/>Only the Amazon EC2 instances running in the private subnets should be able to access a database.<br/><br/>Which solution meets these requirements?<br/><br/>A. Create a new route table that excludes the route to the public subnets' CIDR blocks. Associate the route table to the database subnets.<br/>B. Create a security group that denies ingress from the security group used by instances in the public subnets. Attach the security group to an Amazon RDS DB instance.<br/>C. Create a security group that allows ingress from the security group used by instances in the private subnets. Attach the security group to an Amazon RDS DB instance.<br/>D. Create a new peering connection between the public subnets and the private subnets. Create a different peering connection between the private subnets and the database subnets.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample359' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_195'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_198'>Random</a></p><div class='collapse' id='collapseExample359'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Create a security group that allows ingress from the security group used by instances in the private subnets. Attach the security group to an Amazon RDS DB instance.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 24%;" aria-valuenow="24" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_195><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 195</p><br/>A company needs to provide its employees with secure access to confidential and sensitive files. The company wants to ensure that the tiles can be accessed only by authorized users. The files must be downloaded securely to the employees' devices.<br/><br/>The tiles are stored in an on&#8211;premises Windows file server. However, due to an increase in remote usage, the file server is running out of capacity.<br/><br/>Which solution will meet these requirements?<br/><br/>A. Migrate the file server to an Amazon EC2 instance in a public subnet. Configure the security group to limit inbound traffic to the employees' IP addresses.<br/>B. Migrate the files to an Amazon FSx for Windows File Server file system. Integrate the Amazon FSx file system with the on&#8211;premises Active Directory. Configure AWS Client VP<br/>C. Migrate the tiles to Amazon S3, and create a private VPC endpoint. Create a signed URL to allow download.<br/>D. Migrate the tiles to Amazon S3, and create a public VPC endpoint. Allow employees to sign on with AWS Single Sign&#8211;On.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample449' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_196'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_452'>Random</a></p><div class='collapse' id='collapseExample449'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Migrate the tiles to Amazon S3, and create a public VPC endpoint. Allow employees to sign on with AWS Single Sign-On.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 24%;" aria-valuenow="24" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_196><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 196</p><br/>A company has an application that runs on Amazon EC2 instances within a private subnet in a VPC. The instances access data in an Amazon S3 bucket in the same AWS Region. The VPC contains a NAT gateway in a public subnet to access the S3 bucket. The company wants to reduce costs by replacing the NAT gateway without compromising security or redundancy.<br/><br/>Which solution meets these requirements?<br/><br/>A. Replace the NAT gateway with a NAT instance.<br/>B. Replace the NAT gateway with an internet gateway.<br/>C. Replace the NAT gateway with a gateway VPC endpoint.<br/>D. Replace the NAT gateway with an AWS Direct Connect connection.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample405' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_197'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_536'>Random</a></p><div class='collapse' id='collapseExample405'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Replace the NAT gateway with a gateway VPC endpoint.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 24%;" aria-valuenow="24" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_197><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 197</p><br/>A company is using various types of Amazon EC2 On&#8211;Demand Instances.<br/><br/>The company suspects that these instances have greater CPU and memory capacity than its workloads require.<br/><br/>Which actions should the company take to obtain recommendations to optimize cost? (Select TWO.)<br/><br/>A. Use AWS Trusted Advisor for instance type recommendations<br/>B. Use AWS Compute Optimizer for instance type recommendations<br/>C. Use AWS Budgets for instance type recommendations<br/>D. Use Cost Explorer right sizing recommendations<br/>E. Use Amazon Inspector to identify under utilized EC2 instances.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample523' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_198'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_603'>Random</a></p><div class='collapse' id='collapseExample523'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Use AWS Trusted Advisor for instance type recommendations
<br><b>D. </b>Use Cost Explorer right sizing recommendations</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 24%;" aria-valuenow="24" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_198><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 198</p><br/>An online retailer has a series of flash sales occurring every Friday.<br/><br/>Sales Traffic will increase during the sales only and the platform will handle the increased load. The platform is a three&#8211;tier application. The web tier runs on Amazon EC2 instances behind an Application Load Balancer.<br/><br/>Amazon CloudFront is used to reduce web server load, but many requests for dynamic content must go to the web servers.<br/><br/>What should be done to the web tier to reduce costs without impacting performance or reliability?<br/><br/>A. Use T&#8211;series instances<br/>B. Purchase scheduled Reserved instances.<br/>C. Implement Amazon ElasticCache<br/>D. Use Spot instances.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample619' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_199'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_388'>Random</a></p><div class='collapse' id='collapseExample619'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Use T-series instances</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 25%;" aria-valuenow="25" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_199><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 199</p><br/>An application calls a service run by a vendor.<br/><br/>The vendor charges based on the number of calls.<br/><br/>The finance department needs to know the number of calls that are made to the service to validate the billing statements.<br/><br/>How can a solutions architect design a system to durably store the number of calls without requiring changes to the application?<br/><br/>A. Call the service through an internet gateway<br/>B. Decouple the application from the service with an Amazon Simple Queue Service (Amazon SQS) queue<br/>C. Publish a custom Amazon CloudWatch metric that counts calls to the service<br/>D. Call the service through a VPC peering connection.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample634' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_200'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_307'>Random</a></p><div class='collapse' id='collapseExample634'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Publish a custom Amazon CloudWatch metric that counts calls to the service</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 25%;" aria-valuenow="25" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_200><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 200</p><br/>What should a solutions architect do to optimize utilization MOST cost&#8211;effectively?<br/><br/>A. Enable auto scaling on the original Aurora Database<br/>B. Convert the original Aurora Database to Aurora parallel query<br/>C. Convert the original Aurora Database to Aurora global database<br/>D. Convert the original Aurora Database to Aurora Aurora serverless<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample549' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_201'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_709'>Random</a></p><div class='collapse' id='collapseExample549'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Convert the original Aurora Database to Aurora Aurora serverless</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 25%;" aria-valuenow="25" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_201><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 201</p><br/>A company has two VPCs named Management and Production. The Management VPC uses VPNs through a customer gateway to connect to a single device in the data center The Production VPC uses a virtual private gateway with two attached AWS Direct Connect connections. The Management and Production VPCs both use a single VPC peering connection to allow communication between the applications.<br/><br/>What should a solutions architect do to mitigate any single point of failure in this architecture?<br/><br/>A. Add a second virtual private gateway and attach it to the Management VPC.<br/>B. Add a second VPC peering connection between the Management VPC and the Production VPC.<br/>C. Add a set of VPNs between the Management and Production VPCs.<br/>D. Add a second set of VPNs to the Management VPC from a second customer gateway device.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample514' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_202'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_411'>Random</a></p><div class='collapse' id='collapseExample514'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Add a second virtual private gateway and attach it to the Management VPC.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 25%;" aria-valuenow="25" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_202><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 202</p><br/>A company recently launched its website to serve content to its global user base. The company wants to store and accelerate the delivery of static content to its users by leveraging Amazon CloudFront with an Amazon EC2 instance attached as its origin.<br/><br/>How should a solutions architect optimize high availability for the application?<br/><br/>A. Use Lambda@Edge for CloudFront.<br/>B. Use Amazon S3 Transfer Acceleration for CloudFront.<br/>C. Configure another EC2 instance in a different Availability Zone as part of the origin group.<br/>D. Configure another EC2 instance as part of the origin server cluster in the same Availability Zone.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample163' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_203'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_73'>Random</a></p><div class='collapse' id='collapseExample163'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Use Lambda@Edge for CloudFront.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 25%;" aria-valuenow="25" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_203><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 203</p><br/>A solutions architect is working on optimizing a legacy document management application running on Microsoft Windows Server in an on&#8211;premises data center. The application stores a large number of files on a network file share. The chief information officer wants to reduce the on&#8211;premises data center footprint and minimize storage costs by moving on&#8211;premises storage to AWS.<br/><br/>What should the solutions architect do to meet these requirements?<br/><br/>A. Set up an AWS Storage Gateway file gateway.<br/>B. Set up Amazon Elastic File System (Amazon EFS)<br/>C. Set up AWS Storage Gateway as a volume gateway<br/>D. Set up an Amazon Elastic Block Store (Amazon EBS) volume.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample84' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_204'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_687'>Random</a></p><div class='collapse' id='collapseExample84'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Set up an AWS Storage Gateway file gateway.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 25%;" aria-valuenow="25" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_204><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 204</p><br/>A meteorological startup company has a custom web application to sell weather data to its users online. The company uses Amazon DynamoDB to store its data and wants to build a new service that sends an alert to the managers of four internal teams every time a new weather event is recorded. The company does not want this new service to affect the performance of the current application<br/><br/>What should a solutions architect do to meet these requirements with the LEAST amount of operational overhead?<br/><br/>A. Use DynamoDB transactions to write new event data to the table Configure the transactions to notify internal teams.<br/>B. Have the current application publish a message to four Amazon Simple Notification Service (Amazon SNS) topics. Have each team subscribe to one topic.<br/>C. Enable Amazon DynamoDB Streams on the table Use triggers to write to a single Amazon Simple Notification Service (Amazon SNS) topic to which the teams can subscribe<br/>D. Add a custom attribute to each record to flag new items Write a cron job that scans the table every minute for items that are new and notifies an Amazon Simple Queue Service (Amazon SQS) queue to which the teams can subscribe<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample494' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_205'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_294'>Random</a></p><div class='collapse' id='collapseExample494'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Use DynamoDB transactions to write new event data to the table Configure the transactions to notify internal teams.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 25%;" aria-valuenow="25" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_205><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 205</p><br/>A solutions architect plans to convert a company's monolithic web application into a multi&#8211;tier application.<br/><br/>The company wants to avoid managing its own infrastructure. The minimum requirements for the web application are high availability, scalability, and regional low latency during peak hours. The solution should also store and retrieve data with millisecond latency using the application's API.<br/><br/>Which solution meets these requirements?<br/><br/>A. Use AWS Fargate to host the web application with backend Amazon RDS Multi&#8211;AZ DB instances.<br/>B. Use Amazon API Gateway with an edge&#8211;optimized API endpoint, AWS Lambda for compute, and Amazon DynamoDB as the data store.<br/>C. Use an Amazon Route 53 routing policy with geolocation that points to an Amazon S3 bucket with static website hosting and Amazon DynamoDB as the data store.<br/>D. Use an Amazon CloudFront distribution that points to an Elastic Load Balancer with an Amazon EC2 Auto Scaling group, along with Amazon RDS Multi&#8211;AZ DB instances.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample364' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_206'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_142'>Random</a></p><div class='collapse' id='collapseExample364'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Use AWS Fargate to host the web application with backend Amazon RDS Multi-AZ DB instances.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 25%;" aria-valuenow="25" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_206><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 206</p><br/>A company's web application is running on Amazon EC2 instances behind an Application Load Balancer.<br/><br/>The company recently changed its policy, which now requires the application to be accessed from one specific country only.<br/><br/>Which configuration will meet this requirement?<br/><br/>A. Configure the security group for the EC2 instances.<br/>B. Configure the security group on the Application Load Balancer.<br/>C. Configure AWS WAF on the Application Load Balancer in a VPC.<br/>D. Configure the network ACL for the subnet that contains the EC2 instances.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample57' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_207'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_737'>Random</a></p><div class='collapse' id='collapseExample57'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Configure AWS WAF on the Application Load Balancer in a VPC.

References:

AWS Security Blog > How to use AWS WAF to filter incoming traffic from embargoed countries</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 26%;" aria-valuenow="26" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_207><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 207</p><br/>A company recently started using Amazon Aurora as the data store for its global eCommerce application.<br/><br/>When large reports are run, developers report that the eCommerce application is performing poorly. After reviewing metrics in Amazon CloudWatch. A solutions architect finds that the ReadIOPS and CPU Utilization metrics are spiking when monthly reports run.<br/><br/>What is the MOST cost&#8211;effective solution?<br/><br/>A. Migrate the monthly reporting to Amazon Redshift.<br/>B. Migrate the monthly reporting to an Aurora Replica.<br/>C. Migrate the Aurora database to a larger instance class.<br/>D. Increase the Provisioned IOPS on the Aurora instance.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample312' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_208'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_282'>Random</a></p><div class='collapse' id='collapseExample312'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Increase the Provisioned IOPS on the Aurora instance.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 26%;" aria-valuenow="26" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_208><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 208</p><br/>A company has an application that ingests incoming messages. These messages are then quickly consumed by dozens of other applications and microservices. The number of messages varies drastically and sometimes spikes as high as 100,000 each second. The company wants to decouple the solution and increase scalability.<br/><br/>Which solution meets these requirements?<br/><br/>A. Persist the messages to Amazon Kinesis Data Analytics. All the applications will read and process the messages.<br/>B. Deploy the application on Amazon EC2 instances in an Auto Scaling group, which scales the number of EC2 instances based on CPU metrics.<br/>C. Write the messages to Amazon Kinesis Data Streams with a single shard. All applications will read from the stream and process the messages.<br/>D. Publish the messages to an Amazon Simple Notification Service (Amazon SNS) topic with one or more Amazon Simple Queue Service (Amazon SQS) subscriptions. All applications then process the messages from the queues.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample283' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation283' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_209'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_463'>Random</a></p><div class='collapse' id='collapseExample283'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Publish the messages to an Amazon Simple Notification Service (Amazon SNS) topic with one or more Amazon Simple Queue Service (Amazon SQS) subscriptions. All applications then process the messages from the queues.</div></div></div><div class='collapse' id='explanation283'><div class='card card&#45;body'><div>
Q: How large can Amazon SQS message queues be?
A single Amazon SQS message queue can contain an unlimited number of messages. However, there is a 120,000 quota for the number of inflight messages for a standard queue and 20,000 for a FIFO queue. Messages are inflight after they have been received from the queue by a consuming component, but have not yet been deleted from the queue.

References:

Amazon SQS FAQs</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 26%;" aria-valuenow="26" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_209><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 209</p><br/>A company has a build server that is in an Auto Scaling group and often has multiple Linux instances running.<br/><br/>The build server requires consistent shared NFS storage for jobs and configurations.<br/><br/>Which storage option should a solution architect recommend?<br/><br/>A. Amazon S3<br/>B. Amazon FSx<br/>C. Amazon Elastic Block Store (Amazon EBS)<br/>D. Amazon Elastic File System (Ama on EFS)<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample586' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_210'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_167'>Random</a></p><div class='collapse' id='collapseExample586'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Amazon Elastic File System (Ama on EFS)</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 26%;" aria-valuenow="26" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_210><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 210</p><br/>A company has a large Microsoft SharePoint deployment running on&#8211;premises that requires Microsoft Windows shared file storage. The company wants to migrate this workload to the AWS Cloud and is considering various storage options. The storage solution must be highly available and integrated with Active Directory for access control.<br/><br/>Which solution will satisfy these requirements?<br/><br/>A. Configure Amazon EFS storage and set the Active Directory domain for authentication.<br/>B. Create an SMB file share on an AWS Storage Gateway file gateway in two Availability Zones.<br/>C. Create an Amazon S3 bucket and configure Microsoft Windows Server to mount it as a volume.<br/>D. Create an Amazon FSx for Windows File Server file system on AWS and set the Active Directory domain for authentication.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample124' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation124' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_211'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_27'>Random</a></p><div class='collapse' id='collapseExample124'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Create an Amazon FSx for Windows File Server file system on AWS and set the Active Directory domain for authentication.</div></div></div><div class='collapse' id='explanation124'><div class='card card&#45;body'><div>
Amazon FSx for Windows File Server provides fully managed, highly reliable, and scalable file storage that is accessible over the industry-standard Server Message Block (SMB) protocol. It is built on Windows Server, delivering a wide range of administrative features such as user quotas, end-user file restore, and Microsoft Active Directory (AD) integration. It offers single-AZ and multi-AZ deployment options, fully managed backups, and encryption of data at rest and in transit. You can optimize cost and performance for your workload needs with SSD and HDD storage options; and you can scale storage and change the throughput performance of your file system at any time. Amazon FSx file storage is accessible from Windows, Linux, and macOS compute instances and devices running on AWS or on premises.

Works with Microsoft Active Directory (AD) to easily integrate file systems with Windows environments.

CORRECT: "Amazon FSx" is the correct answer.

INCORRECT: "Amazon EFS" is incorrect as EFS only supports Linux systems. INCORRECT: "Amazon S3" is incorrect as this is not a suitable replacement for a Microsoft filesystem.

INCORRECT: "AWS Storage Gateway" is incorrect as this service is primarily used for connecting on-premises storage to cloud storage. It consists of a software device installed on-premises and can be used with SMB shares but it actually stores the data on S3. It is also used for migration. However, in this case the company need to replace the file server farm and Amazon FSx is the best choice for this job.

References:
Amazon FSx for Windows File Server > Windows User Guide > Availability and durability: Single-AZ and Multi-AZ file systems
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 26%;" aria-valuenow="26" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_211><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 211</p><br/>A company hosts its application using Amazon Elastic Container Service (Amazon ECS) and wants to ensure high availability. The company wants to be able to deploy updates to its application even if nodes in one Availability Zone are not accessible.<br/><br/>The expected request volume for the application is 100 requests per second, and each container task is able to serve at least 60 requests per second. The company set up Amazon ECS with a rolling update deployment type with the minimum healthy percent parameter set to 50% and the maximum percent set to 100%.<br/><br/>Which configuration of tasks and Availability Zones meets these requirements?<br/><br/>A. Deploy the application across two Availability Zones, with one task in each Availability Zone.<br/>B. Deploy the application across two Availability Zones, with two tasks in each Availability Zone.<br/>C. Deploy the application across three Availability Zones, with one task in each Availability Zone.<br/>D. Deploy the application across three Availability Zones, with two tasks in each Availability Zone.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample292' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_212'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_111'>Random</a></p><div class='collapse' id='collapseExample292'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Deploy the application across two Availability Zones, with one task in each Availability Zone.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 26%;" aria-valuenow="26" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_212><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 212</p><br/>A company's security team requests that network traffic be captured in VPC Flow Logs. The logs will be frequently accessed for 90 days and then accessed intermittently.<br/><br/>What should a solutions architect do to meet these requirements when configuring the logs?<br/><br/>A. Use Amazon CloudWatch as the target. Set the CloudWatch log group with an expiration of 90 days.<br/>B. Use Amazon Kinesis as the target Configure the Kinesis stream to always retain the logs for 90 days<br/>C. Use AWS CloudTrail as the target. Configure CloudTrail to save to an Amazon S3 bucket, and enable S3 Intelligent&#8211;Tiering<br/>D. Use Amazon S3 as the target Enable an S3 Lifecycle policy to transition the logs to S3 Standard&#8211;Infrequent Access (S3 Standard&#8211;IA) after 90 days<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample448' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_213'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_453'>Random</a></p><div class='collapse' id='collapseExample448'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Use Amazon S3 as the target Enable an S3 Lifecycle policy to transition the logs to S3 Standard-Infrequent Access (S3 Standard-IA) after 90 days</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 26%;" aria-valuenow="26" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_213><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 213</p><br/>In Amazon EC2 Container Service components, what is the name of a logical grouping of container instances on which you can place tasks?<br/><br/>A. A cluster<br/>B. A container instance<br/>C. A container<br/>D. A task definition<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample784' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation784' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_214'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_497'>Random</a></p><div class='collapse' id='collapseExample784'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>A cluster</div></div></div><div class='collapse' id='explanation784'><div class='card card&#45;body'><div>
Amazon ECS contains the following components:

A Cluster is a logical grouping of container instances that you can place tasks on. A Container instance is an Amazon EC2 instance that is running the Amazon ECS agent and has been registered into a cluster.

A Task definition is a description of an application that contains one or more container definitions. A Scheduler is the method used for placing tasks on container instances. A Service is an Amazon ECS service that allows you to run and maintain a specified number of instances of a task definition simultaneously.

A Task is an instantiation of a task definition that is running on a container instance. A Container is a Linux container that was created as part of a task.

References:

Amazon Elastic Container Service > Developer Guide > What is Amazon Elastic Container Service?</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 26%;" aria-valuenow="26" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_214><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 214</p><br/>A company with facilities in North America, Europe, and Asia is designing new distributed application to optimize its global supply chain and manufacturing process. The orders booked on one continent should be visible to all Regions in a second or less. The database should be able to support failover with a short Recovery Time Objective (RTO). The uptime of the application is important to ensure that manufacturing is not impacted.<br/><br/>What should a solutions architect recommend?<br/><br/>A. Use Amazon DynamoDB global tables.<br/>B. Use Amazon Aurora Global Database.<br/>C. Use Amazon RDS for MySQL with a cross&#8211;Region read replica.<br/>D. Use Amazon RDS for PostgreSQL with a cross&#8211;Region read replica.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample134' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation134' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_215'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_685'>Random</a></p><div class='collapse' id='collapseExample134'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Use Amazon Aurora Global Database.</div></div></div><div class='collapse' id='explanation134'><div class='card card&#45;body'><div>
Cross-Region Disaster Recovery: If your primary region suffers a performance degradation or outage, you can promote one of the secondary regions to take read/write responsibilities. An Aurora cluster can recover in less than 1 minute even in the event of a complete regional outage. This provides your application with an effective Recovery Point Objective (RPO) of 1 second and a Recovery Time Objective (RTO) of less than 1 minute, providing a strong foundation for a global business continuity plan.
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 27%;" aria-valuenow="27" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_215><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 215</p><br/>A company has an on&#8211;premises volume backup solution that has reached its end of life. The company wants to use AWS as part of a new backup solution and wants to maintain local access to all the data while it is backed up on AWS. The company wants to ensure that the data backed up on AWS is automatically and securely transferred.<br/><br/>Which solution meets these requirements?<br/><br/>A. Use AWS Snowball to migrate data out of the on&#8211;premises solution to Amazon S3. Configure on&#8211;premises systems to mount the Snowball S3 endpoint to provide local access to the data.<br/>B. Use AWS Snowball Edge to migrate data out of the on&#8211;premises solution to Amazon S3. Use the Snowball Edge file interface to provide on&#8211;premises systems with local access to the data.<br/>C. Use AWS Storage Gateway and configure a cached volume gateway. Run the Storage Gateway software appliance on&#8211;premises and configure a percentage of data to cache locally. Mount the gateway storage volumes to provide local access to the data.<br/>D. Use AWS Storage Gateway and configure a stored volume gateway. Run the Storage Gateway software appliance on premises and map the gateway storage volumes to on&#8211;premises storage. Mount the gateway storage volumes to provide local access to the data.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample241' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_216'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_514'>Random</a></p><div class='collapse' id='collapseExample241'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Use AWS Storage Gateway and configure a stored volume gateway. Run the Storage Gateway software appliance on premises and map the gateway storage volumes to on-premises storage. Mount the gateway storage volumes to provide local access to the data.

References:

AWS Snowball Edge Developer Guide > Best Practices for the AWS Snowball Edge Device</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 27%;" aria-valuenow="27" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_216><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 216</p><br/>A company runs an application in a branch office within a small data closet with no virtualized compute resources. The application data is stored on an NFS volume. Compliance standards require a daily offsite backup of the NFS volume.<br/><br/>Which solution meet these requirements?<br/><br/>A. Install an AWS Storage Gateway file gateway on premises to replicate the data to Amazon S3.<br/>B. Install an AWS Storage Gateway file gateway hardware appliance on premises to replicate the data to Amazon S3.<br/>C. Install an AWS Storage Gateway volume gateway with stored volumes on premises to replicate the data to Amazon S3.<br/>D. Install an AWS Storage Gateway volume gateway with cached volumes on premises to replicate the data to Amazon S3.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample28' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation28' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_217'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_425'>Random</a></p><div class='collapse' id='collapseExample28'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Install an AWS Storage Gateway file gateway hardware appliance on premises to replicate the data to Amazon S3.</div></div></div><div class='collapse' id='explanation28'><div class='card card&#45;body'><div>
AWS Storage Gateway Hardware Appliance
Hardware Appliance: Storage Gateway is available as a hardware appliance, adding to the existing support for VMware ESXi, Microsoft Hyper-V, and Amazon EC2. This means that you can now make use of Storage Gateway in situations where you do not have a virtualized environment, server-class hardware or IT staff with the specialized skills that are needed to manage them. You can order appliances from Amazon.com for delivery to branch offices, warehouses, and "outpost" offices that lack dedicated IT resources. Setup (as you will see in a minute) is quick and easy, and gives you access to three storage solutions:

File Gateway: A file interface to Amazon S3, accessible via NFS or SMB. The files are stored as S3 objects, allowing you to make use of specialized S3 features such as lifecycle management and cross region replication. You can trigger AWS Lambda functions, run Amazon Athena queries, and use Amazon Macie to discover and classify sensitive data.

Keyword: NFS + Compliance

File gateway provides a virtual on-premises file server, which enables you to store and retrieve files as objects in Amazon S3. It can be used for on-premises applications, and for Amazon EC2- resident applications that need file storage in S3 for object based workloads. Used for flat files only, stored directly on S3. File gateway offers SMB or NFS-based access to data in Amazon S3 with local caching.

WS Storage Gateway – File Gateway

The table below shows the different gateways available and the interfaces and use cases:

Storage Gateway Overview

CORRECT: "Install an AWS Storage Gateway file gateway hardware appliance on premises to replicate the data to Amazon S3" is the correct answer.

INCORRECT: "Install an AWS Storage Gateway file gateway on premises to replicate the data to Amazon S3" is incorrect.

INCORRECT: "Install an AWS Storage Gateway volume gateway with stored volumes on premises to replicate the data to Amazon S3" is incorrect as unsupported NFS. INCORRECT: "Install an AWS Storage Gateway volume gateway with cached volumes on premises to replicate the data to Amazon S3" is incorrect as unsupported NFS.

References:

AWS News Blog > File Interface to AWS Storage Gateway</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 27%;" aria-valuenow="27" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_217><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 217</p><br/>A company is using a VPC peering strategy to connect its VPCs in a single Region to allow for cross communication.<br/><br/>A recent increase in account creations and VPCs has made it difficult to maintain the VPC peering strategy, and the company expects to grow to hundreds of VPCs. There are also new requests to create site&#8211;to&#8211;site VPNs with some of the VPCs. A solutions architect has been tasked with creating a centrally managed networking setup for multiple accounts, VPCs, and VPNs.<br/><br/>Which networking solution meets these requirements?<br/><br/>A. Configure shared VPCs and VPNs and share to each other.<br/>B. Configure a hub&#8211;and&#8211;spoke VPC and route all traffic through VPC peering.<br/>C. Configure an AWS Direct Connect connection between all VPCs and VPNs.<br/>D. Configure a transit gateway with AWS Transit Gateway and connect all VPCs and VPNs.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample95' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_218'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_573'>Random</a></p><div class='collapse' id='collapseExample95'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Configure a transit gateway with AWS Transit Gateway and connect all VPCs and VPNs.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 27%;" aria-valuenow="27" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_218><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 218</p><br/>A company has an on&#8211;premises application that generates a large amount of time&#8211;sensitive data that is backed up to Amazon S3.<br/><br/>The application has grown and there are user complaints about internet bandwidth limitations. A solutions architect needs to design a long&#8211;term solution that allows for both timely backups to Amazon S3 and with minimal impact on internet connectivity for internal users.<br/><br/>Which solution meets these requirements?<br/><br/>A. Establish AWS VPN connections and proxy all traffic through a VPC gateway endpoint<br/>B. Establish a new AWS Direct Connect connection and direct backup traffic through this new connection.<br/>C. Order daily AWS Snowball devices Load the data onto the Snowball devices and return the devices to AWS each day.<br/>D. Submit a support ticket through the AWS Management Console Request the removal of S3 service limits from the account.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample694' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_219'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_509'>Random</a></p><div class='collapse' id='collapseExample694'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Establish a new AWS Direct Connect connection and direct backup traffic through this new connection.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 27%;" aria-valuenow="27" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_219><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 219</p><br/>A solutions architect is moving the static content from a public website hosted on Amazon EC2 instances to an Amazon S3 bucket. An Amazon CloudFront distribution will be used to deliver the static assets. The security group used by the EC2 instances restricts access to a limited set of IP ranges. Access to the static content should be similarly restricted.<br/><br/>Which combination of steps will meet these requirements? (Choose two.)<br/><br/>A. Create an origin access identity (OAI) and associate it with the distribution. Change the permissions in the bucket policy so that only the OAI can read the objects.<br/>B. Create an AWS WAF web ACL that includes the same IP restrictions that exist in the EC2 security group. Associate this new web ACL with the CloudFront distribution.<br/>C. Create a new security group that includes the same IP restrictions that exist in the current EC2 security group. Associate this new security group with the CloudFront distribution.<br/>D. Create a new security group that includes the same IP restrictions that exist in the current EC2 security group. Associate this new security group with the S3 bucket hosting the static content.<br/>E. Create a new IAM role and associate the role with the distribution. Change the permissions either on the S3 bucket or on the files within the S3 bucket so that only the newly created IAM role has read and download permissions.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample162' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_220'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_439'>Random</a></p><div class='collapse' id='collapseExample162'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Create an origin access identity (OAI) and associate it with the distribution. Change the permissions in the bucket policy so that only the OAI can read the objects.
<br><b>B. </b>Create an AWS WAF web ACL that includes the same IP restrictions that exist in the EC2 security group. Associate this new web ACL with the CloudFront distribution.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 27%;" aria-valuenow="27" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_220><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 220</p><br/>Which of the following is true of Amazon EC2 security group?<br/><br/>A. You can modify the outbound rules for EC2&#8211;Classic.<br/>B. You can modify the rules for a security group only if the security group controls the traffic for just one instance.<br/>C. You can modify the rules for a security group only when a new instance is created.<br/>D. You can modify the rules for a security group at any time.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample754' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation754' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_221'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_759'>Random</a></p><div class='collapse' id='collapseExample754'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>You can modify the rules for a security group at any time.</div></div></div><div class='collapse' id='explanation754'><div class='card card&#45;body'><div>
A security group acts as a virtual firewall that controls the traffic for one or more instances. When you launch an instance, you associate one or more security groups with the instance. You add rules to each security group that allow traffic to or from its associated instances. You can modify the rules for a security group at any time; the new rules are automatically applied to all instances that are associated with the security group.

References:

Amazon Elastic Compute Cloud > User Guide for Linux Instances > Amazon EC2 security groups for Linux instances</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 27%;" aria-valuenow="27" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_221><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 221</p><br/>A company has on&#8211;premises servers running a relational database. The current database serves high read traffic for users in different locations. The company wants to migrate to AWS with the least amount of effort.<br/>The database solution should support disaster recovery and not affect the company's current traffic flow.<br/><br/>Which solution meets these requirements?<br/><br/>A. Use a database in Amazon RDS with Multi&#8211;AZ and at least one read replica.<br/>B. Use a database in Amazon RDS with Multi&#8211;AZ and at least one standby replica.<br/>C. Use databases hosted on multiple Amazon EC2 instances in different AWS Regions.<br/>D. Use databases hosted on Amazon EC2 instances behind an Application Load Balancer in different Availability Zones.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample39' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_222'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_335'>Random</a></p><div class='collapse' id='collapseExample39'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Use a database in Amazon RDS with Multi-AZ and at least one read replica.

References:

Enabling data classification for Amazon RDS database with Macie</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 27%;" aria-valuenow="27" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_222><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 222</p><br/>A company hosts its website on AWS. To address the highly variable demand, the company has implemented Amazon EC2 Auto Scaling.<br/><br/>Management is concerned that the company is over&#8211;provisioning its infrastructure, especially at the front end of the three&#8211;tier application. A solutions architect needs to ensure costs are optimized without impacting performance.<br/><br/>What should the solutions architect do to accomplish this?<br/><br/>A. Use Auto Scaling with Reserved Instances.<br/>B. Use Auto Scaling with a scheduled scaling policy.<br/>C. Use Auto Scaling with the suspend&#8211;resume feature.<br/>D. Use Auto Scaling with a target tracking scaling policy.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample110' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_223'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_279'>Random</a></p><div class='collapse' id='collapseExample110'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Use Auto Scaling with a target tracking scaling policy.

References:

Amazon EC2 Auto Scaling > User Guid > Target tracking scaling policies for Amazon EC2 Auto Scaling</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 28%;" aria-valuenow="28" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_223><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 223</p><br/>A company has an API&#8211;based inventory reporting application running on Amazon EC2 instances. The application stores information in an Amazon DynamoDB table. The company's distribution centers have an on&#8211;premises shipping application that calls an API to update the inventory before printing shipping labels.<br/><br/>The company has been experiencing application interruptions several times each day, resulting in lost transactions.<br/><br/>What should a solutions architect recommend to improve application resiliency?<br/><br/>A. Modify the shipping application to write to a local database.<br/>B. Modify the application APIs to run serverless using AWS Lambda<br/>C. Configure Amazon API Gateway to call the EC2 inventory application APIs.<br/>D. Modify the application to send inventory updates using Amazon Simple Queue Service (Amazon SQS).<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample351' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_224'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_12'>Random</a></p><div class='collapse' id='collapseExample351'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Modify the shipping application to write to a local database.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 28%;" aria-valuenow="28" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_224><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 224</p><br/>A company has enabled AWS CloudTrail logs to deliver log files to an Amazon S3 bucket for each of its developer accounts. The company has created a central AWS account for streamlining management and audit reviews. An internal auditor needs to access the CloudTrail logs, yet access needs to be restricted for all developer account users. The solution must be secure and optimized.<br/><br/>How should a solutions architect meet these requirements?<br/><br/>A. Configure an AWS Lambda function in each developer account to copy the log files to the central account. Create an IAM role in the central account for the auditor. Attach an IAM policy providing read only permissions to the bucket.<br/>B. Configure CloudTrail from each developer account to deliver the log files to an S3 bucket in the central account. Create an IAM user in the central account for the auditor. Attach an IAM policy providing full permissions to the bucket.<br/>C. Configure CloudTrail from each developer account to deliver the log files to an S3 bucket in the central account. Create an IAM role in the central account for the auditor. Attach an IAM policy providing read only permissions to the bucket.<br/>D. Configure an AWS Lambda function in the central account to copy the log files from the S3 bucket in each developer account. Create an IAM user in the central account for the auditor. Attach an IAM policy providing full permissions to the bucket.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample71' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_225'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_566'>Random</a></p><div class='collapse' id='collapseExample71'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Configure CloudTrail from each developer account to deliver the log files to an S3 bucket in the central account. Create an IAM role in the central account for the auditor. Attach an IAM policy providing read only permissions to the bucket.

 Go to dashboard</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 28%;" aria-valuenow="28" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_225><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 225</p><br/>A company is implementing new data retention policies for all databases that run on Amazon RDS DB instances. The company must retain daily backups for a minimum period of 2 years. The backups must be consistent and restorable.<br/><br/>Which solution should a solutions architect recommend to meet these requirements?<br/><br/>A. Create a backup vault in AWS Backup to retain RDS backups. Create a new backup plan with a daily schedule and an expiration period of 2 years after creation. Assign the RDS DB instances to the backup plan. Configure a backup window for the RDS DB Instances for daily snapshots. Assign a snapshot retention policy of 2 years to each RDS DB instance. Use Amazon Data Lifecycle Manager (Amazon DLM)<br/>B. to schedule snapshot deletions.<br/>C. Configure database transaction logs to be automatically backed up to Amazon CloudWatch Logs with an expiration period of 2 years<br/>D. Configure an AWS Database Migration Service (AWS DMS) replication task. Deploy a replication instance, and configure a change data capture (CDC) task to stream database changes to Amazon S3 as the target Configure S3 Lifecycle policies to delete the snapshots after 2 years.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample473' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_226'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_181'>Random</a></p><div class='collapse' id='collapseExample473'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Create a backup vault in AWS Backup to retain RDS backups. Create a new backup plan with a daily schedule and an expiration period of 2 years after creation. Assign the RDS DB instances to the backup plan. Configure a backup window for the RDS DB Instances for daily snapshots. Assign a snapshot retention policy of 2 years to each RDS DB instance. Use Amazon Data Lifecycle Manager (Amazon DLM)</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 28%;" aria-valuenow="28" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_226><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 226</p><br/>Cost Explorer is showing charges higher than expected for Amazon Elastic Block Store (Amazon EBS) volumes connected to application servers in a production account.<br/><br/>A significant portion of the changes from Amazon EBS are from volumes that were created as Provisioned IOPS SSD (101) volume types Controlling costs is the highest priority for this application.<br/><br/>Which steps should the user take to analyze and reduce the EBS costs without incurring any application downtime? (Select TWO )<br/><br/>A. Use the Amazon EC2 ModifylnstanceAttribute action to enable EBS optimization on the application server instances<br/>B. Use the Amazon CloudWatch GetMetricData action to evaluate the read write operations and read/write bytes of each volume<br/>C. Use the Amazon EC2 ModifyVolume action to reduce the size of the underutilized 101 volumes<br/>D. Use the Amazon EC2 ModifyVolume action to change the volume type of the underutilized io1 volumes to General Purpose SSD (gp2)<br/>E. Use an Amazon S3 PutBucketPolicy action to migrate existing volume snapshots to Amazon S3 Glacier<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample621' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_227'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_774'>Random</a></p><div class='collapse' id='collapseExample621'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Use the Amazon EC2 ModifylnstanceAttribute action to enable EBS optimization on the application server instances
<br><b>D. </b>Use the Amazon EC2 ModifyVolume action to change the volume type of the underutilized io1 volumes to General Purpose SSD (gp2)</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 28%;" aria-valuenow="28" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_227><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 227</p><br/>A solutions architect needs to design a network that will allow multiple Amazon EC2 instances to access a common data source used for mission&#8211;critical data that can be accessed by all the EC2 instances simultaneously. The solution must be highly scalable, easy to implement, and support the NFS protocol.<br/><br/>Which solution meets these requirements?<br/><br/>A. Create an Amazon EFS file system. Configure a mount target in each Availability Zone. Attach each instance to the appropriate mount target.<br/>B. Create an additional EC2 instance and configure it as a file server. Create security group that allows communication between the instances and apply that to the additional instance.<br/>C. Create an Amazon S3 bucket with the appropriate permissions. Create a role in AWS IAM that grants the correct permissions to the S3 bucket. Attach the role to the EC2 instances that need access to the data.<br/>D. Create an Amazon EBS volume with the appropriate permissions. Create a role in AWS IAM that grants the correct permissions to the EBS volume. Attach the role to then EC2 instances that need access to the data.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample708' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_228'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_468'>Random</a></p><div class='collapse' id='collapseExample708'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Create an Amazon EFS file system. Configure a mount target in each Availability Zone. Attach each instance to the appropriate mount target.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 28%;" aria-valuenow="28" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_228><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 228</p><br/>An application running on AWS uses an Amazon Aurora Multi&#8211;AZ deployment for its database. When evaluating performance metrics, a solutions architect discovered that the database reads are causing high I/O and adding latency to the write requests against the database.<br/><br/>What should the solutions architect do to separate the read requests from the write requests?<br/><br/>A. Enable read&#8211;through caching on the Amazon Aurora database.<br/>B. Update the application to read from the Multi&#8211;AZ standby instance.<br/>C. Create a read replica and modify the application to use the appropriate endpoint.<br/>D. Create a second Amazon Aurora database and link it to the primary database as a read replica.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample178' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation178' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_229'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_296'>Random</a></p><div class='collapse' id='collapseExample178'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Create a read replica and modify the application to use the appropriate endpoint.</div></div></div><div class='collapse' id='explanation178'><div class='card card&#45;body'><div>
Amazon RDS Read Replicas provide enhanced performance and durability for RDS database (DB) instances. They make it easy to elastically scale out beyond the capacity constraints of a single DB instance for read-heavy database workloads. You can create one or more replicas of a given source DB Instance and serve high-volume application read traffic from multiple copies of your data, thereby increasing aggregate read throughput. Read replicas can also be promoted when needed to become standalone DB instances. Read replicas are available in Amazon RDS for MySQL, MariaDB, PostgreSQL, Oracle, and SQL Server as well as Amazon Aurora.

For the MySQL, MariaDB, PostgreSQL, Oracle, and SQL Server database engines, Amazon RDS creates a second DB instance using a snapshot of the source DB instance. It then uses the engines' native asynchronous replication to update the read replica whenever there is a change to the source DB instance. The read replica operates as a DB instance that allows only read-only connections; applications can connect to a read replica just as they would to any DB instance. Amazon RDS replicates all databases in the source DB instance.

Amazon Aurora further extends the benefits of read replicas by employing an SSD-backed virtualized storage layer purpose-built for database workloads. Amazon Aurora replicas share the same underlying storage as the source instance, lowering costs and avoiding the need to copy data to the replica nodes. For more information about replication with Amazon Aurora, see the online documentation.

Amazon Aurora

Aurora Replicas are independent endpoints in an Aurora DB cluster, best used for scaling read operations and increasing availability. Up to 15 Aurora Replicas can be distributed across the Availability Zones that a DB cluster spans within an AWS Region.

The DB cluster volume is made up of multiple copies of the data for the DB cluster. However, the data in the cluster volume is represented as a single, logical volume to the primary instance and to Aurora Replicas in the DB cluster.

As well as providing scaling for reads, Aurora Replicas are also targets for multi-AZ. In this case the solutions architect can update the application to read from the Multi-AZ standby instance.

References:

Amazon Aurora > User Guide for Aurora > Replication with Amazon Aurora</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 28%;" aria-valuenow="28" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_229><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 229</p><br/>A company is planning to use Amazon S3 to store images uploaded by its users. The images must be encrypted at rest in Amazon S3. The company does not want to spend time managing and rotating the keys, but it does want to control who can access those keys.<br/><br/>What should a solutions architect use to accomplish this?<br/><br/>A. Server&#8211;Side Encryption with keys stored in an S3 bucket<br/>B. Server&#8211;Side Encryption with Customer&#8211;Provided Keys (SSE&#8211;C)<br/>C. Server&#8211;Side Encryption with Amazon S3&#8211;Managed Keys (SSE&#8211;S3)<br/>D. Server&#8211;Side Encryption with AWS KMS&#8211;Managed Keys (SSE&#8211;KMS)<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample32' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation32' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_230'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_493'>Random</a></p><div class='collapse' id='collapseExample32'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Server-Side Encryption with AWS KMS-Managed Keys (SSE-KMS)</div></div></div><div class='collapse' id='explanation32'><div class='card card&#45;body'><div>
"Server-Side Encryption with Customer Master Keys (CMKs) Stored in AWS Key Management Service (SSE-KMS) is similar to SSE-S3, but with some additional benefits and charges for using this service.

There are separate permissions for the use of a CMK that provides added protection against unauthorized access of your objects in Amazon S3. SSE-KMS also provides you with an audit trail that shows when your CMK was used and by whom."

Server-Side Encryption: Using SSE-KMS
You can protect data at rest in Amazon S3 by using three different modes of server-side encryption: SSES3, SSE-C, or SSE-KMS.
SSE-S3 requires that Amazon S3 manage the data and master encryption keys. For more information about SSE-S3, see Protecting Data Using Server-Side Encryption with Amazon S3-Managed Encryption Keys (SSE-S3).

SSE-C requires that you manage the encryption key. For more information about SSE-C, see Protecting Data Using Server-Side Encryption with Customer-Provided Encryption Keys (SSE-C).

SSE-KMS requires that AWS manage the data key but you manage the customer master key (CMK) in AWS KMS.

The remainder of this topic discusses how to protect data by using server-side encryption with AWS KMS-managed keys (SSE-KMS).

You can request encryption and select a CMK by using the Amazon S3 console or API. In the console, check the appropriate box to perform encryption and select your CMK from the list. For the Amazon S3 API, specify encryption and choose your CMK by setting the appropriate headers in a GET or PUT request.

SSE-KMS requires that AWS manage the data key but you manage the customer master key (CMK) in AWS KMS. You can choose a customer managed CMK or the AWS managed CMK for Amazon S3 in your account.

Customer managed CMKs are CMKs in your AWS account that you create, own, and manage. You have full control over these CMKs, including establishing and maintaining their key policies, IAM policies, and grants, enabling and disabling them, rotating their cryptographic material, adding tags, creating aliases that refer to the CMK, and scheduling the CMKs for deletion.

For this scenario, the solutions architect should use SSE-KMS with a customer managed CMK. That way KMS will manage the data key but the company can configure key policies defining who can access the keys.

CORRECT: "Server-Side Encryption with AWS KMS-Managed Keys (SSE-KMS)" is the correct answer.

INCORRECT: "Server-Side Encryption with keys stored in an S3 bucket" is incorrect as you cannot store your keys in a bucket with server-side encryption

INCORRECT: "Server-Side Encryption with Customer-Provided Keys (SSE-C)" is incorrect as the company does not want to manage the keys.

INCORRECT: "Server-Side Encryption with Amazon S3-Managed Keys (SSE-S3)" is incorrect as the company needs to manage access control for the keys which is not possible when they're managed by Amazon.

References:

AWS Key Management Service > Developer Guide > Server-Side Encryption: Using SSE-KMS
AWS Key Management Service > Developer Guide > AWS KMS keys concepts

</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 28%;" aria-valuenow="28" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_230><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 230</p><br/>A product team is creating a new application that will store a large amount of data. The data will be analyzed hourly and modified by multiple Amazon EC2 Linux instances. The application team believes the amount of space needed will continue to grow for the next 6 months.<br/><br/>Which set of actions should a solutions architect take to support these needs?<br/><br/>A. Store the data in an Amazon EBS volume. Mount the EBS volume on the application instances.<br/>B. Store the data in an Amazon EFS file system. Mount the file system on the application instances.<br/>C. Store the data in Amazon S3 Glacier. Update the vault policy to allow access to the application instances.<br/>D. Store the data in Amazon S3 Standard&#8211;Infrequent Access (S3 Standard&#8211;IA). Update the bucket policy to allow access to the application instances.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample7' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation7' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_231'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_345'>Random</a></p><div class='collapse' id='collapseExample7'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Store the data in an Amazon EFS file system. Mount the file system on the application instances.</div></div></div><div class='collapse' id='explanation7'><div class='card card&#45;body'><div>
Amazon Elastic File System (Amazon EFS) provides a simple, scalable, fully managed elastic NFS file system for use with AWS Cloud services and on-premises resources. It is built to scale on demand to petabytes without disrupting applications, growing and shrinking automatically as you add and remove files, eliminating the need to provision and manage capacity to accommodate growth.

"The data will be analyzed hourly and modified by multiple Amazon EC2 Linux instances."

Amazon EFS is designed to provide massively parallel shared access to thousands of Amazon EC2 instances, enabling your applications to achieve high levels of aggregate throughput and IOPS with consistent low latencies.

Amazon EFS is well suited to support a broad spectrum of use cases from home directories to business-critical applications. Customers can use EFS to lift-and-shift existing enterprise applications to the AWS Cloud. Other use cases include big data analytics, web serving and content management, application development and testing, media and entertainment workflows, database backups, and container storage.

Amazon EFS is a regional service storing data within and across multiple Availability Zones (AZs) for high availability and durability. Amazon EC2 instances can access your file system across AZs, regions, and VPCs, while on-premises servers can access using AWS Direct Connect or AWS VPN.
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 29%;" aria-valuenow="29" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_231><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 231</p><br/>A company needs comply with a regulatory requirement that states all emails must be stored and archived externally for 7 years.<br/><br/>An administrator has created compressed email files on&#8211;premises and wants a managed service to transfer the files to AWS storage.<br/><br/>Which managed service should a solution architect recommend?<br/><br/>A. Amazon Elastic File System (Amazon EFS).<br/>B. Amazon S3 Glacier.<br/>C. AWS Backup.<br/>D. AWS Storage Gateway.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample703' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_232'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_653'>Random</a></p><div class='collapse' id='collapseExample703'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>AWS Storage Gateway.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 29%;" aria-valuenow="29" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_232><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 232</p><br/>A web application must persist order data to Amazon S3 to support near&#8211;real&#8211;time processing. A solutions architect needs create an architecture that is both scalable and fault tolerant.<br/><br/>Which solutions meet these requirements? (Select TWO)<br/><br/>A. Write the order event to an Amazon DynamoDB table. Use DynamoDB Streams to trigger an AWS Lambda function that parses the payload and writes the data to Amazon<br/>B. Write the order event to an Amazon Simple Queue Service (Amazon SQS) queue. Use the queue to trigger an AWS Lambda function that parses the payload and writes the data to Amazon S3.<br/>C. Write the order event to an Amazon Simple Notification Service (Amazon SNS) topic. Use the SNS topic to trigger an AWS Lambda function that parses the payload and writes the data to Amazon S3.<br/>D. Write the order event to an Amazon Simple Queue Service (Amazon SQS) queue. Use an Amazon EventBridge (Amazon CloudWatch Events) rule to trigger an AWS Lambda function that parses the payload and writes the data to Amazon S3.<br/>E. Write the order event to an Amazon Simple Notification Service (Amazon SNS) topic. Use an Amazon EventBridge (Amazon CloudWatch Events) rule to trigger an AWS Lambda function that parses the payload and writes the data to Amazon S3.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample692' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_233'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_621'>Random</a></p><div class='collapse' id='collapseExample692'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Write the order event to an Amazon DynamoDB table. Use DynamoDB Streams to trigger an AWS Lambda function that parses the payload and writes the data to Amazon
<br><b>B. </b>Write the order event to an Amazon Simple Queue Service (Amazon SQS) queue. Use the queue to trigger an AWS Lambda function that parses the payload and writes the data to Amazon S3.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 29%;" aria-valuenow="29" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_233><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 233</p><br/>A product manager of an eCommerce website is launching a new product line next month. The application hosting the website runs on Amazon EC2 instances in an Auto Scaling group behind a load balancer.<br/><br/>Testing has been performed, and the maximum load at launch has been estimated.<br/><br/>Traffic to the application is expected to decrease gradually within the first few weeks after the launch.<br/><br/>This workload is the only one on this account that is expected to scale during launch.<br/><br/>Which combination of steps is MOST cost&#8211;effective to ensure that will be adequate capacity when the application scales at launch? (Select TWO.)<br/><br/>A. Purchase Reserved instance (RIs) with zonal scope to reserve capacity and get the discount to compute. Then cancel the Ris after the launch.<br/>B. Contact AWS to reserve hardware in the AWS Reg on that will be near the most users.<br/>C. Check the EC2 service quotas on the account, and request an increase if the values are lower than the expected load at launch.<br/>D. Purchase Scheduled instances to reserve capacity for the launch, and run them on a daily schedule during peak capacity hours.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample612' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_234'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_532'>Random</a></p><div class='collapse' id='collapseExample612'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Purchase Reserved instance (RIs) with zonal scope to reserve capacity and get the discount to compute. Then cancel the Ris after the launch.
<br><b>D. </b>Purchase Scheduled instances to reserve capacity for the launch, and run them on a daily schedule during peak capacity hours.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 29%;" aria-valuenow="29" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_234><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 234</p><br/>A company stores user data in AWS. The data is used continuously with peak usage during business hours. Access patterns vary, with some data not being used for months at a time. A solutions architect must choose a cost&#8211;effective solution that maintains the highest level of durability while maintaining high availability.<br/><br/>Which storage solution meets these requirements?<br/><br/>A. Amazon S3 Standard<br/>B. Amazon S3 Intelligent&#8211;Tiering<br/>C. Amazon S3 Glacier Deep Archive<br/>D. Amazon S3 One Zone&#8211;Infrequent Access (S3 One Zone&#8211;IA)<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample139' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_235'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_42'>Random</a></p><div class='collapse' id='collapseExample139'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Amazon S3 Intelligent-Tiering</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 29%;" aria-valuenow="29" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_235><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 235</p><br/>A company has several business systems that require access to data stored in a file share. The business systems will access the file share using the Server Message Block (SMB) protocol. The file share solution should be accessible from both of the company's legacy on&#8211;premises environments and with AWS.<br/><br/>Which services meet the business requirements? (Choose two.)<br/><br/>A. Amazon EBS<br/>B. Amazon EFS<br/>C. Amazon FSx for Windows<br/>D. Amazon S3<br/>E. AWS Storage Gateway file gateway<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample268' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_236'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_447'>Random</a></p><div class='collapse' id='collapseExample268'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Amazon FSx for Windows
<br><b>E. </b>AWS Storage Gateway file gateway</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 29%;" aria-valuenow="29" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_236><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 236</p><br/>A company is creating a three&#8211;tier web application consisting of a web server, an application server, and a database server. The application will track GPS coordinates of packages as they are being delivered. The application will update the database every 0&#8211;5 seconds.<br/><br/>The tracking will need to read a fast as possible for users to check the status of their packages. Only a few packages might be tracked on some days, whereas millions of package might be tracked on other days. Tracking will need to be searchable by tracking ID customer ID and order ID Order than 1 month no longer read to be tracked.<br/><br/>What should a solution architect recommend to accomplish this with minimal cost of ownership?<br/><br/>A. Use Amazon DynamoDB Enable Auto Scaling on the DynamoDB table. Schedule an automatic deletion script for items older than 1 month.<br/>B. Use Amazon DynamoDB with global secondary indexes. Enable Auto Scaling on the DynamoDB table and the global secondary indexes. Enable TTL on the DynamoDB table.<br/>C. Use an Amazon RDS On&#8211;Demand instance with Provisioned IOPS (PIOPS). Enable Amazon CloudWatch alarms to send notifications when PIOPS are exceeded. Increase and decrease PIOPS as needed.<br/>D. Use a Amazon RDS Reserved Instance with Provisioned IOPS (PIOPS). Enable Amazon CloudWatch alarms to send notification when PIOPS are exceeded. Increase and decrease PIOPS as needed.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample488' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_237'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_241'>Random</a></p><div class='collapse' id='collapseExample488'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Use Amazon DynamoDB with global secondary indexes. Enable Auto Scaling on the DynamoDB table and the global secondary indexes. Enable TTL on the DynamoDB table.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 29%;" aria-valuenow="29" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_237><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 237</p><br/>A company is planning to migrate its virtual server&#8211;based workloads to AWS. The company has internet facing load balancers backed by application servers. The application servers rely on patches from an internet&#8211;hosted repository.<br/><br/>Which services should a solutions architect recommend be hosted on the public subnet? (Choose two.)<br/><br/>A. NAT gateway<br/>B. Amazon RDS DB instances<br/>C. Application Load Balancers<br/>D. Amazon EC2 application servers<br/>E. Amazon Elastic File System (Amazon EFS) volumes<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample91' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_238'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_5'>Random</a></p><div class='collapse' id='collapseExample91'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>NAT gateway
<br><b>C. </b>Application Load Balancers</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 30%;" aria-valuenow="30" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_238><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 238</p><br/>A company serves a multilingual website from a fleet of Amazon EC2 instances behind an Application Load Balancer (ALB). This architecture is currently running in the us&#8211;west&#8211;1 Region but is exhibiting high request latency for users located in other parts of the world.<br/><br/>The website needs to serve requests quickly and efficiently regardless of a user's location. However, the company does not want to recreate the existing architecture across multiple Regions.<br/><br/>How should a solutions architect accomplish this?<br/><br/>A. Replace the existing architecture with a website served from an Amazon S3 bucket. Configure an Amazon CloudFront distribution with the S3 bucket as the origin.<br/>B. Configure an Amazon CloudFront distribution with the ALB as the origin. Set the cache behavior settings to only cache based on the Accept&#8211;Language request header.<br/>C. Set up Amazon API Gateway with the ALB as an integration. Configure API Gateway to use an HTTP integration type. Set up an API Gateway stage to enable the API cache.<br/>D. Launch an EC2 instance in each additional Region and configure NGINX to act as a cache server for that Region. Put all the instances plus the ALB behind an Amazon Route 53 record set with a geolocation routing policy.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample256' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_239'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_641'>Random</a></p><div class='collapse' id='collapseExample256'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Configure an Amazon CloudFront distribution with the ALB as the origin. Set the cache behavior settings to only cache based on the Accept-Language request header.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 30%;" aria-valuenow="30" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_239><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 239</p><br/>An application runs on Amazon EC2 instances in private subnets. The application needs to access an Amazon DynamoDB table. What is the MOST secure way to access the table while ensuring that the traffic does not leave the AWS network?<br/><br/>A. Use a VPC endpoint for DynamoDB.<br/>B. Use a NAT gateway in a public subnet.<br/>C. Use a NAT instance in a private subnet.<br/>D. Use the internet gateway attached to the VPC.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample48' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation48' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_240'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_268'>Random</a></p><div class='collapse' id='collapseExample48'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Use a VPC endpoint for DynamoDB.</div></div></div><div class='collapse' id='explanation48'><div class='card card&#45;body'><div>
An Interface endpoint uses AWS PrivateLink and is an elastic network interface (ENI) with a private IP address that serves as an entry point for traffic destined to a supported service.

Using PrivateLink you can connect your VPC to supported AWS services, services hosted by other AWS accounts (VPC endpoint services), and supported AWS Marketplace partner services.

AWS PrivateLink access over Inter-Region VPC Peering:

Applications in an AWS VPC can securely access AWS PrivateLink endpoints across AWS Regions using Inter-Region VPC Peering.

AWS PrivateLink allows you to privately access services hosted on AWS in a highly available and scalable manner, without using public IPs, and without requiring the traffic to traverse the Internet.

Customers can privately connect to a service even if the service endpoint resides in a different AWS Region.

Traffic using Inter-Region VPC Peering stays on the global AWS backbone and never traverses the public Internet.

A gateway endpoint is a gateway that is a target for a specified route in your route table, used for traffic destined to a supported AWS service.

An interface VPC endpoint (interface endpoint) enables you to connect to services powered by AWS PrivateLink.

References:
Amazon DynamoDB > Developer Guide > What Is Amazon DynamoDB?
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 30%;" aria-valuenow="30" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_240><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 240</p><br/>A company hosts historical weather records in Amazon S3. The records are downloaded from the company's website by way of a URL that resolves to a domain name Users all over the world access this content through subscriptions A third&#8211;party provider hosts the company's root domain name, but the company recently migrated some of its services to Amazon Route 53. The company wants to consolidate contracts, reduce latency for users, and reduce costs related to serving the application to subscribers<br/><br/>Which solution meets these requirements?<br/><br/>A. Create a web distribution on Amazon CloudFront to serve the S3 content for the application Create a CNAME record in a Route 53 hosted zone that points to the CloudFront distribution, resolving to the application's URL domain name.<br/>B. Create a web distribution on Amazon CloudFront to serve the S3 content for the application. Create an ALIAS record in the Amazon Route 53 hosted zone that points to the CloudFront distribution, resolving to the application's URL domain name.<br/>C. Create an A record in a Route 53 hosted zone for the application. Create a Route 53 traffic policy for the web application, and configure a geolocation rule Configure health checks to check the health of the endpoint and route DNS queries to other endpoints if an endpoint is unhealthy.<br/>D. Create an A record in a Route 53 hosted zone for the application Create a Route 53 traffic policy for the web application, and configure a geoproximity rule. Configure health checks to check the health of the endpoint and route DNS queries to other endpoints if an endpoint is unhealthy.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample457' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_241'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_149'>Random</a></p><div class='collapse' id='collapseExample457'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Create an A record in a Route 53 hosted zone for the application. Create a Route 53 traffic policy for the web application, and configure a geolocation rule Configure health checks to check the health of the endpoint and route DNS queries to other endpoints if an endpoint is unhealthy.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 30%;" aria-valuenow="30" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_241><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 241</p><br/>A healthcare company stores highly sensitive patient records. Compliance requires that multiple copies be stored in different locations. Each record must be stored for 7 years. The company has a service level agreement (SLA) to provide records to government agencies immediately for the first 30 days and then within 4 hours of a request thereafter.<br/><br/>What should a solutions architect recommend?<br/><br/>A. Use Amazon S3 with cross&#8211;Region replication enabled. After 30 days, transition the data to Amazon S3 Glacier using lifecycle policy.<br/>B. Use Amazon S3 with cross&#8211;origin resource sharing (CORS) enabled. After 30 days, transition the data to Amazon S3 Glacier using a lifecycle policy.<br/>C. Use Amazon S3 with cross&#8211;Region replication enabled. After 30 days, transition the data to Amazon S3 Glacier Deep Achieve using a lifecycle policy.<br/>D. Use Amazon S3 with cross&#8211;origin resource sharing (CORS) enabled. After 30 days, transition the data to Amazon S3 Glacier Deep Archive using a lifecycle policy.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample193' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_242'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_314'>Random</a></p><div class='collapse' id='collapseExample193'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Use Amazon S3 with cross-Region replication enabled. After 30 days, transition the data to Amazon S3 Glacier using lifecycle policy.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 30%;" aria-valuenow="30" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_242><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 242</p><br/>A company hosts a training site on a fleet of Amazon EC2 instances.<br/><br/>The company anticipates that its new course, which consists of dozens of training videos on the site, will be extremely popular when it is released in 1 week.<br/><br/>What should a solutions architect do to minimize the anticipated server load?<br/><br/>A. Store the videos in Amazon ElastiCache for Redis. Update the web servers to serve the videos using the Elastic cache API<br/>B. Store the videos in Amazon Elastic File System (Amazon EFS). Create a user data script for the web servers to mount the EFS volume.<br/>C. Store the videos in an Amazon S3 bucket. Create an Amazon CloudFlight distribution with an origin access identity (OAI) of that S3 bucket. Restrict Amazon S3 access to the OAI.<br/>D. Store the videos in an Amazon S3 bucket. Create an AWS Storage Gateway file gateway to access the S3 bucket. Create a user data script for the web servers to mount the file gateway<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample714' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_243'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_46'>Random</a></p><div class='collapse' id='collapseExample714'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Store the videos in an Amazon S3 bucket. Create an Amazon CloudFlight distribution with an origin access identity (OAI) of that S3 bucket. Restrict Amazon S3 access to the OAI.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 30%;" aria-valuenow="30" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_243><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 243</p><br/>A company wants to migrate its MySQL database from on premises to AWS. The company recently experienced a database outage that significantly impacted the business. To ensure this does not happen again, the company wants a reliable database solution on AWS that minimizes data loss and stores every transaction on at least two nodes.<br/><br/>Which solution meets these requirements?<br/><br/>A. Create an Amazon RDS DB instance with synchronous replication to three nodes in three Availability Zones.<br/>B. Create an Amazon RDS MySQL DB instance with Multi&#8211;AZ functionality enabled to synchronously replicate the data.<br/>C. Create an Amazon RDS MySQL DB instance and then create a read replica in a separate AWS Region that synchronously replicates the data.<br/>D. Create an Amazon EC2 instance with a MySQL engine installed that triggers an AWS Lambda function to synchronously replicate the data to an Amazon RDS MySQL DB instance.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample138' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_244'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_699'>Random</a></p><div class='collapse' id='collapseExample138'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Create an Amazon RDS DB instance with synchronous replication to three nodes in three Availability Zones.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 30%;" aria-valuenow="30" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_244><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 244</p><br/>A company has a website deployed on AWS. The database backend is hosted on Amazon RDS for MySQL with a primary instance and five read replicas to support scaling needs. The read replicas should lag no more than 1 second behind the primary instance to support the user experience.<br/><br/>As traffic on the website continues to increase, the replicas are falling further behind during periods of peak load, resulting in complaints from users when searches yield inconsistent results. A solutions architect needs to reduce the replication lag as much as possible, with minimal changes to the application code or operational requirements.<br/><br/>Which solution meets these requirements?<br/><br/>A. Migrate the database to Amazon Aurora MySQL. Replace the MySQL read replicas with Aurora Replicas and enable Aurora Auto Scaling<br/>B. Deploy an Amazon ElastiCache for Redis cluster in front of the database. Modify the website to check the cache before querying the database read endpoints.<br/>C. Migrate the database from Amazon RDS to MySQL running on Amazon EC2 compute instances. Choose very large compute optimized instances for all replica nodes.<br/>D. Migrate the database to Amazon DynamoDB. Initially provision a large number of read capacity units (RCUs) to support the required throughput with on&#8211;demand capacity scaling enabled.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample350' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_245'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_477'>Random</a></p><div class='collapse' id='collapseExample350'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Deploy an Amazon ElastiCache for Redis cluster in front of the database. Modify the website to check the cache before querying the database read endpoints.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 30%;" aria-valuenow="30" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_245><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 245</p><br/>A company uses Application Load Balancers (ALBs) in different AWS Regions. The ALBs receive inconsistent traffic that can spike and drop throughout the year. The company's networking team needs to allow the IP addresses of the ALBs in the on&#8211;premises firewall to enable connectivity.<br/><br/>Which solution is the MOST scalable with minimal configuration changes?<br/><br/>A. Write an AWS Lambda script to get the IP addresses of the ALBs in different Regions. Update the on&#8211;premises firewall's rule to allow the IP addresses of the ALBs.<br/>B. Migrate all ALBs in different Regions to the Network Load Balancer (NLBs). Update the on&#8211;premises firewall's rule to allow the Elastic IP addresses of all the NLBs.<br/>C. Launch AWS Global Accelerator. Register the ALBs in different Regions to the accelerator. Update the on&#8211;premises firewall's rule to allow static IP addresses associated with the accelerator.<br/>D. Launch a Network Load Balancer (NLB) in one Region. Register the private IP addresses of the ALBs in different Regions with the NLB. Update the on&#8211;premises firewall's rule to allow the Elastic IP address attached to the NLB.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample142' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_246'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_9'>Random</a></p><div class='collapse' id='collapseExample142'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Launch AWS Global Accelerator. Register the ALBs in different Regions to the accelerator. Update the on-premises firewall's rule to allow static IP addresses associated with the accelerator.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 31%;" aria-valuenow="31" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_246><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 246</p><br/>An administrator of a large company wants to monitor for and prevent any cryptocurrency&#8211;related attacks on the company's AWS accounts.<br/><br/>Which AWS service can the administrator use to protect the company against attacks?<br/><br/>A. Amazon Cognito<br/>B. Amazon GuardDuty<br/>C. Amazon Inspector<br/>D. Amazon Macie<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample398' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_247'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_788'>Random</a></p><div class='collapse' id='collapseExample398'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Amazon Inspector</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 31%;" aria-valuenow="31" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_247><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 247</p><br/>A company wants a storage option that enables its data science team to analyze its data on&#8211;premises and in the AWS Cloud. The team needs to be able to run statistical analyses by using the data on&#8211;premises and by using a fleet of Amazon EC2 instances across multiple Availability Zones.<br/><br/>What should a solutions architect do to meet these requirements?<br/><br/>A. Use an AWS Storage Gateway tape gateway to copy the on&#8211;premises files into Amazon S3.<br/>B. Use an AWS Storage Gateway volume gateway to copy the on&#8211;premises files into Amazon S3.<br/>C. Use an AWS Storage Gateway file gateway to copy the on&#8211;premises files to Amazon Elastic Block Store (Amazon EBS).<br/>D. Attach an Amazon Elastic File System (Amazon EFS) file system to the on&#8211;premises servers. Copy the files to Amazon EFS.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample386' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_248'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_146'>Random</a></p><div class='collapse' id='collapseExample386'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Use an AWS Storage Gateway file gateway to copy the on-premises files to Amazon Elastic Block Store (Amazon EBS).</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 31%;" aria-valuenow="31" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_248><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 248</p><br/>A media company is evaluating the possibility of moving its systems to the AWS Cloud. The company needs at least 10 TB of storage with the maximum possible I/O performance for video processing. 300 TB of very durable storage for storing media content, and 900 TB of storage to meet requirements for archival media that is not in use anymore.<br/><br/>Which set of services should a solutions architect recommend to meet these requirements?<br/><br/>A. Amazon EBS for maximum performance, Amazon S3 for durable data storage, and Amazon S3 Glacier for archival storage<br/>B. Amazon EBS for maximum performance. Amazon EFS for durable data storage, and Amazon S3 Glacier for archival storage<br/>C. Amazon EC2 instance store for maximum performance, Amazon EFS for durable data storage, and Amazon S3 for archival storage<br/>D. Amazon EC2 instance store for maximum performance, Amazon S3 for durable data storage, and Amazon S3 Glacier for archival storage<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample735' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_249'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_758'>Random</a></p><div class='collapse' id='collapseExample735'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Amazon EBS for maximum performance, Amazon S3 for durable data storage, and Amazon S3 Glacier for archival storage</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 31%;" aria-valuenow="31" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_249><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 249</p><br/>In Amazon EC2 Container Service, are other container types supported?<br/><br/>A. Yes, EC2 Container Service supports any container service you need.<br/>B. Yes, EC2 Container Service also supports Microsoft container service.<br/>C. No, Docker is the only container platform supported by EC2 Container Service presently.<br/>D. Yes, EC2 Container Service supports Microsoft container service and Openstack.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample737' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation737' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_250'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_387'>Random</a></p><div class='collapse' id='collapseExample737'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>No, Docker is the only container platform supported by EC2 Container Service presently.</div></div></div><div class='collapse' id='explanation737'><div class='card card&#45;body'><div>
In Amazon EC2 Container Service, Docker is the only container platform supported by EC2 Container Service presently.

References:

Amazon Elastic Container Service FAQs</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 31%;" aria-valuenow="31" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_250><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 250</p><br/>A company is running an application on Amazon EC2 instances hosted in a private subnet of a VPC.<br/><br/>The EC2 instances are configured in an Auto Scaling group behind an Elastic Load Balancer (ELB).<br/><br/>The EC2 instances use a NAT gateway for outbound internet access.<br/><br/>However the EC2 instances are not able to connect to the public internet to download software updates.<br/><br/>What are the possible root causes of this issue? (Select TWO )<br/><br/>A. The ELB is not configured with a proper health check<br/>B. The route tables in the VPC are configured incorrectly<br/>C. The EC2 instances are not associated with an Elastic IP address<br/>D. The security group attached to the NAT gateway is configured incorrectly<br/>E. The outbound rules on the security group attached to the EC2 Instances are configured incorrectly.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample658' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_251'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_745'>Random</a></p><div class='collapse' id='collapseExample658'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>The route tables in the VPC are configured incorrectly
<br><b>E. </b>The outbound rules on the security group attached to the EC2 Instances are configured incorrectly.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 31%;" aria-valuenow="31" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_251><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 251</p><br/>A company runs an application on a group of Amazon Linux EC2 instances. The application writes log files using standard API calls. For compliance reasons, all log files must be retained indefinitely and will be analyzed by a reporting tool that must access all files concurrently.<br/><br/>Which storage service should a solutions architect use to provide the MOST cost&#8211;effective solution?<br/><br/>A. Amazon EBS<br/>B. Amazon EFS<br/>C. Amazon EC2 instance store<br/>D. Amazon S3<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample37' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation37' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_252'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_143'>Random</a></p><div class='collapse' id='collapseExample37'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Amazon S3</div></div></div><div class='collapse' id='explanation37'><div class='card card&#45;body'><div>
Amazon S3: Requests to Amazon S3 can be authenticated or anonymous. Authenticated access requires credentials that AWS can use to authenticate your requests. When making REST API calls directly from your code, you create a signature using valid credentials and include the signature in your request. Amazon Simple Storage Service (Amazon S3) is an object storage service that offers industry-leading scalability, data availability, security, and performance. This means customers of all sizes and industries can use it to store and protect any amount of data for a range of use cases, such as websites, mobile applications, backup and restore, archive, enterprise applications, IoT devices, and big data analytics. Amazon S3 provides easy-to-use management features so you can organize your data and configure finely-tuned access controls to meet your specific business, organizational, and compliance requirements. Amazon S3 is designed for 99.999999999% (11 9's) of durability, and stores data for millions of applications for companies all around the world.

The application is writing the files using API calls which means it will be compatible with Amazon S3 which uses a REST API. S3 is a massively scalable key-based object store that is well-suited to allowing concurrent access to the files from many instances.

Amazon S3 will also be the most cost-effective choice. A rough calculation using the AWS pricing calculator shows the cost differences between 1TB of storage on EBS, EFS, and S3 Standard.

CORRECT: "Amazon S3" is the correct answer.

INCORRECT: "Amazon EFS" is incorrect as though this does offer concurrent access from many EC2 Linux instances, it is not the most cost-effective solution.

INCORRECT: "Amazon EBS" is incorrect. The Elastic Block Store (EBS) is not a good solution for concurrent access from many EC2 instances and is not the most cost-effective option either. EBS volumes are mounted to a single instance except when using multi-attach which is a new feature and has several constraints.

INCORRECT: "Amazon EC2 instance store" is incorrect as this is an ephemeral storage solution which means the data is lost when powered down.

Therefore, this is not an option for long-term data storage.

References:

Amazon Simple Storage Service > User Guide > Best practices design patterns: optimizing Amazon S3 performance</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 31%;" aria-valuenow="31" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_252><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 252</p><br/>A company is planning to migrate a mission&#8211;critical three&#8211;tor web application from on&#8211;premises to the AWS Cloud.<br/><br/>The backend database is shared with other on&#8211;premises systems and will remain in the on&#8211;premises data center.<br/><br/>The application tier requires quick and predictable response times between the presentation tier and the database Encryption is required for data in transit between client web browsers and the VPC.<br/><br/>And between the on&#8211;premises data center and the VPC.<br/><br/>Which solution meets these requirements?<br/><br/>A. Use VPN tunnels over an AWS Direct Connect connection for the data transfers between the VPC and the on&#8211;premises data center<br/>B. Use SSL/TLS for the web traffic encryption. Use VPN tunnels for the data transfer between the VPC and the on&#8211;premises data center<br/>C. Use SSL/TLS for the web traffic encryption. Use an AWS Direct Connect connection for the data transfers between the VPC and the on&#8211;premises data center<br/>D. Use SSL/TLS for the web traffic encryption. Use VPN tunnels over an AWS Direct Connect connection for the data transfer between the VPC and the on&#8211;premises data center.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample635' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_253'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_286'>Random</a></p><div class='collapse' id='collapseExample635'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Use SSL/TLS for the web traffic encryption. Use VPN tunnels over an AWS Direct Connect connection for the data transfer between the VPC and the on-premises data center.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 31%;" aria-valuenow="31" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_253><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 253</p><br/>A gaming company is using Amazon DynamoDB to run a high&#8211;score leaderboard and record the game progress for users. The company is launching a new game that is expected to be active for years.<br/><br/>The database activity at launch cannot be predicted; but it is expected to stabilize after 4 weeks. Currently, the company is using on&#8211;demand capacity mode for processing reads and writes on all DynamoDB tables.<br/><br/>What is the MOST cost&#8211;effective way for the company to control the DynamoDB capacity during the new game launch?<br/><br/>A. Use on&#8211;demand mode and purchase DynamoDB reserved capacity for the first 4 weeks of the game launch<br/>B. Use provisioned capacity mode, and purchase DynamoDB reserved capacity for the first 4 weeks of the game launch<br/>C. Use provisioned capacity mode for the game launch, switch back to on&#8211;demand mode after 4 weeks, and then purchase DynamoDB reserved capacity<br/>D. Use on&#8211;demand mode for the game launch, switch to provisioned capacity mode after 4 weeks and then purchase DynamoDB reserved capacity<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample546' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_254'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_702'>Random</a></p><div class='collapse' id='collapseExample546'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Use on-demand mode for the game launch, switch to provisioned capacity mode after 4 weeks and then purchase DynamoDB reserved capacity</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 32%;" aria-valuenow="32" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_254><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 254</p><br/>A company has created a VPC with multiple private subnets in multiple Availability Zones (AZs) and one public subnet in one of the AZs. The public subnet is used to launch a NAT gateway. There are instance in the private subnet that use a NAT gateway to connect to the internet. In case is used of an AZ failure, the company wants to ensure that the instance are not all experiencing internet connectivity issues and that there is a backup plan ready.<br/><br/>Which solution should a solutions architect recommend that is MOST highly available?<br/><br/>A. Create a new public subnet with a NAT gateway in the same AZ Distribute the traffic between the two NAT gateways<br/>B. Create an Amazon EC2 NAT instance in a now public subnet Distribute the traffic between the NAT gateway and the NAT instance<br/>C. Create public subnets In each f\Z and launch a NAT gateway in each subnet Configure the traffic from the private subnets In each A2 to the respective NAT gateway<br/>D. Create an Amazon EC2 NAT instance in the same public subnet Replace the NAT gateway with the NAT instance and associate the instance with an Auto Scaling group with an appropriate scaling policy.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample726' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_255'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_70'>Random</a></p><div class='collapse' id='collapseExample726'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Create public subnets In each f\Z and launch a NAT gateway in each subnet Configure the traffic from the private subnets In each A2 to the respective NAT gateway</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 32%;" aria-valuenow="32" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_255><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 255</p><br/>A recent analysis of a company's IT expenses highlights the need to reduce backup costs. The company's chief information officer wants to simplify the on&#8211;premises backup infrastructure and reduce costs by eliminating the use of physical backup tapes. The company must preserve the existing investment in the on&#8211;premises backup applications and workflows.<br/><br/>What should a solutions architect recommend?<br/><br/>A. Set up AWS Storage Gateway to connect with the backup applications using the NFS interface.<br/>B. Set up an Amazon EFS file system that connects with the backup applications using the NFS interface.<br/>C. Set up an Amazon EFS file system that connects with the backup applications using the iSCSI interface.<br/>D. Set up AWS Storage Gateway to connect with the backup applications using the iSCSI&#8211;virtual tape library (VTL) interface.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample198' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_256'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_572'>Random</a></p><div class='collapse' id='collapseExample198'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Set up AWS Storage Gateway to connect with the backup applications using the iSCSI-virtual tape library (VTL) interface.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 32%;" aria-valuenow="32" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_256><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 256</p><br/>A solutions architect is creating an application that will handle batch processing of large amounts of data.<br/><br/>The input data will be held in Amazon S3 and the output data will be stored in a different S3 bucket. For processing, the application will transfer the data over the network between multiple Amazon EC2 instances.<br/><br/>What should the solutions architect do to reduce the overall data transfer costs?<br/><br/>A. Place all the EC2 instances in an Auto Scaling group.<br/>B. Place all the EC2 instances in the same AWS Region.<br/>C. Place all the EC2 instances in the same Availability Zone.<br/>D. Place all the EC2 instances in private subnets in multiple Availability Zones.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample126' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation126' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_257'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_228'>Random</a></p><div class='collapse' id='collapseExample126'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Place all the EC2 instances in the same Availability Zone.</div></div></div><div class='collapse' id='explanation126'><div class='card card&#45;body'><div>
The transfer is between EC2 instances and not just between S3 and EC2.

Also, be aware of inter-Availability Zones data transfer charges between Amazon EC2 instances, even within the same region. If possible, the instances in a development or test environment that need to communicate with each other should be co-located within the same Availability Zone to avoid data transfer charges. (This doesn't apply to production workloads which will most likely need to span multiple Availability Zones for high availability.)

References:

AWS Management & Governance Blog > Using AWS Cost Explorer to analyze data transfer costs
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 32%;" aria-valuenow="32" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_257><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 257</p><br/>An engineering team is developing and deploying AWS Lambda functions. The team needs to create roles and manage policies in AWS IAM to configure the permissions of the Lambda functions.<br/><br/>How should the permissions for the team be configured so they also adhere to the concept of least privilege?<br/><br/>A. Create an IAM role with a managed policy attached. Allow the engineering team and the Lambda functions to assume this role.<br/>B. Create an IAM group for the engineering team with an IAMFullAccess policy attached. Add all the users from the team to this IAM group.<br/>C. Create an execution role for the Lambda functions. Attach a managed policy that has permission boundaries specific to these Lambda functions.<br/>D. Create an IAM role with a managed policy attached that has permission boundaries specific to the Lambda functions. Allow the engineering team to assume this role.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample361' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_258'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_0'>Random</a></p><div class='collapse' id='collapseExample361'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Create an IAM role with a managed policy attached. Allow the engineering team and the Lambda functions to assume this role.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 32%;" aria-valuenow="32" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_258><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 258</p><br/>A company is building a document storage application on AWS. The application runs on Amazon EC2 instances in multiple Availability Zones. The company requires the document store to be highly available.<br/><br/>The documents need to be returned immediately when requested. The lead engineer has configured the application to use Amazon Elastic Block Store (Amazon EBS) to store the documents, but is willing to consider other options to meet the availability requirement.<br/><br/>What should a solutions architect recommend?<br/><br/>A. Snapshot the EBS volumes regularly and build new volumes using those snapshots in additional Availability Zones.<br/>B. Use Amazon EBS for the EC2 instance root volumes. Configure the application to build the document store on Amazon S3.<br/>C. Use Amazon EBS for the EC2 instance root volumes. Configure the application to build the document store on Amazon S3 Glacier.<br/>D. Use at least three Provisioned IOPS EBS volumes for EC2 instances. Mount the volumes to the EC2 instances in a RAID 5 configuration.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample380' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_259'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_164'>Random</a></p><div class='collapse' id='collapseExample380'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Use Amazon EBS for the EC2 instance root volumes. Configure the application to build the document store on Amazon S3.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 32%;" aria-valuenow="32" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_259><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 259</p><br/>A media company is evaluating the possibility of moving its systems to the AWS Cloud. The company needs at least 10 TB of storage with the maximum possible I/O performance for video processing, 300 TB of very durable storage for storing media content, and 900 TB of storage to meet requirements for archival media that is not in use anymore.<br/><br/>Which set of services should a solutions architect recommend to meet these requirements?<br/><br/>A. Amazon EBS for maximum performance, Amazon S3 for durable data storage, and Amazon S3 Glacier for archival storage<br/>B. Amazon EBS for maximum performance, Amazon EFS for durable data storage, and Amazon S3 Glacier for archival storage<br/>C. Amazon EC2 instance store for maximum performance, Amazon EFS for durable data storage, and Amazon S3 for archival storage<br/>D. Amazon EC2 instance store for maximum performance, Amazon S3 for durable data storage, and Amazon S3 Glacier for archival storage<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample75' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_260'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_510'>Random</a></p><div class='collapse' id='collapseExample75'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Amazon EBS for maximum performance, Amazon S3 for durable data storage, and Amazon S3 Glacier for archival storage</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 32%;" aria-valuenow="32" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_260><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 260</p><br/>A company built a new VPC with the intention of the hosting Amazon EC2 based workloads on AWS. A solutions architect specified that an Amazon S3 gateway endpoint be created and attached to this new VPC. Once the first Application server is built, developers report that server time out when accessing data stored in the S3 bucket.<br/><br/>Which scenario could be causing this issue? ( Select TWO)<br/><br/>A. The S3 bucket is in a region other than the VPC<br/>B. The endpoint has a policy that blocks the CIDR of the VPC<br/>C. The route to the S3 endpoint is not configured in the route table<br/>D. The access is routed through an internet gateway rather than the endpoint<br/>E. The S3 bucket has a bucket policy that does not allow access to the CIDR of the VPC<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample711' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_261'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_384'>Random</a></p><div class='collapse' id='collapseExample711'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>The route to the S3 endpoint is not configured in the route table
<br><b>E. </b>The S3 bucket has a bucket policy that does not allow access to the CIDR of the VPC</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 32%;" aria-valuenow="32" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_261><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 261</p><br/>A company runs a photo processing application that needs to frequently upload and download pictures from Amazon S3 buckets that are located in the same AWS Region.<br/><br/>A solutions architect has noticed an increased cost in data transfer fees and needs to implement a solution to reduce these costs.<br/><br/>How can the solutions architect meet this requirement?<br/><br/>A. Deploy Amazon API Gateway into a public subnet and adjust the route table to route S3 calls through It.<br/>B. Deploy a NAT gateway into a public subnet and attach an end point policy that allows access to the S3 buckets.<br/>C. Deploy the application Into a public subnet and allow it to route through an internet gateway to access the S3 Buckets<br/>D. Deploy an S3 VPC gateway endpoint into the VPC and attach an endpoint policy that allows access to the S3 buckets.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample575' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_262'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_750'>Random</a></p><div class='collapse' id='collapseExample575'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Deploy a NAT gateway into a public subnet and attach an end point policy that allows access to the S3 buckets.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 33%;" aria-valuenow="33" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_262><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 262</p><br/>A media company has an application that tracks user clicks on its websites and performs analytics to provide near&#8211;real&#8211;time recommendations. The application has a Heel of Amazon EC2 instances that receive data from the websites and send the data to an Amazon RDS DB instance. Another fleet of EC2 instances hosts the portion of the application that is continuously checking changes in the database and executing SQL queries to provide recommendations. Management has requested a redesign to decouple the infrastructure. The solution must ensure that data analysts are writing SQL to analyze the data only No data can the lost during the deployment.<br/><br/>What should a solutions architect recommend?<br/><br/>A. Use Amazon Kinesis Data Streams to capture the data from the websites Kinesis Data Firehose to persist the data on Amazon S3, and Amazon Athena to query the data.<br/>B. Use Amazon Kinesis Data Streams to capture the data from the websites. Kinesis Data Analytics to query the data, and Kinesis Data Firehose to persist the data on Amazon S3.<br/>C. Use Amazon Simple Queue Service (Amazon SQS) to capture the data from the websites, keep the fleet of EC2 instances, and change to a bigger instance type in the Auto Scaling group configuration.<br/>D. Use Amazon Simple Notification Service (Amazon SNS) to receive data from the websites and proxy the messages to AWS Lambda functions that execute the queries and persist the data. Change Amazon RDS to Amazon Aurora Serverless to persist the data.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample409' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_263'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_38'>Random</a></p><div class='collapse' id='collapseExample409'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Use Amazon Kinesis Data Streams to capture the data from the websites. Kinesis Data Analytics to query the data, and Kinesis Data Firehose to persist the data on Amazon S3.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 33%;" aria-valuenow="33" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_263><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 263</p><br/>A company hosts multiple production applications.<br/><br/>One of the applications consists of resources from Amazon EC2 AWS Lambda Amazon RDS Amazon Simple Notification Service (Amazon SNS).<br/><br/>And Amazon Simple Queue Service (Amazon SQS) across multiple AWS Regions.<br/><br/>All company resources are tagged with a tag name of "application" and a value that corresponds to each application.<br/><br/>A solutions architect must provide the quickest solution for identifying all of the tagged components.<br/><br/>Which solution meets these requirements?<br/><br/>A. Use AWS CloudTrail to generate a list of resources with the application tag<br/>B. Use the AWS CLI to query each service across all Regions to report the tagged components<br/>C. Run a query in Amazon CloudWatch Logs Insights to report on the components with the application tag<br/>D. Run a query with the AWS Resource Groups Tag Editor to report on the resources globally with the application tag<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample583' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_264'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_499'>Random</a></p><div class='collapse' id='collapseExample583'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Run a query with the AWS Resource Groups Tag Editor to report on the resources globally with the application tag</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 33%;" aria-valuenow="33" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_264><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 264</p><br/>A company delivers files in Amazon S3 to certain users who do not have AWS credentials. These users must be given access for a limited time.<br/><br/>What should a solutions architect do to securely meet these requirements?<br/><br/>A. Enable public access on an Amazon S3 bucket.<br/>B. Generate a presigned URL to share with the users.<br/>C. Encrypt files using AWS KMS and provide keys to the users.<br/>D. Create and assign IAM roles that will grant GetObject permissions to the users.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample63' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_265'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_84'>Random</a></p><div class='collapse' id='collapseExample63'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Generate a presigned URL to share with the users.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 33%;" aria-valuenow="33" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_265><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 265</p><br/>A company finds that, as its use of Amazon EC2 instances grows us Amazon Elastic Block Store (Amazon EDS) storage costs are increasing faster man expected.<br/><br/>Which EBS management practices would help reduce costs? (Select TWO. )<br/><br/>A. Convert the EBS volumes to an EC2 instance store.<br/>B. Monitor and enforce that the Delete on termination attribute is set to true for all EBS volumes, unless persistence requirements dictate otherwise.<br/>C. Purchase an EC2 Instance Savings Plan for an EBS volumes that are serving persistent business requirements.<br/>D. For EBS volumes needed for retention purposes that are not being actively used, take a snapshot and terminate the instance and volume.<br/>E. Convert the existing EBS volumes to EBS Provisio ed IOPS SSD (io1).<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample592' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_266'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_152'>Random</a></p><div class='collapse' id='collapseExample592'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Monitor and enforce that the Delete on termination attribute is set to true for all EBS volumes, unless persistence requirements dictate otherwise.
<br><b>D. </b>For EBS volumes needed for retention purposes that are not being actively used, take a snapshot and terminate the instance and volume.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 33%;" aria-valuenow="33" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_266><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 266</p><br/>A company needs to run its external website on Amazon EC2 instances and on&#8211;premises virtualized servers.<br/><br/>The AWS environment has a 1 GB AWS Direct Connect connection to the data center. The application has IP addresses that will not change.<br/><br/>The on&#8211;premises and AWS servers are able to restart themselves while maintaining the same IP address if a failure occurs.<br/><br/>Some website users have to add their vendors to an allow list, so the solution must have a fixed IP address.<br/><br/>The company needs a solution with the lowest operational overhead to handle this split traffic. What should a solutions architect do to meet these requirements?<br/><br/>A. Deploy an Amazon Route 53 Resolver with rules pointing to the on&#8211;premises and AWS IP addresses<br/>B. Deploy a Network Load Balancer on AWS. Create target groups for the on&#8211;premises and AWS IP addresses.<br/>C. Deploy an Application Load Balancer on AWS Register the on&#8211;premises and AWS IP addresses with the target group.<br/>D. Deploy Amazon API Gateway to direct traffic to the on&#8211;premises and AWS IP addresses based on the header of the request.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample642' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_267'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_723'>Random</a></p><div class='collapse' id='collapseExample642'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Deploy an Amazon Route 53 Resolver with rules pointing to the on-premises and AWS IP addresses</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 33%;" aria-valuenow="33" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_267><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 267</p><br/>A solutions architect needs to host a high performance computing (HPC) workload in the AWS Cloud.<br/><br/>The workload will run on hundreds of Amazon EC2 instances and will require parallel access to a shared file system to enable distributed processing of large datasets. Datasets will be accessed across multiple instances simultaneously.<br/><br/>The workload requires access latency within 1 ms.<br/><br/>After processing has completed, engineer will need access to the dataset for manual postprocessing.<br/><br/>Which solution will meet these requirements?<br/><br/>A. Use Amazon Elastic File System (Amazon EFS) as a shared file system. Access the dataset from Amazon EFS.<br/>B. Mount an Amazon S3 bucket to serve as the shared file system Perform postprocessing directly from the S3 bucket<br/>C. Use Amazon FSx for Lustre as a shared file system. Link the file system to an Amazon S3 bucket for postprocessing.<br/>D. Configure AWS Resource Access Manager to share an Amazon S3 bucket so that it can be mounted to all instances for processing and postprocessing<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample647' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_268'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_398'>Random</a></p><div class='collapse' id='collapseExample647'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Use Amazon Elastic File System (Amazon EFS) as a shared file system. Access the dataset from Amazon EFS.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 33%;" aria-valuenow="33" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_268><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 268</p><br/>A company needs to store 160TB of data for an indefinite of time. The company must be able to use standard SQL and business intelligence tools to query all of the data. The data will be queried no more than twice each month.<br/><br/>What is the MOST cost&#8211;effective solution that meets these requirements?<br/><br/>A. Store the data in Amazon Aurora Serverless with MySQL<br/>B. Use an SQL client to query the data.<br/>C. Store the data in Amazon S3. Use AWS Glue. Amazon Athena. IDBC and COBC drivers to query the data.<br/>D. Store the data in an Amazon EMR cluster with EMR File System (EMRFS) as the storage layer use Apache Presto to query the data.<br/>E. Store a subnet of the data in Amazon Redshift, and store the remaining data in Amazon S3. Use Amazon Redshift Spectrum to query the S3 data.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample479' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_269'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_485'>Random</a></p><div class='collapse' id='collapseExample479'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Store the data in an Amazon EMR cluster with EMR File System (EMRFS) as the storage layer use Apache Presto to query the data.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 33%;" aria-valuenow="33" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_269><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 269</p><br/>A media company stores video content in an Amazon Elastic Block Store (Amazon EBS) volume. A certain video file has become popular and a large number of users across the world are accessing this content.<br/><br/>This has resulted in a cost increase.<br/><br/>Which action will DECREASE cost without compromising user accessibility?<br/><br/>A. Change the EBS volume to Provisioned IOPS (PIOPS).<br/>B. Store the video in an Amazon S3 bucket and create an Amazon CloudFront distribution.<br/>C. Split the video into multiple, smaller segments so users are routed to the requested video segments only.<br/>D. Clear an Amazon S3 bucket in each Region and upload the videos so users are routed to the nearest S3 bucket.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample375' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_270'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_449'>Random</a></p><div class='collapse' id='collapseExample375'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Store the video in an Amazon S3 bucket and create an Amazon CloudFront distribution.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 34%;" aria-valuenow="34" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_270><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 270</p><br/>A company hosts its application in the AWS Cloud. The application runs on Amazon EC2 instances behind an Elastic Load Balancer in an Auto Scaling group and with an Amazon DynamoDB table. The company wants to ensure the application can be made available in another AWS Region with minimal downtime.<br/><br/>What should a solutions architect do to meet these requirements with the LEAST amount of downtime?<br/><br/>A. Create an Auto Scaling group and a load balancer in the disaster recovery Region. Configure the DynamoDB table as a global table. Configure DNS failover to point to the new disaster recovery Region's load balancer.<br/>B. Create an AWS CloudFormation template to create EC2 instances, load balancers, and DynamoDB tables to be executed when needed. Configure DNS failover to point to the new disaster recovery Region's load balancer.<br/>C. Create an AWS CloudFormation template to create EC2 instances and a load balancer to be executed when needed. Configure the DynamoDB table as a global table. Configure DNS failover to point to the new disaster recovery Region's load balancer.<br/>D. Create an Auto Scaling group and load balancer in the disaster recovery Region. Configure the DynamoDB table as a global table. Create an Amazon CloudWatch alarm to trigger and AWS Lambda function that updates Amazon Route 53 pointing to the disaster recovery load balancer.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample246' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_271'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_432'>Random</a></p><div class='collapse' id='collapseExample246'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Create an Auto Scaling group and load balancer in the disaster recovery Region. Configure the DynamoDB table as a global table. Create an Amazon CloudWatch alarm to trigger and AWS Lambda function that updates Amazon Route 53 pointing to the disaster recovery load balancer.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 34%;" aria-valuenow="34" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_271><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 271</p><br/>A company is building a media&#8211;sharing application and decides to use Amazon S3 for storage. When a media file is uploaded the company starts a multi&#8211;step process to create thumbnails, identify objects in the images, transcode videos into standard formats and resolutions and extract and store the metadata to an Amazon DynamoDB table.<br/><br/>The metadata is used for searching and navigation. The amount of traffic is variable The solution must be able to scale to handle spikes in load without unnecessary expenses.<br/><br/>What should a solutions architect recommend to support this workload?<br/><br/>A. Build the processing into the website or mobile app used to upload the content to Amazon S3. Save the required data to the DynamoDB table when the objects are uploaded<br/>B. Trigger AWS Step Functions when an object is stored in the S3 bucket. Have the Step Functions perform the steps needed to process the object and then write the metadata to the DynamoDB table<br/>C. Trigger an AWS Lambda function when an object is stored in the S3 bucket. Have the Lambda function start AWS Batch to perform the steps to process the object. Place the object data in the DynamoDB table when complete<br/>D. Trigger an AWS Lambda function to store an initial entry in the DynamoDB table when an object is uploaded to Amazon S3. Use a program running on an Amazon EC2 instance in an Auto Scaling group to poll the index for unprocess use the program to perform the processing<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample719' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_272'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_560'>Random</a></p><div class='collapse' id='collapseExample719'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Trigger an AWS Lambda function when an object is stored in the S3 bucket. Have the Lambda function start AWS Batch to perform the steps to process the object. Place the object data in the DynamoDB table when complete</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 34%;" aria-valuenow="34" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_272><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 272</p><br/>A Solutions Architect is designing the architecture for a web application that will be hosted on AWS. Internet users will access the application using HTTP and HTTPS.<br/><br/>How should the Architect design the traffic control requirements?<br/><br/>A. Use a network ACL to allow outbound ports for HTTP and HTTPS. Deny other traffic for inbound and outbound.<br/>B. Use a network ACL to allow inbound ports for HTTP and HTTPS. Deny other traffic for inbound and outbound.<br/>C. Allow inbound ports for HTTP and HTTPS in the security group used by the web servers.<br/>D. Allow outbound ports for HTTP and HTTPS in the security group used by the web servers.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample736' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_273'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_151'>Random</a></p><div class='collapse' id='collapseExample736'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Allow inbound ports for HTTP and HTTPS in the security group used by the web servers.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 34%;" aria-valuenow="34" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_273><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 273</p><br/>A user has created an EBS volume with 1000 IOPS. What is the average IOPS that the user will get for most of the year as per EC2 SLA if the instance is attached to the EBS optimized instance?<br/><br/>A. 950<br/>B. 990<br/>C. 1000<br/>D. 900<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample758' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation758' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_274'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_428'>Random</a></p><div class='collapse' id='collapseExample758'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>900</div></div></div><div class='collapse' id='explanation758'><div class='card card&#45;body'><div>
As per AWS SLA if the instance is attached to an EBS-Optimized instance, then the Provisioned IOPS volumes are designed to deliver within 10% of the provisioned IOPS performance 99.9% of the time in a given year. Thus, if the user has created a volume of 1000 IOPS, the user will get a minimum 900 IOPS 99.9% time of the year.

References:

Amazon EC2 FAQs</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 34%;" aria-valuenow="34" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_274><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 274</p><br/>A company recently migrated a message processing system to AWS. The system receives messages into an ActiveMQ queue running on an Amazon EC2 instance. Messages are processed by a consumer application running on Amazon EC2. The consumer application processes the messages and writes results to a MySQL database running on Amazon EC2. The company wants this application to be highly available with low operational complexity<br/><br/>Which architecture offers the HIGHEST availability?<br/><br/>A. Add a second ActiveMQ server to another Availability Zone Add an additional consumer EC2 instance in another Availability Zone Replicate the MySQL database to another Availability Zone.<br/>B. Use Amazon MQ with active/standby brokers configured across two Availability Zones Add an additional consumer EC2 instance in another Availability Zone. Replicate the MySQL database to another Availability Zone<br/>C. Use Amazon MQ with active/standby brokers configured across two Availability Zones. Add an additional consumer EC2 instance in another Availability Zone. Use Amazon RDS for MySQL with Multi&#8211;AZ enabled<br/>D. Use Amazon MQ with active/standby brokers configured across two Availability Zones Add an Auto Scaling group for the consumer EC2 instances across two Availability Zones Use Amazon RDS for MySQL with Multi&#8211;AZ enabled.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample493' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_275'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_455'>Random</a></p><div class='collapse' id='collapseExample493'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Use Amazon MQ with active/standby brokers configured across two Availability Zones Add an Auto Scaling group for the consumer EC2 instances across two Availability Zones Use Amazon RDS for MySQL with Multi-AZ enabled.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 34%;" aria-valuenow="34" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_275><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 275</p><br/>A solutions architect is creating a new VPC design. There are two public subnet for the load balancer, two private subnets for web servers, and two private subnets for MySQL. The web serves use only HTTPS. The solutions architect has already created a security group for the load Balancer allowing port 443 from 0.0 0.0/0. Company policy requires that each resource has the least access required to still be able to perform its tasks.<br/><br/>Which additional configuration strategy should the solution architect use to meet these requirements?<br/><br/>A. Create a security group for the web servers and allow port 443 from 0.0.0.070. Create a security group for the MySQL serve's aid allow port 3306 from the web servers security group.<br/>B. Create a network ACL for the web servers and allow port 443 from 0.0.0.0/0. Create a network ACL for the MySQL servers and allow port 3306 from the web servers security group<br/>C. Create a security group for the web servers and allow port 443 from the load balancer. Create a security group for the MySQL servers and allow port 3306 from the web sewers security group<br/>D. Create a network ACL for the web servers and allow port 443 from the web balancer. Create a network ACL for the MySQL servers and allow port 3306 from the web servers security group.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample504' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_276'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_120'>Random</a></p><div class='collapse' id='collapseExample504'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Create a security group for the web servers and allow port 443 from the load balancer. Create a security group for the MySQL servers and allow port 3306 from the web sewers security group</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 34%;" aria-valuenow="34" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_276><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 276</p><br/>A company has an application that generates a large number of files, each approximately 5 MB in size. The files are stored in Amazon S3. Company policy requires the files to be stored for 4 years before they can be deleted. Immediate accessibility is always required as the files contain critical business data that is not easy to reproduce. The files are frequently accessed in the first 30 days of the object creation but are rarely accessed after the first 30 days.<br/><br/>Which storage solution is MOST cost effective?<br/><br/>A. Create an S3 bucket lifecycle policy to move files from S3 Standard to S3 Glacier 30 days from object creation. Delete the files 4 years after the object creation.<br/>B. Create an S3 bucket lifecycle policy to move files from S3 Standard to S3 One Zone&#8211;Infrequent Access (S3 One Zone&#8211;IA) 30 days from object creation. Delete the files 4 years after the object creation.<br/>C. Create an S3 bucket lifecycle policy to move files from S3 Standard to S3 Standard&#8211;Infrequent Access (S3 Standard&#8211;IA) 30 days from object creation. Delete the files 4 years after the object creation.<br/>D. Create an S3 bucket lifecycle policy to move files from S3 Standard to S3 Standard&#8211;Infrequent Access (S3 Standard&#8211;IA) 30 days from object creation. Move the file to S3 Glacier 4 years after object creation.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample700' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_277'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_771'>Random</a></p><div class='collapse' id='collapseExample700'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Create an S3 bucket lifecycle policy to move files from S3 Standard to S3 Standard-Infrequent Access (S3 Standard-IA) 30 days from object creation. Delete the files 4 years after the object creation.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 34%;" aria-valuenow="34" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_277><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 277</p><br/>A company runs an application on Amazon EC2 instances. The application is deployed in private subnets in three Availability Zones of the us&#8211;east&#8211;1 Region. The instances must be able to connect to the internet to download files. The company wants a design that is highly available across the Region.<br/><br/>Which solution should be implemented to ensure that there are no disruptions to internet connectivity?<br/><br/>A. Deploy a NAT instance in a private subnet of each Availability Zone.<br/>B. Deploy a NAT gateway in a public subnet of each Availability Zone.<br/>C. Deploy a transit gateway in a private subnet of each Availability Zone.<br/>D. Deploy an internet gateway in a public subnet of each Availability Zone.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample86' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_278'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_69'>Random</a></p><div class='collapse' id='collapseExample86'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Deploy a NAT gateway in a public subnet of each Availability Zone.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 35%;" aria-valuenow="35" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_278><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 278</p><br/>A gaming company is designing a highly available architecture.<br/><br/>The application runs on a modified Linux kernel and support only UDP&#8211;based traffic. The company needs the front&#8211;end tier to provide the best possible user experience.<br/><br/>The tier must have low latency, route traffic to the nearest edge location, and possible static IP addresses for entry into the application endpoints.<br/><br/>What should a solution architect do to meet these requirements?<br/><br/>A. Configure Amazon Route 53 to forward requests to an Application Load Balancer. Use AWS Lambda for the application in AWS Application Auto Scaling.<br/>B. Configure Amazon CloudFront to forward requests to a network Load Balancer. Use AWS Lambda for the application in a AWS Application Auto Scaling group<br/>C. Configure AWS Global Accelerator to forward requests to a Network Load Balancer. Use Amazon EC2 instances for the application in an EC2 Auto Sca ing group.<br/>D. Configure Amazon API Gateway to forward requests to an Application Load Balancer. Use Amazon EC2 instances for the application in an EC2 Auto Scaling group.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample600' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_279'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_689'>Random</a></p><div class='collapse' id='collapseExample600'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Configure Amazon Route 53 to forward requests to an Application Load Balancer. Use AWS Lambda for the application in AWS Application Auto Scaling.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 35%;" aria-valuenow="35" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_279><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 279</p><br/>A company runs an application on three very large Amazon EC2 instances.<br/><br/>In a single Availability Zone in the us&#8211;east&#8211;1 Region Multiple 16 TB Amazon Elastic Block Store (Amazon EBS) volumes are attached to each EC2 instance.<br/><br/>The operations team uses an AWS Lambda script triggered by a schedule&#8211;based Amazon EventBridge (Amazon CloudWatch Events) rule to stop the instances on evenings and weekends, and start the instances on weekday mornings.<br/><br/>Before deploying the solution, the company used the public AWS pricing documentation to estimate the overall costs of running this data warehouse solution 5 days a week for 10 hours a day.<br/><br/>When looking at monthly Cost Explorer charges for this new account, the overall charges are higher than the estimate.<br/><br/>What is the MOST likely cost factor that the company overlooked?<br/><br/>A. EC2 data transfer charges between the instances are much higher than expected<br/>B. EC2 and EBS rates are higher in us&#8211;east&#8211;1 than most other AWS Regions<br/>C. The Lambda charges to stop and start the instances are much higher than expected.<br/>D. The company is being billed for the EBS storage on nights and weekends<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample584' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_280'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_521'>Random</a></p><div class='collapse' id='collapseExample584'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>The company is being billed for the EBS storage on nights and weekends</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 35%;" aria-valuenow="35" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_280><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 280</p><br/>A user wants to list the IAM role that is attached to their Amazon EC2 instance. The user has login access to the EC2 instance but does not have IAM permissions.<br/><br/>What should a solutions architect do to retrieve this information?<br/><br/>A. Run the following EC2 command curl http://169.254.169.254/latest/meta&#8211;data/iam/info<br/>B. Run the following EC2 command curl http://169.254.169.254/latest&#8211;/user&#8211;data/iam/info<br/>C. Run the following EC2 command http://169.254.169.254/latest/dynamic/instance&#8211;idencity/<br/>D. Run the following AWS CLI command aws iam get&#8211;instance&#8211;prof lie &#8212;instance&#8211;profile&#8211;name ExamplelnstanceProfile<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample667' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_281'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_422'>Random</a></p><div class='collapse' id='collapseExample667'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Run the following EC2 command curl http://169.254.169.254/latest-/user-data/iam/info</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 35%;" aria-valuenow="35" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_281><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 281</p><br/>A company is designing a website that uses an Amazon S3 bucket to store static images. The company wants all future requests to have faster response times while reducing both latency and cost.<br/><br/>Which service configuration should a solutions architect recommend?<br/><br/>A. Deploy a NAT server in front of Amazon S3.<br/>B. Deploy Amazon CloudFront in front of Amazon S3.<br/>C. Deploy a Network Load Balancer in front of Amazon S3.<br/>D. Configure Auto Scaling to automatically adjust the capacity of the website.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample232' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_282'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_598'>Random</a></p><div class='collapse' id='collapseExample232'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Deploy Amazon CloudFront in front of Amazon S3.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 35%;" aria-valuenow="35" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_282><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 282</p><br/>A company must re&#8211;evaluate its need for the Amazon EC2 instances it currently has provisioned in an Auto Scaling group. At present, the Auto Scaling group is configured for a minimum of two instances and a maximum of four instances across two Availability Zones. A Solutions architect reviewed Amazon CloudWatch metrics and found that CPU utilization is consistently low for all the EC2 instances.<br/><br/>What should the solutions architect recommend to maximize utilization while ensuring the application remains fault&#8211;tolerant?<br/><br/>A. Remove some EC2 instances to increase the utilization of remaining instances.<br/>B. Increase the Amazon Elastic Block Store (Amazon EBS) capacity of instances with less CPU utilization.<br/>C. Modify the Auto Scaling group scaling policy to scale in and out based on a higher CPU utilization metric.<br/>D. Create a new launch configuration that uses smaller instance types. Update the existing Auto Scaling group.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample212' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation212' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_283'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_784'>Random</a></p><div class='collapse' id='collapseExample212'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Create a new launch configuration that uses smaller instance types. Update the existing Auto Scaling group.</div></div></div><div class='collapse' id='explanation212'><div class='card card&#45;body'><div>
As the Launch Configuration can't be modified once created, only way to update the Launch Configuration for an Auto Scaling group is to create a new one and associate it with the Auto Scaling group.
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 35%;" aria-valuenow="35" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_283><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 283</p><br/>A company operates a website on Amazon EC2 Linux instances. Some of the instances are failing.<br/><br/>Troubleshooting points to insufficient swap space on the failed instances. The operations team lead needs a solution to monitor this.<br/><br/>What should a solutions architect recommend?<br/><br/>A. Configure an Amazon CloudWatch SwapUsage metric dimension. Monitor the SwapUsage dimension in the EC2 metrics in CloudWatch.<br/>B. Use EC2 metadata to collect information, then publish it to Amazon CloudWatch custom metrics. Monitor SwapUsage metrics in CloudWatch.<br/>C. Install an Amazon CloudWatch agent on the instances. Run an appropriate script on a set schedule. Monitor SwapUtilization metrics in CloudWatch.<br/>D. Enable detailed monitoring in the EC2 console. Create an Amazon CloudWatch SwapUtilization custom metric. Monitor SwapUtilization metrics in CloudWatch.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample211' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_284'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_166'>Random</a></p><div class='collapse' id='collapseExample211'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Install an Amazon CloudWatch agent on the instances. Run an appropriate script on a set schedule. Monitor SwapUtilization metrics in CloudWatch.

References:

Amazon Elastic Compute Cloud > User Guide for Linux Instances > Monitor memory and disk metrics for Amazon EC2 Linux instances</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 35%;" aria-valuenow="35" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_284><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 284</p><br/>A company wants to reduce its Amazon S3 storage costs in its production environment without impacting durability or performance of the stored objects.<br/><br/>What is the FIRST step the company should take to meet these objectives?<br/><br/>A. Enable Amazon Macie on the business&#8211;critical S3 buckets to classify the sensitivity of the objects.<br/>B. Enable S3 analytics to identify S3 buckets that are candidates for transitioning to S3 Standard&#8211; Infrequent Access (S3 Standard&#8211;IA).<br/>C. Enable versioning on all business&#8211;critical S3 buckets.<br/>D. Migrate the objects in all S3 buckets to S3 Intelligent&#8211;Tiering.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample366' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_285'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_272'>Random</a></p><div class='collapse' id='collapseExample366'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Migrate the objects in all S3 buckets to S3 Intelligent-Tiering.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 35%;" aria-valuenow="35" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_285><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 285</p><br/>A company is hosting 60 TB of production&#8211;level data in an Amazon S3 bucket. A solution architect needs to bring that data on&#8211;premises for quarterly audit requirements. This export of data must be encrypted while in transit. The company has low network bandwidth in place between AWS and its on&#8211;premises data center.<br/><br/>What should the solutions architect do to meet these requirements?<br/><br/>A. Deploy AWS Migration Hub with 90&#8211;day replication windows for data transfer.<br/>B. Deploy an AWS Storage Gateway volume gateway on AWS. Enable a 90&#8211;day replication window to transfer the data.<br/>C. Deploy Amazon Elastic File System (Amazon EFS), with lifecycle policies enabled, on AWS. Use it to transfer the data.<br/>D. Deploy an AWS Snowball device in the on&#8211;premises data center after completing an export job request in the AWS Snowball console.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample286' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation286' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_286'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_487'>Random</a></p><div class='collapse' id='collapseExample286'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Deploy an AWS Snowball device in the on-premises data center after completing an export job request in the AWS Snowball console.</div></div></div><div class='collapse' id='explanation286'><div class='card card&#45;body'><div>
AWS Snowball with the Snowball device has the following features: 80 TB and 50 TB models are available in US Regions; 50 TB model available in all other AWS Regions.

References:

AWS Snowball > User Guide > What Is an AWS Snowball Device?</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 36%;" aria-valuenow="36" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_286><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 286</p><br/>A solutions architect is designing the architecture for a new web application. The application will run on AWS Fargate containers with an Application Load Balancer (ALB) and an Amazon Aurora PostgreSQL database. The web application will perform primarily read queries against the database.<br/><br/>What should the solutions architect do to ensure that the website can scale with increasing traffic? (Select TWO.)<br/><br/>A. Enable auto scaling on the ALB to scale the load balancer horizontally.<br/>B. Configure Aurora Auto Scaling to adjust the number of Aurora Replicas in the Aurora cluster dynamically.<br/>C. Enable cross&#8211;zone load balancing on the ALB to distribute the load evenly across containers in all Availability Zones.<br/>D. Configure an Amazon Elastic Container Service (Amazon ECS) cluster in each Availability Zone to distribute the load across multiple Availability Zones.<br/>E. Configure Amazon Elastic Container Service (Amazon ECS) Service Auto Scaling with a target tracking scaling policy that is based on CPU utilization.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample464' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_287'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_222'>Random</a></p><div class='collapse' id='collapseExample464'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Enable auto scaling on the ALB to scale the load balancer horizontally.
<br><b>B. </b>Configure Aurora Auto Scaling to adjust the number of Aurora Replicas in the Aurora cluster dynamically.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 36%;" aria-valuenow="36" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_287><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 287</p><br/>A company has an application that servers clients that are deployed in more than 20,000 retail storefront locations around the world.<br/><br/>The application consists of backend web services that are exposed over HTTPS on port 443. The application is hosted on Amazon EC2 instance behind an Application Load balancer (ALB). The retail locations communicate with the web applications over the public internet.<br/><br/>The company allows each retail location to register the IP address that the retail location has been allocated by its local ISP.<br/><br/>The company's security team recommends to increase the security of the application endpoint by restricting access to only the IP addresses registered by the retail locations.<br/><br/>What should a solutions architect do to meet these requirements?<br/><br/>A. Associate an AWS WAF web ACL with the ALB. Use IP rule sets on the ALB to filter traffic. Update the IP addresses in the rule to include the registered IP addresses.<br/>B. Deploy AWS Firewall Manager to manage the ALB. Configure firewall rules to restrict traffic to the ALB. Modify the firewall rules to include the registered IP addresses.<br/>C. Store the IP addresses in an Amazon DynamicDB table. Configure an AWS Lambda authorization function on the ALB to validate that incoming requests are from the registered IP addresses.<br/>D. Configure the network ACL on the subnet that contains the public interface of the ALB. Update the ingress rules on the network ACL with entries for each of the registered IP addresses.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample616' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_288'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_293'>Random</a></p><div class='collapse' id='collapseExample616'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Store the IP addresses in an Amazon DynamicDB table. Configure an AWS Lambda authorization function on the ALB to validate that incoming requests are from the registered IP addresses.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 36%;" aria-valuenow="36" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_288><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 288</p><br/>What is a placement group in Amazon EC2?<br/><br/>A. It is a group of EC2 instances within a single Availability Zone.<br/>B. It the edge location of your web content.<br/>C. It is the AWS region where you run the EC2 instance of your web content.<br/>D. It is a group used to span multiple Availability Zones.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample773' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation773' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_289'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_728'>Random</a></p><div class='collapse' id='collapseExample773'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>It is a group of EC2 instances within a single Availability Zone.</div></div></div><div class='collapse' id='explanation773'><div class='card card&#45;body'><div>
A placement group is a logical grouping of instances within a single Availability Zone.

References:

Amazon Elastic Compute Cloud > User Guide for Linux Instances > Placement groups</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 36%;" aria-valuenow="36" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_289><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 289</p><br/>A solutions architect is performing a security review of a recently migrated workload. The workload is a web application that consists of Amazon EC2 instances in an Auto Scaling group behind an Application Load Balancer.<br/><br/>The solution architect must improve the security posture and minimize the impact of a DDoS attack on resources.<br/><br/>Which solution is MOST effective?<br/><br/>A. Configure an AWS WAF ACL with rate&#8211;based rules. Create an Amazon CloudFront distribution that points to the Application Load Balancer. Enable the WAF ACL on the CloudFront distribution.<br/>B. Create a custom AWS Lambda function that adds identified attacks into a common vulnerability pool to capture a potential DDoS attack. Use the identified information to modify a network ACL to block access.<br/>C. Enable VPC Flow Logs and store them in Amazon S3. Create a custom AWS Lambda functions that parses the logs looking for a DDoS attack. Modify a network ACL to block identified source IP addresses.<br/>D. Enable Amazon GuardDuty and configure findings written to Amazon CloudWatch. Create an event with CloudWatch Events for DDoS alerts that triggers Amazon Simple Notification Service (Amazon SNS). Have Amazon SNS invoke a custom AWS Lambda function that parses the logs, looking for a DDoS attack. Modify a network ACL to block identified source IP addresses.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample111' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_290'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_738'>Random</a></p><div class='collapse' id='collapseExample111'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Create a custom AWS Lambda function that adds identified attacks into a common vulnerability pool to capture a potential DDoS attack. Use the identified information to modify a network ACL to block access.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 36%;" aria-valuenow="36" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_290><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 290</p><br/>A company is hosting a website behind multiple Application Load Balancers. The company has different distribution rights for its content around the world. A solutions architect needs to ensure that users are served the correct content without violating distribution rights.<br/><br/>Which configuration should the solutions architect choose to meet these requirements?<br/><br/>A. Configure Amazon CloudFront with AWS WAF.<br/>B. Configure Application Load Balancers with AWS WAF.<br/>C. Configure Amazon Route 53 with a geolocation policy.<br/>D. Configure Amazon Route 53 with a geoproximity routing policy.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample262' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation262' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_291'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_547'>Random</a></p><div class='collapse' id='collapseExample262'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Configure Amazon Route 53 with a geolocation policy.</div></div></div><div class='collapse' id='explanation262'><div class='card card&#45;body'><div>
Geolocation routing policy C Use when you want to route traffic based on the location of your users.

References:

Amazon Route 53 > Developer Guide > Choosing a routing policy</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 36%;" aria-valuenow="36" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_291><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 291</p><br/>A company has recently updated its internal security standards. The company must now ensure all Amazon S3 buckets and Amazon Elastic Block Store (Amazon EBS) volumes are encrypted with keys created and periodically rotated by internal security specialists. The company is looking for a native, software&#8211;based AWS service to accomplish this goal.<br/><br/>What should a solutions architect recommend as a solution?<br/><br/>A. Use AWS Secrets Manager with customer master keys (CMKs) to store master key material and apply a routine to create a new CMK periodically and replace it in AWS Secrets Manager.<br/>B. Use AWS Key Management Service (AWS KMS) with customer master keys (CMKs) to store master key material and apply a routine to re&#8211;create a new key periodically and replace it in AWS KMS.<br/>C. Use an AWS CloudHSM cluster with customer master keys (CMKs) to store master key material and apply a routine to re&#8211;create a new key periodically and replace it in the CloudHSM cluster nodes.<br/>D. Use AWS Systems Manager Parameter Store with customer master keys (CMKs) to store master key material and apply a routine to re&#8211;create a new key periodically and replace it in the Parameter Store.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample105' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_292'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_32'>Random</a></p><div class='collapse' id='collapseExample105'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Use AWS Secrets Manager with customer master keys (CMKs) to store master key material and apply a routine to create a new CMK periodically and replace it in AWS Secrets Manager.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 36%;" aria-valuenow="36" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_292><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 292</p><br/>An eceCommerceompany is experiencing an increase in user traffic. The company's store is deployed on Amazon EC2 instances as a two&#8211;tier two application consisting of a web tier and a separate database tier.<br/><br/>As traffic increases, the company notices that the architecture is causing significant delays in sending timely marketing and order confirmation email to users. The company wants to reduce the time it spends resolving complex email delivery issues and minimize operational overhead.<br/><br/>What should a solutions architect do to meet these requirements?<br/><br/>A. Create a separate application tier using EC2 instances dedicated to email processing.<br/>B. Configure the web instance to send email through Amazon Simple Email Service (Amazon SES).<br/>C. Configure the web instance to send email through Amazon Simple Notification Service (Amazon SNS).<br/>D. Create a separate application tier using EC2 instances dedicated to email processing. Place the instances in an Auto Scaling group.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample305' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_293'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_456'>Random</a></p><div class='collapse' id='collapseExample305'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Configure the web instance to send email through Amazon Simple Email Service (Amazon SES).</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 36%;" aria-valuenow="36" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_293><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 293</p><br/>After reviewing the cost optimization checks in AWS Trusted Advisor, a team finds that it has 10,000 Amazon Elastic Block Store (Amazon EBS) snapshots in its account that are more than 30 days old.<br/><br/>When the team determines that it needs to implement better governance for the lifecycle of its resources.<br/><br/>Which actions should the team take to automate the lifecycle management of the EBS snapshots with the LEAST effort? (Select TWO)<br/><br/>A. Create and schedule a backup plan with AWS Backup<br/>B. Copy the EBS snapshots to Amazon S3 and then create lifecycle configurations in the S3 bucket<br/>C. Use Amazon Data Lifecycle Manager (Amazon DLM)<br/>D. Use a scheduled event in Amazon EventBridge (Amazon CloudWatch Events) and invoke AWS Step Functions to manage the snapshots<br/>E. Schedule and run backups in AWS Systems Manager.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample657' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_294'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_770'>Random</a></p><div class='collapse' id='collapseExample657'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Use a scheduled event in Amazon EventBridge (Amazon CloudWatch Events) and invoke AWS Step Functions to manage the snapshots
<br><b>E. </b>Schedule and run backups in AWS Systems Manager.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 37%;" aria-valuenow="37" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_294><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 294</p><br/>A company is deploying a production portal application on AWS. The database tier has structured data.<br/><br/>The company requires a solution that is easily manageable and highly available.<br/><br/>How can these requirements be met?<br/><br/>A. Deploy the database on multiple Amazon EC2 instances backed by Amazon Elastic Block Store (Amazon EBS) across multiple Availability Zones.<br/>B. Use Amazon RDS with a multiple Availability Zone option<br/>C. Use Amazon RDS with a single Availability Zone option and schedule periodic database snapshots.<br/>D. Use Amazon DynamoDB<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample572' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_295'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_708'>Random</a></p><div class='collapse' id='collapseExample572'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Deploy the database on multiple Amazon EC2 instances backed by Amazon Elastic Block Store (Amazon EBS) across multiple Availability Zones.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 37%;" aria-valuenow="37" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_295><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 295</p><br/>A company wants to improve the availability and performance of its stateless UDP&#8211;based workload. The workload is deployed on Amazon EC2 instances in multiple AWS Regions.<br/><br/>What should a solutions architect recommend to accomplish this?<br/><br/>A. Place the EC2 instances behind Network Load Balancers (NLBs) in each Region. Create an accelerator using AWS Global Accelerator. Use the NLBs as endpoints for the accelerator.<br/>B. Place the EC2 instances behind Application Load Balancers (ALBs) in each Region. Create an accelerator using AWS Global Accelerator. Use the ALBs as endpoints for the accelerator.<br/>C. Place the EC2 instances behind Network Load Balancers (NLBs) in each Region. Create an Amazon CloudFront distribution with an origin that uses Amazon Route 53 latency&#8211;based routing to route requests to the NLBs.<br/>D. Place the EC2 instances behind Application Load Balancers (ALBs) in each Region. Create an Amazon CloudFront distribution with an origin that uses Amazon Route 53 latency&#8211;based routing to route requests to the ALBs.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample387' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_296'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_311'>Random</a></p><div class='collapse' id='collapseExample387'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Place the EC2 instances behind Application Load Balancers (ALBs) in each Region. Create an Amazon CloudFront distribution with an origin that uses Amazon Route 53 latency-based routing to route requests to the ALBs.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 37%;" aria-valuenow="37" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_296><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 296</p><br/>A company is running a multi&#8211;tier eCommerce web application in the AWS Cloud. The web application is running on Amazon EC2 instances.<br/><br/>The database tier Is on a provisioned Amazon Aurora MySQL DB cluster with a writer and a reader in a Multi&#8211;AZ environment.<br/><br/>The new requirement for the database tier is to serve the application to achieve continuous write availability through an Instance failover.<br/><br/>What should a solutions architect do to meet this new requirement?<br/><br/>A. Add a new AWS Region to the DB cluster for multiple writes<br/>B. Add a new reader In the same Availability Zone as the writer.<br/>C. Migrate the database tier to an Aurora multi&#8211;master cluster.<br/>D. Migrate the database tier to an Aurora DB cluster with parallel query enabled.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample585' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_297'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_338'>Random</a></p><div class='collapse' id='collapseExample585'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Migrate the database tier to an Aurora DB cluster with parallel query enabled.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 37%;" aria-valuenow="37" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_297><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 297</p><br/>A company has a web server running on an Amazon EC2 instance in a public subnet with an Elastic IP address. The default security group is assigned to the EC2 instance. The default network ACL has been modified to block all traffic. A solutions architect needs to make the web server accessible from everywhere on port 443.<br/><br/>Which combination of steps will accomplish this task? (Choose two.)<br/><br/>A. Create a security group with a rule to allow TCP port 443 from source 0.0.0.0/0.<br/>B. Create a security group with a rule to allow TCP port 443 to destination 0.0.0.0/0.<br/>C. Update the network ACL to allow TCP port 443 from source 0.0.0.0/0.<br/>D. Update the network ACL to allow inbound/outbound TCP port 443 from source 0.0.0.0/0 and to destination 0.0.0.0/0.<br/>E. Update the network ACL to allow inbound TCP port 443 from source 0.0.0.0/0 and outbound TCP port 32768&#8211;65535 to destination 0.0.0.0/0.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample174' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_298'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_430'>Random</a></p><div class='collapse' id='collapseExample174'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Create a security group with a rule to allow TCP port 443 from source 0.0.0.0/0.
<br><b>B. </b>Create a security group with a rule to allow TCP port 443 to destination 0.0.0.0/0.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 37%;" aria-valuenow="37" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_298><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 298</p><br/>Can a user get a notification of each instance start / terminate configured with Auto Scaling?<br/><br/>A. Yes, if configured with the Launch Config<br/>B. Yes, always<br/>C. Yes, if configured with the Auto Scaling group<br/>D. No<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample781' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation781' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_299'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_77'>Random</a></p><div class='collapse' id='collapseExample781'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Yes, if configured with the Auto Scaling group</div></div></div><div class='collapse' id='explanation781'><div class='card card&#45;body'><div>
The user can get notifications using SNS if he has configured the notifications while creating the Auto Scaling group.

References:

Amazon EC2 Auto Scaling > User Guide > Getting started with Amazon EC2 Auto Scaling</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 37%;" aria-valuenow="37" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_299><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 299</p><br/>A solutions architect is designing an architecture that includes web application and database tiers. The web tier must be capable of auto scaling. The solutions architect has decided to separate each tier into its own subnets. The design includes two public subnets and four private subnets. The security team requires that tiers be able to communicate with each other only when there is a business need and that all other network traffic be blocked.<br/><br/>What should the solutions architect do to meet these requirements?<br/><br/>A. Create an Amazon GuardDuty source destination rule set to control communication<br/>B. Create one security group for all tiers to limit traffic to only the required source and destinations<br/>C. Create specific security groups for each tier to limit traffic to only the required source and destinations<br/>D. Create network ACLs in all six subnets to limit traffic to the sources and destinations required for the application to function<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample529' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_300'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_223'>Random</a></p><div class='collapse' id='collapseExample529'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Create network ACLs in all six subnets to limit traffic to the sources and destinations required for the application to function</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 37%;" aria-valuenow="37" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_300><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 300</p><br/>A company has a service that produces event data. The company wants to use AWS to process the event data as it is received. The data is written in a specific order that must be maintained throughout processing. The company wants to implement a solution that minimizes operational overhead.<br/><br/>How should a solution architect accomplish this"<br/><br/>A. Create an Amazon Simple Queue Service (Amazon SOS) FIFO queue to hold messages. Set up an AWS Lambda function to process messages from the queue.<br/>B. Create an Amazon Simple Notification Service (Amazon SNS) topic to deliver notifications containing payloads to process. Configure an AWS Lambda function as a subscriber<br/>C. Create an Amazon Simple Queue Service (Amazon SOS) standard queue to hold messages Set up an AWS Lambda function process messages from the queue independently<br/>D. Create an Amazon Simple Notification Service (Amazon SNS) topic to deliver notifications containing payloads to process Configure an Amazon Simple Queue Service (Amazon SQS) queue as a subscriber.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample490' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_301'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_57'>Random</a></p><div class='collapse' id='collapseExample490'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Create an Amazon Simple Queue Service (Amazon SOS) FIFO queue to hold messages. Set up an AWS Lambda function to process messages from the queue.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 37%;" aria-valuenow="37" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_301><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 301</p><br/>A company uses Amazon S3 to store its confidential audit documents. The S3 bucket uses bucket policies to restrict access to audit team IAM user credentials according to the principle of least privilege. Company managers are worried about accidental deletion of documents in the S3 bucket and want a more secure solution.<br/><br/>What should a solutions architect do to secure the audit documents?<br/><br/>A. Enable the versioning and MFA Delete features on the S3 bucket.<br/>B. Enable multi&#8211;factor authentication (MFA) on the IAM user credentials for each audit team IAM user account.<br/>C. Add an S3 Lifecycle policy to the audit team's IAM user accounts to deny the s3:DeleteObject action during audit dates.<br/>D. Use AWS Key Management Service (AWS KMS) to encrypt the S3 bucket and restrict audit team IAM user accounts from accessing the KMS key.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample287' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_302'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_779'>Random</a></p><div class='collapse' id='collapseExample287'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Enable the versioning and MFA Delete features on the S3 bucket.

References:

Amazon Simple Storage Service > User Guide > Security Best Practices for Amazon S3</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 38%;" aria-valuenow="38" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_302><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 302</p><br/>A company has an application running on Amazon EC2 On&#8211;Demand Instances. The application does not scale, and the Instances run In one AWS Region. The company wants the flexibility to change the operating system from Windows to AWS Linux in the future. The company needs to reduce the cost of the instances without creating additional operational overhead or changes to the application.<br/><br/>What should the company purchase to meet these requirements MOST cost&#8211;effectively?<br/><br/>A. Dedicated Hosts for the Instance type being used<br/>B. A Compute Savings Plan for the instance type being used<br/>C. An EC2 Instance Savings Plan (or the instance type being used<br/>D. Convertible Reserved Instances tor the instance type being used<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample537' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_303'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_604'>Random</a></p><div class='collapse' id='collapseExample537'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Convertible Reserved Instances tor the instance type being used</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 38%;" aria-valuenow="38" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_303><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 303</p><br/>A solutions architect is designing an VPC that requires access to a remote API server using IPv6 Resources within the VPC should not be accessed directly from the internet.<br/><br/>How should this be achieved?<br/><br/>A. Use a NAT gateway and deny public access using security groups.<br/>B. Attach an egress&#8211;only internet gateway and update the routing tables<br/>C. Use a NAT gateway and update the routing tables<br/>D. Attach an internet gateway and deny public access using security groups<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample664' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_304'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_735'>Random</a></p><div class='collapse' id='collapseExample664'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Attach an egress-only internet gateway and update the routing tables</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 38%;" aria-valuenow="38" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_304><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 304</p><br/>As part of budget planning, management wants a report of AWS billed items listed by user. The data will be used to create department budgets. A solutions architect needs to determine the most efficient way to obtain this report information.<br/><br/>Which solution meets these requirements?<br/><br/>A. Run a query with Amazon Athena to generate the report.<br/>B. Create a report in Cost Explorer and download the report.<br/>C. Access the bill details from the billing dashboard and download the bill.<br/>D. Modify a cost budget in AWS Budgets to alert with Amazon Simple Email Service (Amazon SES).<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample133' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_305'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_543'>Random</a></p><div class='collapse' id='collapseExample133'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Create a report in Cost Explorer and download the report.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 38%;" aria-valuenow="38" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_305><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 305</p><br/>A company decides to migrate its three&#8211;tier web application from on&#8211;premises to the AWS Cloud. The new database must be capable of dynamically scaling storage capacity and performing table joins.<br/><br/>Which AWS service meets these requirements?<br/><br/>A. Amazon Aurora<br/>B. Amazon RDS for SqlServer<br/>C. Amazon DynamoDB Streams<br/>D. Amazon DynamoDB on&#8211;demand<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample94' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_306'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_231'>Random</a></p><div class='collapse' id='collapseExample94'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Amazon Aurora</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 38%;" aria-valuenow="38" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_306><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 306</p><br/>A company needs a secure connection between its on&#8211;premises environment and AWS. This connection does not need high bandwidth and will handle a small amount of traffic. The connection should be set up quickly.<br/><br/>What is the MOST cost&#8211;effective method to establish this type of connection?<br/><br/>A. Implement a client VPN.<br/>B. Implement AWS Direct Connect.<br/>C. Implement a bastion host on Amazon EC2.<br/>D. Implement an AWS Site&#8211;to&#8211;Site VPN connection.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample273' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_307'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_316'>Random</a></p><div class='collapse' id='collapseExample273'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Implement an AWS Site-to-Site VPN connection.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 38%;" aria-valuenow="38" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_307><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 307</p><br/>A company is launching a new application that will be hosted on Amazon EC2 instances. A solutions architect needs to design a solution that does not allow public IPv4 access that originates from the internet. However, the solution must allow the EC2 instances to make outbound IPv4 internet requests.<br/><br/>The initial design proposal shows that the EC2 instances would be located in two private subnets across two Availability Zones.<br/><br/>The entire architecture must be highly available.<br/><br/>How should the solutions architect change the architecture to meet these requirements?<br/><br/>A. Deploy a NAT gateway in public subnets in both Availability Zones. Create and configure one route table for each private subnet.<br/>B. Deploy an internet gateway in public subnets in both Availability Zones. Create and configure a shared route table for the private subnets.<br/>C. Deploy a NAT gateway in public subnets in both Availability Zones. Create and configure a shared route table for the private subnets.<br/>D. Deploy an egress&#8211;only internet gateway in public subnets in both Availability Zones. Create and configure one route table for each private subnet.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample452' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_308'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_85'>Random</a></p><div class='collapse' id='collapseExample452'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Deploy a NAT gateway in public subnets in both Availability Zones. Create and configure a shared route table for the private subnets.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 38%;" aria-valuenow="38" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_308><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 308</p><br/>A company is preparing to launch a public&#8211;facing web application in the AWS Cloud. The architecture consists of Amazon EC2 instances within a VPC behind an Elastic Load Balancer (ELB). A third&#8211;party service is used for the DNS. The company's solutions architect must recommend a solution to detect and protect against large&#8211;scale DDoS attacks.<br/><br/>Which solution meets these requirements?<br/><br/>A. Enable Amazon Guard Duty on the account<br/>B. Enable Amazon Inspector on the EC2 instances<br/>C. Enable AWS Shield and assign Amazon Route 53 to it.<br/>D. Enable AWS Shield Advanced and assign the ELB to it.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample707' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_309'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_697'>Random</a></p><div class='collapse' id='collapseExample707'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Enable AWS Shield Advancd and assign the ELB to it.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 38%;" aria-valuenow="38" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_309><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 309</p><br/>A social media company allows users to upload images to its website. The website runs on Amazon EC2 instances. During upload requests, the website resizes the images to a standard size and stores the resized images in Amazon S3. Users are experiencing slow upload requests to the website.<br/><br/>The company needs to reduce coupling within the application and improve website performance A solutions architect must design the most operationally efficient process for image uploads.<br/><br/>Which combination of actions should the solutions architect take to meet these requirements? (Select TWO.)<br/><br/>A. Configure the application to upload images to S3 Glacier.<br/>B. Configure the web server to upload the original images to Amazon S3.<br/>C. Configure the application to upload images directly from each user's browser to Amazon S3 through the use of a presigned UR<br/>D. Configure S3 Event Notifications to invoke an AWS Lambda function when an image is uploaded. Use the function to resize the image<br/>E. Create an Amazon EventBridge (Amazon CloudWatch Events) rule that invokes an AWS Lambda function on a schedule to resize uploaded images.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample447' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_310'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_99'>Random</a></p><div class='collapse' id='collapseExample447'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Configure S3 Event Notifications to invoke an AWS Lambda function when an image is uploaded. Use the function to resize the image</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 39%;" aria-valuenow="39" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_310><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 310</p><br/>A company stores user data in AWS. The data is used continuously with peak usage during business hours. Access patterns vary, with some data not being used for months at a time. A solution architect must choose a cost&#8211;effective solution that maintains the highest level of durability while maintaining high availability.<br/><br/>Which storage solution meets these requirements?<br/><br/>A. Amazon S3 Standard<br/>B. Amazon S3 intelligent&#8211;Tiering<br/>C. Amazon S3 Glacier Deep Archive<br/>D. Amazon S3 One Zone&#8211;infrequent Access (Se One Zone&#8211;IA)<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample670' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_311'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_243'>Random</a></p><div class='collapse' id='collapseExample670'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Amazon S3 intelligent-Tiering</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 39%;" aria-valuenow="39" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_311><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 311</p><br/>A solutions architect must provide an automated solution for a company's compliance policy that states security groups cannot include a rule that allows SSH from 0.0.0.0/0. The company needs to be notified if there is any breach in the policy. A solution is needed as soon as possible.<br/><br/>What should the solutions architect do to meet these requirements with the LEAST operational overhead?<br/><br/>A. Write an AWS Lambda script that monitors security groups for SSH being open to 0.0.0.0/0 addresses and creates a notification every time it finds one.<br/>B. Enable the restricted&#8211;ssh AWS Config managed rule and generate an Amazon Simple Notification Service (Amazon SNS) notification when a noncompliant rule is created.<br/>C. Create an IAM role with permissions to globally open security groups and network ACLs. Create an Amazon Simple Notification Service (Amazon SNS) topic to generate a notification every time the role is assumed by a user.<br/>D. Configure a service control policy (SCP) that prevents non&#8211;administrative users from creating or editing security groups. Create a notification in the ticketing system when a user requests a rule that needs administrator permissions.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample424' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_312'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_96'>Random</a></p><div class='collapse' id='collapseExample424'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Enable the restricted-ssh AWS Config managed rule and generate an Amazon Simple Notification Service (Amazon SNS) notification when a noncompliant rule is created.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 39%;" aria-valuenow="39" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_312><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 312</p><br/>A company has thousands of files stored in an Amazon S3 bucket that has a well&#8211;defined access pattern. The files are accessed by an application multiple times a day for the first 30 days. Files are rarely accessed within the next 90 days. After that, the files are never accessed again. During the first 120 days, accessing these files should never take more than a few seconds.<br/><br/>Which lifecycle policy should be used for the S3 objects to minimize costs based on the access pattern?<br/><br/>A. Use Amazon S3 Standard&#8211;Infrequent Access (S3 Standard&#8211;IA) storage for the first 30 days. Then move the files to the GLACIER storage class for the next 90 days. Allow the data to expire after that.<br/>B. Use Amazon S3 Standard storage for the first 30 days. Then move the files to Amazon S3 Standard&#8211; Infrequent Access (S3 Standard&#8211;IA) for the next 90 days. Allow the data to expire after that.<br/>C. Use Amazon S3 Standard storage for first 30 days. Then move the files to the GLACIER storage class for the next 90 days. Allow the data to expire after that.<br/>D. Use Amazon S3 Standard&#8211;Infrequent Access (S3 Standard&#8211;IA) for the first 30 days. After that, move the data to the GLACIER storage class, where is will be deleted automatically.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample792' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation792' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_313'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_123'>Random</a></p><div class='collapse' id='collapseExample792'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Use Amazon S3 Standard storage for the first 30 days. Then move the files to Amazon S3 Standard- Infrequent Access (S3 Standard-IA) for the next 90 days. Allow the data to expire after that.</div></div></div><div class='collapse' id='explanation792'><div class='card card&#45;body'><div>
It is mentioned that they need to access data in few seconds during the 120 days.
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 39%;" aria-valuenow="39" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_313><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 313</p><br/>A company wants to host a scalable web application on AWS. The application will be accessed by users from different geographic regions of the world. Application users will be able to download and upload unique data up to gigabytes in size. The development team wants a cost&#8211;effective solution to minimize upload and download latency and maximize performance.<br/><br/>What should a solutions architect do to accomplish this?<br/><br/>A. Use Amazon S3 with Transfer Acceleration to host the application.<br/>B. Use Amazon S3 with CacheControl headers to host the application.<br/>C. Use Amazon EC2 with Auto Scaling and Amazon CloudFront to host the application.<br/>D. Use Amazon EC2 with Auto Scaling and Amazon ElastiCache to host the application.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample259' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation259' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_314'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_494'>Random</a></p><div class='collapse' id='collapseExample259'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Use Amazon S3 with Transfer Acceleration to host the application.</div></div></div><div class='collapse' id='explanation259'><div class='card card&#45;body'><div>
The maximum size of a single file that can be delivered through Amazon CloudFront is 20 GB. This limit applies to all Amazon CloudFront distributions.
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 39%;" aria-valuenow="39" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_314><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 314</p><br/>A company is building an application that consists of several microservices. The company has decided to use container technologies to deploy its software on AWS. The company needs a solution that minimizes the amount of ongoing effort for maintenance and scaling. The company cannot manage additional infrastructure.<br/><br/>Which combination of actions should a solutions architect take to meet these requirements? (Choose two.)<br/><br/>A. Deploy an Amazon Elastic Container Service (Amazon ECS) cluster.<br/>B. Deploy the Kubernetes control plane on Amazon EC2 instances that span multiple Availability Zones.<br/>C. Deploy an Amazon Elastic Container Service (Amazon ECS) service with an Amazon EC2 launch type. Specify a desired task number level of greater than or equal to 2.<br/>D. Deploy an Amazon Elastic Container Service (Amazon ECS) service with a Fargate launch type. Specify a desired task number level of greater than or equal to 2.<br/>E. Deploy Kubernetes worker nodes on Amazon EC2 instances that span multiple Availability Zones. Create a deployment that specifies two or more replicas for each microservice.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample419' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_315'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_589'>Random</a></p><div class='collapse' id='collapseExample419'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Deploy an Amazon Elastic Container Service (Amazon ECS) cluster.
<br><b>B. </b>Deploy the Kubernetes control plane on Amazon EC2 instances that span multiple Availability Zones.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 39%;" aria-valuenow="39" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_315><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 315</p><br/>A company is developing a mobile game that streams score updates to a backend processor and then posts results on a leaderboard A solutions architect needs to design a solution that can handle large traffic spikes process the mobile game updates in order of receipt and store the processed updates in a highly available database. The company also wants to minimize the management overhead required to maintain the solution<br/><br/>What should the solutions architect do to meet these requirements?<br/><br/>A. Push score updates to Amazon Kinesis Data Streams Process the updates in Kinesis Data Streams with AWS Lambda Store the processed updates in Amazon DynamoDB<br/>B. Push score updates to Amazon Kinesis Data Streams Process the updates with a fleet of Amazon EC2 instances set up for Auto Scaling Store the processed updates in Amazon Redshift<br/>C. Push score updates to an Amazon Simple Notification Service (Amazon SNS) topic Subscribe an AWS Lambda function to the SNS topic to process the updates Store the processed updates in a SQL database running on Amazon EC2<br/>D. Push score updates to an Amazon Simple Queue Service (Amazon SQS) queue Use a fleet of Amazon EC2 instances with Auto Scaling to process the updates in the SQS queue Store the processed updates in an Amazon RDS Multi&#8211;AZ DB instance<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample439' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_316'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_571'>Random</a></p><div class='collapse' id='collapseExample439'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Push score updates to Amazon Kinesis Data Streams Process the updates in Kinesis Data Streams with AWS Lambda Store the processed updates in Amazon DynamoDB</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 39%;" aria-valuenow="39" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_316><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 316</p><br/>A solution architect at a company is designing the architecture for a two&#8211;tiered web application. The web application is composed of an internet facing application load balancer that forwards traffic to an auto scaling group of Amazon EC2 instances. The EC2 instances must be able to access a database that runs on Amazon RDS.<br/><br/>The company has requested a defense&#8211;in&#8211;depth approach to the network layout. The company does not want to rely solely on security groups or network ACLs. Only the minimum resources that are necessary should be routable from the internet.<br/><br/>Which network design should the solutions architect recommend to meet these requirements?<br/><br/>A. Place the ALB, EC2 instances and RDS database in private subnets.<br/>B. Place the ALB in public subnets. Place the EC2 instances and RDS database in private subnets<br/>C. Place the ALB and EC2 instances in public subnets. Place the RDS database in private subnets<br/>D. Place the ALB outside the VP<br/>E. Place the EC2 instances and RDS database in private subnets.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample468' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_317'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_616'>Random</a></p><div class='collapse' id='collapseExample468'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Place the ALB in public subnets. Place the EC2 instances and RDS database in private subnets</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 40%;" aria-valuenow="40" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_317><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 317</p><br/>A solutions architect is designing an elastic application that will have between 10 and 50 Amazon EC2 concurrent instances running depending on the load.<br/><br/>Each instance must mount storage that will read and write to the same 50 GB folder.<br/><br/>Which storage type meets the requirements?<br/><br/>A. Amazon S3<br/>B. Amazon Elastic File System (Amazon EFS)<br/>C. Amazon Amazon Elastic Block Store (Amazon EBS) volumes<br/>D. Amazon EC2 instance store<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample543' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_318'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_637'>Random</a></p><div class='collapse' id='collapseExample543'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Amazon Elastic File System (Amazon EFS)</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 40%;" aria-valuenow="40" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_318><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 318</p><br/>A company has three VPCs named Development, Testing, and Production in the us&#8211;east&#8211;1 Region. The three VPCs need to be connected to an on&#8211;premises data center and are designed to be separate to maintain security and prevent any resource sharing. A solutions architect needs to find a scalable and secure solution.<br/><br/>What should the solutions architect recommend?<br/><br/>A. Create an AWS Direct Connect connection and a VPN connection for each VPC to connect back to the data center.<br/>B. Create VPC peers from all the VPCs to the Production VPC. Use an AWS Direct Connect connection from the Production VPC back to the data center.<br/>C. Connect VPN connections from all the VPCs to a VPN in the Production VPC. Use a VPN connection from the Production VPC back to the data center.<br/>D. Create a new VPC called Network. Within the Network VPC, create an AWS Transit Gateway with an AWS Direct Connect connection back to the data center. Attach all the other VPCs to the Network VPC.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample218' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_319'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_710'>Random</a></p><div class='collapse' id='collapseExample218'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Create VPC peers from all the VPCs to the Production VP<br><b>C. </b>Use an AWS Direct Connect connection from the Production VPC back to the data center.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 40%;" aria-valuenow="40" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_319><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 319</p><br/>A company is deploying a web portal. The company wants to ensure that only the web portion of the application is publicly accessible. To accomplish this, the VPC was designed with two public subnets and two private subnets. The application will run on several Amazon EC2 instances in an Auto Scaling group. SSL termination must be offloaded from the EC2 instances.<br/><br/>What should a solutions architect do to ensure these requirements are met?<br/><br/>A. Configure the Network Load Balancer in the public subnets. Configure the Auto Scaling group in the private subnets and associate it with the Application Load Balancer.<br/>B. Configure the Network Load Balancer in the public subnets. Configure the Auto Scaling group in the public subnets and associate it with the Application Load Balancer.<br/>C. Configure the Application Load Balancer in the public subnets. Configure the Auto Scaling group in the private subnets and associate it with the Application Load Balancer.<br/>D. Configure the Application Load Balancer in the private subnets. Configure the Auto Scaling group in the private subnets and associate it with the Application Load Balancer.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample219' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_320'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_622'>Random</a></p><div class='collapse' id='collapseExample219'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Configure the Application Load Balancer in the public subnets. Configure the Auto Scaling group in the private subnets and associate it with the Application Load Balancer.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 40%;" aria-valuenow="40" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_320><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 320</p><br/>A company is planning to transfer multiple terabytes of data to AWS. The data is collected offline from ships. The company wants to run complex transformations before transferring the data.<br/><br/>Which AWS service should a solutions architect recommend for this migrations?<br/><br/>A. AWS Snowball.<br/>B. AWS Snowmobile.<br/>C. AWS Snowball Edge Storage Optimized.<br/>D. AWS Snowball Edge Compute Optimized.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample702' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_321'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_442'>Random</a></p><div class='collapse' id='collapseExample702'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>AWS Snowball Edge Compute Optimized.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 40%;" aria-valuenow="40" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_321><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 321</p><br/>A company is designing a shared storage solution for a gaming application that is hosted in the AWS Cloud. The company needs the ability to use SMB clients to access data solution must be fully managed.<br/><br/>Which AWS solution meets these requirements?<br/><br/>A. Create an AWS DataSync task that shares the data as a mountable file system Mount the file system to the application server<br/>B. Create an Amazon EC2 Windows instance Install and configure a Windows file share role on the instance Connect the application server to the file share<br/>C. Create an Amazon FSx for Windows File Server file system Attach the file system to the origin server Connect the application server to the Me system<br/>D. Create an Amazon S3 bucket Assign an 1AM role to the application to grant access to the S3 bucket Mount the S3 bucket to the application server<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample482' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_322'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_513'>Random</a></p><div class='collapse' id='collapseExample482'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Create an Amazon FSx for Windows File Server file system Attach the file system to the origin server Connect the application server to the Me system</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 40%;" aria-valuenow="40" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_322><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 322</p><br/>A user has underutilized on&#8211;premises resources.<br/><br/>Which AWS Cloud concept can BEST address this issue?<br/><br/>A. High Availability<br/>B. Elasticity<br/>C. Security<br/>D. Loose Coupling<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample690' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_323'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_299'>Random</a></p><div class='collapse' id='collapseExample690'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Elasticity</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 40%;" aria-valuenow="40" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_323><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 323</p><br/>An online photo application lets users upload photos and perform image editing operations. The application offers two classes of service: free and paid. Photos submitted by paid users are processed before those submitted by free users. Photos are uploaded to Amazon S3 and the job information is sent to Amazon SQS.<br/><br/>Which configuration should a solutions architect recommend?<br/><br/>A. Use one SQS FIFO queue. Assign a higher priority to the paid photos so they are processed first.<br/>B. Use two SQS FIFO queues: one for paid and one for free. Set the free queue to use short polling and the paid queue to use long polling.<br/>C. Use two SQS standard queues: one for paid and one for free. Configure Amazon EC2 instances to prioritize polling for the paid queue over the free queue.<br/>D. Use one SQS standard queue. Set the visibility timeout of the paid photos to zero. Configure Amazon EC2 instances to prioritize visibility settings so paid photos are processed first.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample217' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_324'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_22'>Random</a></p><div class='collapse' id='collapseExample217'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Use one SQS FIFO queue. Assign a higher priority to the paid photos so they are processed first.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 40%;" aria-valuenow="40" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_324><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 324</p><br/>A user owns a MySQL database that is accessed by various clients who expect, at most, 100 ms latency on requests.<br/>Once a record is stored in the database, it is rarely changed. Clients only access one record at a time.<br/>Database access has been increasing exponentially due to increased client demand.<br/>The resultant load will soon exceed the capacity of the most expensive hardware available for purchase.<br/>The user wants to migrate to AWS, and is willing to change database systems.<br/><br/>Which service would alleviate the database load issue and offer virtually unlimited scalability for the future?<br/><br/>A. Amazon RDS<br/>B. Amazon DynamoDB<br/>C. Amazon Redshift<br/>D. AWS Data Pipeline<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample518' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_325'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_674'>Random</a></p><div class='collapse' id='collapseExample518'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Amazon DynamoDB</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 41%;" aria-valuenow="41" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_325><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 325</p><br/>An application runs on Amazon EC2 instances in private subnets. The application needs to access an Amazon DynamoDB table.<br/><br/>What is me MOST secure way to access the table while ensuring that the traffic does not leave the AWS network?<br/><br/>A. Use a VPC endpoint for DynamoDB<br/>B. Use a NAT gateway in a public subnet<br/>C. Use a NAT instance in a private subnet<br/>D. Use the internet gateway attached to the VPC<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample446' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_326'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_15'>Random</a></p><div class='collapse' id='collapseExample446'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Use a VPC endpoint for DynamoDB</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 41%;" aria-valuenow="41" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_326><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 326</p><br/>An application team has started using Amazon EMR to run batch jobs using datasets located in Amazon S3.<br/><br/>During the initial testing of the workload a solutions architect notices that the account is starting to accrue NAT gateway data processing costs.<br/><br/>How can the learn optimize the cost of the workload?<br/><br/>A. Detach the NAT gateway from the subnet where the Amazon EMR clusters are running<br/>B. Replace the NAT gateway with a customer gateway<br/>C. Replace the NAT gateway with an S3 VPC endpoint<br/>D. Configure a network ACL on the subnets where the Amazon EMR clusters are running to open access to Amazon S3<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample582' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_327'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_700'>Random</a></p><div class='collapse' id='collapseExample582'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Detach the NAT gateway from the subnet where the Amazon EMR clusters are running</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 41%;" aria-valuenow="41" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_327><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 327</p><br/>Amazon EC2 provides a ___________ . It is an HTTP or HTTPS request that uses the HTTP verbs GET or POST.<br/><br/>A. web database<br/>B. .net framework<br/>C. Query API<br/>D. C library<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample763' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation763' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_328'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_159'>Random</a></p><div class='collapse' id='collapseExample763'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Query API</div></div></div><div class='collapse' id='explanation763'><div class='card card&#45;body'><div>
Amazon EC2 provides a Query API. These requests are HTTP or HTTPS requests that use the HTTP verbs GET or POST and a Query parameter named Action.

References:

Amazon Elastic Compute Cloud > API Reference > Making requests to the Amazon EC2 API</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 41%;" aria-valuenow="41" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_328><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 328</p><br/>In the context of AWS support, why must an EC2 instance be unreachable for 20 minutes rather than allowing customers to open tickets immediately?<br/><br/>A. Because most reachability issues are resolved by automated processes in less than 20 minutes<br/>B. Because all EC2 instances are unreachable for 20 minutes every day when AWS does routine maintenance<br/>C. Because all EC2 instances are unreachable for 20 minutes when first launched<br/>D. Because of all the reasons listed here<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample782' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation782' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_329'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_33'>Random</a></p><div class='collapse' id='collapseExample782'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Because most reachability issues are resolved by automated processes in less than 20 minutes</div></div></div><div class='collapse' id='explanation782'><div class='card card&#45;body'><div>
An EC2 instance must be unreachable for 20 minutes before opening a ticket, because most reachability issues are resolved by automated processes in less than 20 minutes and will not require any action on the part of the customer. If the instance is still unreachable after this time frame has passed, then you should open a case with support.

References:

AWS Support FAQs</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 41%;" aria-valuenow="41" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_329><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 329</p><br/>A company needs to store data for 6 years. The company will need to have immediate and highly available access to the data at any point in time, but will not require frequent access.<br/><br/>What lifecycle action should be taken to meet these requirements while reducing costs?<br/><br/>A. Transition objects from Amazon S3 Standard to Amazon S3 Standard Infrequent Access (S3 Standard IA)<br/>B. Transition objects to expire after 5 years<br/>C. Transition objects from Amazon S3 Standard to Amazon S3 One Zone&#8211;Infrequent Access (S3 One Zone IA)<br/>D. Transition objects from Amazon S3 Standard to the Amazon S3 Glacier<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample663' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_330'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_248'>Random</a></p><div class='collapse' id='collapseExample663'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Transition objects from Amazon S3 Standard to Amazon S3 Standard Infrequent Access (S3 Standard IA)</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 41%;" aria-valuenow="41" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_330><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 330</p><br/>A web application is deployed in the AWS Cloud. It consists of a two&#8211;tier architecture that includes a web layer and a database layer. The web server is vulnerable to cross&#8211;site scripting (XSS) attacks.<br/><br/>What should a solutions architect do to remediate the vulnerability?<br/><br/>A. Create a Classic Load Balancer. Put the web layer behind the load balancer and enable AWS WAF.<br/>B. Create a Network Load Balancer. Put the web layer behind the load balancer and enable AWS WAF.<br/>C. Create an Application Load Balancer. Put the web layer behind the load balancer and enable AWS WAF.<br/>D. Create an Application Load Balancer. Put the web layer behind the load balancer and use AWS Shield Standard.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample22' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation22' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_331'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_376'>Random</a></p><div class='collapse' id='collapseExample22'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Create an Application Load Balancer. Put the web layer behind the load balancer and enable AWS WAF.</div></div></div><div class='collapse' id='explanation22'><div class='card card&#45;body'><div>
Working with cross-site scripting match conditions: Attackers sometimes insert scripts into web requests in an effort to exploit vulnerabilities in web applications. You can create one or more cross-site scripting match conditions to identify the parts of web requests, such as the URI or the query string, that you want AWS WAF Classic to inspect for possible malicious scripts. Later in the process, when you create a web ACL, you specify whether to allow or block requests that appear to contain malicious scripts.
Web Application Firewall: You can now use AWS WAF to protect your web applications on your Application Load Balancers. AWS WAF is a web application firewall that helps protect your web applications from common web exploits that could affect application availability, compromise security, or consume excessive resources.

The AWS Web Application Firewall (WAF) is available on the Application Load Balancer (ALB). You can use AWS WAF directly on Application Load Balancers (both internal and external) in a VPC, to protect your websites and web services.

Attackers sometimes insert scripts into web requests in an effort to exploit vulnerabilities in web applications. You can create one or more cross-site scripting match conditions to identify the parts of web requests, such as the URI or the query string, that you want AWS WAF to inspect for possible malicious scripts.

CORRECT: "Create an Application Load Balancer. Put the web layer behind the load balancer and enable AWS WAF" is the correct answer.

INCORRECT: "Create a Classic Load Balancer. Put the web layer behind the load balancer and enable AWS WAF" is incorrect as you cannot use AWS WAF with a classic load balancer.

INCORRECT: "Create a Network Load Balancer. Put the web layer behind the load balancer and enable AWS WAF" is incorrect as you cannot use AWS WAF with a network load balancer.

INCORRECT: "Create an Application Load Balancer. Put the web layer behind the load balancer and use AWS Shield Standard" is incorrect as you cannot use AWS Shield to protect against XSS attacks. Shield is used to protect against DDoS attacks.

References:

AWS WAF, AWS Firewall Manager, and AWS Shield Advanced > Developer Guide > Working with cross-site scripting match conditions</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 41%;" aria-valuenow="41" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_331><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 331</p><br/>A company wants to optimize the cost of its data storage for data that is accessed quarterly. The company requires high throughput, low latency, and rapid access, when needed.<br/><br/>Which Amazon S3 storage class should a solutions architect recommend?<br/><br/>A. Amazon S3 Glacier (S3 Glacier)<br/>B. Amazon S3 Standard (S3 Standard)<br/>C. Amazon S3 Intelligent&#8211;Tiering (S3 Intelligent&#8211;Tiering)<br/>D. Amazon S3 Standard&#8211;Infrequent Access (S3 Standard&#8211;IA)<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample717' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_332'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_590'>Random</a></p><div class='collapse' id='collapseExample717'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Amazon S3 Standard (S3 Standard)</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 41%;" aria-valuenow="41" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_332><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 332</p><br/>A solutions architect is designing a web application that will run on Amazon EC2 instances behind an Application Load Balancer (ALB). The company strictly requires that the application be resilient against malicious internet activity and attacks, and protect against new common vulnerabilities and exposures.<br/><br/>What should the solutions architect recommend?<br/><br/>A. Leverage Amazon CloudFront with the ALB endpoint as the origin.<br/>B. Deploy an appropriate managed rule for AWS WAF and associate it with the ALB.<br/>C. Subscribe to AWS Shield Advanced and ensure common vulnerabilities and exposures are blocked.<br/>D. Configure network ACLs and security groups to allow only ports 80 and 443 to access the EC2 instances.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample44' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_333'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_705'>Random</a></p><div class='collapse' id='collapseExample44'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Deploy an appropriate managed rule for AWS WAF and associate it with the ALB.

References:

AWS WAF – Web Application Firewall
AWS Shield
AWS Shield Features</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 42%;" aria-valuenow="42" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_333><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 333</p><br/>A company that operates a web application on&#8211;premises is preparing to launch a newer version of the application on AWS. The company needs to route requests to either the AWS&#8211;hosted or the on&#8211;premises&#8211;hosted application based on the URL query string.<br/><br/>The on&#8211;premises application is not available from the internet, and a VPN connection is established between Amazon VPC and the company's data center. The company wants to use an Application Load Balancer (ALB) for this launch.<br/><br/>Which solution meets these requirements?<br/><br/>A. Use two ALBs: one for on&#8211;premises and one for the AWS resource. Add hosts to each target group of each ALB. Route with Amazon Route 53 based on the URL query string.<br/>B. Use two ALBs: one for on&#8211;premises and one for the AWS resource. Add hosts to the target group of each ALB. Create a software router on an EC2 instance based on the URL query string.<br/>C. Use one ALB with two target groups: one for the AWS resource and one for on&#8211;premises. Add hosts to each target group of the ALB. Configure listener rules based on the URL query string.<br/>D. Use one ALB with two AWS Auto Scaling groups: one for the AWS resource and one for on&#8211;premises. Add hosts to each Auto Scaling group. Route with Amazon Route 53 based on the URL query string.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample515' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation515' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_334'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_489'>Random</a></p><div class='collapse' id='collapseExample515'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Use one ALB with two target groups: one for the AWS resource and one for on-premises. Add hosts to each target group of the AL<br><b>B. </b>Configure listener rules based on the URL query string.</div></div></div><div class='collapse' id='explanation515'><div class='card card&#45;body'><div>
The host-based routing feature allows you to write rules that use the Host header to route traffic to the desired target group. Today we are extending and generalizing this feature, giving you the ability to write rules (and route traffic) based on standard and custom HTTP headers and methods, the query string, and the source IP address.

References:

AWS News Blog > New – Advanced Request Routing for AWS Application Load Balancers</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 42%;" aria-valuenow="42" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_334><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 334</p><br/>A solutions architect is redesigning a monolithic application to be a loosely coupled application composed of two microservices: Microservice A and Microservice B.<br/><br/>Microservice A places messages in a main Amazon Simple Queue Service (Amazon SQS) queue for Microservice B to consume. When Microservice B fails to process a message after four retries, the message needs to be removed from the queue and stored for further investigation.<br/><br/>What should the solutions architect do to meet these requirements?<br/><br/>A. Create an SQS dead&#8211;letter queue. Microservice B adds failed messages to that queue after it receives and fails to process the message four times.<br/>B. Create an SQS dead&#8211;letter queue. Configure the main SQS queue to deliver messages to the dead letter queue after the message has been received four times.<br/>C. Create an SQS queue for failed messages. Microservice A adds failed messages to that queue after Microservice B receives and fails to process the message four times.<br/>D. Create an SQS queue for failed messages. Configure the SQS queue for failed messages to pull messages from the main SQS queue after the original message has been received four times.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample325' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_335'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_693'>Random</a></p><div class='collapse' id='collapseExample325'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Create an SQS dead-letter queue. Configure the main SQS queue to deliver messages to the dead letter queue after the message has been received four times.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 42%;" aria-valuenow="42" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_335><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 335</p><br/>A solutions architect is designing a multi&#8211;region disaster recovery solution for an application that will provide public API access. The application will use Amazon EC2 instances with a user data script to load application code and an Amazon RDS for MySQL database. The Recovery Time Objective (RTO) is 3 hours and the Recovery Point Objective (RPO) is 24 hours.<br/><br/>Which architecture would meet these requirements at the LOWEST cost?<br/><br/>A. Use an Application Load Balancer for Region failover. Deploy new EC2 instances with the user data script. Deploy separate RDS instances in each Region.<br/>B. Use Amazon Route 53 for Region failover. Deploy new EC2 instances with the user data script. Create a read replica of the RDS instance in a backup Region.<br/>C. Use Amazon API Gateway for the public APIs and Region failover. Deploy new EC2 instances with the user data script. Create a MySQL read replica of the RDS instance in a backup Region.<br/>D. Use Amazon Route 53 for Region failover. Deploy new EC2 instances with the user data script for APIs, and create a snapshot of the RDS instance daily for a backup. Replicate the snapshot to a backup Region.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample279' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_336'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_423'>Random</a></p><div class='collapse' id='collapseExample279'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Use Amazon Route 53 for Region failover. Deploy new EC2 instances with the user data script for APIs, and create a snapshot of the RDS instance daily for a backup. Replicate the snapshot to a backup Region.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 42%;" aria-valuenow="42" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_336><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 336</p><br/>A solutions architect needs to design a network that will allow multiple Amazon EC2 instances to access a common data source used for mission&#8211;critical data that can be accessed by all the EC2 instances simultaneously. The solution must be highly scalable, easy to implement and support the NFS protocol.<br/><br/>Which solution meets these requirements?<br/><br/>A. Create an Amazon EFS file system. Configure a mount target in each Availability Zone. Attach each instance to the appropriate mount target.<br/>B. Create an additional EC2 instance and configure it as a file server. Create a security group that allows communication between the Instances and apply that to the additional instance.<br/>C. Create an Amazon S3 bucket with the appropriate permissions. Create a role in AWS IAM that grants the correct permissions to the S3 bucket. Attach the role to the EC2 Instances that need access to the data.<br/>D. Create an Amazon EBS volume with the appropriate permissions. Create a role in AWS IAM that grants the correct permissions to the EBS volume. Attach the role to the EC2 instances that need access to the data.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample384' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_337'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_83'>Random</a></p><div class='collapse' id='collapseExample384'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Create an Amazon EFS file system. Configure a mount target in each Availability Zone. Attach each instance to the appropriate mount target.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 42%;" aria-valuenow="42" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_337><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 337</p><br/>A company is preparing to deploy a new serverless workload. A solutions architect needs to configure permissions for invoking an AWS Lambda function. The function will be triggered by an Amazon EventBridge (Amazon CloudWatch Events) rule. Permissions should be configured using the principle of least privilege.<br/><br/>Which solution will meet these requirements?<br/><br/>A. Add an execution role to the function with lambda:InvokeFunction as the action and * as the principal.<br/>B. Add an execution rote to the function with lambda:InvokeFunction as the action and Service:eventsamazonaws.com as the principal.<br/>C. Add a resource&#8211;based policy to the function with lambda:' as the action and Service:events.amazonaws.com as the principal.<br/>D. Add a resource&#8211;based policy to the function with lambda:InvokeFunction as the action and Service:events.amazonaws.com as the principal.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample321' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_338'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_763'>Random</a></p><div class='collapse' id='collapseExample321'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Add a resource-based policy to the function with lambda:' as the action and Service:events.amazonaws.com as the principal.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 42%;" aria-valuenow="42" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_338><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 338</p><br/>An application is running on Amazon EC2 instances. Sensitive information required for the application is stored in an Amazon S3 bucket. The bucket needs to be protected from internet access while only allowing services within the VPC access to the bucket.<br/><br/>Which combination of actions should solutions archived take to accomplish this? (Choose two.)<br/><br/>A. Create a VPC endpoint for Amazon S3.<br/>B. Enable server access logging on the bucket.<br/>C. Apply a bucket policy to restrict access to the S3 endpoint.<br/>D. Add an S3 ACL to the bucket that has sensitive information.<br/>E. Restrict users using the IAM policy to use the specific bucket.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample76' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation76' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_339'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_634'>Random</a></p><div class='collapse' id='collapseExample76'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Create a VPC endpoint for Amazon S3.
<br><b>C. </b>Apply a bucket policy to restrict access to the S3 endpoint.</div></div></div><div class='collapse' id='explanation76'><div class='card card&#45;body'><div>
ACL is a property at object level not at bucket level. Also by just adding ACL you cant let the services in VPC allow access to the bucket.
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 42%;" aria-valuenow="42" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_339><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 339</p><br/>A solutions architect must design a solution that uses Amazon CloudFront with an Amazon S3 origin to store a static website. The company's security policy requires that all website traffic be inspected by AWS WAF.<br/><br/>How should the solutions architect comply with these requirements?<br/><br/>A. Configure an S3 bucket policy to accept requests coming from the AWS WAF Amazon Resource Name (ARN) only.<br/>B. Configure Amazon CloudFront to forward all incoming requests to AWS WAF before requesting content from the S3 origin.<br/>C. Configure a security group that allows Amazon CloudFront IP addresses to access Amazon S3 only. Associate AWS WAF to CloudFront.<br/>D. Configure Amazon CloudFront and Amazon S3 to use an origin access identity (OAI) to restrict access to the S3 bucket. Enable AWS WAF on the distribution.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample271' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_340'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_562'>Random</a></p><div class='collapse' id='collapseExample271'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Configure Amazon CloudFront and Amazon S3 to use an origin access identity (OAI) to restrict access to the S3 bucket. Enable AWS WAF on the distribution.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 42%;" aria-valuenow="42" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_340><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 340</p><br/>A company runs an AWS Lambda function in private subnets in a VPC. The subnets have a default route to the internet through an Amazon EC2 NAT instance. The Lambda function processes input data and saves its output as an object to Amazon S3 intermittently the Lambda function times out while trying to upload the object because of saturated traffic on the NAT instance's network. The company wants to access Amazon S3 without traversing the internet<br/><br/>Which solution will meet these requirements?<br/><br/>A. Replace the fcC2 NAT instance with an AWS managed NAT gateway<br/>B. Increase the size of the EC2 NAT instance in the VPC to a network optimized instance type<br/>C. Provision a gateway endpoint for Amazon S3 in the VPC Update the route tables of the subnets accordingly<br/>D. Provision a transit gateway Place transit gateway attachments in the private subnets where the Lambda function is running<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample475' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_341'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_202'>Random</a></p><div class='collapse' id='collapseExample475'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Increase the size of the EC2 NAT instance in the VPC to a network optimized instance type</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 43%;" aria-valuenow="43" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_341><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 341</p><br/>A company wants to monitor its AWS costs for financial review. The cloud operations team is designing an architecture in the AWS Organizations master account to query AWS Cost and Usage Reports for all member accounts.<br/><br/>The team must run this query once a month and provide a detailed analysis of the bill.<br/><br/>Which solution is the MOST scalable and cost&#8211;effective way to meet these requirements?<br/><br/>A. Enable Cost and Usage Reports in the master account. Deliver reports to Amazon Kinesis. Use Amazon EMR for analysis.<br/>B. Enable Cost and Usage Reports in the master account. Deliver the reports to Amazon S3. Use Amazon Athena for analysis.<br/>C. Enable Cost and Usage Reports for member accounts. Deliver the reports to Amazon S3. Use Amazon Redshift for analysis.<br/>D. Enable Cost and Usage Reports for member accounts. Deliver the reports to Amazon Kinesis. Use Amazon QuicKSight for analysis.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample650' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_342'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_443'>Random</a></p><div class='collapse' id='collapseExample650'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Enable Cost and Usage Reports in the master account. Deliver the reports to Amazon S3. Use Amazon Athena for analysis.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 43%;" aria-valuenow="43" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_342><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 342</p><br/>A solutions architect is deploying a distributed database on multiple Amazon EC2 instances. The database stores all data on multiple instances so it can withstand the loss of an instance. The database requires block storage with latency and throughput to support several million transactions per second per server.<br/><br/>Which storage solution should the solutions architect use?<br/><br/>A. Amazon EBS<br/>B. Amazon EC2 instance store<br/>C. Amazon EFS<br/>D. Amazon S3<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample9' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation9' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_343'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_171'>Random</a></p><div class='collapse' id='collapseExample9'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Amazon EBS</div></div></div><div class='collapse' id='explanation9'><div class='card card&#45;body'><div>
Amazon Elastic Block Store (EBS) is an easy to use, high performance block storage service designed for use with Amazon Elastic Compute Cloud (EC2) for both throughput and transaction intensive workloads at any scale. A broad range of workloads, such as relational and non-relational databases, enterprise applications, containerized applications, big data analytics engines, file systems, and media workflows are widely deployed on Amazon EBS.

References:
https://quizform.net/exam/24/learning/14
Amazon Elastic Compute Cloud > User Guide for Linux Instances > Amazon EC2 instance store</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 43%;" aria-valuenow="43" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_343><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 343</p><br/>An application is running on an Amazon EC2 instance and must have millisecond latency when running the workload. The application makes many small reads and writes to the file system, but the file system itself is small.<br/><br/>Which Amazon Elastic Block Store (Amazon EBS) volume type should a solutions architect attach to their EC2 instance?<br/><br/>A. Cold HDD (sc1)<br/>B. General Purpose SSD (gp2)<br/>C. Provisioned IOPS SSD (io1)<br/>D. Throughput Optimized HDD (st1)<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample227' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_344'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_53'>Random</a></p><div class='collapse' id='collapseExample227'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>General Purpose SSD (gp2)</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 43%;" aria-valuenow="43" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_344><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 344</p><br/>A company uses Amazon Redshift for its data warehouse. The company wants to ensure high durability for its data in case of any component failure.<br/><br/>What should a solutions architect recommend?<br/><br/>A. Enable concurrency scaling.<br/>B. Enable cross&#8211;Region snapshots.<br/>C. Increase the data retention period.<br/>D. Deploy Amazon Redshift in Multi&#8211;AZ.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample215' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_345'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_8'>Random</a></p><div class='collapse' id='collapseExample215'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Enable cross-Region snapshots.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 43%;" aria-valuenow="43" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_345><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 345</p><br/>A company recently migrated a message processing system to AWS. The system receives messages into an ActiveMQ queue running on an Amazon EC2 instance. Messages are processed by a consumer application running on Amazon EC2. The consumer application processes the messages and writes results to a MySQL database running on Amazon EC2. The company wants this application to be highly available with low operational complexity<br/><br/>Which architecture offers the HIGHEST availability?<br/><br/>A. Add a second ActiveMQ server to another Availability Zone Add an additional consumer EC2 instance in another Availability Zone Replicate the MySQL database to another Availability Zone.<br/>B. Use Amazon MQ with active/standby brokers configured across two Availability Zones Add an additional consumer EC2 instance in another Availability Zone. Replicate the MySQL database to another Availability Zone<br/>C. Use Amazon MQ with active/standby brokers configured across two Availability Zones. Add an additional consumer EC2 instance in another Availability Zone. Use Amazon RDS for MySQL with Multi&#8211;AZ enabled<br/>D. Use Amazon MQ with active/standby brokers configured across two Availability Zones Add an Auto Scaling group for the consumer EC2 instances across two Availability Zones Use Amazon RDS for MySQL with Multi&#8211;AZ enabled.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample500' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_346'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_399'>Random</a></p><div class='collapse' id='collapseExample500'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Use Amazon MQ with active/standby brokers configured across two Availability Zones Add an Auto Scaling group for the consumer EC2 instances across two Availability Zones Use Amazon RDS for MySQL with Multi-AZ enabled.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 43%;" aria-valuenow="43" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_346><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 346</p><br/>A company is preparing to migrate its on&#8211;premises application to AWS. The application consists of application servers and a Microsoft SQL Server database The database cannot be migrated to a different engine because SQL Server features are used in the application's NET code. The company wants to attain the greatest availability possible while minimizing operational and management overhead.<br/><br/><br/><br/>What should a solutions architect do to accomplish this?<br/><br/>A. Install SQL Server on Amazon EC2 in a Multi&#8211;AZ deployment.<br/>B. Migrate the data to Amazon RDS for SQL Server in a Multi&#8211;AZ deployment.<br/>C. Deploy the database on Amazon RDS for SQL Server with Multi&#8211;AZ Replicas.<br/>D. Migrate the data to Amazon RDS for SQL Server in a cross&#8211;Region Multi&#8211;AZ deployment.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample354' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_347'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_638'>Random</a></p><div class='collapse' id='collapseExample354'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Migrate the data to Amazon RDS for SQL Server in a Multi-AZ deployment.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 43%;" aria-valuenow="43" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_347><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 347</p><br/>A company has two applications: a sender application that sends messages with payloads to be processed and a processing application intended to receive messages with payloads. The company wants to implement an AWS service to handle messages between the two applications. The sender application can send about 1,000 messages each hour. The messages may take up to 2 days to be processed. If the messages fail to process, they must be retained so that they do not impact the processing of any remaining messages.<br/><br/>Which solution meets these requirements and is the MOST operationally efficient?<br/><br/>A. Set up an Amazon EC2 instance running a Redis database. Configure both applications to use the instance. Store, process, and delete the messages, respectively.<br/>B. Use an Amazon Kinesis data stream to receive the messages from the sender application. Integrate the processing application with the Kinesis Client Library (KCL).<br/>C. Integrate the sender and processor applications with an Amazon Simple Queue Service (Amazon SQS) queue. Configure a dead&#8211;letter queue to collect the messages that failed to process.<br/>D. Subscribe the processing application to an Amazon Simple Notification Service (Amazon SNS) topic to receive notifications to process. Integrate the sender application to write to the SNS topic.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample258' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_348'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_615'>Random</a></p><div class='collapse' id='collapseExample258'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Integrate the sender and processor applications with an Amazon Simple Queue Service (Amazon SQS) queue. Configure a dead-letter queue to collect the messages that failed to process.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 43%;" aria-valuenow="43" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_348><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 348</p><br/>A company has two AWS accounts: Production and Development. There are code changes ready in the Development account to push to the Production account. In the alpha phase, only two senior developers on the development team need access to the Production account. In the beta phase, more developers might need access to perform testing as well.<br/><br/>What should a solutions architect recommend?<br/><br/>A. Create two policy documents using the AWS Management Console in each account. Assign the policy to developers who need access.<br/>B. Create an IAM role in the Development account. Give one IAM role access to the Production account. Allow developers to assume the role.<br/>C. Create an IAM role in the Production account with the trust policy that specifies the Development account. Allow developers to assume the role.<br/>D. Create an IAM group in the Production account and add it as a principal in the trust policy that specifies the Production account. Add developers to the group.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample306' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_349'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_89'>Random</a></p><div class='collapse' id='collapseExample306'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Create an IAM group in the Production account and add it as a principal in the trust policy that specifies the Production account. Add developers to the group.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 44%;" aria-valuenow="44" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_349><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 349</p><br/>A company operates a website on Amazon EC2 Linux instances Some of the instances are failing. Troubleshooting points to insufficient swap space on the failed instances. The operations team lead needs a solution to monitor this<br/><br/>What should a solutions architect recommend?<br/><br/>A. Configure an Amazon CloudWatch SwapUsage metric dimension Monitor the SwapUsage dimension in the EC2 metrics in CloudWatch.<br/>B. Use EC2 metadata to collect information, then publish it to Amazon CloudWatch custom metrics Monitor SwapUsage metrics in CloudWatch<br/>C. Install an Amazon CloudWatch agent on the instances. Run an appropriate script on a set schedule. Monitor SwapUtilization metrics in CloudWatch<br/>D. Enable detailed monitoring in the EC2 console Create an Amazon CloudWatch SwapUtilization custom metric Monitor SwapUtilization metrics in CloudWatch<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample481' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_350'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_592'>Random</a></p><div class='collapse' id='collapseExample481'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Configure an Amazon CloudWatch SwapUsage metric dimension Monitor the SwapUsage dimension in the EC2 metrics in CloudWatch.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 44%;" aria-valuenow="44" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_350><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 350</p><br/>An application launched on Amazon EC2 instances needs to publish personally identifiable information (PH) about customers using Amazon Simple Notification Service (Amazon SNS). The application is launched in private subnets within an Amazon VPC.<br/><br/>What is the MOST secure way to allow the application to access service endpoints in the same AWS Region?<br/><br/>A. Use an internet gateway<br/>B. Use AWS PrivateLink<br/>C. Use a NAT gateway.<br/>D. Use a proxy instance<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample533' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_351'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_755'>Random</a></p><div class='collapse' id='collapseExample533'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Use AWS PrivateLink</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 44%;" aria-valuenow="44" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_351><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 351</p><br/>A company wants to run workload&#8211;Intensive queries from its 10 TB Amazon Aurora MySQL DB cluster.<br/><br/>Temporary schema changes need to be made to the database to generate monthly reports. However, these changes are not desired for the ongoing production cluster.<br/><br/>The company must choose the most operationally efficient solution to meet these requirements.<br/><br/>Which solution should the company choose?<br/><br/>A. Create a database clone and use the clone for reporting.<br/>B. Create Aurora Read Replicas and use them for reporting<br/>C. Export the needed tables to Amazon S3 Query the data by using Amazon<br/>D. Take a snapshot of the production DB cluster. Restore the snapshot to a new database for reporting.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample574' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_352'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_132'>Random</a></p><div class='collapse' id='collapseExample574'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Create Aurora Read Replicas and use them for reporting</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 44%;" aria-valuenow="44" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_352><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 352</p><br/>A company uses Amazon S3 to store its confidential audit documents. The S3 bucket uses bucket policies to restrict access to audit team IAM user credentials according to the principle of least privilege. Company managers are worried about accidental deletion of documents in the S3 bucket and want a more secure solution.<br/><br/>What should a solutions architect do to secure the audit documents?<br/><br/>A. Enable the versioning and MFA Delete features on the S3 bucket<br/>B. Enable multi&#8211;factor authentication (MFA) on the IAM user credentials for each audit team IAM user account.<br/>C. Add an S3 Lifecycle policy to the audit team's IAM user accounts to deny the s3:DeleteObject action during audit dates.<br/>D. Use AWS Key Management Service (AWS KMS> to encrypt the S3 bucket and restrict audit team IAM user accounts from accessing the KMS key.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample503' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_353'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_577'>Random</a></p><div class='collapse' id='collapseExample503'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Enable the versioning and MFA Delete features on the S3 bucket</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 44%;" aria-valuenow="44" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_353><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 353</p><br/>A solutions architect is tasked with transferring 750 TB of data from a network&#8211;attached file system located at a branch office Amazon S3 Glacier. The solution must avoid saturating the branch office's low&#8211;bandwidth internet connection.<br/><br/>What is the MOST cost&#8211;effective solution?<br/><br/>A. Create a site&#8211;to&#8211;site VPN tunnel to an Amazon S3 bucket and transfer the files directly. Create a bucket policy to enforce a VPC endpoint.<br/>B. Order 10 AWS Snowball appliances and select an S3 Glacier vault as the destination. Create a bucket policy to enforce a VPC endpoint.<br/>C. Mount the network&#8211;attached file system to Amazon S3 and copy the files directly. Create a lifecycle policy to transition the S3 objects to Amazon S3 Glacier.<br/>D. Order 10 AWS Snowball appliances and select an Amazon S3 bucket as the destination. Create a lifecycle policy to transition the S3 objects to Amazon S3 Glacier.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample33' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation33' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_354'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_661'>Random</a></p><div class='collapse' id='collapseExample33'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Order 10 AWS Snowball appliances and select an Amazon S3 bucket as the destination. Create a lifecycle policy to transition the S3 objects to Amazon S3 Glacier.</div></div></div><div class='collapse' id='explanation33'><div class='card card&#45;body'><div>
Regional Limitations for AWS Snowball
The AWS Snowball service has two device types, the standard Snowball and the Snowball Edge. The following table highlights which of these devices are available in which regions.

The following table highlights which of these devices are available in which regions.

The following table highlights which of these devices are available in which regions.

Limitations on Jobs in AWS Snowball

The following limitations exist for creating jobs in AWS Snowball:

For security purposes, data transfers must be completed within 90 days of the Snowball being prepared.

Currently, AWS Snowball Edge device doesn't support server-side encryption with customer-provided keys (SSE-C). AWS Snowball Edge device does support server-side encryption with Amazon S3–managed encryption keys (SSE-S3) and server-side encryption with AWS Key Management Service – managed keys (SSE-KMS). For more information, see Protecting Data Using Server-Side Encryption in the Amazon Simple Storage Service Developer Guide.

In the US regions, Snowballs come in two sizes: 50 TB and 80 TB. All other regions have the 80 TB Snowballs only. If you're using Snowball to import data, and you need to transfer more data than will fit on a single Snowball, create additional jobs. Each export job can use multiple Snowballs.

The default service limit for the number of Snowballs you can have at one time is 1. If you want to increase your service limit, contact AWS Support.

All objects transferred to the Snowball have their metadata changed. The only metadata that remains the same is filename and filesize. All other metadata is set as in the following example: -rw-rw-r– 1 root root [filesize] Dec 31 1969 [path/filename].

Object lifecycle management
To manage your objects so that they are stored cost effectively throughout their lifecycle, configure their Amazon S3 Lifecycle. An S3 Lifecycle configuration is a set of rules that define actions that Amazon S3 applies to a group of objects. There are two types of actions:

Transition actions – Define when objects transition to another storage class. For example, you might choose to transition objects to the S3 Standard-IA storage class 30 days after you created them, or archive objects to the S3 Glacier storage class one year after creating them.

Expiration actions – Define when objects expire. Amazon S3 deletes expired objects on your behalf. The lifecycle expiration costs depend on when you choose to expire objects.

As the company's internet link is low-bandwidth uploading directly to Amazon S3 (ready for transition to Glacier) would saturate the link. The best alternative is to use AWS Snowball appliances. The Snowball Edge appliance can hold up to 75 TB of data so 10 devices would be required to migrate 750 TB of data.

Snowball moves data into AWS using a hardware device and the data is then copied into an Amazon S3 bucket of your choice. From there, lifecycle policies can transition the S3 objects to Amazon S3 Glacier.

CORRECT: "Order 10 AWS Snowball appliances and select an Amazon S3 bucket as the destination. Create a lifecycle policy to transition the S3 objects to Amazon S3 Glacier" is the correct answer.

INCORRECT: "Order 10 AWS Snowball appliances and select an S3 Glacier vault as the destination. Create a bucket policy to enforce a VPC endpoint" is incorrect as you cannot set a Glacier vault as the destination, it must be an S3 bucket. You also can't enforce a VPC endpoint using a bucket policy.

INCORRECT: "Create an AWS Direct Connect connection and migrate the data straight into Amazon Glacier" is incorrect as this is not the most cost-effective option and takes time to setup. INCORRECT: "Use AWS Global Accelerator to accelerate upload and optimize usage of the available bandwidth" is incorrect as this service is not used for accelerating or optimizing the upload of data from on-premises networks.

References:

AWS Snowball Edge Developer Guide > AWS Snowball Edge Specifications</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 44%;" aria-valuenow="44" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_354><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 354</p><br/>A company stores call recordings on a monthly basis. Statistically, the recorded data may be referenced randomly within a year but accessed rarely after 1 year. Files that are newer than 1 year old must be queried and retrieved as quickly as possible. A delay in retrieving older files is acceptable. A solutions architect needs to store the recorded data at a minimal cost.<br/><br/>Which solution is MOST cost&#8211;effective?<br/><br/>A. Store individual files in Amazon S3 Glacier and store search metadata in object tags created in S3 Glacier Query S3 Glacier tags and retrieve the files from S3 Glacier.<br/>B. Store individual files in Amazon S3. Use lifecycle policies to move the files to Amazon S3 Glacier after1 year. Query and retrieve the files from Amazon S3 or S3 Glacier.<br/>C. Archive individual files and store search metadata for each archive in Amazon S3. Use lifecycle policies to move the files to Amazon S3 Glacier after 1 year. Query and retrieve the files by searching for metadata from Amazon S3.<br/>D. Archive individual files in Amazon S3. Use lifecycle policies to move the files to Amazon S3 Glacier after 1 year. Store search metadata in Amazon DynamoDB. Query the files from DynamoDB and retrieve them from Amazon S3 or S3 Glacier.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample339' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_355'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_767'>Random</a></p><div class='collapse' id='collapseExample339'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Store individual files in Amazon S3. Use lifecycle policies to move the files to Amazon S3 Glacier after1 year. Query and retrieve the files from Amazon S3 or S3 Glacier.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 44%;" aria-valuenow="44" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_355><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 355</p><br/>A company has a multi&#8211;tier application deployed on several Amazon EC2 instances in an Auto Scaling group. An Amazon RDS for Oracle instance is the application, data layer that uses Oracle&#8211;specific PSQL functions. Traffic to the application has been steadily increasing. This is causing the EC2 instances to become overloaded and RDS instance to run out of storage. The Auto Scaling group does not have any scaling metrics and defines the minimum healthy instance count only. The company predicts that traffic will continue to increase at a steady but unpredictable rate before leveling off.<br/><br/>What should a solutions architect do to ensure the system can automatically scale for the increased traffic? (Choose two.)<br/><br/>A. Configure storage Auto Scaling on the RDS for Oracle instance.<br/>B. Migrate the database to Amazon Aurora to use Auto Scaling storage.<br/>C. Configure an alarm on the RDS for Oracle instance for low free storage space.<br/>D. Configure the Auto Scaling group to use the average CPU as the scaling metric.<br/>E. Configure the Auto Scaling group to use the average free memory as the scaling metric.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample412' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_356'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_414'>Random</a></p><div class='collapse' id='collapseExample412'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Configure storage Auto Scaling on the RDS for Oracle instance.
<br><b>C. </b>Configure an alarm on the RDS for Oracle instance for low free storage space.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 44%;" aria-valuenow="44" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_356><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 356</p><br/>A company has no existing file share services. A new project requires access to file storage that is mountable as a drive for on&#8211;premises desktops. The file server must authenticate users to an Active Directory domain before they are able to access the storage.<br/><br/>Which service will allow Active Directory users to mount storage as a drive on their desktops?<br/><br/>A. Amazon S3 Glacier<br/>B. AWS DataSync<br/>C. AWS Snowball Edge<br/>D. AWS Storage Gateway<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample340' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_357'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_105'>Random</a></p><div class='collapse' id='collapseExample340'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>AWS Storage Gateway</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 45%;" aria-valuenow="45" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_357><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 357</p><br/>A solutions architect is creating a new Amazon CloudFront distribution for an application Some of the information submitted by users is sensitive. The application uses HTTPS but needs another layer of security. The sensitive information should be protected throughout the entire application stack, and access to the information should be restricted to certain applications.<br/><br/>Which action should the solutions architect take?<br/><br/>A. Configure a CloudFront signed URL<br/>B. Configure a CloudFront signed cookie.<br/>C. Configure a CloudFront field&#8211;level encryption profile.<br/>D. Configure CloudFront and set the Origin Protocol Policy setting to HTTPS Only for the Viewer Protocol Pokey<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample484' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_358'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_482'>Random</a></p><div class='collapse' id='collapseExample484'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Configure a CloudFront signed URL</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 45%;" aria-valuenow="45" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_358><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 358</p><br/>The DNS provider that hosts a company's domain name records is experiencing outages that cause service disruption for a website running on AWS.<br/><br/>The company needs to migrate to a more resilient managed DNS service and wants the service to run on AWS.<br/><br/>What should a solutions architect do to rapidly migrate the DNS hosting service?<br/><br/>A. Create an Amazon Route 53 public hosted zone for the domain name. Import the zone file containing the domain records hosted by the previous provider.<br/>B. Create an Amazon Route 53 private hosted zone for the domain name. Import the zone file containing the domain records hosted by the previous provider<br/>C. Create a Simple AD directory in AWS. Enable zone transfer between the DNS provider and AWS Directory Service for Microsoft Active Directory for the domain records.<br/>D. Create an Amazon Route 53 Resolver inbound endpoint in the VPC. Specify the IP addresses that the provider's DNS will forward DNS queries to Configure the provider's DNS to forward DNS queries for the domain to the IP addresses that are specified in the inbound endpoint.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample648' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_359'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_663'>Random</a></p><div class='collapse' id='collapseExample648'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Create an Amazon Route 53 public hosted zone for the domain name. Import the zone file containing the domain records hosted by the previous provider.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 45%;" aria-valuenow="45" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_359><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 359</p><br/>A company is developing a mobile game that streams score updates to a backend processor and then posts results on a leaderboard A solutions architect needs to design a solution that can handle large traffic spikes process the mobile game updates in order of receipt and store the processed updates in a highly available database. The company also wants to minimize the management overhead required to maintain the solution<br/><br/>What should the solutions architect do to meet these requirements?<br/><br/>A. Push score updates to Amazon Kinesis Data Streams Process the updates in Kinesis Data Streams with AWS Lambda Store the processed updates in Amazon DynamoDB<br/>B. Push score updates to Amazon Kinesis Data Streams Process the updates with a fleet of Amazon EC2 instances set up for Auto Scaling Store the processed updates in Amazon Redshift<br/>C. Push score updates to an Amazon Simple Notification Service (Amazon SNS) topic Subscribe an AWS Lambda function to the SNS topic to process the updates Store the processed updates in a SQL database running on Amazon EC2<br/>D. Push score updates to an Amazon Simple Queue Service (Amazon SQS) queue Use a fleet of Amazon EC2 instances with Auto Scaling to process the updates in the SQS queue Store the processed updates in an Amazon RDS Multi&#8211;AZ DB instance<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample460' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation460' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_360'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_742'>Random</a></p><div class='collapse' id='collapseExample460'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Push score updates to Amazon Kinesis Data Streams Process the updates in Kinesis Data Streams with AWS Lambda Store the processed updates in Amazon DynamoDB</div></div></div><div class='collapse' id='explanation460'><div class='card card&#45;body'><div>
You can use Amazon Kinesis Data Streams to collect and process large streams of data records in real-time. You can use Kinesis Data Streams for rapid and continuous data intake and aggregation. The type of data used can include IT infrastructure log data, application logs, social media, market data feeds, and web clickstream data. Because the response time for the data intake and processing is in real-time, the processing is typically lightweight.
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 45%;" aria-valuenow="45" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_360><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 360</p><br/>A company runs a web&#8211;based portal that provides users with global breaking news, local alerts, and weather updates.<br/><br/>The portal delivers each user a personalized view by using a mixture of static and dynamic content.<br/><br/>Content is served over HTTPS through an API server running on an Amazon EC2 instance behind an Application Load Balancer (ALB).<br/><br/>The company wants the portal to provide this content to its users across the world as quickly s possible.<br/><br/>How should a solutions architect design the application to ensure the LEAST amount of latency for all users?<br/><br/>A. Deploy the application stack in a single AWS Region. Use Amazon CloudFront to serve all static and dynamic content by specifying the ALB as an origin<br/>B. Deploy the application stack in two AWS Regions. Use an Amazon Route 53 latency routing policy to serve all content from the ALB in the closest Region.<br/>C. Deploy the application stack in a single AWS Region Use Amazon CloudFront to serve the static content. Serve the dynamic content directly from the ALB.<br/>D. Deploy t e application stack in two AWS Regions. Use an Amazon Route 53 geolocation routing policy to serve all content from the ALB in the closest Region.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample639' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_361'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_226'>Random</a></p><div class='collapse' id='collapseExample639'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Deploy the application stack in two AWS Regions. Use an Amazon Route 53 latency routing policy to serve all content from the ALB in the closest Region.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 45%;" aria-valuenow="45" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_361><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 361</p><br/>A security team needs to enforce the rotation of all IAM users' access keys every 90 days. If an access key is found to be older, the key must be made inactive and removed. A solutions architect must create a solution that will check for and remediate any keys older than 90 days.<br/><br/>Which solution meets these requirements with the LEAST operational effort?<br/><br/>A. Create an AWS Config rule to check for the key age. Configure the AWS Config rule to run an AWS Batch job to remove the key.<br/>B. Create an Amazon EventBridge (Amazon CloudWatch Events) rule to check for the key age. Configure the rule to run an AWS Batch job to remove the key.<br/>C. Create an AWS Config rule to check for the key age. Define an Amazon EventBridge (Amazon CloudWatch Events) rule to schedule an AWS Lambda function to remove the key.<br/>D. Create an Amazon EventBridge (Amazon CloudWatch Events) rule to check for the key age. Define an EventBridge (CloudWatch Events) rule to run an AWS Batch job to remove the key.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample423' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_362'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_180'>Random</a></p><div class='collapse' id='collapseExample423'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Create an AWS Config rule to check for the key age. Configure the AWS Config rule to run an AWS Batch job to remove the key.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 45%;" aria-valuenow="45" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_362><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 362</p><br/>A company runs a web application that is backed by Amazon RDS. A new database administrator caused data loss by accidentally editing information in a database table. To help recover from this type of incident, the company wants the ability to restore the database to its state from 5 minutes before any change within the last 30 days.<br/><br/>Which feature should the solutions architect include in the design to meet this requirement?<br/><br/>A. Read replicas<br/>B. Manual snapshots<br/>C. Automated backups<br/>D. Multi&#8211;AZ deployments<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample436' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_363'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_461'>Random</a></p><div class='collapse' id='collapseExample436'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Automated backups</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 45%;" aria-valuenow="45" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_363><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 363</p><br/>A company's cloud operations team wants to standardize resource remediation.<br/><br/>The company wants to provide a standard set of governance evaluations and remediation's to all member accounts in its organization in AWS Organizations.<br/><br/>Which self&#8211;managed AWS service can the company use to meet these requirements with the LEAST amount of operational effort?<br/><br/>A. AWS Security Hub compliance standards<br/>B. AWS Config conformance packs<br/>C. AWS CloudTrail<br/>D. AWS Trusted Advisor<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample613' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_364'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_324'>Random</a></p><div class='collapse' id='collapseExample613'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>AWS Security Hub compliance standards</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 45%;" aria-valuenow="45" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_364><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 364</p><br/>A company recently expanded globally and wants to make its application accessible to users in those geographic locations. The application is deployed on Amazon EC2 instances behind an Application Load Balancer in an Auto Scaling group. The company needs the ability shift traffic from resources in one region to another.<br/><br/>What should a solutions architect recommend?<br/><br/>A. Configure an Amazon Route 53 latency routing policy.<br/>B. Configure an Amazon Route 53 geolocation routing policy.<br/>C. Configure an Amazon Route 53 geoproximity routing policy.<br/>D. Configure an Amazon Route 53 multivalue answer routing policy.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample54' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation54' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_365'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_680'>Random</a></p><div class='collapse' id='collapseExample54'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Configure an Amazon Route 53 geoproximity routing policy.</div></div></div><div class='collapse' id='explanation54'><div class='card card&#45;body'><div>
Keyword: Users in those Geographic Locations

Condition: Ability Shift traffic from resources in One Region to Another Region The following table highlights the key function of each type of routing policy:

Geo-location:

Caters to different users in different countries and different languages.

Contains users within a particular geography and offers them a customized version of the workload based on their specific needs.

Geolocation can be used for localizing content and presenting some or all of your website in the language of your users.

Can also protect distribution rights.

Can be used for spreading load evenly between regions.

If you have multiple records for overlapping regions, Route 53 will route to the smallest geographic region.

You can create a default record for IP addresses that do not map to a geographic location.

References:

Amazon Route 53 > Developer Guide > Choosing a routing policy
Amazon Route 53</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 46%;" aria-valuenow="46" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_365><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 365</p><br/>A company requires operating system permission on a relational database server.<br/><br/>What should a solutions architect suggest as a configuration for a highly available database architecture?<br/><br/>A. Multiple Amazon EC2 instances in a database replication configuration that uses two Availability Zones<br/>B. A standalone Amazon FC2 instance with a selected database installed<br/>C. Amazon RDS m a Multi&#8211;AZ configuration with Provisioned IOPS<br/>D. Multiple Amazon EC2 instances in a replication configuration that uses a placement group<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample577' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_366'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_58'>Random</a></p><div class='collapse' id='collapseExample577'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Multiple Amazon EC2 instances in a database replication configuration that uses two Availability Zones</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 46%;" aria-valuenow="46" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_366><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 366</p><br/>A company requires that all versions of objects in its Amazon S3 bucket be retained. Current object versions will be frequently accessed during the first 30 days, after which they will be rarely accessed and must be retrievable within 5 minutes. Previous object versions need to be kept forever, will be rarely accessed, and can be retrieved within 1 week. All storage solutions must be highly available and highly durable.<br/><br/>What should a solutions architect recommend to meet these requirements in the MOST cost&#8211;effective manner?<br/><br/>A. Create an S3 lifecycle policy for the bucket that moves current object versions from S3 Standard storage to S3 Glacier after 30 days and moves previous object versions to S3 Glacier after 1 day.<br/>B. Create an S3 lifecycle policy for the bucket that moves current object versions from S3 Standard storage to S3 Glacier after 30 days and moves previous object versions to S3 Glacier Deep Archive after 1 day.<br/>C. Create an S3 lifecycle policy for the bucket that moves current object versions from S3 Standard storage to S3 Standard&#8211;infrequent Access (S3 Standard&#8211;IA) after 30 days and moves previous object versions toS3 Glacier Deep Archive after 1 day.<br/>D. Create an S3 lifecycle policy for the bucket that moves current object versions from S3 Standard storage to S3 One Zone&#8211;Infrequent Access (S3 One Zone&#8211;IA) after 30 days and moves previous object versions to S3 Glacier Deep Archive after 1 day.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample396' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_367'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_245'>Random</a></p><div class='collapse' id='collapseExample396'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Create an S3 lifecycle policy for the bucket that moves current object versions from S3 Standard storage to S3 Glacier after 30 days and moves previous object versions to S3 Glacier after 1 day.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 46%;" aria-valuenow="46" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_367><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 367</p><br/>To specify a resource in a policy statement, in Amazon EC2, can you use its Amazon Resource Name (ARN)?<br/><br/>A. Yes, you can.<br/>B. No, you can't because EC2 is not related to ARN.<br/>C. No, you can't because you can't specify a particular Amazon EC2 resource in an IAM policy.<br/>D. Yes, you can but only for the resources that are not affected by the action.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample779' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation779' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_368'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_701'>Random</a></p><div class='collapse' id='collapseExample779'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Yes, you can.</div></div></div><div class='collapse' id='explanation779'><div class='card card&#45;body'><div>
Some Amazon EC2 API actions allow you to include specific resources in your policy that can be created or modified by the action. To specify a resource in the statement, you need to use its Amazon Resource Name (ARN).

References:

Amazon EC2 User Guide</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 46%;" aria-valuenow="46" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_368><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 368</p><br/>An application requires a development environment (DEV) and production environment (PROD) for several years. The DEV instances will run for 10 hours each day during normal business hours, while the PROD instances will run 24 hours each day. A solutions architect needs to determine a compute instance purchase strategy to minimize costs.<br/><br/>Which solution is the MOST cost&#8211;effective?<br/><br/>A. DEV with Spot Instances and PROD with On&#8211;Demand Instances<br/>B. DEV with On&#8211;Demand Instances and PROD with Spot Instances<br/>C. DEV with Scheduled Reserved Instances and PROD with Reserved Instances<br/>D. DEV with On&#8211;Demand Instances and PROD with Scheduled Reserved Instances<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample158' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_369'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_486'>Random</a></p><div class='collapse' id='collapseExample158'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>DEV with Scheduled Reserved Instances and PROD with Reserved Instances</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 46%;" aria-valuenow="46" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_369><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 369</p><br/>A company has an application that generates a large number of files, each approximately 5 MB in size. The files are stored in Amazon S3. Company policy requires the files to be stored for 4 years before they can be deleted. Immediate accessibility is always required as the files contain critical business data that is not easy to reproduce. The files are frequently accessed in the first 30 days of the object creation but are rarely accessed after the first 30 days.<br/><br/>Which storage solution is MOST cost&#8211;effective?<br/><br/>A. Create an S3 bucket lifecycle policy to move files from S3 Standard to S3 Glacier 30 days from object creation. Delete the files 4 years after object creation.<br/>B. Create an S3 bucket lifecycle policy to move files from S3 Standard to S3 One Zone&#8211;Infrequent Access (S3 One Zone&#8211;IA) 30 days from object creation. Delete the files 4 years after object creation.<br/>C. Create an S3 bucket lifecycle policy to move files from S3 Standard to S3 Standard&#8211;Infrequent Access (S3 Standard&#8211;IA) 30 days from object creation. Delete the files 4 years after object creation.<br/>D. Create an S3 bucket lifecycle policy to move files from S3 Standard to S3 Standard&#8211;Infrequent Access (S3 Standard&#8211;IA) 30 days from object creation. Move the files to S3 Glacier 4 years after object creation.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample347' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_370'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_593'>Random</a></p><div class='collapse' id='collapseExample347'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Create an S3 bucket lifecycle policy to move files from S3 Standard to S3 Standard-Infrequent Access (S3 Standard-IA) 30 days from object creation. Delete the files 4 years after object creation.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 46%;" aria-valuenow="46" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_370><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 370</p><br/>During a review of business applications, a Solutions Architect identifies a critical application with a relational database that was built by a business user and is running on the user's desktop. To reduce the risk of a business interruption, the Solutions Architect wants to migrate the application to a highly available, multi&#8211;tiered solution in AWS.<br/><br/>What should the Solutions Architect do to accomplish this with the LEAST amount of disruption to the business?<br/><br/>A. Create an import package of the application code for upload to AWS Lambda, and include a function to create another Lambda function to migrate data into an Amazon RDS database<br/>B. Create an image of the user's desktop, migrate it to Amazon EC2 using VM Import, and place the EC2 instance in an Auto Scaling group<br/>C. Pre&#8211;stage new Amazon EC2 instances running the application code on AWS behind an Application Load Balancer and an Amazon RDS Multi&#8211;AZ DB instance<br/>D. Use AWS DMS to migrate the backend database to an Amazon RDS Multi&#8211;AZ DB instance. Migrate the application code to AWS Elastic Beanstalk<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample793' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_371'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_736'>Random</a></p><div class='collapse' id='collapseExample793'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Use AWS DMS to migrate the backend database to an Amazon RDS Multi-AZ DB instance. Migrate the application code to AWS Elastic Beanstalk</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 46%;" aria-valuenow="46" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_371><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 371</p><br/>A company needs to share an Amazon S3 bucket with an external vendor. The bucket owner must be able to access all objects.<br/><br/>Which action should be taken to share the S3 bucket?<br/><br/>A. Update the bucket to be a Requester Pays bucket.<br/>B. Update the bucket to enable cross&#8211;origin resource sharing (CORS).<br/>C. Create a bucket policy to require users to grant bucket&#8211;owner&#8211;full&#8211;control when uploading objects.<br/>D. Create an IAM policy to require users to grant bucket&#8211;owner&#8211;full&#8211;control when uploading objects.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample113' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation113' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_372'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_424'>Random</a></p><div class='collapse' id='collapseExample113'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Create a bucket policy to require users to grant bucket-owner-full-control when uploading objects.</div></div></div><div class='collapse' id='explanation113'><div class='card card&#45;body'><div>
By default, an S3 object is owned by the AWS account that uploaded it. This is true even when the bucket is owned by another account. To get access to the object, the object owner must explicitly grant you (the bucket owner) access. The object owner can grant the bucket owner full control of the object by updating the access control list (ACL) of the object. The object owner can update the ACL either during a put or copy operation, or after the object is added to the bucket.

Resolution Add a bucket policy that grants users access to put objects in your bucket only when they grant you (the bucket owner) full control of the object.
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 46%;" aria-valuenow="46" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_372><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 372</p><br/>A company is creating a three&#8211;tier web application consisting of a web server, an application server, and a database server. The application will track GPS coordinates of packages as they are being delivered. The application will update the database every 0&#8211;5 seconds.<br/><br/>The tracking will need to read a fast as possible for users to check the status of their packages. Only a few packages might be tracked on some days, whereas millions of package might be tracked on other days.<br/><br/>Tracking will need to be searchable by tracking ID customer ID and order ID. Order than 1 month no longer read to be tracked.<br/><br/>What should a solution architect recommend to accomplish this with minimal cost of ownership?<br/><br/>A. Use Amazon DynamoDB Enable Auto Scaling on the DynamoDB table. Schedule an automatic deletion script for items older than 1 month.<br/>B. Use Amazon DynamoDB with global secondary indexes. Enable Auto Scaling on the DynamoDB table and the global secondary indexes. Enable TTL on the DynamoDB table.<br/>C. Use an Amazon RDS On&#8211;Demand instance with Provisioned IOPS (PIOPS). Enable Amazon CloudWatch alarms to send notifications when PIOPS are exceeded. Increase and decrease PIOPS as needed.<br/>D. Use an Amazon RDS Reserved Instance with Provisioned IOPS (PIOPS). Enable Amazon CloudWatch alarms to send notification when PIOPS are exceeded. Increase and decrease PIOPS as needed.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample388' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_373'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_450'>Random</a></p><div class='collapse' id='collapseExample388'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Use Amazon DynamoDB with global secondary indexes. Enable Auto Scaling on the DynamoDB table and the global secondary indexes. Enable TTL on the DynamoDB table.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 47%;" aria-valuenow="47" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_373><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 373</p><br/>A company is running a highly sensitive application on Amazon EC2 backed by an Amazon RDS database.<br/><br/>Compliance regulations mandate that all personally identifiable information (PII) be encrypted at rest.<br/><br/>Which solution should a solutions architect recommend to meet this requirement with the LEAST amount of changes to the infrastructure?<br/><br/>A. Deploy AWS Certificate Manager to generate certificates. Use the certificates to encrypt the database volume.<br/>B. Deploy AWS CloudHSM, generate encryption keys, and use the customer master key (CMK) to encrypt database volumes.<br/>C. Configure SSL encryption using AWS Key Management Service customer master keys (AWS KMS CMKs) to encrypt database volumes.<br/>D. Configure Amazon Elastic Block Store (Amazon EBS) encryption and Amazon RDS encryption with AWS Key Management Service (AWS KMS) keys to encrypt instance and database volumes.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample69' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_374'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_632'>Random</a></p><div class='collapse' id='collapseExample69'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Configure Amazon Elastic Block Store (Amazon EBS) encryption and Amazon RDS encryption with AWS Key Management Service (AWS KMS) keys to encrypt instance and database volumes.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 47%;" aria-valuenow="47" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_374><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 374</p><br/>A company runs a static website through its on&#8211;premises data center. The company has multiple servers that handle all of its traffic, but on busy days, services are interrupted and the website becomes unavailable.<br/><br/>The company wants to expand its presence globally and plans to triple its website traffic.<br/><br/>What should a solutions architect recommend to meet these requirements?<br/><br/>A. Migrate the website content to Amazon S3 and host the website on Amazon CloudFront.<br/>B. Migrate the website content to Amazon EC2 instances with public Elastic IP addresses in multiple AWS Regions.<br/>C. Migrate the website content to Amazon EC2 instances and vertically scale as the load increases.<br/>D. Use Amazon Route 53 to distribute the loads across multiple Amazon CloudFront distributions for each AWS Region that exists globally.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample229' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_375'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_197'>Random</a></p><div class='collapse' id='collapseExample229'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Use Amazon Route 53 to distribute the loads across multiple Amazon CloudFront distributions for each AWS Region that exists globally.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 47%;" aria-valuenow="47" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_375><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 375</p><br/>A company has multiple AWS accounts with applications deployed in the us&#8211;west&#8211;2 Region Application togs are stored within Amazon S3 buckets in each account. The company wants to build a centralized log analysts solution that uses a single S3 bucket Logs must not leave us&#8211; west&#8211;2T and the company wants to incur minimal operational overhead.<br/><br/>Which solution meets these requirements and is MOST cost&#8211;effective?<br/><br/>A. Create an S3 Lifecycle policy that copies the objects from one of the application S3 buckets to the centralized S3 bucket<br/>B. Use S3 Same&#8211;Region Replication to replicate togs from the S3 buckets to another S3 bucket in us&#8211;west&#8211;2 Use this S3 bucket for log analysis<br/>C. Write a script that uses the PutObject API operation every day to copy the entire contents of the buckets to another S3 bucket in us&#8211;west&#8211;2 Use this S3 bucket for log analysis<br/>D. Write AWS Lambda functions in these accounts that are triggered every time logs ate delivered to the S3 buckets (s3 ObjectCreated. * event) Copy the logs to another S3 bucket in us&#8211;west&#8211;2 Use this S3 bucket for log analysis<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample563' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_376'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_55'>Random</a></p><div class='collapse' id='collapseExample563'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Create an S3 Lifecycle policy that copies the objects from one of the application S3 buckets to the centralized S3 bucket</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 47%;" aria-valuenow="47" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_376><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 376</p><br/>A solutions architect is designing the cloud architecture for a company that needs to host hundreds of machine learning models for its users. During startup, the models need to load up to 10 GB of data from Amazon S3 into memory, but they do not need disk access. Most of the models are used sporadically, but the users expect all of them to be highly available and accessible with low latency.<br/><br/>Which solution meets the requirements and is MOST cost&#8211;effective?<br/><br/>A. Deploy models as AWS Lambda functions behind an Amazon API Gateway for each model.<br/>B. Deploy models as Amazon Elastic Container Service (Amazon ECS) services behind an Application Load Balancer for each model.<br/>C. Deploy models as AWS Lambda functions behind a single Amazon API Gateway with path&#8211;based routing where one path corresponds to each model.<br/>D. Deploy models as Amazon Elastic Container Service (Amazon ECS) services behind a single Application Load Balancer with path&#8211;based routing where one path corresponds to each model.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample243' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation243' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_377'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_469'>Random</a></p><div class='collapse' id='collapseExample243'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Deploy models as AWS Lambda functions behind a single Amazon API Gateway with path-based routing where one path corresponds to each model.</div></div></div><div class='collapse' id='explanation243'><div class='card card&#45;body'><div>
AWS just update Lambda to support 10G memory and helping compute intensive applications like machine learning…
No disk access, lowest cost.

References:

AWS Lambda now supports up to 10 GB of memory and 6 vCPU cores for Lambda Functions
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 47%;" aria-valuenow="47" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_377><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 377</p><br/>A company has data stored in an on&#8211;premises data center that is used by several on&#8211;premises applications.<br/><br/>The company wants to maintain its existing application environment and be able to use AWS services for data analytics and future visualizations.<br/><br/>Which storage service should a solutions architect recommend?<br/><br/>A. Amazon Redshift<br/>B. AWS Storage Gateway for files<br/>C. Amazon Elastic Block Store (Amazon EBS)<br/>D. Amazon Elastic File System (Amazon EFS)<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample378' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_378'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_329'>Random</a></p><div class='collapse' id='collapseExample378'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>AWS Storage Gateway for files</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 47%;" aria-valuenow="47" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_378><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 378</p><br/>An operations team has a standard that states IAM policies should not be applied directly to users. Some new team members have not been following this standard. The operations manager needs a way to easily identify the users with attached policies.<br/><br/>What should a solutions architect do to accomplish this?<br/><br/>A. Monitor using AWS CloudTrail.<br/>B. Create an AWS Config rule to run daily.<br/>C. Publish IAM user changes to Amazon SNS.<br/>D. Run AWS Lambda when a user is modified.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample109' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation109' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_379'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_312'>Random</a></p><div class='collapse' id='collapseExample109'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Create an AWS Config rule to run daily.</div></div></div><div class='collapse' id='explanation109'><div class='card card&#45;body'><div>
A new AWS Config rule is deployed in the account after you enable AWS Security Hub. The AWS Config rule reacts to resource configuration and compliance changes and send these change items to AWS CloudWatch. When AWS CloudWatch receives the compliance change, a CloudWatch event rule triggers the AWS Lambda function.
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 47%;" aria-valuenow="47" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_379><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 379</p><br/>A company is using Amazon RDS for MySQL. The company disaster recovery requirements state that a near real&#8211;time replica of the database must be maintained on&#8211;premises.<br/><br/>The company wants the data to be encrypted in transit/ Which solution meets these requirements?<br/><br/>A. Use AWS Database Migration Service (AWS DMS) and AWS Direct Connect to migrate the data from AWS to on&#8211;premises.<br/>B. Use MySQL replication to replicate from AWS to on&#8211;premises over an IPsec VPN on top of an AWS Direct Connect Connection.<br/>C. Use AWS Data Pipeline to replicate from AWS to on&#8211;premises over an IPsec VPN on top of an AWS Direct Connect Connection.<br/>D. Use the Amazon RDS Multi&#8211;Az Feature. Choose on&#8211;premises as the failover availability zone over an IPsec VPN on top of an AWS Direct Connect Connection<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample542' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_380'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_16'>Random</a></p><div class='collapse' id='collapseExample542'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Use the Amazon RDS Multi-Az Feature. Choose on-premises as the failover availability zone over an IPsec VPN on top of an AWS Direct Connect Connection</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 47%;" aria-valuenow="47" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_380><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 380</p><br/>A company needs to retain application log files for a critical application for 10years. The application team regularly accesses logs from the past month for troubleshooting, but logs older than 1 month are rarely accessed. The application generates more than 10 TB of logs per month.<br/><br/>Which storage option meets these requirements MOST cost&#8211;effectively?<br/><br/>A. Store the logs in Amazon S3. Use AWS Backup to move logs more than 1 month old to S3 Glacier Deep Archive<br/>B. Store the logs in Amazon S3. Use S3 Lifecycle policies to move logs more than 1 month old to S3 Glacier Deep Archive.<br/>C. Store the logs in Amazon CloudWatch Logs. Use AWS Backup to move logs more than 1 month old to S3 Glacier Deep Archive.<br/>D. Store the logs in Amazon CloudWatch Logs. Use Amazon S3 Lifecycle policies to move logs more than 1 month old to S3 Glacier Deep Archive.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample547' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_381'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_288'>Random</a></p><div class='collapse' id='collapseExample547'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Store the logs in Amazon S3. Use S3 Lifecycle policies to move logs more than 1 month old to S3 Glacier Deep Archive.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 48%;" aria-valuenow="48" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_381><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 381</p><br/>A company hosts its multi&#8211;tier applications on AWS.<br/><br/>For compliance, governance, auditing, and security, the company must track configuration changes on its AWS resources and record a history of API calls made o these resources.<br/><br/>What should a solutions architect do to meet these requirements?<br/><br/>A. Use AWS CloudTrail to track configuration changes and AWS Config to record API calls<br/>B. Use AWS Config to track configuration changes and AWS CloudTrail to record API calls<br/>C. Use AWS Config to track configuration changes and Amazon CloudWatch to record API calls<br/>D. Use AWS CloudTrail to track configuration changes and Amazon CloudWatch to record API calls<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample630' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_382'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_118'>Random</a></p><div class='collapse' id='collapseExample630'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Use AWS Config to track configuration changes and AWS CloudTrail to record API calls</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 48%;" aria-valuenow="48" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_382><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 382</p><br/>A company has a web application with sporadic usage patterns. There is heavy usage at the beginning of each month, moderate usage at the start of each week, and unpredictable usage during the week. The application consists of a web server and a MySQL database server running inside the data center. The company would like to move the application to the AWS Cloud, and needs to select a cost&#8211;effective database platform that will not require database modifications.<br/><br/>Which solution will meet these requirements?<br/><br/>A. Amazon DynamoDB<br/>B. Amazon RDS for MySQL<br/>C. MySQL&#8211;compatible Amazon Aurora Serverless<br/>D. MySQL deployed on Amazon EC2 in an Auto Scaling group<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample125' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_383'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_13'>Random</a></p><div class='collapse' id='collapseExample125'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Amazon RDS for MySQL</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 48%;" aria-valuenow="48" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_383><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 383</p><br/>A company is running a multi&#8211;tier web application on&#8211;premises. The web application is containerized and runs on a number of Linux hosts connected to a PostgreSQL database that contains user records. The operational overhead of maintaining the infrastructure and capacity planning is limiting the company's growth. A solutions architect must improve the application's infrastructure.<br/><br/>Which combination of actions should the solutions architect take to accomplish this? (Select TWO.)<br/><br/>A. Migrate the PostgreSQL database to Amazon Aurora<br/>B. Migrate the web application to be hosted on Amazon EC2 instances.<br/>C. Set up an Amazon CloudFront distribution for the web application content.<br/>D. Set up Amazon ElastiCache between the web application and the PostgreSQL database<br/>E. Migrate the web application to be hosted on AWS Fargate with Amazon Elastic Container Service (Amazon ECS)<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample681' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_384'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_168'>Random</a></p><div class='collapse' id='collapseExample681'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Migrate the PostgreSQL database to Amazon Aurora
<br><b>E. </b>Migrate the web application to be hosted on AWS Fargate with Amazon Elastic Container Service (Amazon ECS)</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 48%;" aria-valuenow="48" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_384><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 384</p><br/>A company has an application running on Amazon EC2 instances in a private subnet. The application needs to store and retrieve data in Amazon S3. To reduce costs, the company wants to configure its AWS resources in a cost&#8211;effective manner.<br/><br/>How should the company accomplish this?<br/><br/>A. Deploy a NAT gateway to access the S3 buckets.<br/>B. Deploy AWS Storage Gateway to access the S3 buckets.<br/>C. Deploy an S3 gateway endpoint to access the S3 buckets.<br/>D. Deploy an S3 interface endpoint to access the S3 buckets.<br/><br/><br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample355' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_385'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_676'>Random</a></p><div class='collapse' id='collapseExample355'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Deploy AWS Storage Gateway to access the S3 buckets.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 48%;" aria-valuenow="48" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_385><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 385</p><br/>A company uses an Amazon S3 bucket as its data lake storage platform.<br/><br/>The S3 bucket contains a massive amount of data that is accessed randomly by multiple teams and hundreds of applications.<br/><br/>The company wants to reduce the S3 storage costs and provide immediate availability for frequently accessed objects.<br/><br/>What is the MOST operationally efficient solution that meets these requirements?<br/><br/>A. Create an S3 Lifecycle rule to transition objects to the S3 Intelligent&#8211;Tiering storage class<br/>B. Store objects in Amazon S3 Glacier. Use S3 Select to provide applications with access to the data<br/>C. Use data from S3 storage class analysis to create S3 Lifecycle rules to automatically transition objects to the S3 Standard&#8211;Infrequent Access {S3 Standard&#8211;IA) storage class<br/>D. Transition objects to the S3 Standard&#8211;Infrequent Access (S3 Standard&#8211;IA) storage class. Create an AWS Lambda function to transition objects to the S3 Standard storage class when they are accessed by an application<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample623' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_386'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_613'>Random</a></p><div class='collapse' id='collapseExample623'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Create an S3 Lifecycle rule to transition objects to the S3 Intelligent-Tiering storage class</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 48%;" aria-valuenow="48" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_386><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 386</p><br/>A company is building applications in containers. The company wants to migrate its on&#8211;premises development and operations services from its on&#8211;premises data center to AWS. Management states that production system must be cloud agnostic and use the same configuration and administrator tools across production systems. A solutions architect needs to design a managed solution that will align open&#8211;source software.<br/><br/>Which solution meets these requirements?<br/><br/>A. Launch the containers on Amazon EC2 with EC2 instance worker nodes.<br/>B. Launch the containers on Amazon Elastic Kubernetes Service (Amazon EKS) and EKS workers nodes.<br/>C. Launch the containers on Amazon Elastic Containers service (Amazon ECS) with AWS Fargate instances.<br/>D. Launch the containers on Amazon Elastic Container Service (Amazon ECS) with Amazon EC2 instance worker nodes.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample209' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation209' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_387'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_271'>Random</a></p><div class='collapse' id='collapseExample209'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Launch the containers on Amazon Elastic Kubernetes Service (Amazon EKS) and EKS workers nodes.</div></div></div><div class='collapse' id='explanation209'><div class='card card&#45;body'><div>
When talking about containerized applications, the leading technologies which will always come up during the conversation are Kubernetes and Amazon ECS (Elastic Container Service).

While Kubernetes is an open-sourced container orchestration platform that was originally developed by Google, Amazon ECS is AWS' proprietary, managed container orchestration service.
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 48%;" aria-valuenow="48" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_387><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 387</p><br/>A company has a web application for travel ticketing.<br/><br/>The application is based on a database that runs in a single data center in North America. The company wants to expand the application to serve a global user base. The company needs to display the application to multiple AWS Regions. Average latency must be less than 1 second on updates to reservation database.<br/><br/>The company wants to have separate deployments of its web platform across multiple Regions. However, the company must maintain a single primary reservation database that is globally consistent.<br/><br/>Which solution should a solutions architect recommend to meet these requirements?<br/><br/>A. Convert the application to use Amazon DynamoDB. Use a global table for the center reservation table. Use the correct Regional endpoint in each Regional deployment.<br/>B. Migrate the database to an Amazon Aurora MySQL database. Deploy Aurora Read Replicas in each Region. Use the correct Region endpoint in each Regional deployment for access to the database.<br/>C. Migrate the database to an Amazon RDS for MySQL database. Deploy MySQL read replicas in each Region. Use the correct Regional endpoint In each Regional deployment for access to the database.<br/>D. Migrate the application to an Amazon Aurora Serverless database. Deploy instances of the database to each Region. Use the correct Region endpoint in each Regional deployment to access the database. Use AWS Lambda functions to process event streams in each Region to synchronize the databases.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample609' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_388'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_582'>Random</a></p><div class='collapse' id='collapseExample609'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Convert the application to use Amazon DynamoD<br><b>B. </b>Use a global table for the center reservation table. Use the correct Regional endpoint in each Regional deployment.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 48%;" aria-valuenow="48" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_388><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 388</p><br/>A solutions architect needs to ensure that all Amazon Elastic Block Store (Amazon EBS) volumes restored from unencrypted EBC snapshots are encrypted.<br/><br/>What should the solutions architect do to accomplish this?<br/><br/>A. Enable EBS encryption by default for the AWS Region.<br/>B. Enable EBS encryption by default for the specific volumes.<br/>C. Create a new volume and specify the symmetric customer master key (CMK) to use for encryption.<br/>D. Create a new volume and specify the asymmetric customer master key (CMK) to use for encryption.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample228' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation228' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_389'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_717'>Random</a></p><div class='collapse' id='collapseExample228'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Enable EBS encryption by default for the AWS Region.</div></div></div><div class='collapse' id='explanation228'><div class='card card&#45;body'><div>
Question asked is to ensure that all volumes restored are encrypted. So have to be "Enable encryption by default".
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 49%;" aria-valuenow="49" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_389><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 389</p><br/>In Amazon EC2, partial instance&#8211;hours are billed __________ .<br/><br/>A. per second used in the hour<br/>B. per minute used<br/>C. by combining partial segments into full hours<br/>D. as full hours<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample752' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation752' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_390'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_581'>Random</a></p><div class='collapse' id='collapseExample752'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>as full hours</div></div></div><div class='collapse' id='explanation752'><div class='card card&#45;body'><div>
Partial instance-hours are billed to the next hour.

References:

Amazon EC2 FAQs</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 49%;" aria-valuenow="49" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_390><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 390</p><br/>A company wants to deploy an additional Amazon Aurora MySQL DB cluster for development purposes.<br/><br/>The cluster will be used several times a week for a few minutes upon to debug production query issues.<br/><br/>The company wants to keep overhead low for this resource.<br/><br/>Which solution meets the company's requirements MOST cost&#8211;effectively?<br/><br/>A. Purchas a Reserved Instance for the DB instances.<br/>B. Run the DB instances on Aurora Serverless<br/>C. Create a stop/start schedule for the DB instances.<br/>D. Create an AWS Lambda function to stop DB instances if there are no active connections<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample579' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_391'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_647'>Random</a></p><div class='collapse' id='collapseExample579'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Create an AWS Lambda function to stop DB instances it there are no active connections</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 49%;" aria-valuenow="49" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_391><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 391</p><br/>A company is building a web application that serves a content management system. The content management system runs on Amazon EC2 instances behind an Application Load Balancer (ALB). The EC2 instances run in an Auto Scaling group across multiple Availability Zones Users are constantly adding and updating files blogs and other website assets in the content management system.<br/><br/>A solutions architect must implement a solution in which all the EC2 instances share up&#8211;to&#8211;date website content with the least possible lag time.<br/><br/>Which solution meets these requirements?<br/><br/>A. Update the EC2 user data in the Auto Scaling group lifecycle policy to copy the website assets from the EC2 instance that was launched most recently Configure the ALB to make changes to the website assets only m the newest EC2 instance<br/>B. Copy the website assets to an Amazon Elastic File System (Amazon EFS) file system Configure each EC2 instance to mount the EPS file system locally Configure the website hosting application to reference the website assets that are stored in the EFS file system<br/>C. Copy the website assets to an Amazon S3 bucket Ensure that each EC2 instance downloads the website assets from the S3 bucket to the attached Amazon Elastic Block Store (Amazon EBS) volume Run the S3 sync command once each hour to keep files up to date<br/>D. Restore an Amazon Elastic Block Store (Amazon EBS) snapshot with the website assets Attach the EBS snapshot as a secondary EBS volume when a new EC2 instance is launched Configure the website hosting application to reference the website assets that are stored in the secondary EBS volume<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample463' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_392'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_778'>Random</a></p><div class='collapse' id='collapseExample463'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Update the EC2 user data in the Auto Scaling group lifecycle policy to copy the website assets from the EC2 instance that was launched most recently Configure the ALB to make changes to the website assets only m the newest EC2 instance</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 49%;" aria-valuenow="49" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_392><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 392</p><br/>A company has concerns about its Amazon RDS database.<br/><br/>The workload is unpredictable, and periodic floods of new user registrations can cause the company to run out of storage.<br/><br/>The database runs on a general purpose instance with 300 GB of storage.<br/><br/>What should a solution architect recommend to the company?<br/><br/>A. Enable RDS storage autoscaling.<br/>B. Schedule vertical instance scaling<br/>C. Change to a storage optimized instance type and vertically scale the database.<br/>D. Configure an AWS Lambda function to increase RDS storage by 1 GiB when storage space is low.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample618' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_393'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_507'>Random</a></p><div class='collapse' id='collapseExample618'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Configure an AWS Lambda function to increase RDS storage by 1 GiB when storage space is low.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 49%;" aria-valuenow="49" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_393><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 393</p><br/>A company has a build server that is in an Auto Scaling group and often has multiple Linux instances running. The build server requires consistent and mountable shared NFS storage for jobs and configurations.<br/><br/>Which storage option should a solutions architect recommend?<br/><br/>A. Amazon S3<br/>B. Amazon FSx<br/>C. Amazon Elastic Block Store (Amazon EBS)<br/>D. Amazon Elastic File System (Amazon EFS)<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample368' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_394'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_541'>Random</a></p><div class='collapse' id='collapseExample368'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Amazon Elastic File System (Amazon EFS)</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 49%;" aria-valuenow="49" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_394><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 394</p><br/>A company operates an eCommerce website on Amazon EC2 instances behind an Application Load Balancer (ALB) in an Auto Scaling group. The site is experiencing performance issues related to a high request rate from illegitimate external systems with changing IP addresses. The security team is worried about potential DDoS attacks against the website. The company must block the illegitimate incoming requests in a way that has a minimal impact on legitimate users.<br/><br/>What should a solutions architect recommend?<br/><br/>A. Deploy Amazon Inspector and associate it with the ALB.<br/>B. Deploy AWS WAF, associate it with the ALB, and configure a rate&#8211;limiting rule.<br/>C. Deploy rules to the network ACLs associated with the ALB to block the incoming traffic.<br/>D. Deploy Amazon GuardDuty and enable rate&#8211;limiting protection when configuring GuardDuty.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample127' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation127' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_395'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_688'>Random</a></p><div class='collapse' id='collapseExample127'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Deploy AWS WAF, associate it with the ALB, and configure a rate-limiting rule.</div></div></div><div class='collapse' id='explanation127'><div class='card card&#45;body'><div>
Rate limit

For a rate-based rule, enter the maximum number of requests to allow in any five-minute period from an IP address that matches the rule's conditions. The rate limit must be at least 100.

You can specify a rate limit alone, or a rate limit and conditions. If you specify only a rate limit, AWS WAF places the limit on all IP addresses. If you specify a rate limit and conditions, AWS WAF places the limit on IP addresses that match the conditions.

When an IP address reaches the rate limit threshold, AWS WAF applies the assigned action (block or count) as quickly as possible, usually within 30 seconds. Once the action is in place, if five minutes pass with no requests from the IP address, AWS WAF resets the counter to zero.
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 49%;" aria-valuenow="49" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_395><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 395</p><br/>A company hosts a static website within an Amazon S3 bucket. A solutions architect needs to ensure that data can be recovered in case of accidental deletion.<br/><br/>Which action will accomplish this?<br/><br/>A. Enable Amazon S3 versioning.<br/>B. Enable Amazon S3 Intelligent&#8211;Tiering.<br/>C. Enable an Amazon S3 lifecycle policy.<br/>D. Enable Amazon S3 cross&#8211;Region replication.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample26' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation26' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_396'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_620'>Random</a></p><div class='collapse' id='collapseExample26'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Enable Amazon S3 versioning.</div></div></div><div class='collapse' id='explanation26'><div class='card card&#45;body'><div>
Data can be recover if versioning enable, also it provide a extra protection like file delete, MFA delete. MFA. Delete only works for CLI or API interaction, not in the AWS Management Console. Also, you cannot make version DELETE actions with MFA using IAM user credentials. You must use your root AWS account.

Object Versioning: Use Amazon S3 Versioning to keep multiple versions of an object in one bucket. For example, you could store my-image.jpg (version 111111) and my-image.jpg (version 222222) in a single bucket. S3 Versioning protects you from the consequences of unintended overwrites and deletions. You can also use it to archive objects so that you have access to previous versions.

You must explicitly enable S3 Versioning on your bucket. By default, S3 Versioning is disabled. Regardless of whether you have enabled Versioning, each object in your bucket has a version ID. If you have not enabled Versioning, Amazon S3 sets the value of the version ID to null. If S3 Versioning is enabled, Amazon S3 assigns a version ID value for the object. This value distinguishes it from other versions of the same key.

Object versioning is a means of keeping multiple variants of an object in the same Amazon S3 bucket. Versioning provides the ability to recover from both unintended user actions and application failures. You can use versioning to preserve, retrieve, and restore every version of every object stored in your Amazon S3 bucket.

CORRECT: "Enable Amazon S3 versioning" is the correct answer.

INCORRECT: "Enable Amazon S3 Intelligent-Tiering" is incorrect. This is a storage class that automatically moves data between frequent access and infrequent access classes based on usage patterns.

INCORRECT: "Enable an Amazon S3 lifecycle policy" is incorrect. An S3 lifecycle policy is a set of rules that define actions that apply to groups of S3 objects such as transitioning objects to another storage class.

INCORRECT: "Enable Amazon S3 cross-Region replication" is incorrect as this is used to copy objects to different regions. CRR relies on versioning which is the feature that is required for protecting against accidental deletion.

References:

Protecting Amazon S3 Against Object Deletion</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 50%;" aria-valuenow="50" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_396><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 396</p><br/>A solutions architect is designing a high performance computing (HPC) workload on Amazon EC2. The EC2 instances need to communicate to each other frequently and require network performance with low latency and high throughput.<br/><br/>Which EC2 configuration meets these requirements?<br/><br/>A. Launch the EC2 instances in a cluster placement group in one Availability Zone.<br/>B. Launch the EC2 instances in a spread placement group in one Availability Zone.<br/>C. Launch the EC2 instances in an Auto Scaling group in two Regions and peer the VPCs.<br/>D. Launch the EC2 instances in an Auto Scaling group spanning multiple Availability Zones.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample144' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation144' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_397'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_115'>Random</a></p><div class='collapse' id='collapseExample144'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Launch the EC2 instances in a cluster placement group in one Availability Zone.</div></div></div><div class='collapse' id='explanation144'><div class='card card&#45;body'><div>
When you launch a new EC2 instance, the EC2 service attempts to place the instance in such a way that all of your instances are spread out across underlying hardware to minimize correlated failures. You can use placement groups to influence the placement of a group of interdependent instances to meet the needs of your workload.

Depending on the type of workload, you can create a placement group using one of the following placement strategies:

Cluster • packs instances close together inside an Availability Zone. This strategy enables workloads to achieve the low-latency network performance necessary for tightly-coupled node-to-node communication that is typical of HPC applications.

Partition • spreads your instances across logical partitions such that groups of instances in one partition do not share the underlying hardware with groups of instances in different partitions. This strategy is typically used by large distributed and replicated workloads, such as Hadoop, Cassandra, and Kafka.

Spread • strictly places a small group of instances across distinct underlying hardware to reduce correlated failures.

For this scenario, a cluster placement group should be used as this is the best option for providing low-latency network performance for a HPC application.

CORRECT: "Launch the EC2 instances in a cluster placement group in one Availability Zone" is the correct answer.

INCORRECT: "Launch the EC2 instances in a spread placement group in one Availability Zone" is incorrect as the spread placement group is used to spread instances across distinct underlying hardware.

INCORRECT: "Launch the EC2 instances in an Auto Scaling group in two Regions. Place a Network Load Balancer in front of the instances" is incorrect as this does not achieve the stated requirement to provide low-latency, high throughput network performance between instances. Also, you cannot use an ELB across Regions.

INCORRECT: "Launch the EC2 instances in an Auto Scaling group spanning multiple Availability Zones" is incorrect as this does not reduce network latency or improve performance.

References:

Amazon Elastic Compute Cloud > User Guide for Linux Instances > Placement groups</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 50%;" aria-valuenow="50" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_397><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 397</p><br/>A solutions architect is reviewing the cost of a company's scheduled nightly maintenance. The solutions architect notices that three Amazon EC2 instances are being run to perform nine scripted tasks that take less than 5 minutes each to complete. The scripts are all written in Python.<br/><br/>Which action should the company take to optimize costs of the nightly maintenance?<br/><br/>A. Consolidate the scripts from the three EC2 instances to run on one EC2 instance.<br/>B. Convert the scripts to AWS Lambda functions and schedule them with Amazon EventBridge (Amazon CloudWatch Events).<br/>C. Purchase a Compute Savings Plan for the running EC2 instances.<br/>D. Create a Spot Fleet to replace the running EC2 instances for executing the scripts.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample545' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_398'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_565'>Random</a></p><div class='collapse' id='collapseExample545'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Convert the scripts to AWS Lambda functions and schedule them with Amazon EventBridge (Amazon CloudWatch Events).</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 50%;" aria-valuenow="50" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_398><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 398</p><br/>A company wants to move a multi&#8211;tiered application from on&#8211;premises to the AWS Cloud to improve the application's performance. The application consists of application tiers that communicate with each other by way of RESTful services.<br/><br/>Transactions are dropped when one tier becomes overloaded. A solutions architect must design a solution that resolves these issues and modernizes the application.<br/><br/>Which solution meets these requirements and is the MOST operationally efficient?<br/><br/>A. Use Amazon API Gateway and direct transactions to the AWS Lambda functions as the application layer. Use Amazon Simple Queue Service (Amazon SQS) as the communication layer between application services.<br/>B. Use Amazon CloudWatch metrics to analyze the application performance history to determine the server's peak utilization during the performance failures. Increase the size of the application server's Amazon EC2 instances to meet the peak requirements.<br/>C. Use Amazon Simple Notification Service (Amazon SNS) to handle the messaging between application servers running on Amazon EC2 in an Auto Scaling group. Use Amazon CloudWatch to monitor the SNS queue length and scale up and down as required.<br/>D. Use Amazon Simple Queue Service (Amazon SQS) to handle the messaging between application servers running on Amazon EC2 in an Auto Scaling group. Use Amazon CloudWatch to monitor the SQS queue length and scale up when communication failures are detected.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample255' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_399'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_131'>Random</a></p><div class='collapse' id='collapseExample255'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Use Amazon Simple Queue Service (Amazon SQS) to handle the messaging between application servers running on Amazon EC2 in an Auto Scaling group. Use Amazon CloudWatch to monitor the SQS queue length and scale up when communication failures are detected.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 50%;" aria-valuenow="50" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_399><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 399</p><br/>A company has established a new AWS account. The account is newly provisioned and no changed have been made to the default settings. The company is concerned about the security of the AWS account root user.<br/><br/>What should be done to secure the root user?<br/><br/>A. Create IAM users for daily administrative tasks. Disable the root user.<br/>B. Create IAM users for daily administrative tasks. Enable multi&#8211;factor authentication on the root user.<br/>C. Generate an access key for the root user. Use the access key for daily administration tasks instead of the AWS Management Console.<br/>D. Provide the root user credentials to the most senior solutions architect. Have the solutions architect use the root user for daily administration tasks.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample92' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_400'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_260'>Random</a></p><div class='collapse' id='collapseExample92'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Create IAM users for daily administrative tasks. Enable multi-factor authentication on the root user.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 50%;" aria-valuenow="50" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_400><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 400</p><br/>A company's operations team has an existing Amazon S3 bucket configured to notify an Amazon SQS queue when new objects are created within the bucket. The development team also wants to receive events when new objects are created. The existing operations team workflow must remain intact.<br/><br/>Which solution would satisfy these requirements?<br/><br/>A. Create another SQS queue. Update the S3 events in the bucket to also update the new queue when a new object is created.<br/>B. Create a new SQS queue that only allows Amazon S3 to access the queue. Update Amazon S3 to update this queue when a new object is created.<br/>C. Create an Amazon SNS topic and SQS queue for the bucket updates. Update the bucket to send events to the new topic. Updates both queues to poll Amazon SNS.<br/>D. Create an Amazon SNS topic and SQS queue for the bucket updates. Update the bucket to send events to the new topic. Add subscriptions for both queues in the topic.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample47' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_401'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_743'>Random</a></p><div class='collapse' id='collapseExample47'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Create an Amazon SNS topic and SQS queue for the bucket updates. Update the bucket to send events to the new topic. Add subscriptions for both queues in the topic.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 50%;" aria-valuenow="50" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_401><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 401</p><br/>A company has hired a new cloud engineer who should not have access to an Amazon S3 bucket named Company Confidential. the cloud engineer must be able to read from and write to an S3 bucket called AdminTools.<br/><br/>Which IAM policy will meet these requirements?<br/><br/>A.<br/>B.<br/>C.<br/>D.<div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample498' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_402'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_125'>Random</a></p><div class='collapse' id='collapseExample498'><div class='card card&#45;body'><div class=' border border&#45;success'></div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 50%;" aria-valuenow="50" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_402><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 402</p><br/>A solutions architect is designing a publicly accessible web application that is on an Amazon CloudFront distribution with an Amazon S3 website endpoint as the origin.<br/><br/>When the solution is deployed, the website returns an Error 403: Access Denied message.<br/><br/>Which steps should the solutions architect take to correct the issue? (Select TWO.)<br/><br/>A. Remove the S3 block public access option from the S3 bucket.<br/>B. Remove the requester pays option from the S3 bucket.<br/>C. Remove the origin access identity (OAI) from the CloudFront distribution.<br/>D. Change the storage class from S3 Standard to S3 One Zone&#8211;Infrequent Access (S3 One Zone&#8211; IA).<br/>E. Disable S3 object versioning<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample685' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_403'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_683'>Random</a></p><div class='collapse' id='collapseExample685'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Remove the S3 block public access option from the S3 bucket.
<br><b>B. </b>Remove the requester pays option from the S3 bucket.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 50%;" aria-valuenow="50" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_403><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 403</p><br/>A company must migrate 20 TB of data from a data center to the AWS Cloud within 30 days. The company's network bandwidth is limited to 15 Mbps and cannot exceed 70% utilization. What should a solutions architect do to meet these requirements?<br/><br/>A. Use AWS Snowball.<br/>B. Use AWS DataSync.<br/>C. Use a secure VPN connection.<br/>D. Use Amazon S3 Transfer Acceleration.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample722' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_404'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_600'>Random</a></p><div class='collapse' id='collapseExample722'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Use AWS Snowball.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 51%;" aria-valuenow="51" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_404><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 404</p><br/>A company has three AWS accounts Management Development and Production. These accounts use AWS services only in the us&#8211;east&#8211;1 Region All accounts have a VPC with VPC Flow Logs configured to publish data to an Amazon S3 bucket in each separate account For compliance reasons the company needs an ongoing method to aggregate all the VPC flow logs across all accounts into one destination S3 bucket in the Management account.<br/><br/>What should a solutions architect do to meet these requirements with the LEAST operational overhead?<br/><br/>A. Add S3 Same&#8211;Region Replication rules in each S3 bucket that stores VPC flow logs to replicate objects to the destination S3 bucket Configure the destination S3 bucket to allow objects to be received from the S3 buckets in other accounts<br/>B. Set up an 1AM user in the Management account Grant permissions to the 1AM user to access the S3 buckets that contain the VPC flow logs Run the aws s3 sync command in the AWS CLI to copy the objects to the destination S3 bucket<br/>C. Use an S3 inventory report to specify which objects in the S3 buckets to copy Perform an S3 batch operation to copy the objects into the destination S3 bucket in the Management account with a single request.<br/>D. Create an AWS Lambda function in the Management account Grant S3 GET permissions on the source S3 buckets Grant S3 PUT permissions on the destination S3 bucket Configure the function to invoke when objects are loaded in the source S3 buckets<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample462' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_405'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_30'>Random</a></p><div class='collapse' id='collapseExample462'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Add S3 Same-Region Replication rules in each S3 bucket that stores VPC flow logs to replicate objects to the destination S3 bucket Configure the destination S3 bucket to allow objects to be received from the S3 buckets in other accounts</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 51%;" aria-valuenow="51" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_405><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 405</p><br/>A company recently implemented hybrid cloud connectivity using AWS Direct Connect and is migrating data to Amazon S3. The company is looking for a fully managed solution that will automate and accelerate the replication of data between the on&#8211;premises storage systems and AWS storage services.<br/><br/>Which solution should a solutions architect recommend to keep the data private?<br/><br/>A. Deploy an AWS DataSync agent for the on&#8211;premises environment. Configure a sync job to replicate the data and connect it with an AWS service endpoint.<br/>B. Deploy an AWS DataSync agent for the on&#8211;premises environment. Schedule a batch job to replicate point&#8211;in&#8211;time snapshots to AWS.<br/>C. Deploy an AWS Storage Gateway volume gateway for the on&#8211;premises environment. Configure it to store data locally, and asynchronously back up point&#8211;in&#8211;time snapshots to AWS.<br/>D. Deploy an AWS Storage Gateway file gateway for the on&#8211;premises environment. Configure it to store data locally, and asynchronously back up point&#8211;in&#8211;time snapshots to AWS.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample51' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation51' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_406'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_187'>Random</a></p><div class='collapse' id='collapseExample51'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Deploy an AWS DataSync agent for the on-premises environment. Configure a sync job to replicate the data and connect it with an AWS service endpoint.</div></div></div><div class='collapse' id='explanation51'><div class='card card&#45;body'><div>
You can use AWS DataSync with your Direct Connect link to access public service endpoints or private VPC endpoints. When using VPC endpoints, data transferred between the DataSync agent and AWS services does not traverse the public internet or need public IP addresses, increasing the security of data as it is copied over the network.

</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 51%;" aria-valuenow="51" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_406><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 406</p><br/>A solutions architect is designing a solution that will include a database in Amazon RDS Corporate security policy mandates that the database its logs, and its backups are all encrypted.<br/><br/>What is the MOST efficient option to fulfill the security policy using Amazon RDS?<br/><br/>A. Launch an Amazon RDS instance with encryption enabled Enable encryption for logs and backups<br/>B. Launch an Amazon RDS instance Enable encryption for the database, logs, and backups<br/>C. Launch an Amazon RDS instance with encryption enabled Logs and backups are automatically encrypted<br/>D. Launch an Amazon RDS instance Enable encryption for backups Encrypt logs with a database&#8211; engine feature<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample651' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_407'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_500'>Random</a></p><div class='collapse' id='collapseExample651'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Launch an Amazon RDS instance with encryption enabled Logs and backups are automatically encrypted</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 51%;" aria-valuenow="51" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_407><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 407</p><br/>A company runs an internal browser&#8211;based application. The application runs on Amazon EC2 instances behind an Application Load Balancer. The instances run in an Amazon EC2 Auto Scaling group across multiple Availability Zones. The Auto Scaling group scales up to 20 instances during work hours, but scales down to 2 instances overnight. Staff are complaining that the application is very slow when the day begins, although it runs well by mid&#8211;morning.<br/><br/>How should the scaling be changed to address the staff complaints and keep costs to a minimum?<br/><br/>A. Implement a scheduled action that sets the desired capacity to 20 shortly before the office opens.<br/>B. Implement a step scaling action triggered at a lower CPU threshold, and decrease the cooldown period.<br/>C. Implement a target tracking action triggered at a lower CPU threshold, and decrease the cooldown period.<br/>D. Implement a scheduled action that sets the minimum and maximum capacity to 20 shortly before the office opens.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample149' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation149' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_408'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_275'>Random</a></p><div class='collapse' id='collapseExample149'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Implement a scheduled action that sets the desired capacity to 20 shortly before the office opens.</div></div></div><div class='collapse' id='explanation149'><div class='card card&#45;body'><div>
Though this sounds like a good use case for scheduled actions, both answers using scheduled actions will have 20 instances running regardless of actual demand. A better option to be more cost effective is to use a target tracking action that triggers at a lower CPU threshold.

With this solution the scaling will occur before the CPU utilization gets to a point where performance is affected. This will result in resolving the performance issues whilst minimizing costs. Using a reduced cooldown period will also more quickly terminate unneeded instances, further reducing costs.

References:

Amazon EC2 Auto Scaling > User Guide > Target tracking scaling policies for Amazon EC2 Auto Scaling</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 51%;" aria-valuenow="51" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_408><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 408</p><br/>You are trying to launch an EC2 instance, however the instance seems to go into a terminated status immediately. What would probably not be a reason that this is happening?<br/><br/>A. The AMI is missing a required part.<br/>B. The snapshot is corrupt.<br/>C. You need to create storage in EBS first.<br/>D. You've reached your volume limit.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample786' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation786' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_409'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_280'>Random</a></p><div class='collapse' id='collapseExample786'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>You need to create storage in EBS first.</div></div></div><div class='collapse' id='explanation786'><div class='card card&#45;body'><div>
Amazon EC2 provides a virtual computing environments, known as an instance. After you launch an instance, AWS recommends that you check its status to confirm that it goes from the pending status to the running status, the not terminated status. The following are a few reasons why an Amazon EBS-backed instance might immediately terminate:

You've reached your volume limit. The AMI is missing a required part. The snapshot is corrupt.

References:

Amazon Elastic Compute Cloud > User Guide for Linux Instances > Instance terminates immediately</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 51%;" aria-valuenow="51" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_409><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 409</p><br/>While using the EC2 GET requests as URLs, the _________ is the URL that serves as the entry point for the web service.<br/><br/>A. token<br/>B. endpoint<br/>C. action<br/>D. None of these<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample748' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation748' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_410'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_457'>Random</a></p><div class='collapse' id='collapseExample748'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>endpoint</div></div></div><div class='collapse' id='explanation748'><div class='card card&#45;body'><div>
The endpoint is the URL that serves as the entry point for the web service.

References:

Amazon Elastic Compute Cloud > API Reference > Query requests for Amazon EC2</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 51%;" aria-valuenow="51" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_410><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 410</p><br/>A company runs an online marketplace web application on AWS. The application serves hundreds of thousands of users during peak hours. The company needs a scalable, near&#8211;real&#8211;time solution to share the details of millions of financial transactions with several other internal applications. Transactions also need to be processed to remove sensitive data before being stored in a document database for low&#8211;latency retrieval.<br/><br/>What should a solutions architect recommend to meet these requirements?<br/><br/>A. Store the batched transactions data in Amazon S3 as files. Use AWS Lambda to process every file and remove sensitive data before updating the files in Amazon S3. The Lambda function then stores the data in Amazon DynamoDB. Other applications can consume transaction files stored in Amazon S3.<br/>B. Store the transactions data into Amazon DynamoDB. Set up a rule in DynamoDB to remove sensitive data from every transaction upon write. Use DynamoDB Streams to share the transactions data with other applications.<br/>C. Stream the transactions data into Amazon Kinesis Data Streams. Use AWS Lambda integration to remove sensitive data from every transaction and then store the transactions data in Amazon DynamoDB. Other applications can consume the transactions data off the Kinesis data stream.<br/>D. Stream the transactions data into Amazon Kinesis Data Firehose to store data in Amazon DynamoDB and Amazon S3. Use AWS Lambda integration with Kinesis Data Firehose to remove sensitive data. Other applications can consume the data stored in Amazon S3.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample511' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_411'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_495'>Random</a></p><div class='collapse' id='collapseExample511'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Stream the transactions data into Amazon Kinesis Data Streams. Use AWS Lambda integration to remove sensitive data from every transaction and then store the transactions data in Amazon DynamoD<br><b>B. </b>Other applications can consume the transactions data off the Kinesis data stream.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 51%;" aria-valuenow="51" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_411><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 411</p><br/>A company is developing an eCommerce application that will consist of a load&#8211;balanced front end. a container&#8211;based application and a relational database A solutions architect needs to create a highly available solution that operates with as little manual intervention as possible<br/><br/>Which solutions meet these requirements? (Select TWO.)<br/><br/>A. Create an Amazon RDS DB instance in Multi&#8211;AZ mode<br/>B. Create an Amazon RDS DB instance and one or more replicas in another Availability Zone<br/>C. Create an Amazon EC2 instance&#8211;based Docker cluster to handle the dynamic application load<br/>D. Create an Amazon Elastic Container Service (Amazon ECS) cluster with a Fargate launch type to handle the dynamic application load<br/>E. Create an Amazon Elastic Container Service (Amazon ECS) cluster with an Amazon EC2 launch type to handle the dynamic application load<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample502' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation502' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_412'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_157'>Random</a></p><div class='collapse' id='collapseExample502'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Create an Amazon RDS DB instance in Multi-AZ mode
<br><b>D. </b>Create an Amazon Elastic Container Service (Amazon ECS) cluster with a Fargate launch type to handle the dynamic application load</div></div></div><div class='collapse' id='explanation502'><div class='card card&#45;body'><div>
Relational database: RDS
Container-based applications: ECS
"Amazon ECS enables you to launch and stop your container-based applications by using simple API calls. You can also retrieve the state of your cluster from a centralized service and have access to many familiar Amazon EC2 features."
Little manual intervention: Fargate
You can run your tasks and services on a serverless infrastructure that is managed by AWS Fargate. Alternatively, for more control over your infrastructure, you can run your tasks and services on a cluster of Amazon EC2 instances that you manage.

References:

Amazon Elastic Container Service > Developer Guide > What is Amazon Elastic Container Service?</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 52%;" aria-valuenow="52" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_412><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 412</p><br/>A company is moving its legacy workload to the AWS Cloud.<br/><br/>The workload files will be shared, appended, and frequently accessed through Amazon EC2 instances when they are first created.<br/><br/>The files will be accessed occasionally as they age.<br/><br/>What should a solutions architect recommend?<br/><br/>A. Store the data using Amazon EC2 instances with attached Amazon Elastic Block Store (Amazon EBS) data volumes<br/>B. Store the data using AWS Storage Gateway volume gateway and export rarely accessed data to Amazon S3 storage<br/>C. Store the data using Amazon Elastic File System (Amazon EFS) with lifecycle management enabled for rarely accessed data<br/>D. Store the data using Amazon S3 with an S3 lifecycle policy enabled to move data to S3 Standard&#8211; Infrequent Access (S3 Standard&#8211;IA)<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample720' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_413'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_533'>Random</a></p><div class='collapse' id='collapseExample720'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Store the data using Amazon S3 with an S3 lifecycle policy enabled to move data to S3 Standard- Infrequent Access (S3 Standard-IA)</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 52%;" aria-valuenow="52" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_413><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 413</p><br/>A company has a Microsoft Windows&#8211;based application that must be migrated to AWS. This application requires the use of a shared Windows file system attached to multiple Amazon EC2 Windows instances.<br/><br/>What should a solution architect do to accomplish this?<br/><br/>A. Configure a volume using Amazon EFS Mount the EPS volume to each Windows Instance<br/>B. Configure AWS Storage Gateway in Volume Gateway mode Mount the volume to each Windows instance<br/>C. Configure Amazon FSx for Windows File Server Mount the Amazon FSx volume to each Windows Instance<br/>D. Configure an Amazon EBS volume with the required size Attach each EC2 instance to the volume Mount the file system within the volume to each Windows instance<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample724' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_414'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_364'>Random</a></p><div class='collapse' id='collapseExample724'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Configure Amazon FSx for Windows File Server Mount the Amazon FSx volume to each Windows Instance</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 52%;" aria-valuenow="52" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_414><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 414</p><br/>A company is preparing to store confidential data in Amazon S3. For compliance reasons, the data must be encrypted at rest. Encryption key usage must be logged for auditing purposes. Keys must be rotated every year.<br/><br/>Which solution meets these requirements and is the MOST operationally efficient?<br/><br/>A. Server&#8211;side encryption with customer&#8211;provided keys (SSE&#8211;C)<br/>B. Server&#8211;side encryption with Amazon S3 managed keys (SSE&#8211;S3)<br/>C. Server&#8211;side encryption with AWS KMS (SSE&#8211;KMS) customer master keys (CMKs) with manual rotation<br/>D. Server&#8211;side encryption with AWS KMS (SSE&#8211;KMS) customer master keys (CMKs) with automatic rotation<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample408' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_415'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_304'>Random</a></p><div class='collapse' id='collapseExample408'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Server-side encryption with AWS KMS (SSE-KMS) customer master keys (CMKs) with automatic rotation</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 52%;" aria-valuenow="52" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_415><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 415</p><br/>A company relies on an application that needs at least 4 Amazon EC2 instances during regular traffic and must scale up to 12 EC2 instances during peak loads. The application is critical to the business and must be highly available.<br/><br/>Which solution will meet these requirements?<br/><br/>A. Deploy the EC2 instances in an Auto Scaling group. Set the minimum to 4 and the maximum to 12, with 2 in Availability Zone A and 2 in Availability Zone B.<br/>B. Deploy the EC2 instances in an Auto Scaling group. Set the minimum to 4 and the maximum to 12, with all 4 in Availability Zone A.<br/>C. Deploy the EC2 instances in an Auto Scaling group. Set the minimum to 8 and the maximum to 12, with 4 in Availability Zone A and 4 in Availability Zone B.<br/>D. Deploy the EC2 instances in an Auto Scaling group. Set the minimum to 8 and the maximum to 12, with all 8 in Availability Zone A.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample165' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_416'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_135'>Random</a></p><div class='collapse' id='collapseExample165'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Deploy the EC2 instances in an Auto Scaling group. Set the minimum to 8 and the maximum to 12, with 4 in Availability Zone A and 4 in Availability Zone B.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 52%;" aria-valuenow="52" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_416><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 416</p><br/>A company is investigating potential solutions that would collect, process, and store users' service usage data. The business objective is to create an analytics capability that will enable the company to gather operational insights quickly using standard SQL queries. The solution should be highly available and ensure Atomicity, Consistency, Isolation, and Durability (ACID) compliance in the data tier.<br/><br/>Which solution should a solutions architect recommend?<br/><br/>A. Use Amazon DynamoDB transactions.<br/>B. Create an Amazon Neptune database in a Multi&#8211;AZ design<br/>C. Use a fully managed Amazon RDS for MySQL database in a Multi&#8211;AZ design.<br/>D. Deploy PostgreSQL on an Amazon EC2 instance that uses Amazon EBS Throughput Optimized HDD (st1) storage.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample64' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_417'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_678'>Random</a></p><div class='collapse' id='collapseExample64'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Use a fully managed Amazon RDS for MySQL database in a Multi-AZ design.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 52%;" aria-valuenow="52" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_417><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 417</p><br/>A company has created a multi&#8211;tier application for its eCommerce website. The website uses an Application Load Balancer that resides in the public subnets, a web tier in the public subnets, and a MySQL cluster hosted on Amazon EC2 instances in the private subnets. The MySQL database needs to retrieve product catalog and pricing information that is hosted on the internet by a third&#8211;party provider. A solutions architect must devices a strategy that maximizes security without increasing operational overhead.<br/><br/>What should the solutions architect do to meet these requirements?<br/><br/>A. Deploy a NAT instance in the VPC. Route all the internet&#8211;based traffic through the NAT instance.<br/>B. Deploy a NAT gateway in the public subnets. Modify the private subnet route table to direct all internet&#8211;bound traffic to the NAT gateway.<br/>C. Configure an internet gateway and attach it to the VPC. Modify the private subnet route table to direct internet&#8211;bound traffic to the internet gateway.<br/>D. Configure a virtual private gateway and attach it to the VPC. Modify the private subnet route table to direct internet&#8211;bound traffic to the virtual private gateway.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample244' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_418'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_62'>Random</a></p><div class='collapse' id='collapseExample244'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Configure an internet gateway and attach it to the VP<b>C. </b>Modify the private subnet route table to direct internet-bound traffic to the internet gateway.

References:

Amazon Virtual Private Cloud > User Guide > NAT gateways</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 52%;" aria-valuenow="52" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_418><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 418</p><br/>You have set up an Auto Scaling group. The cool down period for the Auto Scaling group is 7 minutes. The first instance is launched after 3 minutes, while the second instance is launched after 4 minutes. How many minutes after the first instance is launched will Auto Scaling accept another scaling activity request?<br/><br/>A. 11 minutes<br/>B. 7 minutes<br/>C. 10 minutes<br/>D. 14 minutes<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample785' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation785' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_419'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_216'>Random</a></p><div class='collapse' id='collapseExample785'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>11 minutes</div></div></div><div class='collapse' id='explanation785'><div class='card card&#45;body'><div>
If an Auto Scaling group is launching more than one instance, the cool down period for each instance starts after that instance is launched. The group remains locked until the last instance that was launched has completed its cool down period. In this case the cool down period for the first instance starts after 3 minutes and finishes at the 10th minute (3+7 cool down), while for the second instance it starts at the 4th minute and finishes at the 11th minute (4+7 cool down). Thus, the Auto Scaling group will receive another request only after 11 minutes.

References:

Amazon EC2 Auto Scaling > User Guide > What is Amazon EC2 Auto Scaling?</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 52%;" aria-valuenow="52" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_419><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 419</p><br/>A solutions architect is designing a solution where users will be directed to a backup static error page if the primary website is unavailable. The primary website's DNS records are hosted in Amazon Route 53 where their domain is pointing to an Application Load Balancer (ALB).<br/><br/>Which configuration should the solutions architect use to meet the company's needs while minimizing changes and infrastructure overhead?<br/><br/>A. Point a Route 53 alias record to an Amazon CloudFront distribution with the ALB as one of its origins. Then, create custom error pages for the distribution.<br/>B. Set up a Route 53 active&#8211;passive failover configuration. Direct traffic to a static error page hosted within an Amazon S3 bucket when Route 53 health checks determine that the ALB endpoint is unhealthy.<br/>C. Update the Route 53 record to use a latency&#8211;based routing policy. Add the backup static error page hosted within an Amazon S3 bucket to the record so the traffic is sent to the most responsive endpoints.<br/>D. Set up a Route 53 active&#8211;active configuration with the ALB and an Amazon EC2 instance hosting a static error page as endpoints. Route 53 will only send requests to the instance if the health checks fail for the ALB.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample177' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation177' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_420'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_407'>Random</a></p><div class='collapse' id='collapseExample177'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Set up a Route 53 active-passive failover configuration. Direct traffic to a static error page hosted within an Amazon S3 bucket when Route 53 health checks determine that the ALB endpoint is unhealthy.</div></div></div><div class='collapse' id='explanation177'><div class='card card&#45;body'><div>
Active-passive failover
Use an active-passive failover configuration when you want a primary resource or group of resources to be available the majority of the time and you want a secondary resource or group of resources to be on standby in case all the primary resources become unavailable. When responding to queries, Route 53 includes only the healthy primary resources. If all the primary resources are unhealthy, Route 53 begins to include only the healthy secondary resources in response to DNS queries.

To create an active-passive failover configuration with one primary record and one secondary record, you just create the records and specify Failover for the routing policy. When the primary resource is healthy, Route 53 responds to DNS queries using the primary record. When the primary resource is unhealthy, Route 53 responds to DNS queries using the secondary record.

How Amazon Route 53 averts cascading failures
As the first defense against cascading failures, each request routing algorithm (such as weighted and failover) has a mode of last resort. In this special mode, when all records are considered unhealthy, the Route 53 algorithm reverts to considering all records healthy.

For example, if all instances of an application, on several hosts, are rejecting health check requests, Route 53 DNS servers will choose an answer anyway and return it rather than returning no DNS answer or returning an NXDOMAIN (non-existent domain) response. An application can respond to users but still fail health checks, so this provides some protection against misconfiguration.

Similarly, if an application is overloaded, and one out of three endpoints fails its health checks, so that it's excluded from Route 53 DNS responses, Route 53 distributes responses between the two remaining endpoints. If the remaining endpoints are unable to handle the additional load and they fail, Route 53 reverts to distributing requests to all three endpoints.

Using Amazon CloudFront as the front-end provides the option to specify a custom message instead of the default message. To specify the specific file that you want to return and the errors for which the file should be returned, you update your CloudFront distribution to specify those values.

For example, the following is a customized error message:

The CloudFront distribution can use the ALB as the origin, which will cause the website content to be cached on the CloudFront edge caches.

This solution represents the most operationally efficient choice as no action is required in the event of an issue, other than troubleshooting the root cause.

References:

Amazon CloudFront > Developer Guide > What is Amazon CloudFront?</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 53%;" aria-valuenow="53" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_420><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 420</p><br/>A solutions architect is designing a two&#8211;tier web application. The application consists of a public&#8211;facing web tier hosted on Amazon EC2 in public subnets. The database tier consists of Microsoft SQL Server running on Amazon EC2 in a private subnet. Security is a high priority for the company.<br/><br/>How should security groups be configured in this situation? (Choose two.)<br/><br/>A. Configure the security group for the web tier to allow inbound traffic on port 443 from 0.0.0.0/0.<br/>B. Configure the security group for the web tier to allow outbound traffic on port 443 from 0.0.0.0/0.<br/>C. Configure the security group for the database tier to allow inbound traffic on port 1433 from the security group for the web tier.<br/>D. Configure the security group for the database tier to allow outbound traffic on ports 443 and 1433 to the security group for the web tier.<br/>E. Configure the security group for the database tier to allow inbound traffic on ports 443 and 1433 from the security group for the web tier.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample187' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation187' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_421'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_363'>Random</a></p><div class='collapse' id='collapseExample187'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Configure the security group for the web tier to allow inbound traffic on port 443 from 0.0.0.0/0.
<br><b>C. </b>Configure the security group for the database tier to allow inbound traffic on port 1433 from the security group for the web tier.</div></div></div><div class='collapse' id='explanation187'><div class='card card&#45;body'><div>
In this scenario an inbound rule is required to allow traffic from any internet client to the web front end on SSL/TLS port 443. The source should therefore be set to 0.0.0.0/0 to allow any inbound traffic.

To secure the connection from the web frontend to the database tier, an outbound rule should be created from the public EC2 security group with a destination of the private EC2 security group. The port should be set to 1433 for MySQL. The private EC2 security group will also need to allow inbound traffic on 1433 from the public EC2 security group.

This configuration can be seen in the diagram:

CORRECT: "Configure the security group for the web tier to allow inbound traffic on port 443 from 0.0.0.0/0" is a correct answer.

CORRECT: "Configure the security group for the database tier to allow inbound traffic on port 1433 from the security group for the web tier" is also a correct answer.

INCORRECT: "Configure the security group for the web tier to allow outbound traffic on port 443 from 0.0.0.0/0" is incorrect as this is configured backwards.

INCORRECT: "Configure the security group for the database tier to allow outbound traffic on ports 443 and 1433 to the security group for the web tier" is incorrect as the MySQL database instance does not need to send outbound traffic on either of these ports.

INCORRECT: "Configure the security group for the database tier to allow inbound traffic on ports 443 and 1433 from the security group for the web tier" is incorrect as the database tier does not need to allow inbound traffic on port 443.

References:
Amazon Virtual Private Cloud > User Guide > Security groups for your VPC
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 53%;" aria-valuenow="53" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_421><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 421</p><br/>An eCommerce application places orders in an Amazon Simple Queue Service (Amazon SQS) queue.<br/><br/>When a message is received, the Amazon EC2 worker instances process the request The EC2 instances are in an Auto Scaling group 236.<br/><br/>How should the architecture be designed to scale the auto scaling group with the LEAST amount of operational overhead?<br/><br/>A. Use an Amazon CloudWatch alarm on the EC2 CPU to scale the Auto Scaling group up and down<br/>B. Use an Amazon EC2 Auto Scaling health check for messages processed on the EC2 instances to scale up or down.<br/>C. Use an Amazon CloudWatch alarm based on the number of messages in the queue to scale the Auto Scaling group up or down<br/>D. Use an Amazon CloudWatch alarm based on the CPU to scale the Auto Scaling group up or down<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample526' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_422'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_346'>Random</a></p><div class='collapse' id='collapseExample526'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Use an Amazon CloudWatch alarm based on the number of messages in the queue to scale the Auto Scaling group up or down</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 53%;" aria-valuenow="53" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_422><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 422</p><br/>A company's application is running on Amazon EC2 instances in a single Region. In the event of a disaster, a solutions architect needs to ensure that the resources can also be deployed to a second Region.<br/><br/>Which combination of actions should the solutions architect take to accomplish this? (Choose two.)<br/><br/>A. Detach a volume on an EC2 instance and copy it to Amazon S3.<br/>B. Launch a new EC2 instance from an Amazon Machine Image (AMI) in a new Region.<br/>C. Launch a new EC2 instance in a new Region and copy a volume from Amazon S3 to the new instance.<br/>D. Copy an Amazon Machine Image (AMI) of an EC2 instance and specify a different Region for the destination.<br/>E. Copy an Amazon Elastic Block Store (Amazon EBS) volume from Amazon S3 and launch an EC2 instance in the destination Region using that EBS volume.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample145' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation145' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_423'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_427'>Random</a></p><div class='collapse' id='collapseExample145'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Launch a new EC2 instance from an Amazon Machine Image (AMI) in a new Region.
<br><b>D. </b>Copy an Amazon Machine Image (AMI) of an EC2 instance and specify a different Region for the destination.</div></div></div><div class='collapse' id='explanation145'><div class='card card&#45;body'><div>
Cross Region EC2 AMI Copy
We know that you want to build applications that span AWS Regions and we're working to provide you with the services and features needed to do so. We started out by launching the EBS Snapshot Copy feature late last year. This feature gave you the ability to copy a snapshot from Region to Region with just a couple of clicks. In addition, last month we made a significant reduction (26% to 83%) in the cost of transferring data between AWS Regions, making it less expensive to operate in more than one AWS region.

Today we are introducing a new feature: Amazon Machine Image (AMI) Copy. AMI Copy enables you to easily copy your Amazon Machine Images between AWS Regions. AMI Copy helps enable several key scenarios including:

Simple and Consistent Multi-Region Deployment – You can copy an AMI from one region to another, enabling you to easily launch consistent instances based on the same AMI into different regions.

Scalability – You can more easily design and build world-scale applications that meet the needs of your users, regardless of their location.

Performance – You can increase performance by distributing your application and locating critical components of your application in closer proximity to your users. You can also take advantage of region specific features such as instance types or other AWS services.

Even Higher Availability – You can design and deploy applications across AWS regions, to increase availability. Once the new AMI is in an Available state the copy is complete.

Once the new AMI is in an Available state the copy is complete.
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 53%;" aria-valuenow="53" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_423><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 423</p><br/>A company is developing a mobile game that streams score updates to a backend processor and then posts results on a leaderboard. A solutions architect needs to design a solution that can handle large traffic spikes, process the mobile game updates in order of receipt, and store the processed updates in a highly available database. The company also wants to minimize the management overhead required to maintain the solution.<br/><br/>What should the solutions architect do to meet these requirements?<br/><br/>A. Push score updates to Amazon Kinesis Data Streams. Process the updates in Kinesis Data Streams with AWS Lambda. Store the processed updates in Amazon DynamoDB.<br/>B. Push score updates to Amazon Kinesis Data Streams. Process the updates with a fleet of Amazon EC2 instances set up for Auto Scaling. Store the processed updates in Amazon Redshift.<br/>C. Push score updates to an Amazon Simple Notification Service (Amazon SNS) topic. Subscribe an AWS Lambda function to the SNS topic to process the updates. Store the processed updates in a SQL database running on Amazon EC2.<br/>D. Push score updates to an Amazon Simple Queue Service (Amazon SQS) queue. Use a fleet of Amazon EC2 instances with Auto Scaling to process the updates in the SQS queue. Store the processed updates in an Amazon RDS Multi&#8211;AZ DB instance.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample379' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation379' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_424'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_633'>Random</a></p><div class='collapse' id='collapseExample379'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Push score updates to Amazon Kinesis Data Streams. Process the updates in Kinesis Data Streams with AWS Lambda. Store the processed updates in Amazon DynamoDB.</div></div></div><div class='collapse' id='explanation379'><div class='card card&#45;body'><div>
Keywords to focus on would be highly available database – DynamoDB would be a better choice for leaderboard.
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 53%;" aria-valuenow="53" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_424><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 424</p><br/>A company needs a storage solution for an application that runs on a high performance computing (HPC) cluster. The cluster is hosted on AWS Fargate for Amazon Elastic Container Service (Amazon ECS). The company needs a mountable file system that provides concurrent access to files while delivering hundreds of Gbps of throughput at sub&#8211;millisecond latencies<br/><br/>Which solution meets these requirements?<br/><br/>A. Create an Amazon FSx for Lustre file share for the application data Create an IAM role that allows Fargate to access the FSx for Lustre file share<br/>B. Create an Amazon Elastic File System (Amazon EFS) file share for the application data. Create an IAM role that allows Fargate to access the EFS file share.<br/>C. Create an Amazon S3 bucket for the application data. Create an S3 bucket policy that allows Fargate to access the S3 bucket<br/>D. Create an Amazon Elastic Block Store (Amazon EBS) Provisioned IOPS SSD (io2) volume for the application data Create an IAM role that allows Fargate to access the volume.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample456' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_425'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_530'>Random</a></p><div class='collapse' id='collapseExample456'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Create an Amazon FSx for Lustre file share for the application data Create an IAM role that allows Fargate to access the FSx for Lustre file share</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 53%;" aria-valuenow="53" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_425><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 425</p><br/>A company wants to educe Its Amazon S3 storage costs in its production environment without impacting durability or performance of the stored objects.<br/><br/>What is the FIRST step the company should take to meet these objectives?<br/><br/>A. Enable Amazon Made on the business&#8211;critical S3 buckets to classify the sensitivity of the objects<br/>B. Enable S3 analytics to Identify S3 buckets that are candidates for transitioning to S3 Standard&#8211; Infrequent Access (S3 Standard&#8211;IA)<br/>C. Enable versioning on all business&#8211;critical S3 buckets.<br/>D. Migrate me objects in all S3 buckets to S3 Intelligent&#8211;Tie ring<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample571' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_426'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_714'>Random</a></p><div class='collapse' id='collapseExample571'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Migrate me objects in all S3 buckets to S3 Intelligent-Tie ring</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 53%;" aria-valuenow="53" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_426><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 426</p><br/>A company is developing a new machine learning model solution in AWS. The models are developed as independent microservices that fetch about 1 GB of model data from Amazon S3 at startup and load the data into memory. Users access the models through an asynchronous API. Users can send a request or a batch of requests and specify where the results should be sent.<br/><br/>The company provides models to hundreds of users. The usage patterns for the models are irregular Some models could be unused for days or weeks. Other models could receive batches of thousands of requests at a time.<br/><br/>Which solution meets these requirements?<br/><br/>A. The requests from the API are sent to an Application Load Balancer (ALB). Models are deployed as AWS Lambda functions invoked by the ALB.<br/>B. The requests from the API are sent to the models Amazon Simple Queue Service (Amazon SQS) queue. Models are deployed as AWS Lambda functions triggered by SQS events AWS Auto Scaling is enabled on Lambda to increase the number of vCPUs based on the SQS queue size.<br/>C. The requests from the API are sent to the model's Amazon Simple Queue Service (Amazon SQS) queue. Models are deployed as Amazon Elastic Container Service (Amazon ECS) services reading from the queue AWS App Mesh scales the instances of the ECS cluster based on the SQS queue size.<br/>D. The requests from the API are sent to the models Amazon Simple Queue Service (Amazon SQS) queue. Models are deployed as Amazon Elastic Container Service (Amazon ECS) services reading from the queue AWS Auto Scaling is enabled on Amazon ECS for both the cluster and copies of the service based on the queue size.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample400' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_427'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_227'>Random</a></p><div class='collapse' id='collapseExample400'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>The requests from the API are sent to the models Amazon Simple Queue Service (Amazon SQS) queue. Models are deployed as Amazon Elastic Container Service (Amazon ECS) services reading from the queue AWS Auto Scaling is enabled on Amazon ECS for both the cluster and copies of the service based on the queue size.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 53%;" aria-valuenow="53" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_427><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 427</p><br/>A company runs its two&#8211;tier eCommerce website on AWS. The web tier consists of a load balancer that sends traffic to Amazon EC2 instances. The database tier uses an Amazon RDS DB instance. The EC2 instances and the RDS DB instance should not be exposed to the public internet. The EC2 instances require internet access to complete payment processing of orders through a third&#8211;party web service. The application must be highly available.<br/><br/>Which combination of configuration options will meet these requirements? (Choose two.)<br/><br/>A. Use an Auto Scaling group to launch the EC2 instances in private subnets. Deploy an RDS Multi&#8211;AZ DB instance in private subnets.<br/>B. Configure a VPC with two private subnets and two NAT gateways across two Availability Zones. Deploy an Application Load Balancer in the private subnets.<br/>C. Use an Auto Scaling group to launch the EC2 instances in public subnets across two Availability Zones. Deploy an RDS Multi&#8211;AZ DB instance in private subnets.<br/>D. Configure a VPC with one public subnet, one private subnet, and two NAT gateways across two Availability Zones. Deploy an Application Load Balancer in the public subnet.<br/>E. Configure a VPC with two public subnets, two private subnets, and two NAT gateways across two Availability Zones. Deploy an Application Load Balancer in the public subnets.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample422' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_428'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_726'>Random</a></p><div class='collapse' id='collapseExample422'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Use an Auto Scaling group to launch the EC2 instances in private subnets. Deploy an RDS Multi-AZ DB instance in private subnets.
<br><b>B. </b>Configure a VPC with two private subnets and two NAT gateways across two Availability Zones. Deploy an Application Load Balancer in the private subnets.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 54%;" aria-valuenow="54" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_428><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 428</p><br/>A solutions architect is investigating AWS file storage solutions that can be used with a company's on&#8211;premises Linux servers and applications. The company has an existing VPN connection set up between the company's VPC and its on&#8211;premises network.<br/><br/>Which AWS services should the solutions architect use? (Select TWO)<br/><br/>A. AWS Backup<br/>B. AWS DataSync<br/>C. AWS Snowball Edge<br/>D. AWS Storage Gateway<br/>E. Amazon Elastic File System (Amazon EFS)<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample644' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_429'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_760'>Random</a></p><div class='collapse' id='collapseExample644'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>AWS Backup
<br><b>E. </b>Amazon Elastic File System (Amazon EFS)</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 54%;" aria-valuenow="54" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_429><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 429</p><br/>A company is planning to migrate a legacy application to AWS. The application currently uses NFS to communicate to an on&#8211;premises storage solution to store application data. The application cannot be modified to use any other communication protocols other than NFS for this purpose.<br/><br/>Which storage solution should a solutions architect recommend for use after the migration?<br/><br/>A. AWS DataSync<br/>B. Amazon Elastic Block Store (Amazon EBS)<br/>C. Amazon Elastic File System (Amazon EFS)<br/>D. Amazon EMR File System (Amazon EMRFS)<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample365' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_430'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_246'>Random</a></p><div class='collapse' id='collapseExample365'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Amazon Elastic File System (Amazon EFS)</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 54%;" aria-valuenow="54" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_430><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 430</p><br/>A company is planning to migrate a commercial off&#8211;the&#8211;shelf application from its on&#8211;premises data center to AWS. The software has a software licensing model using sockets and cores with predictable capacity and uptime requirements. The company wants to use its existing licenses, which were purchased earlier this year.<br/><br/>Which Amazon EC2 pricing option is the MOST cost&#8211;effective?<br/><br/>A. Dedicated Reserved Hosts<br/>B. Dedicated On&#8211;Demand Hosts<br/>C. Dedicated Reserved Instances<br/>D. Dedicated On&#8211;Demand Instances<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample280' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_431'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_776'>Random</a></p><div class='collapse' id='collapseExample280'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Dedicated Reserved Instances</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 54%;" aria-valuenow="54" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_431><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 431</p><br/>A company has an application with a REST&#8211;based interface that allows data to be received in near&#8211;real time from a third&#8211;party vendor. Once received, the application processes and stores the data for further analysis.<br/>The application is running on Amazon EC2 instances.<br/><br/>The third&#8211;party vendor has received many 503 Service Unavailable Errors when sending data to the application. When the data volume spikes, the compute capacity reaches its maximum limit and the application is unable to process all requests.<br/><br/>Which design should a solutions architect recommend to provide a more scalable solution?<br/><br/>A. Use Amazon Kinesis Data Streams to ingest the data. Process the data using AWS Lambda functions.<br/>B. Use Amazon API Gateway on top of the existing application. Create a usage plan with a quota limit for the third&#8211;party vendor.<br/>C. Use Amazon Simple Notification Service (Amazon SNS) to ingest the data. Put the EC2 instances in an Auto Scaling group behind an Application Load Balancer.<br/>D. Repackage the application as a container. Deploy the application using Amazon Elastic Container Service (Amazon ECS) using the EC2 launch type with an Auto Scaling group.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample83' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_432'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_768'>Random</a></p><div class='collapse' id='collapseExample83'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Use Amazon Kinesis Data Streams to ingest the data. Process the data using AWS Lambda functions.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 54%;" aria-valuenow="54" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_432><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 432</p><br/>A company is running a database on Amazon Aurora.<br/><br/>The database is idle every evening. An application that performs extensive reads on the database experiences performance issues during morning thus when user traffic spikes.<br/><br/>During these peak periods, the application receives timeout errors when reading from the database.<br/><br/>The company does not have a dedicated operations team and needs an automated solution to address the performance issues.<br/><br/>Which actions should a solutions architect take to automatically adjust to the increased read load on the database? (Select TWO )<br/><br/>A. Migrate the database to Aurora Serverless.<br/>B. Increase the instance size of the Aurora database<br/>C. Configure Aurora Auto Scaling with Aurora Replicas<br/>D. Migrate the database to an Aurora multi&#8211;master cluster<br/>E. Migrate the database to an Amazon RDS for MySQL Multi&#8211;AZ deployment<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample661' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_433'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_306'>Random</a></p><div class='collapse' id='collapseExample661'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Migrate the database to Aurora Serverless.
<br><b>C. </b>Configure Aurora Auto Scaling with Aurora Replicas</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 54%;" aria-valuenow="54" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_433><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 433</p><br/>A company has created an isolated backup of its environment in another Region. The application is running in warm standby mode and is fronted by an Application Load Balancer (ALB). The current failover process is manual and requires updating a DNS alias record to point to the secondary ALB in another Region. What should a solutions architect do to automate the failover process?<br/><br/>A. Enable an ALB health check<br/>B. Enable an Amazon Route 53 health check.<br/>C. Crate an CNAME record on Amazon Route 53 pointing to the ALB endpoint.<br/>D. Create conditional forwarding rules on Amazon Route 53 pointing to an internal BIND DNS server.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample164' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_434'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_78'>Random</a></p><div class='collapse' id='collapseExample164'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Crate an CNAME record on Amazon Route 53 pointing to the ALB endpoint.

References:

How do I use Route 53 health checks for DNS failover?</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 54%;" aria-valuenow="54" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_434><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 434</p><br/>A solutions architect is planning the deployment of a new static website. The solution must minimize costs and provide at least 99% availability. Which solution meets these requirements?<br/><br/>A. Deploy the application to an Amazon S3 bucket in one AWS Region that has versioning disabled.<br/>B. Deploy the application to Amazon EC2 instances that run in two AWS Regions and two Availability Zones.<br/>C. Deploy the application to an Amazon S3 bucket that has versioning and cross&#8211;Region replication enabled.<br/>D. Deploy the application to an Amazon EC2 instance that runs in one AWS Region and one Availability Zone.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample336' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_435'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_471'>Random</a></p><div class='collapse' id='collapseExample336'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Deploy the application to an Amazon S3 bucket in one AWS Region that has versioning disabled.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 54%;" aria-valuenow="54" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_435><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 435</p><br/>A Solutions Architect is designing the architecture for a web application that will be hosted on AWS. Internet users will access the application using HTTP and HTTPS.<br/><br/>How should the Architect design the traffic control requirements?<br/><br/>A. Use a network ACL to allow outbound ports for HTTP and HTTPS. Deny other traffic for inbound and outbound.<br/>B. Use a network ACL to allow inbound ports for HTTP and HTTPS. Deny other traffic for inbound and outbound.<br/>C. Allow inbound ports for HTTP and HTTPS in the security group used by the web servers.<br/>D. Allow outbound ports for HTTP and HTTPS in the security group used by the web servers.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample736' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_436'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_277'>Random</a></p><div class='collapse' id='collapseExample736'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Allow inbound ports for HTTP and HTTPS in the security group used by the web servers.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 55%;" aria-valuenow="55" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_436><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 436</p><br/>A company runs multiple Amazon EC2 Linux instances in a VPC with applications that use a hierarchical directory structure. The applications need to rapidly and concurrently read and write to shared storage.<br/><br/>How can this be achieved?<br/><br/>A. Create an Amazon EFS file system and mount it from each EC2 instance.<br/>B. Create an Amazon S3 bucket and permit access from all the EC2 instances in the VPC.<br/>C. Create a file system on an Amazon EBS Provisioned IOPS SSD (io1) volume. Attach the volume to all the EC2 instances.<br/>D. Create file systems on Amazon EBS volumes attached to each EC2 instance. Synchronize the Amazon EBS volumes across the different EC2 instances.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample195' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_437'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_252'>Random</a></p><div class='collapse' id='collapseExample195'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Create an Amazon EFS file system and mount it from each EC2 instance.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 55%;" aria-valuenow="55" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_437><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 437</p><br/>A company has NFS servers in an on&#8211;premises data center that need to periodically back up small amounts of data to Amazon S3.<br/><br/>Which solution meets these requirements and is MOST cost&#8211;effective?<br/><br/>A. Set up AWS Glue to copy the data from the on&#8211;premises servers to Amazon S3.<br/>B. Set up an AWS DataSync agent on the on&#8211;premises servers, and sync the data to Amazon S3.<br/>C. Set up an SFTP sync using AWS Transfer for SFTP to sync data from on&#8211;premises to Amazon S3.<br/>D. Set up an AWS Direct Connect connection between the on&#8211;premises data center and a VPC, and copy the data to Amazon S3.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample391' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_438'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_529'>Random</a></p><div class='collapse' id='collapseExample391'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Set up an SFTP sync using AWS Transfer for SFTP to sync data from on-premises to Amazon S3.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 55%;" aria-valuenow="55" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_438><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 438</p><br/>Application developers have noticed that a production application is very slow when business reporting users run large production reports against the Amazon RDS instance backing the application. The CPU and memory utilization metrics for the RDS instance do not exceed 60% while the reporting queries are running.<br/><br/>The business reporting users must be able to generate reports without affecting the application's performance.<br/><br/>Which action will accomplish this?<br/><br/>A. Increase the size of the RDS instance.<br/>B. Create a read replica and connect the application to it.<br/>C. Enable multiple Availability Zones on the RDS instance.<br/>D. Create a read replica and connect the business reports to it.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample171' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_439'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_360'>Random</a></p><div class='collapse' id='collapseExample171'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Create a read replica and connect the business reports to it.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 55%;" aria-valuenow="55" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_439><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 439</p><br/>A company wants to create an application that will transmit protected health information (PHI) to thousands of service consumers in different AWS accounts.<br/><br/>The application servers will sit in private VPC subnets The routing for the application must be fault tolerant.<br/><br/>What should be done to meet these requirements?<br/><br/>A. Create a VPC endpoint service and grant permissions to specific service consumers to create a connection<br/>B. Create a virtual private gateway connection between each pair of service provider VPCs and service consumer VPCs<br/>C. Create an internal Application Load Balancer in the service provider VPC and put application servers behind it.<br/>D. Create a proxy server in the service provider VPC to route requests from service consumers to the application servers.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample622' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_440'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_761'>Random</a></p><div class='collapse' id='collapseExample622'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Create a VPC endpoint service and grant permissions to specific service consumers to create a connection</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 55%;" aria-valuenow="55" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_440><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 440</p><br/>A company is hosting a web application on AWS using a single Amazon EC2 instance that stores user uploaded documents in an Amazon EBS volume. For better scalability and availability, the company duplicated the architecture and created a second EC2 instance and EBS volume in another Availability Zone, placing both behind an Application Load Balancer. After completing this change, users reported that each time they refreshed the website, they could see one subset of their documents or the other, but never all of the documents at the same time.<br/><br/>What should a solutions architect propose to ensure users see all of their documents at once?<br/><br/>A. Copy the data so both EBS volumes contain all the documents.<br/>B. Configure the Application Load Balancer to direct a user to the server with the documents.<br/>C. Copy the data from both EBS volumes to Amazon EFS. Modify the application to save new documents to Amazon EFS.<br/>D. Configure the Application Load Balancer to send the request to both servers. Return each document from the correct server.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample31' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation31' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_441'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_195'>Random</a></p><div class='collapse' id='collapseExample31'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Copy the data from both EBS volumes to Amazon EFS. Modify the application to save new documents to Amazon EFS.</div></div></div><div class='collapse' id='explanation31'><div class='card card&#45;body'><div>
Amazon EFS provides file storage in the AWS Cloud. With Amazon EFS, you can create a file system, mount the file system on an Amazon EC2 instance, and then read and write data to and from your file system. You can mount an Amazon EFS file system in your VPC, through the Network File System versions 4.0 and 4.1 (NFSv4) protocol. We recommend using a current generation Linux NFSv4.1 client, such as those found in the latest Amazon Linux, Redhat, and Ubuntu AMIs, in conjunction with the Amazon EFS Mount Helper. For instructions, see Using the amazon-efs-utils Tools.

For a list of Amazon EC2 Linux Amazon Machine Images (AMIs) that support this protocol, see NFS Support. For some AMIs, you'll need to install an NFS client to mount your file system on your Amazon EC2 instance. For instructions, see Installing the NFS Client.

You can access your Amazon EFS file system concurrently from multiple NFS clients, so applications that scale beyond a single connection can access a file system. Amazon EC2 instances running in multiple Availability Zones within the same AWS Region can access the file system, so that many users can access and share a common data source.

How Amazon EFS Works with Amazon EC2</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 55%;" aria-valuenow="55" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_441><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 441</p><br/>A developer has a script to generate daily reports that users previous. The script consistently complete in under 10 minutes. The developer needs to automate the process in a cost effective manner.<br/><br/>Which combination of services should the developer use? (Select two)<br/><br/>A. AWS Lambda<br/>B. AWS CloudTrail<br/>C. Cron on an Amazon EC2 instance<br/>D. Amazon EC2 On&#8211;Demand instance with user data<br/>E. Amazon EventBridge (Amazon CloudWatch Event)<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample561' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_442'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_426'>Random</a></p><div class='collapse' id='collapseExample561'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>AWS Lambda
<br><b>B. </b>AWS CloudTrail</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 55%;" aria-valuenow="55" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_442><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 442</p><br/>A company wants to host its web application on AWS using multiple Amazon EC2 instances across different AWS Regions. Since the application content will be specific to each geographic region, the client requests need to be routed to the server that hosts the content for that clients Region.<br/><br/>What should a solutions architect do to accomplish this?<br/><br/>A. Configure Amazon Route 53 with a latency routing policy.<br/>B. Configure Amazon Route 53 with a weighted routing policy.<br/>C. Configure Amazon Route 53 with a geolocation routing policy.<br/>D. Configure Amazon Route 53 with a multivalue answer routing policy.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample399' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_443'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_359'>Random</a></p><div class='collapse' id='collapseExample399'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Configure Amazon Route 53 with a geolocation routing policy.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 55%;" aria-valuenow="55" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_443><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 443</p><br/>A company is concerned about the security of its public web application due to recent web attacks. The application uses an Application Load Balancer (ALB). A solutions architect must reduce the risk of DDoS attacks against the application<br/><br/>What should the solutions architect do to meet this requirement?<br/><br/>A. Add an Amazon Inspector agent to the ALB<br/>B. Configure Amazon Made to prevent attacks.<br/>C. Enable AWS Shield Advanced to prevent attacks.<br/>D. Configure Amazon GuardDuty to monitor the ALB<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample451' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_444'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_445'>Random</a></p><div class='collapse' id='collapseExample451'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Enable AWS Shield Advanced to prevent attacks.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 56%;" aria-valuenow="56" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_444><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 444</p><br/>A solution architect needs to design a highly available application consisting of web, application, and database tiers. HTTPS content delivery should be as close to the edge as possible, with the least delivery time.<br/><br/>Which solution meets these requirements and is MOST secure?<br/><br/>A. Configure a public Application Load Balancer (ALB) with multiple redundant Amazon EC2 instances in public subnets. Configure Amazon CloudFront to deliver HTTPS content using the public ALB as the origin.<br/>B. Amazon EC2 instances in private subnets Configure. Configure a public Application Load Balancer with multiple redundant Amazon CloudFront to deliver HTTPS content using the EC2 instances as the origin.<br/>C. Configure a public Application Load Balancer (ALB) with multiple redundant Amazon EC2 instances in private subnets. Configure Amazon CloudFront to deliver HTTPS content using the public ALB as the origin.<br/>D. Configure a public Application Load Balancer with multiple redundant Amazon EC2 instances in public subnets. Configure Amazon CloudFront to deliver HTTPS content using the EC2 instances as the origin.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample314' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_445'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_370'>Random</a></p><div class='collapse' id='collapseExample314'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Amazon EC2 instances in private subnets Configure. Configure a public Application Load Balancer with multiple redundant Amazon CloudFront to deliver HTTPS content using the EC2 instances as the origin.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 56%;" aria-valuenow="56" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_445><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 445</p><br/>A database is on an Amazon RDS MySQL 5.6 Multi&#8211;AZ DB instance that experiences highly dynamic reads.<br/><br/>Application developers notice a significant slowdown when testing read performance from a secondary AWS Region. The developers want a solution that provides less than 1 second of read replication latency.<br/><br/>What should the solutions architect recommend?<br/><br/>A. Install MySQL on Amazon EC2 in the secondary Region.<br/>B. Migrate the database to Amazon Aurora with cross&#8211;Region replicas.<br/>C. Create another RDS for MySQL read replica in the secondary Region.<br/>D. Implement Amazon ElastiCache to improve database query performance.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample175' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_446'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_107'>Random</a></p><div class='collapse' id='collapseExample175'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Migrate the database to Amazon Aurora with cross-Region replicas.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 56%;" aria-valuenow="56" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_446><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 446</p><br/>A company is using Amazon Route 53 latency&#8211;based routing to route requests to its UDP&#8211;based application for users around the world. The application is hosted on redundant servers in the company's on&#8211;premises data centers in the United States, Asia, and Europe. The company's compliance requirements state that the application must be hosted on&#8211;premises. The company wants to improve the performance and availability of the application.<br/><br/>What should a solutions architect do to meet these requirements?<br/><br/>A. Configure three Network Load Balancers (NLBs) in the three AWS Regions to address the on&#8211;premises endpoints. Create an accelerator by using AWS Global Accelerator, and register the NLBs as its endpoints. Provide access to the application by using a CNAME that points to the accelerator DNS.<br/>B. Configure three Application Load Balancers (ALBs) in the three AWS Regions to address the on&#8211;premises endpoints. Create an accelerator by using AWS Global Accelerator, and register the ALBs as its endpoints. Provide access to the application by using a CNAME that points to the accelerator DNS.<br/>C. Configure three Network Load Balancers (NLBs) in the three AWS Regions to address the on&#8211;premises endpoints. In Route 53, create a latency&#8211;based record that points to the three NLBs, and use it as an origin for an Amazon CloudFront distribution. Provide access to the application by using a CNAME that points to the CloudFront DNS.<br/>D. Configure three Application Load Balancers (ALBs) in the three AWS Regions to address the on&#8211;premises endpoints. In Route 53, create a latency&#8211;based record that points to the three ALBs, and use it as an origin for an Amazon CloudFront distribution. Provide access to the application by using a CNAME that points to the CloudFront DNS.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample309' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_447'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_523'>Random</a></p><div class='collapse' id='collapseExample309'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Configure three Network Load Balancers (NLBs) in the three AWS Regions to address the on-premises endpoints. In Route 53, create a latency-based record that points to the three NLBs, and use it as an origin for an Amazon CloudFront distribution. Provide access to the application by using a CNAME that points to the CloudFront DNS.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 56%;" aria-valuenow="56" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_447><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 447</p><br/>A company is designing a cloud communications platform trial is driven by APIs.<br/><br/>The application is hosted on Amazon EC2 instances behind a Network Load Balancer (NLB).<br/><br/>The company uses Amazon API Gateway to provide external users with access to the application through APIs. The company wants to protect the platform against web exploits like SQL Injection and also wants to detect and mitigate large, sophisticated DDoS attacks.<br/><br/>Which combination of solutions provides the MOST protection? (Select TWO.)<br/><br/>A. Use AWS WAF to protect the NLB<br/>B. Use AWS Shield Advanced with the NLB<br/>C. Use AWS WAF to protect Amazon API Gateway<br/>D. Use Amazon GuardDuty with AWS Shield Standard<br/>E. Use AWS Shield Standard with Amazon API Gateway<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample564' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_448'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_327'>Random</a></p><div class='collapse' id='collapseExample564'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Use AWS WAF to protect the NLB
<br><b>D. </b>Use Amazon GuardDuty with AWS Shield Standard</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 56%;" aria-valuenow="56" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_448><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 448</p><br/>A company must generate sales reports at the beginning of every month. The reporting process launches 20 Amazon EC2 instances on the first of the month. The process runs for 7 days and cannot be interrupted.<br/><br/>The company wants to minimize costs.<br/><br/>Which pricing model should the company choose?<br/><br/>A. Reserved Instances<br/>B. Spot Block Instances<br/>C. On&#8211;Demand Instances<br/>D. Scheduled Reserved Instances<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample18' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation18' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_449'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_45'>Random</a></p><div class='collapse' id='collapseExample18'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Scheduled Reserved Instances</div></div></div><div class='collapse' id='explanation18'><div class='card card&#45;body'><div>
Scheduled Reserved Instances: Scheduled Reserved Instances (Scheduled Instances) enable you to purchase capacity reservations that recur on a daily, weekly, or monthly basis, with a specified start time and duration, for a one-year term. You reserve the capacity in advance, so that you know it is available when you need it. You pay for the time that the instances are scheduled, even if you do not use them.

Scheduled Instances are a good choice for workloads that do not run continuously, but do run on a regular schedule. For example, you can use Scheduled Instances for an application that runs during business hours or for batch processing that runs at the end of the week.

If you require a capacity reservation on a continuous basis, Reserved Instances might meet your needs and decrease costs.

How Scheduled Instances Work

Amazon EC2 sets aside pools of EC2 instances in each Availability Zone for use as Scheduled Instances.

Each pool supports a specific combination of instance type, operating system, and network.

To get started, you must search for an available schedule. You can search across multiple pools or a single pool. After you locate a suitable schedule, purchase it.

You must launch your Scheduled Instances during their scheduled time periods, using a launch configuration that matches the following attributes of the schedule that you purchased: instance type, Availability Zone, network, and platform. When you do so, Amazon EC2 launches EC2 instances on your behalf, based on the specified launch specification. Amazon EC2 must ensure that the EC2 instances have terminated by the end of the current scheduled time period so that the capacity is available for any other Scheduled Instances it is reserved for. Therefore, Amazon EC2 terminates the EC2 instances three minutes before the end of the current scheduled time period.

You can't stop or reboot Scheduled Instances, but you can terminate them manually as needed. If you terminate a Scheduled Instance before its current scheduled time period ends, you can launch it again after a few minutes. Otherwise, you must wait until the next scheduled time period.

The following diagram illustrates the lifecycle of a Scheduled Instance.


References:

Amazon Elastic Compute Cloud > User Guide for Linux Instances > Scheduled Reserved Instances</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 56%;" aria-valuenow="56" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_449><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 449</p><br/>A company is designing a web application using AWS that processes insurance quotes. Users will request quotes from the application. Quotes must be separated by quote type must be responded to within 24 hours, and must not be lost. The solution should be simple to set up and maintain.<br/><br/>Which solution meets these requirements?<br/><br/>A. Create multiple Amazon Kinesis data streams based on the quote type. Configure the web application to send messages to the proper data stream. Configure each backend group of application servers to pool messages from its own data stream using the Kinesis Client Library (KCL).<br/>B. Create multiple Amazon Simple Notification Service (Amazon SNS) topics and register Amazon SQS queues to their own SNS topic based on the quote type. Configure the web application to publish messages to the SNS topic queue. Configure each backend application server to work its own SQS queue.<br/>C. Create a single Amazon Simple Notification Service (Amazon SNS) topic and subscribe the Amazon SQS queues to the SNS topic. Configure SNS message filtering to publish messages to the proper SQS queue based on the quote type. Configure each backend application server to work its own SQS queue.<br/>D. Create multiple Amazon Kinesis Data Firehose delivery streams based on the quote type to deliver data streams to an Amazon Elasticsearch Service (Amazon ES) cluster. Configure the web application to send messages to the proper delivery stream. Configure each backend group of application servers to search for the messages from Amazon ES and process them accordingly.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample207' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation207' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_450'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_606'>Random</a></p><div class='collapse' id='collapseExample207'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Create a single Amazon Simple Notification Service (Amazon SNS) topic and subscribe the Amazon SQS queues to the SNS topic. Configure SNS message filtering to publish messages to the proper SQS queue based on the quote type. Configure each backend application server to work its own SQS queue.</div></div></div><div class='collapse' id='explanation207'><div class='card card&#45;body'><div>
It all depends on where you want to do the quote type classification i.e. in the app and send to a different/multiple SNS topics (B) or use SNS filtering to do the type classification (C). The question doesn't really give you enough info to make a clear choice but configuring SNS filtering is probably less work and easier to maintain than maintaining app code.

References:
Amazon Simple Notification Service > Developer Guide > Amazon SNS message filtering
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 56%;" aria-valuenow="56" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_450><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 450</p><br/>What should a solutions architect do to ensure that all objects uploaded to an Amazon S3 bucket are encrypted?<br/><br/>A. Update the bucket policy to deny if the PutObject does not have an s3:x&#8211;amz&#8211;acl header set.<br/>B. Update the bucket policy to deny if the PutObject does not have an s3:x&#8211;amz&#8211;acl header set to private.<br/>C. Update the bucket policy to deny if the PutObject does not have an aws:SecureTransport header set to true.<br/>D. Update the bucket policy to deny if the PutObject does not have an x&#8211;amz&#8211;server&#8211;side&#8211;encryption header set.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample141' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_451'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_68'>Random</a></p><div class='collapse' id='collapseExample141'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Update the bucket policy to deny if the PutObject does not have an x-amz-server-side-encryption header set.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 56%;" aria-valuenow="56" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_451><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 451</p><br/>A company has a three&#8211;tier environment on AWS that ingests sensor data from its users' devices. The traffic flows through a Network Load Balancer (NLB) then to Amazon EC2 instances for the web tier, and finally toEC2 instances for the application tier that makes database calls.<br/><br/><br/><br/>What should a solutions architect do to improve the security of data in transit to the web tier?<br/><br/>A. Configure a TLS listener and add the server certificate on the NLB.<br/>B. Configure AWS Shield Advanced and enable AWS WAF on the NLB.<br/>C. Change the load balancer to an Application Load Balancer and attach AWS WAF to it.<br/>D. Encrypt the Amazon Elastic Block Store (Amazon EBS) volume on the EC2 instances using AWS Key Management Service (AWS KMS).<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample352' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation352' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_452'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_158'>Random</a></p><div class='collapse' id='collapseExample352'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Configure a TLS listener and add the server certificate on the NLB.</div></div></div><div class='collapse' id='explanation352'><div class='card card&#45;body'><div>
User – NLB – EC2 (Web) + DB
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 57%;" aria-valuenow="57" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_452><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 452</p><br/>A company designs a mobile app for its customers to upload photos to a website. The app needs a secure login with multi&#8211;factor authentication (MFA).<br/><br/>The company wants to limit the initial build time and the maintenance of the solution.<br/><br/>Which solution should a solutions architect recommend to meet these requirements?<br/><br/>A. Use Amazon Cognito Identity with SMS based MFA.<br/>B. Edit 1AM policies to require MFA for all users<br/>C. Federate 1AM against the corporate Active Directory that requires MFA<br/>D. Use Amazon API Gateway and require server&#8211;side encryption (SSE) for photos<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample653' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_453'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_7'>Random</a></p><div class='collapse' id='collapseExample653'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Use Amazon Cognito Identity with SMS based MFA.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 57%;" aria-valuenow="57" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_453><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 453</p><br/>A company uses Amazon S3 to store its confidential audit documents.<br/><br/>The S3 bucket uses bucket policies to restrict access to audit team 1AM user credentials according to the principle of least privilege.<br/><br/>Company managers are worried about accidental deletion of documents in the S3 bucket and want a more secure solution.<br/><br/>What should a solutions architect do to secure the audit documents?<br/><br/>A. Enable the versioning and MFA Delete features on the S3 bucket<br/>B. Enable multi&#8211;factor authentication (MFA) on the 1AM user credentials for each audit team 1AM user account.<br/>C. Add an S3 Lifecycle policy to the audit team's 1AM user accounts to deny the s3:DeleteOb|ect action during audit dates.<br/>D. Use AWS Key Management Service (AWS KMS) to encrypt the S3 bucket and restrict audit team 1AM user accounts from accessing the KMS key.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample679' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_454'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_435'>Random</a></p><div class='collapse' id='collapseExample679'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Enable the versioning and MFA Delete features on the S3 bucket</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 57%;" aria-valuenow="57" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_454><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 454</p><br/>A company processes large amounts of data. The output data is stored in Amazon S3 Standard storage in an S3 bucket, where it is analyzed for 1 month. The data must remain immediately accessible after the 1&#8211;month analysis period.<br/><br/>Which storage solution meets these requirements MOST cost&#8211;effectively?<br/><br/>A. Configure an S3 Lifecycle policy to transition the objects to S3 Glacier after 30 days.<br/>B. Configure S3 Intelligent&#8211;Tiering to transition the objects to S3 Glacier after 30 days.<br/>C. Configure an S3 Lifecycle policy to transition the objects to S3 One Zone&#8211;Infrequent Access (S3 One Zone&#8211;IA) after 30 days.<br/>D. Configure an S3 Lifecycle policy to delete the objects after 30 days. Enable versioning on the S3 bucket so that deleted objects can still be immediately restored as needed.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample442' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_455'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_92'>Random</a></p><div class='collapse' id='collapseExample442'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Configure S3 Intelligent-Tiering to transition the objects to S3 Glacier after 30 days.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 57%;" aria-valuenow="57" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_455><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 455</p><br/>A company recently deployed a new auditing system to centralize information about operating system versions, patching, and installed software for Amazon EC2 instances. A solutions architect must ensure all instances provisioned through EC2 Auto Scaling groups successfully send reports to the auditing system as soon as they are launched and terminated.<br/><br/>Which solution achieves these goals MOST efficiently?<br/><br/>A. Use a scheduled AWS Lambda function and execute a script remotely on all EC2 instances to send data to the audit system.<br/>B. Use EC2 Auto Scaling lifecycle hooks to execute a custom script to send data to the audit system when instances are launched and terminated.<br/>C. Use an EC2 Auto Scaling launch configuration to execute a custom script through user data to send data to the audit system when instances are launched and terminated.<br/>D. Execute a custom script on the instance operating system to send data to the audit system. Configure the script to be executed by the EC2 Auto Scaling group when the instance starts and is terminated.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample50' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_456'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_751'>Random</a></p><div class='collapse' id='collapseExample50'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Use EC2 Auto Scaling lifecycle hooks to execute a custom script to send data to the audit system when instances are launched and terminated.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 57%;" aria-valuenow="57" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_456><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 456</p><br/>A solutions architect is optimizing a website for an upcoming musical event Videos of the performances will be streamed in real&#8211;time and then will be available on demand. The event is expected to attract a global online audience<br/><br/>Which service will improve the performance of both real&#8211;time and on&#8211;demand streaming?<br/><br/>A. Amazon CloudFront<br/>B. AWS Global Accelerator<br/>C. Amazon Route 53<br/>D. Amazon S3 Transfer Acceleration<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample458' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation458' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_457'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_124'>Random</a></p><div class='collapse' id='collapseExample458'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Amazon CloudFront</div></div></div><div class='collapse' id='explanation458'><div class='card card&#45;body'><div>
Amazon CloudFront can be used to stream video to users across the globe using a wide variety of protocols that are layered on top of HTTP. This can include both on-demand video as well as real-time streaming video.

CORRECT: "Amazon CloudFront" is the correct answer.

INCORRECT: "AWS Global Accelerator" is incorrect as this would be an expensive way of getting the content closer to users compared to using CloudFront. As this is a use case for CloudFront and there are so many edge locations it is the better option.

INCORRECT: "Amazon Route 53" is incorrect as you still need a solution for getting the content closer to users.

INCORRECT: "Amazon S3 Transfer Acceleration" is incorrect as this is used to accelerate uploads of data to Amazon S3 buckets.

References:

Amazon CloudFront media streaming tutorials
Amazon CloudFront > Developer Guide > Video on Demand and Live Streaming Video with CloudFront</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 57%;" aria-valuenow="57" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_457><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 457</p><br/>A company has an Amazon EC2 instance running on a private subnet that needs to access a public website to download patches and updates.<br/><br/>The company does not want external websites to see the EC2 instance IP address or initiate connections to it.<br/><br/>How can a solutions architect achieve this objective?<br/><br/>A. Create a site&#8211;to&#8211;site VPN connection between the private subnet and the network in which the public site is deployed.<br/>B. Create a NAT gateway in a public subnet. Route outbound traffic from the private subnet through the NAT gateway.<br/>C. Create a network ACL for the private subnet where the EC2 instance deployed only allows access from the IP address range of the public website.<br/>D. Create a security group that only allows connections from the IP address range of the public website. Attach the security group to the EC2 instance.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample59' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_458'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_441'>Random</a></p><div class='collapse' id='collapseExample59'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Create a NAT gateway in a public subnet. Route outbound traffic from the private subnet through the NAT gateway.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 57%;" aria-valuenow="57" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_458><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 458</p><br/>A company has an AWS Direct Connect connection from its corporate data center to its VPC in the us&#8211;east&#8211;1 Region.<br/><br/>The company recently acquired a corporation that has several VPCs and a Direct Connect connection between its on&#8211;premises data center and the eu&#8211;west&#8211;2 Region.<br/><br/>The CIDR blocks for the VPCs of the company and the corporation do not overlap. The company requires connectivity between two Regions and the data centers.<br/><br/>The company needs a solution that is scalable while reducing operational overhead. What should a solutions architect do to meet these requirements?<br/><br/>A. Set up inter&#8211;Region VPC peering between the VPC m us&#8211;east&#8211;1 and the VPCs in eu&#8211;west&#8211;2<br/>B. Create private virtual interfaces from the Direct Connect connection in us&#8211;east&#8211;1 to the VPCs in eu&#8211;west&#8211;2<br/>C. Establish VPN appliances in a fully meshed VPN network hosted by Amazon EC2 Use AWS VPN CloudHub to send and receive data between the data centers and each VPC<br/>D. Connect the existing Direct Connect connection to a Direct Connect gateway Route traffic from the virtual private gateways of the VPCs in each Region to the Direct Connect gateway<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample519' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_459'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_192'>Random</a></p><div class='collapse' id='collapseExample519'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Connect the existing Direct Connect connection to a Direct Connect gateway Route traffic from the virtual private gateways of the VPCs in each Region to the Direct Connect gateway</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 57%;" aria-valuenow="57" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_459><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 459</p><br/>A financial company operates its production AWS environment in the us&#8211;east&#8211;1 Region and uses Amazon Elastic Block Store (Amazon EBS) snapshots to back up its instances.<br/><br/>To meet a compliance requirement, the company must maintain a secondary copy of all critical data at least 100 miles (160.9 km) away from its primary location.<br/><br/>What is the MOST cost&#8211;effective way for the company to meet this requirement?<br/><br/>A. Replicate the EBS snapshots to a different Availability Zone in us&#8211;east&#8211;1.<br/>B. Replicate the EBS snapshots to us&#8211;east&#8211;2.<br/>C. Replicate the EBS snapshots to us&#8211;west&#8211;1.<br/>D. Replicate the EBS snapshots to us&#8211;west&#8211;2<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample645' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_460'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_352'>Random</a></p><div class='collapse' id='collapseExample645'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Replicate the EBS snapshots to us-west-1.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 58%;" aria-valuenow="58" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_460><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 460</p><br/>Organizers for a global event want to put daily reports online as static HTML pages. The pages are expected to generate millions of views from users around the world. The files are stored in an Amazon S3 bucket. A solutions architect has been asked to design an efficient and effective solution.<br/><br/>Which action should the solutions architect take to accomplish this?<br/><br/>A. Generate presigned URLs for the files.<br/>B. Use cross&#8211;Region replication to all Regions.<br/>C. Use the geoproximity feature of Amazon Route 53.<br/>D. Use Amazon CloudFront with the S3 bucket as its origin.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample10' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation10' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_461'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_110'>Random</a></p><div class='collapse' id='collapseExample10'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Use Amazon CloudFront with the S3 bucket as its origin.</div></div></div><div class='collapse' id='explanation10'><div class='card card&#45;body'><div>
Using Amazon S3 Origins, MediaPackage Channels, and Custom Origins for Web Distributions

Using Amazon S3 Buckets for Your Origin
When you use Amazon S3 as an origin for your distribution, you place any objects that you want CloudFront to deliver in an Amazon S3 bucket. You can use any method that is supported by Amazon S3 to get your objects into Amazon S3, for example, the Amazon S3 console or API, or a third-party tool. You can create a hierarchy in your bucket to store the objects, just as you would with any other Amazon S3 bucket.

Using an existing Amazon S3 bucket as your CloudFront origin server doesn't change the bucket in any way; you can still use it as you normally would to store and access Amazon S3 objects at the standard Amazon S3 price. You incur regular Amazon S3 charges for storing the objects in the bucket.

Using Amazon S3 Buckets Configured as Website Endpoints for Your Origin
You can set up an Amazon S3 bucket that is configured as a website endpoint as custom origin with CloudFront.

When you configure your CloudFront distribution, for the origin, enter the Amazon S3 static website hosting endpoint for your bucket. This value appears in the Amazon S3 console, on the Properties tab, in the Static website hosting pane. For example: http://bucket-name.s3-website-region.amazonaws.com

For more information about specifying Amazon S3 static website endpoints, see Website endpoints in the Amazon Simple Storage Service Developer Guide.

When you specify the bucket name in this format as your origin, you can use Amazon S3 redirects and Amazon S3 custom error documents. For more information about Amazon S3 features, see the Amazon S3 documentation.

Using an Amazon S3 bucket as your CloudFront origin server doesn't change it in any way. You can still use it as you normally would and you incur regular Amazon S3 charges.

Amazon CloudFront can be used to cache the files in edge locations around the world and this will improve the performance of the webpages.

To serve a static website hosted on Amazon S3, you can deploy a CloudFront distribution using one of these configurations:

Using a REST API endpoint as the origin with access restricted by an origin access identity (OAI) Using a website endpoint as the origin with anonymous (public) access allowed

Using a website endpoint as the origin with access restricted by a Referer header CORRECT: "Use Amazon CloudFront with the S3 bucket as its origin" is the correct answer.

INCORRECT: "Generate presigned URLs for the files" is incorrect as this is used to restrict access which is not a requirement.

INCORRECT: "Use cross-Region replication to all Regions" is incorrect as this does not provide a mechanism for directing users to the closest copy of the static webpages.

INCORRECT: "Use the geoproximity feature of Amazon Route 53" is incorrect as this does not include a solution for having multiple copies of the data in different geographic locations.

References:

How do I use CloudFront to serve a static website hosted on Amazon S3?</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 58%;" aria-valuenow="58" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_461><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 461</p><br/>A city has deployed a web application running on AmazonEC2 instances behind an Application Load Balancer (ALB).<br/><br/>The Application's users have reported sporadic performance, which appears to be related to DDoS attacks originating from random IP addresses.<br/><br/>The City needs a solution that requires minimal configuration changes and provides an audit trail for the DDoS source.<br/><br/>Which solution meets these requirements?<br/><br/>A. Enable an AWS WAF web ACL on the ALB and configure rules to block traffic from unknown sources.<br/>B. Subscribe to Amazon inspector. Engage the AWS DDoS Resource Team (DRT) to integrate migrating controls into the service.<br/>C. Subscribe to AWS shield advanced. Engage the AWS DDoS Response Team (DRT) to integrate migrating controls into the service.<br/>D. Create an Amazon CloudFront distribution for the application and set the ALB as the origin. Enable an AWS WAF web ACL on the distribution and configure rules to block traffic from unknown sources.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample541' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_462'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_2'>Random</a></p><div class='collapse' id='collapseExample541'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Subscribe to AWS shield advanced. Engage the AWS DDoS Response Team (DRT) to integrate migrating controls into the service.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 58%;" aria-valuenow="58" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_462><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 462</p><br/>A user is designing a new service that receives location updates from 3 600 rental cars every hour.<br/><br/>The cars upload their location to an Amazon S3 bucket.<br/><br/>Each location must be checked for distance from the original rental location.<br/><br/>Which services will process the updates and automatically scale?<br/><br/>A. Amazon EC2 and Amazon Elastic Block Store (Amazon EBS)<br/>B. Amazon Kinesis Data Firehose and Amazon S3<br/>C. Amazon Elastic Container Service (Amazon ECS) and Amazon RDS<br/>D. Amazon S3 events and AWS Lambda<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample631' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_463'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_785'>Random</a></p><div class='collapse' id='collapseExample631'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Amazon Kinesis Data Firehose and Amazon S3</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 58%;" aria-valuenow="58" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_463><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 463</p><br/>After you recommend Amazon Redshift to a client as an alternative solution to paying data warehouses to analyze his data, your client asks you to explain why you are recommending Redshift.<br/><br/>Which of the following would be a reasonable response to his request?<br/><br/>A. It has high performance at scale as data and query complexity grows.<br/>B. It prevents reporting and analytic processing from interfering with the performance of OLTP workloads.<br/>C. You don't have the administrative burden of running your own data warehouse and dealing with setup, durability, monitoring, scaling, and patching.<br/>D. All answers listed are a reasonable response to his question<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample778' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation778' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_464'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_628'>Random</a></p><div class='collapse' id='collapseExample778'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>All answers listed are a reasonable response to his question</div></div></div><div class='collapse' id='explanation778'><div class='card card&#45;body'><div>
Amazon Redshift delivers fast query performance by using columnar storage technology to improve I/O efficiency and parallelizing queries across multiple nodes. Redshift uses standard PostgreSQL JDBC and ODBC drivers, allowing you to use a wide range of familiar SQL clients. Data load speed scales linearly with cluster size, with integrations to Amazon S3, Amazon DynamoDB, Amazon Elastic MapReduce, Amazon Kinesis or any SSH-enabled host. AWS recommends Amazon Redshift for customers who have a combination of needs, such as:

High performance at scale as data and query complexity grows Desire to prevent reporting and analytic processing from interfering with the performance of OLTP workloads Large volumes of structured data to persist and query using standard SQL and existing BI tools Desire to the administrative burden of running one's own data warehouse and dealing with setup, durability, monitoring, scaling and patching.

References:

AWS Cloud Databases</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 58%;" aria-valuenow="58" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_464><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 464</p><br/>A company has a 143 TB MySQL database that it wants to migrate to AWS. The plan is to use Amazon Aurora MySQL as the platform going forward. The company has a 100 Mbps AWS Direct Connect connection to Amazon VPC.<br/><br/>Which solution meets the company's needs and takes the LEAST amount of time?<br/><br/>A. Use a gateway endpoint for Amazon S3. Migrate the data to Amazon S3. Import the data into Aurora.<br/>B. Upgrade the Direct Connect link to 500 Mbps. Copy the data to Amazon S3. Import the data into Aurora.<br/>C. Order an AWS Snowmobile and copy the database backup to it. Have AWS import the data into Amazon S3. Import the backup into Aurora.<br/>D. Order four 50&#8211;TB AWS Snowball devices and copy the database backup onto them. Have AWS import the data into Amazon S3. Import the data into Aurora.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample130' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_465'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_322'>Random</a></p><div class='collapse' id='collapseExample130'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Order four 50-TB AWS Snowball devices and copy the database backup onto them. Have AWS import the data into Amazon S3. Import the data into Aurora.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 58%;" aria-valuenow="58" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_465><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 465</p><br/>A company's legacy application is currently relying on a single&#8211;instance Amazon RDS MySQL database without encryption. Due to new compliance requirements, all existing and new data in this database must be encrypted.<br/><br/>How should this be accomplished?<br/><br/>A. Create an Amazon S3 bucket with server&#8211;side encryption enabled. Move all the data to Amazon S3. Delete the RDS instance.<br/>B. Enable RDS Multi&#8211;AZ mode with encryption at rest enabled. Perform a failover to the standby instance to delete the original instance.<br/>C. Take a Snapshot of the RDS instance. Create an encrypted copy of the snapshot. Restore the RDS instance from the encrypted snapshot.<br/>D. Create an RDS read replica with encryption at rest enabled. Promote the read replica to master and switch the over to the new master. Delete the old RDS instance.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample182' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation182' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_466'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_576'>Random</a></p><div class='collapse' id='collapseExample182'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Take a Snapshot of the RDS instance. Create an encrypted copy of the snapshot. Restore the RDS instance from the encrypted snapshot.</div></div></div><div class='collapse' id='explanation182'><div class='card card&#45;body'><div>
How do I encrypt Amazon RDS snapshots?
The following steps are applicable to Amazon RDS for MySQL, Oracle, SQL Server, PostgreSQL, or MariaDB.

Important: If you use Amazon Aurora, you can restore an unencrypted Aurora DB cluster snapshot to an encrypted Aurora DB cluster if you specify an AWS Key Management Service (AWS KMS) encryption key when you restore from the unencrypted DB cluster snapshot. For more information, see Limitations of Amazon RDS Encrypted DB Instances.

Open the Amazon RDS console, and then choose Snapshots from the navigation pane.

Select the snapshot that you want to encrypt.

Under Snapshot Actions, choose Copy Snapshot.

Choose your Destination Region, and then enter your New DB Snapshot Identifier.

Change Enable Encryption to Yes.

Select your Master Key from the list, and then choose Copy Snapshot.

After the snapshot status is available, the Encrypted field will be True to indicate that the snapshot is encrypted.

You now have an encrypted snapshot of your DB. You can use this encrypted DB snapshot to restore the DB instance from the DB snapshot.
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 58%;" aria-valuenow="58" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_466><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 466</p><br/>A company wants to run a hybrid workload for data processing. The data needs to be accessed by on&#8211;premises applications for local data processing using an NFS protocol, and must also be accessible from the AWS Cloud for further analytics and batch processing.<br/><br/>Which solution will meet these requirements?<br/><br/>A. Use an AWS Storage Gateway file gateway to provide file storage to AWS, then perform analytics on this data in the AWS Cloud.<br/>B. Use an AWS storage Gateway tape gateway to copy the backup of the local data to AWS, then perform analytics on this data in the AWS cloud.<br/>C. Use an AWS Storage Gateway volume gateway in a stored volume configuration to regularly take snapshots of the local data, then copy the data to AWS.<br/>D. Use an AWS Storage Gateway volume gateway in a cached volume configuration to back up all the local storage in the AWS cloud, then perform analytics on this data in the cloud.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample161' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_467'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_557'>Random</a></p><div class='collapse' id='collapseExample161'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Use an AWS Storage Gateway file gateway to provide file storage to AWS, then perform analytics on this data in the AWS Cloud.

References:

AWS Storage Gateway</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 58%;" aria-valuenow="58" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_467><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 467</p><br/>A company is planning to migrate a legacy application to AWS. The application currently uses NFS to communicate to an on&#8211;premises storage solution to store application data. The application cannot be modified to use any other communication protocols other than NFS for this purpose.<br/><br/>Which storage solution should a solutions architect recommend for use after the migrations?<br/><br/>A. AWS DataSync<br/>B. Amazon Elastic Block Store (Amazon EBS)<br/>C. Amazon Elastic File System (Amazon EFS)<br/>D. Amazon EMR File System (Amazon EMRFS)<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample705' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_468'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_342'>Random</a></p><div class='collapse' id='collapseExample705'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Amazon Elastic File System (Amazon EFS)

References:

Amazon Elastic File System</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 59%;" aria-valuenow="59" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_468><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 468</p><br/>A company uses a legacy on&#8211;premises analytics application that operates on gigabytes of .csv files and represents months of data. The legacy application cannot handle the growing size of .csv files. New .csv files are added daily from various data sources to a central on&#8211;premises storage location. The company wants to continue to support the legacy application while users learn AWS analytics services. To achieve this, a solutions architect wants to maintain two synchronized copies of all the .csv files on&#8211;premises and in Amazon S3.<br/><br/>Which solution should the solutions architect recommend?<br/><br/>A. Deploy AWS DataSync on&#8211;premises. Configure DataSync to continuously replicate the .csv files between the company's on&#8211;premises storage and the company's S3 bucket.<br/>B. Deploy an on&#8211;premises file gateway. Configure data sources to write the .csv files to the file gateway. Point the legacy analytics application to the file gateway. The file gateway should replicate the .csv files to Amazon S3.<br/>C. Deploy an on&#8211;premises volume gateway. Configure data sources to write the .csv files to the volume gateway. Point the legacy analytics application to the volume gateway. The volume gateway should replicate data to Amazon S3.<br/>D. Deploy AWS DataSync on&#8211;premises. Configure DataSync to continuously replicate the .csv files between on&#8211;premises and Amazon Elastic File System (Amazon EFS). Enable replication from Amazon EFS to the company's S3 bucket.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample274' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_469'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_292'>Random</a></p><div class='collapse' id='collapseExample274'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Deploy an on-premises file gateway. Configure data sources to write the .csv files to the file gateway. Point the legacy analytics application to the file gateway. The file gateway should replicate the .csv files to Amazon S3.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 59%;" aria-valuenow="59" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_469><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 469</p><br/>A company needs to comply with a regulatory requirement that states all emails must be stored and archived externally for 7 years. An administrator has created compressed email files on premises and wants a managed service to transfer the files to AWS storage.<br/><br/>Which managed service should a solutions architect recommend?<br/><br/>A. Amazon Elastic File System (Amazon EFS)<br/>B. Amazon S3 Glacier<br/>C. AWS Backup<br/>D. AWS Storage Gateway<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample233' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_470'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_526'>Random</a></p><div class='collapse' id='collapseExample233'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>AWS Storage Gateway</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 59%;" aria-valuenow="59" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_470><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 470</p><br/>Do Amazon EBS volumes persist independently from the running life of an Amazon EC2 instance?<br/><br/>A. Yes, they do but only if they are detached from the instance.<br/>B. No, you cannot attach EBS volumes to an instance.<br/>C. No, they are dependent.<br/>D. Yes, they do.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample767' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation767' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_471'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_679'>Random</a></p><div class='collapse' id='collapseExample767'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Yes, they do.</div></div></div><div class='collapse' id='explanation767'><div class='card card&#45;body'><div>
An Amazon EBS volume behaves like a raw, unformatted, external block device that you can attach to a single instance. The volume persists independently from the running life of an Amazon EC2 instance.

References:

Amazon Elastic Compute Cloud > User Guide for Linux Instances > Storage</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 59%;" aria-valuenow="59" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_471><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 471</p><br/>A company wants to build an online marketplace application on AWS as a set of loosely coupled microservices For this application, when a customer submits a new order two microservices should handle the event simultaneously. The Email microservice will send a confirmation email and the order processing microservice will start the order delivery process If a customer cancels an order, the order cancellation and Email microservices should handle the event simultaneously.<br/><br/>A solutions architect wants to use Amazon Simple Queue Service (Amazon SQS) and Amazon Simple Notification Service (Amazon SNS) to design the messaging between the microservices.<br/><br/>How should the solutions architect design the solution?<br/><br/>A. Create a single SOS queue and publish order events to it. The Email, OrderProcessing and OrderCancellation microservices can then consume messages off the queue<br/>B. Create three SNS topics for each microservice Publish order events to the three topics Subscribe each of the Email OrderProcessmg, and OrderCancellation microservices to its own topic<br/>C. Create an SNS topic and publish order events to it Create three SQS queues for the Email OrderProcessing and OrderCancellation microservices Subscribe all SQS queues to the SNS topic with message filtering<br/>D. Create two SQS queues and publish order events to both queues simultaneously One queue is for the Email and OrderProcessmg microservices. The second queue is for the Email and Order Cancellation microservices<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample459' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_472'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_640'>Random</a></p><div class='collapse' id='collapseExample459'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Create an SNS topic and publish order events to it Create three SQS queues for the Email OrderProcessing and OrderCancellation microservices Subscribe all SQS queues to the SNS topic with message filtering</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 59%;" aria-valuenow="59" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_472><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 472</p><br/>A business application is hosted on Amazon EC2 and uses Amazon S3 for encrypted object storage. The chief information security officer has directed that no application traffic between the two services should traverse the public internet.<br/><br/>Which capability should the solutions architect use to meet the compliance requirements?<br/><br/>A. AWS Key Management Service (AWS KMS)<br/>B. VPC endpoint<br/>C. Private subnet<br/>D. Virtual private gateway<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample247' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_473'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_320'>Random</a></p><div class='collapse' id='collapseExample247'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>AWS Key Management Service (AWS KMS)

References:

Amazon VPC FAQs</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 59%;" aria-valuenow="59" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_473><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 473</p><br/>A company has created a VPC with multiple private subnets in multiple Availability Zones (AZs) and one public subnet in one of the AZs. The public subnet is used to launch a NAT gateway. There are instances in the private subnets that use a NAT gateway to connect to the internet. In case of an AZ failure, the company wants to ensure that the instances are not all experiencing internet connectivity issues and that there is a backup plan ready.<br/><br/>Which solution should a solutions architect recommend that is MOST highly available?<br/><br/>A. Create a new public subnet with a NAT gateway in the same AZ. Distribute the traffic between the two NAT gateways.<br/>B. Create an Amazon EC2 NAT instance in a new public subnet. Distribute the traffic between the NAT gateway and the NAT instance.<br/>C. Create public subnets in each AZ and launch a NAT gateway in each subnet. Configure the traffic from the private subnets in each AZ to the respective NAT gateway.<br/>D. Create an Amazon EC2 NAT instance in the same public subnet. Replace the NAT gateway with the NAT instance and associate the instance with an Auto Scaling group with an appropriate scaling policy.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample49' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_474'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_462'>Random</a></p><div class='collapse' id='collapseExample49'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Create public subnets in each AZ and launch a NAT gateway in each subnet. Configure the traffic from the private subnets in each AZ to the respective NAT gateway.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 59%;" aria-valuenow="59" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_474><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 474</p><br/>A company has an application workflow that uses an AWS Lambda function to download and decrypt files from Amazon S3.<br/><br/>These files are encrypted using AWS Key Management Service Customer Master Keys (AWS KMS CMKs).<br/><br/>A solutions architect needs to design a solution that will ensure the required permissions are set correctly.<br/><br/>Which combination of actions accomplish this? (Select TWO)<br/><br/>A. Attach the kms.decrypt permission to the Lambda function's resource policy.<br/>B. Grant the decrypt permission for the Lambda IAM role in the KMS key's policy.<br/>C. Grant the decrypt permission for the Lambda resource policy in the KMS key's policy.<br/>D. Create a new IAM policy with the kms:decrypt permission and attach the policy to the Lambda function.<br/>E. Create a new IAM role with the kms decrypt permission and attach the execution role to the Lambda function.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample691' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_475'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_242'>Random</a></p><div class='collapse' id='collapseExample691'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Grant the decrypt permission for the Lambda IAM role in the KMS key's policy.
<br><b>E. </b>Create a new IAM role with the kms decrypt permission and attach the execution role to the Lambda function.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 60%;" aria-valuenow="60" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_475><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 475</p><br/>A solutions architect is designing a solution that involves orchestrating a series of Amazon Elastic Container Service (Amazon ECS) task types running on Amazon EC2 instances that are part of an ECS cluster. The output and state data for all tasks needs to be stored.<br/><br/>The amount of data output by each task is approximately 10MB, and there could be hundreds of tasks running at a time. The system should be optimized for high&#8211;frequency reading and writing. As old outputs are archived and deleted, the storage size is not expected to exceed 1TB.<br/><br/>Which storage solution should the solutions architect recommend?<br/><br/>A. An Amazon DynamoDB table accessible by all ECS cluster instances.<br/>B. An Amazon Elastic File System (Amazon EFS) with Provisioned Throughput mode.<br/>C. An Amazon Elastic File System (Amazon EFS) file system with Bursting Throughput mode.<br/>D. An Amazon Elastic File System (Amazon EFS) volume mounted to the ECS cluster instances.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample683' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_476'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_170'>Random</a></p><div class='collapse' id='collapseExample683'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>An Amazon Elastic File System (Amazon EFS) file system with Bursting Throughput mode.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 60%;" aria-valuenow="60" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_476><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 476</p><br/>A company wants to run a static website served through Amazon CloudFront.<br/><br/>What is an advantage of storing the website content in an Amazon S3 bucket instead of an Amazon Elastic Block Store (Amazon EBS) volume?<br/><br/>A. S3 buckets are replicated globally, allowing for large scalability. EBS volumes are replicated only within an AWS Region.<br/>B. S3 is an origin for CloudFront. EBS volumes would need EC2 instances behind an Elastic Load Balancing load balancer to be an origin<br/>C. S3 buckets can be encrypted, allowing for secure storage of the web files. EBS volumes cannot be encrypted.<br/>D. S3 buckets support object&#8211;level read throttling, preventing abuse. EBS volumes do not provide object&#8211;level throttling.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample538' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_477'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_374'>Random</a></p><div class='collapse' id='collapseExample538'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>S3 is an origin for CloudFront. EBS volumes would need EC2 instances behind an Elastic Load Balancing load balancer to be an origin</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 60%;" aria-valuenow="60" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_477><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 477</p><br/>A company has a 10 Gbps AWS Direct Connect connection from its on&#8211;premises servers to AWS. The workloads using the connection are critical. The company requires a disaster recovery strategy with maximum resiliency that maintains the current connection bandwidth at a minimum.<br/><br/>What should a solutions architect recommend?<br/><br/>A. Set up a new Direct Connect connection in another AWS Region.<br/>B. Set up a new AWS managed VPN connection in another AWS Region.<br/>C. Set up two new Direct Connect connections one in the current AWS Region and one in another Region.<br/>D. Set up two new AWS managed VPN connections one in the current AWS Region and one in another Region.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample706' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_478'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_76'>Random</a></p><div class='collapse' id='collapseExample706'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Set up a new Direct Connect connection in anothr AWS Region.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 60%;" aria-valuenow="60" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_478><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 478</p><br/>An application running on an Amazon EC2 instance needs to access an Amazon DynamoDB table. Both the EC2 instance and the DynamoDB table are in the same AWS account. A solutions architect must configure the necessary permissions.<br/><br/>Which solution will allow least privilege access to the DynamoDB table from the EC2 instance?<br/><br/>A. Create an IAM role with the appropriate policy to allow access to the DynamoDB table. Create an instance profile to assign this IAM role to the EC2 instance.<br/>B. Create an IAM role with the appropriate policy to allow access to the DynamoDB table. Add the EC2 instance to the trust relationship policy document to allow it to assume the role.<br/>C. Create an IAM user with the appropriate policy to allow access to the DynamoDB table. Store the credentials in an Amazon S3 bucket and read them from within the application code directly.<br/>D. Create an IAM user with the appropriate policy to allow access to the DynamoDB table. Ensure that the application stores the IAM credentials securely on local storage and uses them to make the DynamoDB calls.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample136' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_479'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_460'>Random</a></p><div class='collapse' id='collapseExample136'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Create an IAM role with the appropriate policy to allow access to the DynamoDB table. Create an instance profile to assign this IAM role to the EC2 instance.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 60%;" aria-valuenow="60" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_479><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 479</p><br/>An application generates audit logs of operational activities. Compliance requirements mandate that the application retain the logs for 5 years.<br/><br/>How can these requirements be met?<br/><br/>A. Save the logs in an Amazon S3 bucket and enable Multi&#8211;Factor Authentication Delete (MFA Delete) on the bucket.<br/>B. Save the logs in an Amazon EFS volume and use Network File System version 4 (NFSv4) locking with the volume.<br/>C. Save the logs in an Amazon Glacier vault and use the Vault Lock feature.<br/>D. Save the logs in an Amazon EBS volume and take monthly snapshots.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample790' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation790' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_480'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_36'>Random</a></p><div class='collapse' id='collapseExample790'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Save the logs in an Amazon Glacier vault and use the Vault Lock feature.</div></div></div><div class='collapse' id='explanation790'><div class='card card&#45;body'><div>
Amazon Glacier, which enables long-term storage of mission-critical data, has added Vault Lock. This new feature allows you to lock your vault with a variety of compliance controls that are designed to support such long-term records retention.
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 60%;" aria-valuenow="60" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_480><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 480</p><br/>A company hosts a static website on&#8211;premises and wants to migrate the website to AWS. The website should load as quickly as possible for users around the world. The company also wants the most cost&#8211;effective solution.<br/><br/>What should a solutions architect do to accomplish this?<br/><br/>A. Copy the website content to an Amazon S3 bucket. Configure the bucket to serve static webpage content. Replicate the S3 bucket to multiple AWS Regions.<br/>B. Copy the website content to an Amazon S3 bucket. Configure the bucket to serve static webpage content. Configure Amazon CloudFront with the S3 bucket as the origin.<br/>C. Copy the website content to an Amazon EBS&#8211;backed Amazon EC2 instance running Apache HTTP Server. Configure Amazon Route 53 geolocation routing policies to select the closest origin.<br/>D. Copy the website content to multiple Amazon EBS&#8211;backed Amazon EC2 instances running Apache HTTP Server in multiple AWS Regions. Configure Amazon CloudFront geolocation routing policies to select the closest origin.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample150' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation150' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_481'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_413'>Random</a></p><div class='collapse' id='collapseExample150'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Copy the website content to an Amazon S3 bucket. Configure the bucket to serve static webpage content. Configure Amazon CloudFront with the S3 bucket as the origin.</div></div></div><div class='collapse' id='explanation150'><div class='card card&#45;body'><div>
What Is Amazon CloudFront?
Amazon CloudFront is a web service that speeds up distribution of your static and dynamic web content, such as .html, .css, .js, and image files, to your users. CloudFront delivers your content through a worldwide network of data centers called edge locations. When a user requests content that you're serving with CloudFront, the user is routed to the edge location that provides the lowest latency (time delay), so that content is delivered with the best possible performance.

Using Amazon S3 Buckets for Your Origin
When you use Amazon S3 as an origin for your distribution, you place any objects that you want CloudFront to deliver in an Amazon S3 bucket. You can use any method that is supported by Amazon S3 to get your objects into Amazon S3, for example, the Amazon S3 console or API, or a third-party tool. You can create a hierarchy in your bucket to store the objects, just as you would with any other Amazon S3 bucket.

Using an existing Amazon S3 bucket as your CloudFront origin server doesn't change the bucket in any way; you can still use it as you normally would to store and access Amazon S3 objects at the standard Amazon S3 price. You incur regular Amazon S3 charges for storing the objects in the bucket.

The most cost-effective option is to migrate the website to an Amazon S3 bucket and configure that bucket for static website hosting. To enable good performance for global users the solutions architect should then configure a CloudFront distribution with the S3 bucket as the origin. This will cache the static content around the world closer to users.

CORRECT: "Copy the website content to an Amazon S3 bucket. Configure the bucket to serve static webpage content. Configure Amazon CloudFront with the S3 bucket as the origin" is the correct answer.

INCORRECT: "Copy the website content to an Amazon S3 bucket. Configure the bucket to serve static webpage content. Replicate the S3 bucket to multiple AWS Regions" is incorrect as there is no solution here for directing users to the closest region. This could be a more cost-effective (though less elegant) solution if AWS Route 53 latency records are created.

INCORRECT: "Copy the website content to an Amazon EC2 instance. Configure Amazon Route 53 geolocation routing policies to select the closest origin" is incorrect as using Amazon EC2 instances is less cost-effective compared to hosting the website on S3. Also, geolocation routing does not achieve anything with only a single record.

INCORRECT: "Copy the website content to multiple Amazon EC2 instances in multiple AWS Regions. Configure AWS Route 53 geolocation routing policies to select the closest region" is incorrect as using Amazon EC2 instances is less cost-effective compared to hosting the website on S3.

References:

How do I use CloudFront to serve a static website hosted on Amazon S3?</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 60%;" aria-valuenow="60" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_481><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 481</p><br/>A company has hired a solutions architect to design a reliable architecture for its application.<br/><br/>The application consists of one Amazon RDS DB instance and two manually provisioned Amazon EC2 instances that run web servers.<br/><br/>The EC2 instances are located in a single Availability Zone.<br/><br/>An employee recently deleted the DB instance and the application was unavailable for 24 hours as a result.<br/><br/>The company is concerned with the overall reliability of its environment.<br/><br/>What should the solutions architect do to maximize reliability of the application's infrastructure?<br/><br/>A. Delete one EC2 instance and enable termination protection on the other EC2 instance. Update the DB instance to be Muto&#8211;AZ and enable deletion protection<br/>B. Update the DB instance to be Multiple&#8211;AZ and enable deletion protection. Place the EC2 instances behind an Application Load Balancer and run them in an EC2 Auto Seating group across multiple Availability Zones<br/>C. Create an additional DB instance along with an Amazon API Gateway and an AWS Lambda function. Configure the application to invoke the Lambda function through API Gateway. Have the Lambda function write the data to the two DB instances<br/>D. Place the EC2 instances in an EC2 Auto Scaling group that has multiple subnets located in multiple Availability Zones. Use Spot Instances instead of On&#8211;Demand instances. Set up Amazon CloudWatch alarms to monitor the health of the instances. Update the DB instance to be Multi&#8211;AZ and enable deletion protection<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample528' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_482'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_377'>Random</a></p><div class='collapse' id='collapseExample528'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Update the DB instance to be Multiple-AZ and enable deletion protection. Place the EC2 instances behind an Application Load Balancer and run them in an EC2 Auto Seating group across multiple Availability Zones</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 60%;" aria-valuenow="60" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_482><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 482</p><br/>A company has a popular gaming platform running on AWS. The application is sensitive to latency because latency can impact the user experience and introduce unfair advantages to some players. The application is deployed in every AWS Region it runs on Amazon EC2 instances that are part of Auto Scaling groups configured behind Application Load Balancers (ALBs). A solutions architect needs to implement a mechanism to monitor the health of the application and redirect traffic to healthy endpoints.<br/><br/>Which solution meets these requirements?<br/><br/>A. Configure an accelerator in AWS Global Accelerator. Add a listener for the port that the application listens on and attach it to a Regional endpoint in each Region. Add the ALB as the endpoint.<br/>B. Create an Amazon CloudFront distribution and specify the ALB as the origin server. Configure the cache behavior to use origin cache headers. Use AWS Lambda functions to optimize the traffic.<br/>C. Create an Amazon CloudFront distribution and specify Amazon S3 as the origin server. Configure the cache behavior to use origin cache headers. Use AWS Lambda functions to optimize the traffic.<br/>D. Configure an Amazon DynamoDB database to serve as the data store for the application. Create a DynamoDB Accelerator (DAX) cluster to act as the in&#8211;memory cache for DynamoDB hosting the application data.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample315' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_483'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_649'>Random</a></p><div class='collapse' id='collapseExample315'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Configure an Amazon DynamoDB database to serve as the data store for the application. Create a DynamoDB Accelerator (DAX) cluster to act as the in-memory cache for DynamoDB hosting the application data.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 61%;" aria-valuenow="61" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_483><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 483</p><br/>A company designed a stateless two&#8211;tier application that uses Amazon EC2 in a single Availability Zone and an Amazon RDS Multi&#8211;AZ DB instance. New company management wants to ensure the application is highly available.<br/><br/>What should a solutions architect do to meet this requirement?<br/><br/>A. Configure the application to use Multi&#8211;AZ EC2 Auto Scaling and create an Application Load Balancer.<br/>B. Configure the application to take snapshots of the EC2 instances and send them to a different AWS Region.<br/>C. Configure the application to use Amazon Route 53 latency&#8211;based routing to feed requests to the application.<br/>D. Configure Amazon Route 53 rules to handle incoming requests and create a Multi&#8211;AZ Application Load Balancer.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample438' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_484'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_789'>Random</a></p><div class='collapse' id='collapseExample438'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Configure the application to use Multi-AZ EC2 Auto Scaling and create an Application Load Balancer.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 61%;" aria-valuenow="61" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_484><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 484</p><br/>A solution architect is performing a security review of a recently migrated workload. The workload is a web application that consists of Amazon EC2 instances in an Auto Scaling group behind an Application Load balancer. The solution architect must improve the security posture and minimize the impact of a DDoS attack on resources.<br/><br/>Which solution is MOST effective?<br/><br/>A. Configure an AWS WAF ACL with rate&#8211;based rules Create an Amazon CloudFront distribution that points to the Application Load Balancer. Enable the EAF ACL on the CloudFront distribution<br/>B. Create a custom AWS Lambda function that adds identified attacks into a common vulnerability pool to capture a potential DDoS attack. use the identified information to modify a network ACL to block access.<br/>C. Enable VPC Flow Logs and store them in Amazon S3. Create a custom AWS Lambda functions that parse the logs looking for a DDoS attack. Modify a network ACL to block identified source IP addresses.<br/>D. Enable Amazon GuardDuty and, configure findings written 10 Amazon GloudWatch Create an event with Cloud Watch Events for DDoS alerts that triggers Amazon Simple Notification Service (Amazon SNS) Have Amazon SNS invoke a custom AWS Lambda function that parses the logs looking for a DDoS attack Modify a network ACL to block identified source IP addresses<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample729' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_485'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_594'>Random</a></p><div class='collapse' id='collapseExample729'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Configure an AWS WAF ACL with rate-based rules Create an Amazon CloudFront distribution that points to the Application Load Balancer. Enable the EAF ACL on the CloudFront distribution</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 61%;" aria-valuenow="61" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_485><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 485</p><br/>A solutions architect observes that a nightly batch processing job is automatically scaled up for 1 hour before the desired Amazon EC2 capacity is reached. The peak capacity is the same every night and the batch jobs always start at 1 AM. The solutions architect needs to find a cost&#8211;effective solution that will allow for the desired EC2 capacity to be reached quickly and allow the Auto Scaling group to scale down after the batch jobs are complete.<br/><br/>What should the solutions architect do to meet these requirements?<br/><br/>A. Increase the minimum capacity for the Auto Scaling group.<br/>B. Increase the maximum capacity for the Auto Scaling group.<br/>C. Configure scheduled scaling to scale up to the desired compute level.<br/>D. Change the scaling policy to add more EC2 instances during each scaling operation.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample159' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_486'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_711'>Random</a></p><div class='collapse' id='collapseExample159'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Configure scheduled scaling to scale up to the desired compute level.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 61%;" aria-valuenow="61" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_486><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 486</p><br/>A company has an application that uses overnight digital images of products on store shelves to analyze inventory data. The application runs on Amazon EC2 instances behind an Application Load Balancer (ALB) and obtains the images from an Amazon S3 bucket for its metadata to be processed by worker nodes for analysis. A solutions architect needs to ensure that every image is processed by the worker nodes.<br/><br/>What should the solutions architect do to meet this requirement in the MOST cost&#8211;efficient way?<br/><br/>A. Send the image metadata from the application directly to a second ALB for the worker nodes that use an Auto Scaling group of EC2 Spot Instances as the target group.<br/>B. Process the image metadata by sending it directly to EC2 Reserved Instances in an Auto Scaling group. With a dynamic scaling policy, use an Amazon CloudWatch metric for average CPU utilization of the Auto Scaling group as soon as the front&#8211;end application obtains the images.<br/>C. Write messages to Amazon Simple Queue Service (Amazon SQS) when the front&#8211;end application obtains an image. Process the images with EC2 On&#8211;Demand instances in an Auto Scaling group with instance scale&#8211;in protection and a fixed number of instances with periodic health checks.<br/>D. Write messages to Amazon Simple Queue Service (Amazon SQS) when the application obtains an image. Process the images with EC2 Spot Instances in an Auto Scaling group with instance scale&#8211;in protection and a dynamic scaling policy using a custom Amazon CloudWatch metric for the current number of messages in the queue.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample310' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_487'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_156'>Random</a></p><div class='collapse' id='collapseExample310'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Process the image metadata by sending it directly to EC2 Reserved Instances in an Auto Scaling group. With a dynamic scaling policy, use an Amazon CloudWatch metric for average CPU utilization of the Auto Scaling group as soon as the front-end application obtains the images.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 61%;" aria-valuenow="61" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_487><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 487</p><br/>A solutions architect wants all new users to have specific complexity requirements and mandatory rotation periods for 1AM user passwords.<br/><br/>What should the solutions architect do to accomplish this?<br/><br/>A. Set an overall password policy for the entire AWS account<br/>B. Set a password policy for each 1AM user in the AWS account.<br/>C. Use third&#8211;party vendor software to set password requirements,<br/>D. Attach an Amazon CloudWatch rule to the Create_newuser event to set the password with the appropriate requirements.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample676' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_488'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_669'>Random</a></p><div class='collapse' id='collapseExample676'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Set an overall password policy for the entire AWS account</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 61%;" aria-valuenow="61" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_488><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 488</p><br/>A gaming company has multiple Amazon EC2 instances in a single Availability Zone for its multiplayer game that communicates with users on Layer 4. The chief technology officer (CTO) wants to make the architecture highly available and cost&#8211;effective.<br/>What should a solutions architect do to meet these requirements? (Choose two.)?<br/><br/>A. Increase the number of EC2 instances.<br/>B. Decrease the number of EC2 instances.<br/>C. Configure a Network Load Balancer in front of the EC2 instances.<br/>D. Configure an Application Load Balancer in front of the EC2 instances.<br/>E. Configure an Auto Scaling group to add or remove instances in multiple Availability Zones automatically.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample19' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation19' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_489'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_189'>Random</a></p><div class='collapse' id='collapseExample19'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Configure a Network Load Balancer in front of the EC2 instances.
<br><b>E. </b>Configure an Auto Scaling group to add or remove instances in multiple Availability Zones automatically.</div></div></div><div class='collapse' id='explanation19'><div class='card card&#45;body'><div>
Network Load Balancer overview: A Network Load Balancer functions at the fourth layer of the Open Systems Interconnection (OSI) model. It can handle millions of requests per second. After the load balancer receives a connection request, it selects a target from the target group for the default rule. It attempts to open a TCP connection to the selected target on the port specified in the listener configuration.

When you enable an Availability Zone for the load balancer, Elastic Load Balancing creates a load balancer node in the Availability Zone. By default, each load balancer node distributes traffic across the registered targets in its Availability Zone only. If you enable cross-zone load balancing, each load balancer node distributes traffic across the registered targets in all enabled Availability Zones. For more information, see Availability Zones.

If you enable multiple Availability Zones for your load balancer and ensure that each target group has at least one target in each enabled Availability Zone, this increases the fault tolerance of your applications. For example, if one or more target groups does not have a healthy target in an Availability Zone, we remove the IP address for the corresponding subnet from DNS, but the load balancer nodes in the other Availability Zones are still available to route traffic. If a client doesn't honor the time-to-live (TTL) and sends requests to the IP address after it is removed from DNS, the requests fail.

For TCP traffic, the load balancer selects a target using a flow hash algorithm based on the protocol, source IP address, source port, destination IP address, destination port, and TCP sequence number. The TCP connections from a client have different source ports and sequence numbers, and can be routed to different targets. Each individual TCP connection is routed to a single target for the life of the connection.

For UDP traffic, the load balancer selects a target using a flow hash algorithm based on the protocol, source IP address, source port, destination IP address, and destination port. A UDP flow has the same source and destination, so it is consistently routed to a single target throughout its lifetime. Different UDP flows have different source IP addresses and ports, so they can be routed to different targets.

An Auto Scaling group contains a collection of Amazon EC2 instances that are treated as a logical grouping for the purposes of automatic scaling and management. An Auto Scaling group also enables you to use Amazon EC2 Auto Scaling features such as health check replacements and scaling policies. Both maintaining the number of instances in an Auto Scaling group and automatic scaling are the core functionality of the Amazon EC2 Auto Scaling service.

The size of an Auto Scaling group depends on the number of instances that you set as the desired capacity. You can adjust its size to meet demand, either manually or by using automatic scaling.

An Auto Scaling group starts by launching enough instances to meet its desired capacity. It maintains this number of instances by performing periodic health checks on the instances in the group. The Auto Scaling group continues to maintain a fixed number of instances even if an instance becomes unhealthy. If an instance becomes unhealthy, the group terminates the unhealthy instance and launches another instance to replace it.

The solutions architect must enable high availability for the architecture and ensure it is cost- effective. To enable high availability an Amazon EC2 Auto Scaling group should be created to add and remove instances across multiple availability zones.

In order to distribute the traffic to the instances the architecture should use a Network Load Balancer which operates at Layer 4. This architecture will also be cost-effective as the Auto Scaling group will ensure the right number of instances are running based on demand.

CORRECT: "Configure a Network Load Balancer in front of the EC2 instances" is a correct answer.

CORRECT: "Configure an Auto Scaling group to add or remove instances in multiple Availability Zones automatically" is also a correct answer.

INCORRECT: "Increase the number of instances and use smaller EC2 instance types" is incorrect as this is not the most cost-effective option. Auto Scaling should be used to maintain the right number of active instances.

INCORRECT: "Configure an Auto Scaling group to add or remove instances in the Availability Zone automatically" is incorrect as this is not highly available as it's a single AZ.

INCORRECT: "Configure an Application Load Balancer in front of the EC2 instances" is incorrect as an ALB operates at Layer 7 rather than Layer 4.

References:

Amazon EC2 Auto Scaling > User Guide > Elastic Load Balancing and Amazon EC2 Auto Scaling
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 61%;" aria-valuenow="61" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_489><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 489</p><br/>A company provides a three&#8211;tier web application to its customers.<br/><br/>Each customer has an AWS account in which the application is deployed, and these accounts are members of the company's organization in AWS Organizations.<br/><br/>To protect its customers' AWS accounts and applications the company wants to monitor them for unusual and unexpected behavior.<br/><br/>The company needs to analyze and monitor customer VPC Flow Logs. AWS CloudTrail logs, and DNS logs.<br/><br/>What should a solutions architect do to meet these requirements?<br/><br/>A. Designate an account in the organization as the AWS Shield master account. Enable Shield and Shield logs in every account and invite the accounts to join the Shield master account. Analyze Shield findings m the Shield master account<br/>B. Designate an account in the organization as the Amazon GuardDuty master account. Enable GuardDuty in every account and invite the accounts to join the GuardDuty master account Analyze GuardDuty finding in the GuardDuty master account<br/>C. Designate an account in the organization as the AWS WAF master account. Enable AWS WAF and AWS WAF logs in every account and invite the accounts to join the AWS WAF master account. Analyze AWS WAF logs in the AWS WAF master account<br/>D. Designate an account in the organization as the AWS Resource Access Manager (AWS RAM) master account. Enable AWS RAM in every account, and invite the accounts to join the AWS RAM master account. Analyze AWS RAM logs in the AWS RAM master account<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample628' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_490'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_25'>Random</a></p><div class='collapse' id='collapseExample628'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Designate an account in the organization as the Amazon GuardDuty master account. Enable GuardDuty in every account and invite the accounts to join the GuardDuty master account Analyze GuardDuty finding in the GuardDuty master account</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 61%;" aria-valuenow="61" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_490><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 490</p><br/>A solutions architect must create a highly available bastion host architecture. The solution needs to be resilient within a single AWS Region and should require only minimal effort to maintain.<br/><br/>What should the solutions architect do to meet these requirements?<br/><br/>A. Create a Network Load Balancer backed by an Auto Scaling group with a UDP listener.<br/>B. Create a Network Load Balancer backed by a Spot Fleet with instances in a partition placement group.<br/>C. Create a Network Load Balancer backed by the existing servers in different Availability Zones as the target.<br/>D. Create a Network Load Balancer backed by an Auto Scaling group with instances in multiple Availability Zones as the target.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample78' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_491'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_542'>Random</a></p><div class='collapse' id='collapseExample78'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Create a Network Load Balancer backed by an Auto Scaling group with instances in multiple Availability Zones as the target.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 62%;" aria-valuenow="62" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_491><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 491</p><br/>A company hosts its static website content from an Amazon S3 bucket in the us&#8211;east&#8211;1 Region. Content is made available through an Amazon CloudFront origin pointing to that bucket. Cross&#8211;Region replication is set to create a second copy of the bucket in the ap&#8211;southeast&#8211;1 Region. Management wants a solution that provides greater availability for the website.<br/><br/>Which combination of actions should a solutions architect take to increase availability? (Choose two.)<br/><br/>A. Add both buckets to the CloudFront origin.<br/>B. Configure failover routing in Amazon Route 53.<br/>C. Create a record in Amazon Route 53 pointing to the replica bucket.<br/>D. Create an additional CloudFront origin pointing to the ap&#8211;southeast&#8211;1 bucket.<br/>E. Set up a CloudFront origin group with the us&#8211;east&#8211;1 bucket as the primary and the ap&#8211;southeast&#8211;1 bucket as the secondary.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample236' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_492'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_67'>Random</a></p><div class='collapse' id='collapseExample236'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Configure failover routing in Amazon Route 53.
<br><b>E. </b>Set up a CloudFront origin group with the us-east-1 bucket as the primary and the ap-southeast-1 bucket as the secondary.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 62%;" aria-valuenow="62" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_492><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 492</p><br/>A company is running a multi&#8211;tier eCommerce web application in the AWS Cloud. The application runs on Amazon EC2 Instances with an Amazon RDS MySQL Multi&#8211;AZ DB instance. Amazon RDS is configured with the latest generation instance with 2,000 GB of storage in an Amazon EBS General Purpose SSD (gp2) volume. The database performance impacts the application during periods of high demand.<br/><br/>After analyzing the logs in Amazon CloudWatch Logs, a database administrator finds that the application performance always degrades when the number of read and write IOPS is higher than 6.000.<br/><br/>What should a solutions architect do to improve the application performance?<br/><br/>A. Replace the volume with a Magnetic volume.<br/>B. Increase the number of IOPS on the gp2 volume.<br/>C. Replace the volume with a Provisioned IOPS (PIOPS) volume.<br/>D. Replace the 2,000 GB gp2 volume with two 1,000 GBgp2 volumes.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample301' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_493'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_646'>Random</a></p><div class='collapse' id='collapseExample301'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Replace the volume with a Provisioned IOPS (PIOPS) volume.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 62%;" aria-valuenow="62" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_493><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 493</p><br/>A company is deploying a two&#8211;tier web application in a VPC. The web tier is using an Amazon EC2 Auto Scaling group with public subnets that span multiple Availability Zones. The database tier consists of an Amazon RDS for MySQL DB instance in separate private subnets. The web tier requires access to the database to retrieve product information.<br/><br/>The web application is not working as intended. The web application reports that it cannot connect to the database. The database is confirmed to be up and running. All configurations for the network ACLs. security groups, and route tables are still in their default states.<br/><br/>What should a solutions architect recommend to fix the application?<br/><br/>A. Add an explicit rule to the private subnet's network ACL to allow traffic from the web tier's EC2 instances.<br/>B. Add a route in the VPC route table to allow traffic between the web tier's EC2 instances and The database tier.<br/>C. Deploy the web tier's EC2 instances and the database tier's RDS instance into two separate VPCs. and configure VPC peering.<br/>D. Add an inbound rule to the security group of the database tier's RDS instance to allow traffic from the web tier's security group.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample477' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_494'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_136'>Random</a></p><div class='collapse' id='collapseExample477'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Add an inbound rule to the security group of the database tier's RDS instance to allow traffic from the web tier's security group.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 62%;" aria-valuenow="62" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_494><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 494</p><br/>A company is migrating to the AWS Cloud. A file server is the first workload to migrate. Users must be able to access the file share using the Server Message Block (SMB) protocol. Which AWS managed service meets these requirements?<br/><br/>A. Amazon EBS<br/>B. Amazon EC2<br/>C. Amazon FSx<br/>D. Amazon S3<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample202' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation202' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_495'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_786'>Random</a></p><div class='collapse' id='collapseExample202'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Amazon FSx</div></div></div><div class='collapse' id='explanation202'><div class='card card&#45;body'><div>
Amazon FSx for Windows File Server provides fully managed, highly reliable file storage that is accessible over the industry-standard Server Message Block (SMB) protocol.

Amazon FSx is built on Windows Server and provides a rich set of administrative features that include end-user file restore, user quotas, and Access Control Lists (ACLs).

Additionally, Amazon FSX for Windows File Server supports Distributed File System Replication (DFSR) in both Single-AZ and Multi-AZ deployments as can be seen in the feature comparison table below.

CORRECT: "Amazon FSx" is the correct answer.

INCORRECT: "Amazon Elastic Block Store (EBS)" is incorrect. EFS and EBS are not good use cases for this solution. Neither storage solution is capable of presenting Amazon S3 objects as files to the application.

INCORRECT: "Amazon EC2" is incorrect as no SMB support.

INCORRECT: "Amazon S3" is incorrect as this is not a suitable replacement for a Microsoft filesystem.
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 62%;" aria-valuenow="62" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_495><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 495</p><br/>A company uses an Amazon S3 bucket to store static images for its website. The company configured permissions to allow access to Amazon S3 objects by privileged users only.<br/><br/>What should a solutions architect do to protect against data loss? (Choose two.)<br/><br/>A. Enable versioning on the S3 bucket.<br/>B. Enable access logging on the S3 bucket.<br/>C. Enable server&#8211;side encryption on the S3 bucket.<br/>D. Configure an S3 lifecycle rule to transition objects to Amazon S3 Glacier.<br/>E. Use MFA Delete to require multi&#8211;factor authentication to delete an object.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample108' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_496'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_205'>Random</a></p><div class='collapse' id='collapseExample108'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Enable versioning on the S3 bucket.
<br><b>E. </b>Use MFA Delete to require multi-factor authentication to delete an object.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 62%;" aria-valuenow="62" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_496><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 496</p><br/>A company fails an AWS security reviews conducted by the third party.<br/><br/>The review finds out that some of the company method to access the Amazon EMR through the public internet.<br/><br/>Which combination of steps should the company take to MOST improve its security? (Select TWO.)<br/><br/>A. Set up a VPC peering connect to the Amazon EMR API.<br/>B. Set up VPC endpoints to connect to the Amazon EMR API.<br/>C. Set up a NAT gateway to connect to the Amazon EMR API.<br/>D. Set up 1AM roles to be used to connect to the Amazon FMR API.<br/>E. Set up each developer with AWS Secrets Manager to store access keys.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample604' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_497'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_281'>Random</a></p><div class='collapse' id='collapseExample604'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Set up a VPC peering connect to the Amazon EMR API.
<br><b>D. </b>Set up 1AM roles to be used to connect to the Amazon FMR API.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 62%;" aria-valuenow="62" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_497><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 497</p><br/>A company is migrating a three&#8211;tier application to AWS. The application requires a MySQL database. In the past, the application users reported poor application performance when creating new entries. These performance issues were caused by users generating different real&#8211;time reports from the application during working hours.<br/><br/>Which solution will improve the performance of the application when it is moved to AWS?<br/><br/>A. Import the data into an Amazon DynamoDB table with provisioned capacity. Refactor the application to use DynamoDB for reports.<br/>B. Create the database on a compute optimized Amazon EC2 instance. Ensure compute resources exceed the on&#8211;premises database.<br/>C. Create an Amazon Aurora MySQL Multi&#8211;AZ DB cluster with multiple read replicas. Configure the application to use the reader endpoint for reports.<br/>D. Create an Amazon Aurora MySQL Multi&#8211;AZ DB cluster. Configure the application to use the backup instance of the cluster as an endpoint for the reports.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample8' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation8' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_498'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_454'>Random</a></p><div class='collapse' id='collapseExample8'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Create an Amazon Aurora MySQL Multi-AZ DB cluster with multiple read replicas. Configure the application to use the reader endpoint for reports.</div></div></div><div class='collapse' id='explanation8'><div class='card card&#45;body'><div>
Amazon RDS Read Replicas Now Support Multi-AZ Deployments

Starting today, Amazon RDS Read Replicas for MySQL and MariaDB now support Multi-AZ deployments. Combining Read Replicas with Multi-AZ enables you to build a resilient disaster recovery strategy and simplify your database engine upgrade process.

Amazon RDS Read Replicas enable you to create one or more read-only copies of your database instance within the same AWS Region or in a different AWS Region. Updates made to the source database are then asynchronously copied to your Read Replicas. In addition to providing scalability for read-heavy workloads, Read Replicas can be promoted to become a standalone database instance when needed.

Amazon RDS Multi-AZ deployments provide enhanced availability for database instances within a single AWS Region. With Multi-AZ, your data is synchronously replicated to a standby in a different Availability Zone (AZ). In the event of an infrastructure failure, Amazon RDS performs an automatic failover to the standby, minimizing disruption to your applications.

You can now use Read Replicas with Multi-AZ as part of a disaster recovery (DR) strategy for your production databases. A well-designed and tested DR plan is critical for maintaining business continuity after a disaster. A Read Replica in a different region than the source database can be used as a standby database and promoted to become the new production database in case of a regional disruption.

You can also combine Read Replicas with Multi-AZ for your database engine upgrade process. You can create a Read Replica of your production database instance and upgrade it to a new database engine version. When the upgrade is complete, you can stop applications, promote the Read Replica to a standalone database instance, and switch over your applications. Since the database instance is already a Multi-AZ deployment, no additional steps are needed.

Overview of Amazon RDS Read Replicas

Deploying one or more read replicas for a given source DB instance might make sense in a variety of scenarios, including the following:

Scaling beyond the compute or I/O capacity of a single DB instance for read-heavy database workloads. You can direct this excess read traffic to one or more read replicas.

Serving read traffic while the source DB instance is unavailable. In some cases, your source DB instance might not be able to take I/O requests, for example due to I/O suspension for backups or scheduled maintenance. In these cases, you can direct read traffic to your read replicas. For this use case, keep in mind that the data on the read replica might be "stale" because the source DB instance is unavailable.

Business reporting or data warehousing scenarios where you might want business reporting queries to run against a read replica, rather than your primary, production DB instance.

Implementing disaster recovery. You can promote a read replica to a standalone instance as a disaster recovery solution if the source DB instance fails.

The MySQL-compatible edition of Aurora delivers up to 5X the throughput of standard MySQL running on the same hardware, and enables existing MySQL applications and tools to run without requiring modification.

References:

Amazon Aurora Features: MySQL-Compatible Edition</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 62%;" aria-valuenow="62" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_498><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 498</p><br/>A company has an Amazon S3 bucket that contains mission&#8211;critical data. The company wants to ensure this data is protected from accidental deletion. The data should still be accessible, and a user should be able to delete the data intentionally.<br/><br/>Which combination of steps should a solutions architect take to accomplish this? (Choose two.)<br/><br/>A. Enable versioning on the S3 bucket.<br/>B. Enable MFA Delete on the S3 bucket.<br/>C. Create a bucket policy on the S3 bucket.<br/>D. Enable default encryption on the S3 bucket.<br/>E. Create a lifecycle policy for the objects in the S3 bucket.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample362' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_499'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_505'>Random</a></p><div class='collapse' id='collapseExample362'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Enable versioning on the S3 bucket.
<br><b>B. </b>Enable MFA Delete on the S3 bucket.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 63%;" aria-valuenow="63" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_499><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 499</p><br/>A company has an on&#8211;premises data center that is running out of storage capacity. The company wants to migrate its storage infrastructure to AWS while minimizing bandwidth costs. The solution must allow for immediate retrieval of data at no additional cost.<br/><br/>How can these requirements be met?<br/><br/>A. Deploy Amazon S3 Glacier Vault and enable expedited retrieval. Enable provisioned retrieval capacity for the workload.<br/>B. Deploy AWS Storage Gateway using cached volumes. Use Storage Gateway to store data in Amazon S3 while retaining copies of frequently accessed data subsets locally.<br/>C. Deploy AWS Storage Gateway using stored volumes to store data locally. Use Storage Gateway to asynchronously back up point&#8211;in&#8211;time snapshots of the data to Amazon S3.<br/>D. Deploy AWS Direct Connect to connect with the on&#8211;premises data center. Configure AWS Storage Gateway to store data locally. Use Storage Gateway to asynchronously back up point&#8211;in&#8211;time snapshots of the data to Amazon S3.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample62' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation62' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_500'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_287'>Random</a></p><div class='collapse' id='collapseExample62'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Deploy AWS Storage Gateway using stored volumes to store data locally. Use Storage Gateway to asynchronously back up point-in-time snapshots of the data to Amazon S3.</div></div></div><div class='collapse' id='explanation62'><div class='card card&#45;body'><div>
Volume Gateway provides an iSCSI target, which enables you to create block storage volumes and mount them as iSCSI devices from your on-premises or EC2 application servers. The Volume Gateway runs in either a cached or stored mode:

In the cached mode, your primary data is written to S3, while retaining your frequently accessed data locally in a cache for low-latency access.

In the stored mode, your primary data is stored locally and your entire dataset is available for low-latency access while asynchronously backed up to AWS.
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 63%;" aria-valuenow="63" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_500><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 500</p><br/>A leasing company generates and emails PDF statements every month for all its customers. Each statement is about 400 KB in size.<br/><br/>Customers can download their statements from the website for up to 30 days from when the statements were generated. At the end of their 3&#8211;year lease, the customers are emailed a ZIP file that contains all the statements.<br/><br/>What is the MOST cost&#8211;effective storage solution for this situation?<br/><br/>A. Store the statements using the Amazon S3 Standard storage class. Create a lifecycle policy to move the statements to Amazon S3 Glacier storage after 1 day.<br/>B. Store the statements using the Amazon S3 Glacier storage class. Create a lifecycle policy to move the statements to Amazon S3 Glacier Deep Archive storage after 30 days.<br/>C. Store the statements using the Amazon S3 Standard storage class. Create a lifecycle policy to move the statements to Amazon S3 One Zone&#8211;Infrequent Access (S3 One Zone&#8211;IA) storage after 30 days.<br/>D. Store the statements using the Amazon S3 Standard&#8211;Infrequent Access (S3 Standard&#8211;IA) storage class. Create a lifecycle policy to move the statements to Amazon S3 Glacier storage after 30 days.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample115' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_501'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_579'>Random</a></p><div class='collapse' id='collapseExample115'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Store the statements using the Amazon S3 Glacier storage class. Create a lifecycle policy to move the statements to Amazon S3 Glacier Deep Archive storage after 30 days.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 63%;" aria-valuenow="63" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_501><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 501</p><br/>A company runs an application using Amazon ECS. The application creates resized versions of an original image and then makes Amazon S3 API calls to store the resized images in Amazon S3. How can a solutions architect ensure that the application has permission to access Amazon S3?<br/><br/>A. Update the S3 role in AWS IAM to allow read/write access from Amazon ECS, and then relaunch the container.<br/>B. Create an IAM role with S3 permissions, and then specify that role as the taskRoleArn in the task definition.<br/>C. Create a security group that allows access from Amazon ECS to Amazon S3, and update the launch configuration used by the ECS cluster.<br/>D. Create an IAM user with S3 permissions, and then relaunch the Amazon EC2 instances for the ECS cluster while logged in as this account.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample204' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_502'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_204'>Random</a></p><div class='collapse' id='collapseExample204'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Create an IAM role with S3 permissions, and then specify that role as the taskRoleArn in the task definition.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 63%;" aria-valuenow="63" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_502><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 502</p><br/>A recently created startup built a three&#8211;tier web application. The front end has static content. The application layer is based on microservices. User data is stored as JSON documents that need to be accessed with low latency. The company expects regular traffic to be low during the first year, with peaks in traffic when it publicizes new features every month. The startup team needs to minimize operational overhead costs.<br/><br/>What should a solutions architect recommend to accomplish this?<br/><br/>A. Use Amazon S3 static website hosting to store and serve the front end. Use AWS Elastic Beanstalk for the application layer. Use Amazon DynamoDB to store user data.<br/>B. Use Amazon S3 static website hosting to store and serve the front end. Use Amazon Elastic KubernetesService (Amazon EKS) for the application layer. Use Amazon DynamoDB to store user data.<br/>C. Use Amazon S3 static website hosting to store and serve the front end. Use Amazon API Gateway and AWS Lambda functions for the application layer. Use Amazon DynamoDB to store user data.<br/>D. Use Amazon S3 static website hosting to store and serve the front end. Use Amazon API Gateway and AWS Lambda functions for the application layer. Use Amazon RDS with read replicas to store user data.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample337' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_503'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_390'>Random</a></p><div class='collapse' id='collapseExample337'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Use Amazon S3 static website hosting to store and serve the front end. Use Amazon API Gateway and AWS Lambda functions for the application layer. Use Amazon DynamoDB to store user data.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 63%;" aria-valuenow="63" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_503><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 503</p><br/>A company receives structured and semi&#8211;structured data from various sources once every day. A solutions architect needs to design a solution that leverages big data processing frameworks. The data should be accessible using SQL queries and business intelligence tools.<br/><br/>What should the solutions architect recommend to build the MOST high&#8211;performing solution?<br/><br/>A. Use AWS Glue to process data and Amazon S3 to store data.<br/>B. Use Amazon EMR to process data and Amazon Redshift to store data.<br/>C. Use Amazon EC2 to process data and Amazon Elastic Block Store (Amazon EBS) to store data.<br/>D. Use Amazon Kinesis Data Analytics to process data and Amazon Elastic File System (Amazon EFS) to store data.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample128' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_504'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_14'>Random</a></p><div class='collapse' id='collapseExample128'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Use Amazon EMR to process data and Amazon Redshift to store data.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 63%;" aria-valuenow="63" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_504><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 504</p><br/>A company runs a production application on a fleet of Amazon EC2 instances. The application reads the data from an Amazon SQS queue and processes the messages in parallel. The message volume is unpredictable and often has intermittent traffic. This application should continually process messages without any downtime.<br/><br/>Which solution meets these requirements MOST cost&#8211;effectively?<br/><br/>A. Use Spot Instances exclusively to handle the maximum capacity required.<br/>B. Use Reserved Instances exclusively to handle the maximum capacity required.<br/>C. Use Reserved Instances for the baseline capacity and use Spot Instances to handle additional capacity.<br/>D. Use Reserved Instances for the baseline capacity and use On&#8211;Demand Instances to handle additional capacity.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample238' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_505'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_52'>Random</a></p><div class='collapse' id='collapseExample238'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Use Reserved Instances for the baseline capacity and use Spot Instances to handle additional capacity.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 63%;" aria-valuenow="63" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_505><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 505</p><br/>You are checking the workload on some of your General Purpose (SSD) and Provisioned IOPS (SSD) volumes and it seems that the I/O latency is higher than you require. You should probably check the to make sure that your application is not trying to drive more IOPS than you have provisioned.<br/><br/>A. Amount of IOPS that are available<br/>B. Acknowledgement from the storage subsystem<br/>C. Average queue length<br/>D. Time it takes for the I/O operation to complete<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample746' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation746' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_506'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_128'>Random</a></p><div class='collapse' id='collapseExample746'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Average queue length</div></div></div><div class='collapse' id='explanation746'><div class='card card&#45;body'><div>
In EBS workload demand plays an important role in getting the most out of your General Purpose (SSD) and Provisioned IOPS (SSD) volumes. In order for your volumes to deliver the amount of IOPS that are available, they need to have enough I/O requests sent to them. There is a relationship between the demand on the volumes, the amount of IOPS that are available to them, and the latency of the request (the amount of time it takes for the I/O operation to complete).

Latency is the true end-to-end client time of an I/O operation; in other words, when the client sends a IO, how long does it take to get an acknowledgment from the storage subsystem that the IO read or write is complete.

If your I/O latency is higher than you require, check your average queue length to make sure that your application is not trying to drive more IOPS than you have provisioned. You can maintain high IOPS while keeping latency down by maintaining a low average queue length (which is achieved by provisioning more IOPS for your volume).

References:

Amazon Elastic Compute Cloud > User Guide for Linux Instances > What is Amazon EC2?</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 63%;" aria-valuenow="63" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_506><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 506</p><br/>A company needs to connect its on&#8211;premises data center network to a new VPC. The data center network has a 100 Mbps symmetrical Internet connection. An application that is running on&#8211;premises will transfer multiple gigabytes of data each day. The application will use an Amazon Kinesis Data Firehose delivery stream for processing.<br/><br/>What should a solutions architect recommend for maximum performance?<br/><br/>A. Create a VPC peering connection between the on&#8211;premises network and the VPC Configure routing for the on&#8211;premises network to use the VPC peering connection.<br/>B. Procure an AWS Snowball Edge Storage Optimized device. After several days' worth of data has accumulated, copy the data to the device and ship the device to AWS for expedited transfer to Kinesis Data Firehose Repeat as needed<br/>C. Create an AWS Site&#8211;to&#8211;Site VPN connection between the on&#8211;premises network and the VPC Configure BGP routing between the customer gateway and the virtual private gateway. Use the VPN connection to send the data from on&#8211;premises to Kinesis Data Firehose.<br/>D. Use AWS PrivateLink to create an interface VPC endpoint for Kinesis Data Firehose in the VP<br/>E. Set up a 1 Gbps AWS Direct Connect connection between the on&#8211;premises network and AWS Use the PrivateLink endpoint to send the data from on&#8211;premises to Kinesis Data Firehose.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample480' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_507'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_660'>Random</a></p><div class='collapse' id='collapseExample480'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Use AWS PrivateLink to create an interface VPC endpoint for Kinesis Data Firehose in the VP</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 64%;" aria-valuenow="64" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_507><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 507</p><br/>A new employee has joined a company as a deployment engineer. The deployment engineer will be using AWS CloudFormation templates to create multiple AWS resources. A solutions architect wants the deployment engineer to perform job activities while following the principle of least privilege.<br/><br/>Which combination of actions should the solutions architect take to accomplish this goal? (Choose two.)<br/><br/>A. Have the deployment engineer use AWS account root user credentials for performing AWS CloudFormation stack operations.<br/>B. Create a new IAM user for the deployment engineer and add the IAM user to a group that has the PowerUsers IAM policy attached.<br/>C. Create a new IAM user for the deployment engineer and add the IAM user to a group that has the Administrate/Access IAM policy attached.<br/>D. Create a new IAM User for the deployment engineer and add the IAM user to a group that has an IAM policy that allows AWS CloudFormation actions only.<br/>E. Create an IAM role for the deployment engineer to explicitly define the permissions specific to the AWS CloudFormation stack and launch stacks using Dial IAM role.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample389' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_508'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_503'>Random</a></p><div class='collapse' id='collapseExample389'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Have the deployment engineer use AWS account root user credentials for performing AWS CloudFormation stack operations.
<br><b>E. </b>Create an IAM role for the deployment engineer to explicitly define the permissions specific to the AWS CloudFormation stack and launch stacks using Dial IAM role.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 64%;" aria-valuenow="64" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_508><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 508</p><br/>A company is hosting its static website in an Amazon S3 bucket, which is the origin for Amazon CloudFront.<br/><br/>The company has users in the United States, Canada, and Europe and wants to reduce costs.<br/><br/>What should a solutions architect recommend?<br/><br/>A. Adjust the CloudFront caching time to live (TTL) from the default to a longer timeframe.<br/>B. Implement CloudFront events with Lambda@Edge to run the website's data processing.<br/>C. Modify the CloudFront price class to include only the locations of the countries that are served.<br/>D. Implement a CloudFront Secure Sockets Layer (SSL) certificate to push security closer to the locations of the countries that are served.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample231' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_509'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_310'>Random</a></p><div class='collapse' id='collapseExample231'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Modify the CloudFront price class to include only the locations of the countries that are served.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 64%;" aria-valuenow="64" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_509><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 509</p><br/>A company needs guaranteed Amazon EC2 capacity in three specific Availability Zones in a specific AWS Region for an upcoming event that will last 1 week.<br/><br/>What should the company do to guarantee the EC2 capacity?<br/><br/>A. Purchase Reserved Instances that specify the Region needed.<br/>B. Create an On&#8211;Demand Capacity Reservation that specifies the Region needed.<br/>C. Purchase Reserved Instances that specify the Region and three Availability Zones needed.<br/>D. Create an On&#8211;Demand Capacity Reservation that specifies the Region and three Availability Zones needed.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample495' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_510'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_87'>Random</a></p><div class='collapse' id='collapseExample495'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Purchase Reserved Instances that specify the Region needed.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 64%;" aria-valuenow="64" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_510><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 510</p><br/>A company has developed a new video game as a web application. The application is in a three&#8211;tier architecture in a VPC with Amazon RDS for MySQL. In the database layer several players will compete concurrently online. The game's developers want to display a top&#8211;10 scoreboard in near&#8211;real&#8211;time and offer the ability to stop and restore the game while preserving the current scores.<br/><br/>What should a solutions architect do to meet these requirements?<br/><br/>A. Set up an Amazon ElastiCache for Memcached cluster to cache the scores for the web application to display.<br/>B. Set up an Amazon ElastiCache for Redis cluster to compute and cache the scores for the web application to display.<br/>C. Place an Amazon CloudFront distribution in front of the web application to cache the scoreboard in a section of the application.<br/>D. Create a read replica on Amazon RDS for MySQL to run queries to compute the scoreboard and serve the read traffic to the web application.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample371' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_511'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_644'>Random</a></p><div class='collapse' id='collapseExample371'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Create a read replica on Amazon RDS for MySQL to run queries to compute the scoreboard and serve the read traffic to the web application.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 64%;" aria-valuenow="64" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_511><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 511</p><br/>A company is developing a data lake solution in Amazon S3 to analyze large scale datasets. The solution makes infrequent SOL queries only in addition, the company wants to minimize infrastructure costs.<br/><br/>Which AWS service should be used to meet these requirements?<br/><br/>A. Amazon Athena<br/>B. Amazon Redshift Spectrum<br/>C. Amazon RDS for PostgreSQL<br/>D. Amazon Aurora<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample595' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_512'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_417'>Random</a></p><div class='collapse' id='collapseExample595'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Amazon Redshift Spectrum</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 64%;" aria-valuenow="64" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_512><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 512</p><br/>A company has developed a microservices application. It uses a client&#8211;facing API with Amazon API Gateway and multiple internal services hosted on Amazon EC2 instances to process user requests. The API is designed to support unpredictable surges in traffic, but internal services may become overwhelmed and unresponsive for a period of time during surges. A solutions architect needs to design a more reliable solution that reduces errors when internal services become unresponsive or unavailable.<br/><br/>Which solution meets these requirements?<br/><br/>A. Use AWS Auto Scaling to scale up internal services when there is a surge in traffic.<br/>B. Use different Availability Zones to host internal services. Send a notification to a system administrator when an internal service becomes unresponsive.<br/>C. Use an Elastic Load Balancer to distribute the traffic between internal services. Configure Amazon CloudWatch metrics to monitor traffic to internal services.<br/>D. Use Amazon Simple Queue Service (Amazon SQS) to store user requests as they arrive. Change the internal services to retrieve the requests from the queue for processing.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample285' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_513'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_172'>Random</a></p><div class='collapse' id='collapseExample285'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Use Amazon Simple Queue Service (Amazon SQS) to store user requests as they arrive. Change the internal services to retrieve the requests from the queue for processing.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 64%;" aria-valuenow="64" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_513><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 513</p><br/>A solutions architect must design a database solution for a high&#8211;traffic eCommerce web application.<br/><br/>The database stores customer profiles and shopping cart information.<br/><br/>The database must support a peak load of several million requests each second and deliver responses in milliseconds.<br/><br/>The operational overhead for managing and scaling the database must be minimized.<br/><br/>Which database solution should the solutions architect recommend?<br/><br/>A. Amazon Aurora<br/>B. Amazon DynamoDB<br/>C. Amazon RDS<br/>D. Amazon Redshift<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample677' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_514'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_528'>Random</a></p><div class='collapse' id='collapseExample677'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Amazon Aurora</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 64%;" aria-valuenow="64" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_514><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 514</p><br/>A company is designing a new application that runs in a VPC on Amazon EC2 instances. The application stores data in Amazon S3 and uses Amazon DynamoDB as its database. For compliance reasons, the company prohibits all traffic between the EC2 instances and other AWS services from passing over the public internet.<br/><br/>What can a solutions architect do to meet this requirement?<br/><br/>A. Configure gateway VPC endpoints to Amazon S3 and DynamoDB.<br/>B. Configure interface VPC endpoints to Amazon S3 and DynamoDB.<br/>C. Configure a gateway VPC endpoint to Amazon S3. Configure an interface VPC endpoint to DynamoDB.<br/>D. Configure a gateway VPC endpoint to DynamoDB. Configure an interface VPC endpoint to Amazon S3.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample415' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_515'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_618'>Random</a></p><div class='collapse' id='collapseExample415'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Configure a gateway VPC endpoint to Amazon S3. Configure an interface VPC endpoint to DynamoDB.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 65%;" aria-valuenow="65" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_515><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 515</p><br/>A company is moving its on&#8211;premises Oracle database to Amazon Aurora PostgreSQL. The database has several applications that write to the same tables. The applications need to be migrated one by one with a month in between each migration Management has expressed concerns that the database has a high number of reads and writes. The data must be kept in sync across both databases throughout tie migration.<br/><br/>What should a solutions architect recommend?<br/><br/>A. Use AWS DataSync for the initial migration. Use AWS Database Migration Service (AWS DMS) to create a change data capture (CDC) replication task and a table mapping to select all cables.<br/>B. Use AWS DataSync for the initial migration. Use AWS Database Migration Service (AWS DMS) to create a full load plus change data capture (CDC) replication task and a table mapping to select all tables.<br/>C. Use the AWS Schema Conversion Tool with AWS Database Migration Service (AWS DMS) using a memory optimized replication instance. Create a full load plus change data capture (CDC) replication task and a table mapping to select all tables.<br/>D. Use the AWS Schema Conversion Tool with AWS Database Migration Service (AWS DMS) using a compute optimized replication instance. Create a full load plus change data capture (CDC) replication task and a table mapping to select the largest tables.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample291' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation291' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_516'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_141'>Random</a></p><div class='collapse' id='collapseExample291'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Use the AWS Schema Conversion Tool with AWS Database Migration Service (AWS DMS) using a memory optimized replication instance. Create a full load plus change data capture (CDC) replication task and a table mapping to select all tables.</div></div></div><div class='collapse' id='explanation291'><div class='card card&#45;body'><div>
As you can see, we have three important memory buffers in this architecture for CDC in AWS DMS. If any of these buffers experience memory pressure, the migration can have performance issues that can potentially cause failures.

References:

AWS Database Migration Service > User Guide > Choosing the right AWS DMS replication instance for your migration


</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 65%;" aria-valuenow="65" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_516><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 516</p><br/>A company hosts a website on&#8211;premises and wants to migrate it to the AWS Cloud. The website exposes a single hostname to the internet but it routes its functions to different on&#8211;premises server groups based on the path of the URL. The server groups are scaled independently depending on the needs of the functions they support. The company has an AWS Direct Connect connection configured to its on&#8211;premises network.<br/><br/>What should a solutions architect do to provide path&#8211;based routing to send the traffic to the correct group of servers?<br/><br/>A. Route all traffic to an internet gateway. Configure pattern matching rules at the internet gateway to route traffic to the group of servers supporting that path.<br/>B. Route all traffic to a Network Load Balancer (NLB) with target groups for each group of servers. Use pattern matching rules at the NLB to route traffic to the correct target group.<br/>C. Route all traffic to an Application Load Balancer (ALB). Configure path&#8211;based routing at the ALB to route traffic to the correct target group for the servers supporting that path.<br/>D. Use Amazon Route 53 as the DNS server. Configure Route 53 path&#8211;based alias records to route traffic to the correct Elastic Load Balancer for the group of servers supporting that path.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample348' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_517'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_60'>Random</a></p><div class='collapse' id='collapseExample348'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Route all traffic to a Network Load Balancer (NLB) with target groups for each group of servers. Use pattern matching rules at the NLB to route traffic to the correct target group.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 65%;" aria-valuenow="65" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_517><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 517</p><br/>A financial services company has a web application that serves users in the United States and Europe. The application consists of a database tier and a web server tier. The database tier consists of a MySQL database hosted in us&#8211;east&#8211;1. Amazon Route 53 geoproximity routing is used to direct traffic to instances in the closest Region. A performance review of the system reveals that European users are not receiving the same level of query performance as those in the United States.<br/><br/>Which changes should be made to the database tier to improve performance?<br/><br/>A. Migrate the database to Amazon RDS for MySQL. Configure Multi&#8211;AZ in one of the European Regions.<br/>B. Migrate the database to Amazon DynamoDB. Use DynamoDB global tables to enable replication to additional Regions.<br/>C. Deploy MySQL instances in each Region. Deploy an Application Load Balancer in front of MySQL to reduce the load on the primary instance.<br/>D. Migrate the database to an Amazon Aurora global database in MySQL compatibility mode. Configure read replicas in one of the European Regions.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample24' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation24' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_518'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_119'>Random</a></p><div class='collapse' id='collapseExample24'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Migrate the database to an Amazon Aurora global database in MySQL compatibility mode. Configure read replicas in one of the European Regions.</div></div></div><div class='collapse' id='explanation24'><div class='card card&#45;body'><div>
The issue here is latency with read queries being directed from Australia to UK which is great physical distance. A solution is required for improving read performance in Australia.

An Aurora global database consists of one primary AWS Region where your data is mastered, and up to five read-only, secondary AWS Regions.

Aurora replicates data to the secondary AWS Regions with typical latency of under a second. You issue write operations directly to the primary DB instance in the primary AWS Region.

This solution will provide better performance for users in the Australia Region for queries. Writes must still take place in the UK Region but read performance will be greatly improved.

CORRECT: "Migrate the database to an Amazon Aurora global database in MySQL compatibility mode. Configure read replicas in ap-southeast-2" is the correct answer.

INCORRECT: "Migrate the database to Amazon RDS for MySQL. Configure Multi-AZ in the Australian Region" is incorrect. The database is located in UK. If the database is migrated to Australia then the reverse problem will occur. Multi-AZ does not assist with improving query performance across Regions.

INCORRECT: "Migrate the database to Amazon DynamoDB. Use DynamoDB global tables to enable replication to additional Regions" is incorrect as a relational database running on MySQL is unlikely to be compatible with DynamoDB.

INCORRECT: "Deploy MySQL instances in each Region. Deploy an Application Load Balancer in front of MySQL to reduce the load on the primary instance" is incorrect as you can only put ALBs in front of the web tier, not the DB tier.

References:

Amazon Aurora > User Guide for Aurora > Using Amazon Aurora global databases
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 65%;" aria-valuenow="65" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_518><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 518</p><br/>A company is designing a message&#8211;driven order processing application on AWS.<br/><br/>The application consists of many services and needs to communicate the results of its processing to multiple consuming services.<br/><br/>Each of the consuming services may take up to 5 days to receive the messages. Which process will meet these requirements?<br/><br/>A. The application sends the results of its processing to an Amazon Simple Notification Service (Amazon SNS) topic. Each consuming service subscribes to this SNS topic and consumes the results<br/>B. The application sends the results of its processing to an Amazon Simple Notification Service (Amazon SNS) topic. Each consuming service consumes the messages directly from its corresponding SNS topic.<br/>C. The application sends the results of its processing to an Amazon Simple Queue Service (Amazon SQS) queue. Each consuming service runs as an AWS Lambda function that consumes this single SQS queue.<br/>D. The application sends the results of its processing to an Amazon Simple Notification Service (Amazon SNS) topic. An Amazon Simple Queue Service (Amazon SQS) queue is created for each service and each queue is configured to be a subscriber of the SNS topic.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample716' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_519'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_256'>Random</a></p><div class='collapse' id='collapseExample716'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>The application sends the results of its processing to an Amazon Simple Queue Service (Amazon SQS) queue. Each consuming service runs as an AWS Lambda function that consumes this single SQS queue.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 65%;" aria-valuenow="65" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_519><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 519</p><br/>A company is implementing a data lake solution on Amazon S3. Its security policy mandates that the data stored in Amazon S3 should be encrypted at rest.<br/><br/>Which options can achieve this? (Select TWO.)<br/><br/>A. Use S3 server&#8211;side encryption with an Amazon EC2 key pair.<br/>B. Use S3 server&#8211;side encryption with customer&#8211;provided keys (SSE&#8211;C).<br/>C. Use S3 bucket policies to restrict access to the data at rest.<br/>D. Use client&#8211;side encryption before ingesting the data to Amazon S3 using encryption keys.<br/>E. Use SSL to encrypt the data while in transit to Amazon S3.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample787' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_520'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_224'>Random</a></p><div class='collapse' id='collapseExample787'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Use S3 server-side encryption with customer-provided keys (SSE-C).
<br><b>D. </b>Use client-side encryption before ingesting the data to Amazon S3 using encryption keys.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 65%;" aria-valuenow="65" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_520><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 520</p><br/>A company is running a two&#8211;tier eCommerce website using services. The current architect uses a public facing Elastic Load Balancer that sends traffic to Amazon EC2 instances in a private subnet. The static content is hosted on EC2 instances, and the dynamic content is retrieved from a MYSQL database. The application is running in the United States. The company recently started selling to users in Europe and Australia. A solutions architect needs to design solution so their international users have an improved browsing experience.<br/><br/>Which solution is MOST cost&#8211;effective?<br/><br/>A. Host the entire website on Amazon S3.<br/>B. Use Amazon CloudFront and Amazon S3 to host static images.<br/>C. Increase the number of public load balancers and EC2 instances.<br/>D. Deploy the two&#8211;tier website in AWS Regions in Europe and Australia.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample87' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_521'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_769'>Random</a></p><div class='collapse' id='collapseExample87'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Use Amazon CloudFront and Amazon S3 to host static images.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 65%;" aria-valuenow="65" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_521><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 521</p><br/>You have been asked to build a database warehouse using Amazon Redshift. You know a little about it, including that it is a SQL data warehouse solution, and uses industry standard ODBC and JDBC connections and PostgreSQL drivers. However you are not sure about what sort of storage it uses for database tables. What sort of storage does Amazon Redshift use for database tables?<br/><br/>A. InnoDB Tables<br/>B. NDB data storage<br/>C. Columnar data storage<br/>D. NDB CLUSTER Storage<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample747' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation747' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_522'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_690'>Random</a></p><div class='collapse' id='collapseExample747'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Columnar data storage</div></div></div><div class='collapse' id='explanation747'><div class='card card&#45;body'><div>
Amazon Redshift achieves efficient storage and optimum query performance through a combination of massively parallel processing, columnar data storage, and very efficient, targeted data compression encoding schemes.

Columnar storage for database tables is an important factor in optimizing analytic query performance because it drastically reduces the overall disk I/O requirements and reduces the amount of data you need to load from disk.

References:

Amazon Redshift > Database Developer Guide > Columnar storage</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 65%;" aria-valuenow="65" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_522><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 522</p><br/>A company currently has 250 TB of backup files stored in Amazon S3 in a vendor's proprietary format.<br/><br/>Using a Linux&#8211;based software application provided by the vendor, the company wants to retrieve files from Amazon S3, transform the files to an industry&#8211;standard format, and re&#8211;upload them to Amazon S3. The company wants to minimize the data transfer charges associated with this conversation.<br/><br/>What should a solutions architect do to accomplish this?<br/><br/>A. Install the conversion software as an Amazon S3 batch operation so the data is transformed without leaving Amazon S3.<br/>B. Install the conversion software onto an on&#8211;premises virtual machine. Perform the transformation and reupload the files to Amazon S3 from the virtual machine.<br/>C. Use AWS Snowball Edge devices to export the data and install the conversion software onto the devices. Perform the data transformation and re&#8211;upload the files to Amazon S3 from the Snowball Edge devices.<br/>D. Launch an Amazon EC2 instance in the same Region as Amazon S3 and install the conversion software onto the instance. Perform the transformation and re&#8211;upload the files to Amazon S3 from the EC2 instance.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample122' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_523'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_126'>Random</a></p><div class='collapse' id='collapseExample122'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Launch an Amazon EC2 instance in the same Region as Amazon S3 and install the conversion software onto the instance. Perform the transformation and re-upload the files to Amazon S3 from the EC2 instance.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 66%;" aria-valuenow="66" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_523><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 523</p><br/>A company is planning a large event where a promotional offer will be introduced. The company's website is hosted on AWS and backed by an Amazon RDS for PostgreSQL DB instance. The website explains the promotion and includes a sign&#8211;up page that collects user information and preferences. Management expects large and unpredictable volumes of traffic periodically, which will create many database writes.<br/><br/>A solutions architect needs to build a solution that does not change the underlying data model and ensures that submissions are not dropped before they are committed to the database.<br/><br/>Which solutions meets these requirements?<br/><br/>A. Immediately before the event, scale up the existing DB instance to meet the anticipated demand. Then scale down after the event.<br/>B. Use Amazon SQS to decouple the application and database layers. Configure an AWS Lambda function to write items from the queue into the database.<br/>C. Migrate to Amazon DynamoDB and manage throughput capacity with automatic scaling.<br/>D. Use Amazon ElastiCache for Memcached to increase write capacity to the DB instance.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample686' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_524'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_626'>Random</a></p><div class='collapse' id='collapseExample686'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Use Amazon SQS to decouple the application and database layers. Configure an AWS Lambda function to write items from the queue into the database.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 66%;" aria-valuenow="66" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_524><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 524</p><br/>A solutions architect has configured the following IAM policy.<br/>A solutions architect has configured the following IAM policy.<br/>Which action will be allowed by the policy?<br/><br/>A. An AWS Lambda function can be deleted from any network.<br/>B. An AWS Lambda function can be created from any network.<br/>C. An AWS Lambda function can be deleted from the 100.220.0.0/20 network<br/>D. An AWS Lambda function can be deleted from the 220 100.16 0 20 network<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample505' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_525'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_651'>Random</a></p><div class='collapse' id='collapseExample505'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>An AWS Lambda function can be deleted from the 220 100.16 0 20 network</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 66%;" aria-valuenow="66" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_525><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 525</p><br/>A company's website is using an Amazon RDS MySQL Multi&#8211;AZ DB instance for its transactional data storage. There are other internal systems that query this DB instance to fetch data for internal batch processing. The RDS DB instance slows down significantly when the internal systems fetch data. This impacts the website's read and write performance, and the users experience slow response times.<br/><br/>Which solution will improve the website's performance?<br/><br/>A. Use an RDS PostgreSQL DB instance instead of a MySQL database.<br/>B. Use Amazon ElastiCache to cache the query responses for the website.<br/>C. Add an additional Availability Zone to the current RDS MySQL Multi&#8211;AZ DB instance.<br/>D. Add a read replica to the RDS DB instance and configure the internal systems to query the read replica.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample23' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation23' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_526'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_365'>Random</a></p><div class='collapse' id='collapseExample23'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Add a read replica to the RDS DB instance and configure the internal systems to query the read replica.</div></div></div><div class='collapse' id='explanation23'><div class='card card&#45;body'><div>
Amazon RDS Read Replicas
Enhanced performance
You can reduce the load on your source DB instance by routing read queries from your applications to the read replica. Read replicas allow you to elastically scale out beyond the capacity constraints of a single DB instance for read-heavy database workloads. Because read replicas can be promoted to master status, they are useful as part of a sharding implementation.

To further maximize read performance, Amazon RDS for MySQL allows you to add table indexes directly to Read Replicas, without those indexes being present on the master.
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 66%;" aria-valuenow="66" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_526><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 526</p><br/>An online gaming company is designing a game that is expected to be popular all over the world. A solutions architect needs to define an AWS Cloud architecture that supports near&#8211;real&#8211;time recording and displaying of current game statistics for each player, along with the names of the top 25 players in the world, at any given time.<br/><br/>Which AWS database solution and configuration should the solutions architect use to meet these requirements?<br/><br/>A. Use Amazon RDS for MySQL as the data store for player activity. Configure the RDS DB instance for Multi&#8211;AZ support.<br/>B. Use Amazon DynamoDB as the data store for player activity. Configure DynamoDB Accelerator (DAX) for the player data.<br/>C. Use Amazon DynamoDB as the data store for player activity. Configure global tables in each required AWS Region for the player data.<br/>D. Use Amazon RDS for MySQL as the data store for player activity. Configure cross&#8211;region read replicas in each required AWS Region based on player proximity.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample430' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_527'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_155'>Random</a></p><div class='collapse' id='collapseExample430'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Use Amazon RDS for MySQL as the data store for player activity. Configure cross-region read replicas in each required AWS Region based on player proximity.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 66%;" aria-valuenow="66" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_527><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 527</p><br/>A company has an application that posts messages to Amazon SQS. Another application polls the queue and processes the messages in an I/O&#8211;intensive operation. The company has a service level agreement (SLA) that specifies the maximum amount of time that can elapse between receiving the messages and responding to the users. Due to an increase in the number of messages, the company has difficulty meeting its SLA consistently.<br/><br/>What should a solutions architect do to help improve the application's processing time and ensure it can handle the load at any level?<br/><br/>A. Create an Amazon Machine Image (AMI) from the instance used for processing. Terminate the instance and replace it with a larger size.<br/>B. Create an Amazon Machine Image (AMI) from the instance used for processing. Terminate the instance and replace it with an Amazon EC2 Dedicated Instance.<br/>C. Create an Amazon Machine Image (AMI) from the instance used for processing. Create an Auto Scaling group using this image in its launch configuration. Configure the group with a target tracking policy to keep its aggregate CPU utilization below 70%.<br/>D. Create an Amazon Machine Image (AMI) from the instance used for processing. Create an Auto Scaling group using this image in its launch configuration. Configure the group with a target tracking policy based on the age of the oldest message in the SQS queue.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample118' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_528'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_733'>Random</a></p><div class='collapse' id='collapseExample118'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Create an Amazon Machine Image (AMI) from the instance used for processing. Create an Auto Scaling group using this image in its launch configuration. Configure the group with a target tracking policy based on the age of the oldest message in the SQS queue.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 66%;" aria-valuenow="66" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_528><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 528</p><br/>A company runs a legacy application with a single&#8211;tier architecture on an Amazon EC2 instance Disk I/O is low. With occasional small spikes during business hours. The company requires the instance to be stopped from 8 PM to 8 AM daily.<br/><br/>Which storage option is MOST appropriate for this workload?<br/><br/>A. Amazon EC2 instance storage<br/>B. Amazon EBS General Purpose SSD (gp2) storage<br/>C. Amazon S3<br/>D. Amazon EBS Provisioned IOPS SSD (io2) storage<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample656' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_529'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_211'>Random</a></p><div class='collapse' id='collapseExample656'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Amazon EBS General Purpose SSD (gp2) storage</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 66%;" aria-valuenow="66" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_529><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 529</p><br/>A company has an asynchronous web application where Amazon API Gateway triggers AWS Lambda functions to perform write and update operations on an Amazon RDS DB instance. During periods of extreme use API Gateway and Lambda scale in response to the incoming workload but service outages occur due to congestion with Amazon RDS.<br/><br/>The company is seeking a cost&#8211;effective design to alleviate this congestion. What should a solutions architect recommend'?<br/><br/>A. implement RDS storage autoscaling with a larger instance type<br/>B. Create read replicas to alleviate me read requests on the database<br/>C. Use Amazon Kinesis to poll the incoming requests from API Gateway to the Lambda functions<br/>D. Use Amazon Simple Queue Service (Amazon SQS) to buffer the incoming requests before delivering them to the Lambda functions<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample516' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_530'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_147'>Random</a></p><div class='collapse' id='collapseExample516'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Use Amazon Simple Queue Service (Amazon SQS) to buffer the incoming requests before delivering them to the Lambda functions</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 66%;" aria-valuenow="66" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_530><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 530</p><br/>A company serves content to its subscribers across the world using an application running on AWS. The application has several Amazon EC2 instances in a private subnet behind an Application Load Balancer (ALB). Due to a recent change in copyright restrictions, the chief information officer (CIO) wants to block access for certain countries.<br/><br/>Which action will meet these requirements?<br/><br/>A. Modify the ALB security group to deny incoming traffic from blocked countries.<br/>B. Modify the security group for EC2 instances to deny incoming traffic from blocked countries.<br/>C. Use Amazon CloudFront to serve the application and deny access to blocked countries.<br/>D. Use ALB listener rules to return access denied responses to incoming traffic from blocked countries.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample180' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation180' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_531'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_302'>Random</a></p><div class='collapse' id='collapseExample180'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Use Amazon CloudFront to serve the application and deny access to blocked countries.</div></div></div><div class='collapse' id='explanation180'><div class='card card&#45;body'><div>
"block access for certain countries." You can use geo restriction, also known as geo blocking, to prevent users in specific geographic locations from accessing content that you're distributing through a CloudFront web distribution.

When a user requests your content, CloudFront typically serves the requested content regardless of where the user is located. If you need to prevent users in specific countries from accessing your content, you can use the CloudFront geo restriction feature to do one of the following:

Allow your users to access your content only if they're in one of the countries on a whitelist of approved countries.

Prevent your users from accessing your content if they're in one of the countries on a blacklist of banned countries.

For example, if a request comes from a country where, for copyright reasons, you are not authorized to distribute your content, you can use CloudFront geo restriction to block the request. This is the easiest and most effective way to implement a geographic restriction for the delivery of content.

CORRECT: "Use Amazon CloudFront to serve the application and deny access to blocked countries" is the correct answer.

INCORRECT: "Use a Network ACL to block the IP address ranges associated with the specific countries" is incorrect as this would be extremely difficult to manage.

INCORRECT: "Modify the ALB security group to deny incoming traffic from blocked countries" is incorrect as security groups cannot block traffic by country.

INCORRECT: "Modify the security group for EC2 instances to deny incoming traffic from blocked countries" is incorrect as security groups cannot block traffic by country.

References:

Amazon CloudFront > Developer Guide > Restricting the geographic distribution of your content</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 67%;" aria-valuenow="67" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_531><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 531</p><br/>An application hosted on AWS is experiencing performance problems, and the application vendor wants to perform an analysis of the log file to troubleshoot further. The log file is stored on Amazon S3 and is 10 GB in size. The application owner will make the log file available to the vendor for a limited time.<br/><br/>What is the MOST secure way to do this?<br/><br/>A. Enable public read on the S3 object and provide the link to the vendor.<br/>B. Upload the file to Amazon WorkDocs and share the public link with the vendor.<br/>C. Generate a presigned URL and have the vendor download the log file before it expires.<br/>D. Create an IAM user for the vendor to provide access to the S3 bucket and the application. Enforce multi&#8211;factor authentication.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample34' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation34' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_532'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_11'>Random</a></p><div class='collapse' id='collapseExample34'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Generate a presigned URL and have the vendor download the log file before it expires.</div></div></div><div class='collapse' id='explanation34'><div class='card card&#45;body'><div>
Share an object with others
All objects by default are private. Only the object owner has permission to access these objects. However, the object owner can optionally share objects with others by creating a presigned URL, using their own security credentials, to grant time-limited permission to download the objects.

When you create a presigned URL for your object, you must provide your security credentials, specify a bucket name, an object key, specify the HTTP method (GET to download the object) and expiration date and time. The presigned URLs are valid only for the specified duration.

Anyone who receives the presigned URL can then access the object. For example, if you have a video in your bucket and both the bucket and the object are private, you can share the video with others by generating a presigned URL.
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 67%;" aria-valuenow="67" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_532><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 532</p><br/>A solutions architect is designing a solution to access a catalog of images and provide users with the ability to submit requests to customize images. Image customization parameters will be in any request sent to an AWS API Gateway API. The customized image will be generated on demand, and users will receive a link they can click to view or download their customized image. The solution must be highly available for viewing and customizing images.<br/><br/>What is the MOST cost&#8211;effective solution to meet these requirements?<br/><br/>A. Use Amazon EC2 instances to manipulate the original image into the requested customization. Store the original and manipulated images in Amazon S3. Configure an Elastic Load Balancer in front of the EC2 instances.<br/>B. Use AWS Lambda to manipulate the original image to the requested customization. Store the original and manipulated images in Amazon S3. Configure an Amazon CloudFront distribution with the S3 bucket as the origin.<br/>C. Use AWS Lambda to manipulate the original image to the requested customization. Store the original images in Amazon S3 and the manipulated images in Amazon DynamoDB. Configure an Elastic Load Balancer in front of the Amazon EC2 instances.<br/>D. Use Amazon EC2 instances to manipulate the original image into the requested customization. Store the original images in Amazon S3 and the manipulated images in Amazon DynamoDB. Configure an Amazon CloudFront distribution with the S3 bucket as the origin.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample12' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation12' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_533'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_525'>Random</a></p><div class='collapse' id='collapseExample12'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Use AWS Lambda to manipulate the original image to the requested customization. Store the original and manipulated images in Amazon S3. Configure an Amazon CloudFront distribution with the S3 bucket as the origin.</div></div></div><div class='collapse' id='explanation12'><div class='card card&#45;body'><div>
AWS Lambda is a compute service that lets you run code without provisioning or managing servers. AWS Lambda executes your code only when needed and scales automatically, from a few requests per day to thousands per second. You pay only for the compute time you consume – there is no charge when your code is not running. With AWS Lambda, you can run code for virtually any type of application or backend service – all with zero administration. AWS Lambda runs your code on a high-availability compute infrastructure and performs all of the administration of the compute resources, including server and operating system maintenance, capacity provisioning and automatic scaling, code monitoring, and logging.

All you need to do is supply your code in one of the languages that AWS Lambda supports.

Storing your static content with S3 provides a lot of advantages. But to help optimize your application's performance and security while effectively managing cost, we recommend that you also set up Amazon CloudFront to work with your S3 bucket to serve and protect the content. CloudFront is a content delivery network (CDN) service that delivers static and dynamic web content, video streams, and APIs around the world, securely and at scale. By design, delivering data out of CloudFront can be more cost effective than delivering it from S3 directly to your users.

CloudFront serves content through a worldwide network of data centers called Edge Locations. Using edge servers to cache and serve content improves performance by providing content closer to where viewers are located. CloudFront has edge servers in locations all around the world.

All solutions presented are highly available. The key requirement that must be satisfied is that the solution should be cost-effective and you must choose the most cost-effective option.

Therefore, it's best to eliminate services such as Amazon EC2 and ELB as these require ongoing costs even when they're not used. Instead, a fully serverless solution should be used. AWS Lambda, Amazon S3 and CloudFront are the best services to use for these requirements.

CORRECT: "Use AWS Lambda to manipulate the original images to the requested customization. Store the original and manipulated images in Amazon S3. Configure an Amazon CloudFront distribution with the S3 bucket as the origin" is the correct answer.

INCORRECT: "Use Amazon EC2 instances to manipulate the original images into the requested customization. Store the original and manipulated images in Amazon S3. Configure an Elastic Load Balancer in front of the EC2 instances" is incorrect. This is not the most cost-effective option as the ELB and EC2 instances will incur costs even when not used.

INCORRECT: "Use AWS Lambda to manipulate the original images to the requested customization. Store the original images in Amazon S3 and the manipulated images in Amazon DynamoDB. Configure an Elastic Load Balancer in front of the Amazon EC2 instances" is incorrect. This is not the most cost-effective option as the ELB will incur costs even when not used. Also, Amazon DynamoDB will incur RCU/WCUs when running and is not the best choice for storing images.

INCORRECT: "Use Amazon EC2 instances to manipulate the original images into the requested customization. Store the original images in Amazon S3 and the manipulated images in Amazon DynamoDB. Configure an Amazon CloudFront distribution with the S3 bucket as the origin" is incorrect. This is not the most cost-effective option as the EC2 instances will incur costs even when not used.

References:

Serverless on AWS</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 67%;" aria-valuenow="67" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_533><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 533</p><br/>A company relies on an application that needs at least 4 Amazon EC2 instances during regular traffic and must scale up to 12 EC2 instances during peak loads.<br/><br/>The application is critical to the business and must be highly available.<br/><br/>Which solution will meet these requirements?<br/><br/>A. Deploy the EC2 instances in an Auto Scaling group. Set the minimum to 4 and the maximum to M, with 2 in Availability Zone A and 2 in Availability Zone B<br/>B. Deploy the EC2 instances in an Auto Scaling group. Set the minimum to 4 and the maximum to 12, with all 4 in Availability Zone A<br/>C. Deploy the EC2 instances in an Auto Scaling group. Set the minimum to 8 and the maximum to 12, with 4 in Availability Zone A and 4 in Availability Zone B<br/>D. Deploy the EC2 instances in an Auto Scaling group. Set the minimum to 8 and the maximum to 12 with all 8 in Availability Zone A<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample721' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation721' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_534'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_82'>Random</a></p><div class='collapse' id='collapseExample721'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Deploy the EC2 instances in an Auto Scaling group. Set the minimum to 8 and the maximum to 12, with 4 in Availability Zone A and 4 in Availability Zone B</div></div></div><div class='collapse' id='explanation721'><div class='card card&#45;body'><div>
It requires HA and if one AZ is down then at least 4 instances will be active in another AZ which is key for this question.
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 67%;" aria-valuenow="67" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_534><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 534</p><br/>A solutions architect is using an AWS Cloud Formation template to deploy a three&#8211;tier web application. The web application consists of a web tier and an application tier that stores and retrieves user data in Amazon DynamoDB tables. The web and application tiers are hosted on Amazon EC2 instances, and the database tier is not publicly accessible. The application EC2 instances need to access the DynamoDB tables without exposing API credentials in the template.<br/><br/>What should the solutions architect do to meet these requirements?<br/><br/>A. Create an IAM role to read the DynamoOB tables. Associate the role with the application instances by reference an instance profile<br/>B. Create an IAM role that has the required permissions to read and write from the DynamoOB tables. Add the role to the EC2 instance profile and associate the instance profile with the apphcanon instances<br/>C. Use the parameter section in the AWS CkHidFormaton template to have the user input access and secret keys from an already&#8211;created IAM user mat has the required permissions to read and write from the DynamoOB tables<br/>D. Create an IAM user m the AWS CioudFormation template that has the required permissions to read and write from the DynamoOB tables. Use the GetAti function to retrieve the access and secret keys and pass them to the application instances through the user data<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample525' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_535'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_240'>Random</a></p><div class='collapse' id='collapseExample525'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Create an IAM role that has the required permissions to read and write from the DynamoOB tables. Add the role to the EC2 instance profile and associate the instance profile with the apphcanon instances</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 67%;" aria-valuenow="67" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_535><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 535</p><br/>A company hosts more than 300 global websites and applications. The company requires a platform to analyze more than 30 TB of clickstream data each day. What should a solutions architect do to transmit and process the clickstream data?<br/><br/>A. Design an AWS Data Pipeline to archive the data to an Amazon S3 bucket and run an Amazon EMR cluster with the data to generate analytics.<br/>B. Create an Auto Scaling group of Amazon EC2 instances to process the data and send it to an Amazon S3 data lake for Amazon Redshift to use for analysis.<br/>C. Cache the data to Amazon CloudFront. Store the data in an Amazon S3 bucket. When an object is added to the S3 bucket, run an AWS Lambda function to process the data for analysis.<br/>D. Collect the data from Amazon Kinesis Data Streams. Use Amazon Kinesis Data firehose to transmit the data to an Amazon S3 data lake. Load the data in Amazon Redshift for analysis.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample299' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_536'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_253'>Random</a></p><div class='collapse' id='collapseExample299'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Cache the data to Amazon CloudFront. Store the data in an Amazon S3 bucket. When an object is added to the S3 bucket, run an AWS Lambda function to process the data for analysis.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 67%;" aria-valuenow="67" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_536><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 536</p><br/>A company hosts its multi&#8211;tier public web application in the AWS Cloud. The web application runs on Amazon EC2 instances and its database runs on Amazon RDS. The company is anticipating a large increase in sales during an upcoming holiday weekend A solutions architect needs to build a solution to analyze the performance of the web application with a granularity of no more than 2 minutes.<br/><br/>What should the solutions architect do to meet this requirement?<br/><br/>A. Send Amazon CloudWatch logs to Amazon Redshift Use Amazon QuickSight to perform further analysis<br/>B. Enable detailed monitoring on all EC2 instances Use Amazon CloudWatch metrics to perform further analysis<br/>C. Create an AWS Lambda function to fetch EC2 logs from Amazon CloudWatch Logs Use Amazon CloudWatch metrics to perform further analysis<br/>D. Send EC2 logs to Amazon S3 Use Amazon Redshift to fetch logs from the S3 bucket to process raw data for further analysis with Amazon QuickSight.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample487' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_537'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_233'>Random</a></p><div class='collapse' id='collapseExample487'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Enable detailed monitoring on all EC2 instances Use Amazon CloudWatch metrics to perform further analysis</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 67%;" aria-valuenow="67" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_537><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 537</p><br/>A company is managing health records on&#8211;premises. The company must keep these records indefinitely, disable any modifications to the records once they are stored, and granularly audit access at all levels. The chief technology officer (CTO) is concerned because there are already millions of records not being used by any application, and the current infrastructure is running out of space. The CTO has requested a solutions architect design a solution to move existing data and support future records.<br/><br/>Which services can the solutions architect recommend to meet these requirements?<br/><br/>A. Use AWS DataSync to move existing data to AWS. Use Amazon S3 to store existing and new data. Enable Amazon S3 object lock and enable AWS CloudTrail with data events.<br/>B. Use AWS Storage Gateway to move existing data to AWS. Use Amazon S3 to store existing and new data. Enable Amazon S3 object lock and enable AWS CloudTrail with management events.<br/>C. Use AWS DataSync to move existing data to AWS. Use Amazon S3 to store existing and new data. Enable Amazon S3 object lock and enable AWS CloudTrail with management events.<br/>D. Use AWS Storage Gateway to move existing data to AWS. Use Amazon Elastic Block Store (Amazon EBS) to store existing and new data. Enable Amazon S3 object lock and enable Amazon S3 server access logging.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample45' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation45' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_538'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_80'>Random</a></p><div class='collapse' id='collapseExample45'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Use AWS DataSync to move existing data to AWS. Use Amazon S3 to store existing and new data. Enable Amazon S3 object lock and enable AWS CloudTrail with data events.</div></div></div><div class='collapse' id='explanation45'><div class='card card&#45;body'><div>
Keyword: Move existing data and support future records + Granular audit access at all levels

Use AWS DataSync to migrate existing data to Amazon S3, and then use the File Gateway configuration of AWS Storage Gateway to retain access to the migrated data and for ongoing updates from your on-premises file-based applications.

Need a solution to move existing data and support future records = AWS DataSync should be used for migration.

Need granular audit access at all levels = Data Events should be used in CloudTrail, Management Events is enabled by default.

CORRECT: "Use AWS DataSync to move existing data to AWS. Use Amazon S3 to store existing and new data. Enable Amazon S3 object lock and enable AWS CloudTrail with data events" is the correct answer.

INCORRECT: "Use AWS Storage Gateway to move existing data to AWS. Use Amazon S3 to store existing and new data. Enable Amazon S3 object lock and enable AWS CloudTrail with management events" is incorrect as "current infrastructure is running out of space" INCORRECT: "Use AWS DataSync to move existing data to AWS. Use Amazon S3 to store existing and new data. Enable Amazon S3 object lock and enable AWS CloudTrail with management events." is incorrect as "Management Events is enabled by default" INCORRECT: "Use AWS Storage Gateway to move existing data to AWS. Use Amazon Elastic Block Store (Amazon EBS) to store existing and new data. Enable Amazon S3 object lock and enable Amazon S3 server access logging." is incorrect as "current infrastructure is running out of space"

References:

AWS DataSync
AWS CloudTrail
AWS Storage Gateway</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 67%;" aria-valuenow="67" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_538><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 538</p><br/>Much of your company's data does not need to be accessed often, and can take several hours for retrieval time, so it's stored on Amazon Glacier. However someone within your organization has expressed concerns that his data is more sensitive than the other data, and is wondering whether the high level of encryption that he knows is on S3 is also used on the much cheaper Glacier service.<br/><br/>Which of the following statements would be most applicable in regards to this concern?<br/><br/>A. There is no encryption on Amazon Glacier, that's why it is cheaper.<br/>B. Amazon Glacier automatically encrypts the data using AES&#8211;128 a lesser encryption method than Amazon S3 but you can change it to AES&#8211;256 if you are willing to pay more.<br/>C. Amazon Glacier automatically encrypts the data using AES&#8211;256, the same as Amazon S3.<br/>D. Amazon Glacier automatically encrypts the data using AES&#8211;128 a lesser encryption method than Amazon S3.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample741' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation741' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_539'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_650'>Random</a></p><div class='collapse' id='collapseExample741'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Amazon Glacier automatically encrypts the data using AES-256, the same as Amazon S3.</div></div></div><div class='collapse' id='explanation741'><div class='card card&#45;body'><div>
Like Amazon S3, the Amazon Glacier service provides low-cost, secure, and durable storage. But where S3 is designed for rapid retrieval, Glacier is meant to be used as an archival service for data that is not accessed often, and for which retrieval times of several hours are suitable.

Amazon Glacier automatically encrypts the data using AES-256 and stores it durably in an immutable form. Amazon Glacier is designed to provide average annual durability of 99.999999999% for an archive. It stores each archive in multiple facilities and multiple devices. Unlike traditional systems which can require laborious data verification and manual repair, Glacier performs regular, systematic data integrity checks, and is built to be automatically self-healing.

References:

Amazon Web Services: Overview of Security Processes
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 68%;" aria-valuenow="68" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_539><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 539</p><br/>A company has a dynamic web application hosted on two Amazon EC2 instances. The company has its own SSL certificate, which is on each instance to perform SSL termination.<br/><br/>There has been an increase in traffic recently, and the operations team determined that SSL encryption and decryption is causing the compute capacity of the web servers to reach their maximum limit.<br/><br/>What should a solutions architect do to increase the application's performance?<br/><br/>A. Create a new SSL certificate using AWS Certificate Manager (ACM). Install the ACM certificate on each instance.<br/>B. Create an Amazon S3 bucket. Migrate the SSL certificate to the S3 bucket. Configure the EC2 instances to reference the bucket for SSL termination.<br/>C. Create another EC2 instance as a proxy server. Migrate the SSL certificate to the new instance and configure it to direct connections to the existing EC2 instances.<br/>D. Import the SSL certificate into AWS Certificate Manager (ACM). Create an Application Load Balancer with an HTTPS listener that uses the SSL certificate from ACM.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample406' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_540'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_98'>Random</a></p><div class='collapse' id='collapseExample406'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Import the SSL certificate into AWS Certificate Manager (ACM). Create an Application Load Balancer with an HTTPS listener that uses the SSL certificate from ACM.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 68%;" aria-valuenow="68" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_540><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 540</p><br/>A company plans to host a survey website on AWS. The company anticipates an unpredictable amount of traffic. This traffic results in asynchronous updates to the database. The company wants to ensure that writes to the database hosted on AWS do not get dropped.<br/><br/>How should the company write its application to handle these database requests?<br/><br/>A. Configure the application to publish to an Amazon Simple Notification Service (Amazon SNS) topic. Subscribe the database to the SNS topic.<br/>B. Configure the application to subscribe to an Amazon Simple Notification Service (Amazon SNS) topic. Publish the database updates to the SNS topic.<br/>C. Use Amazon Simple Queue Service (Amazon SQS) FIFO queues to queue the database connection until the database has resources to write the data.<br/>D. Use Amazon Simple Queue Service (Amazon SQS) FIFO queues for capturing the writes and draining the queue as each write is made to the database.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample329' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_541'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_706'>Random</a></p><div class='collapse' id='collapseExample329'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Configure the application to publish to an Amazon Simple Notification Service (Amazon SNS) topic. Subscribe the database to the SNS topic.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 68%;" aria-valuenow="68" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_541><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 541</p><br/>A company plans to deploy a new application in AWS that reads and writes information to a database.<br/><br/>The company wants to deploy the application in two different AWS Regions with each application writing to a database in their Region.<br/><br/>The databases in the Two Regions needs to keep We data synchronized What should be used to meet these requirements?<br/><br/>A. Use Amazon Athena with Amazon S3 Cross&#8211;Region Replication<br/>B. Use AWS Database Migration Service (AWS DMS] with change data capture between an RDS for MySQL cluster in each Region<br/>C. Use Amazon DynamoDB with global tables<br/>D. Use Amazon RDS for PostgreSQL cluster with a Cross&#8211;Region Read Replica<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample591' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_542'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_474'>Random</a></p><div class='collapse' id='collapseExample591'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Use Amazon Athena with Amazon S3 Cross-Region Replication</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 68%;" aria-valuenow="68" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_542><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 542</p><br/>A company wants to improve the availability of an existing firewall.<br/><br/>To meet the compliance requirements of the applications hosted in the VPC.<br/><br/>The company's security team is using a proprietary firewall running on Amazon EC2 instances. All internet traffic flows through the primary firewall.<br/><br/>When the primary firewall goes down, the team manually changes the VPC route table so that it uses a secondary firewall running in a different Availability Zone.<br/><br/>Which strategies should a solutions architect use to improve the availability of the firewall? (Select TWO.)<br/><br/>A. Create an EC2 gateway endpoint In the VPC where the firewall is hosted.<br/>B. Create an EC2 interface endpoint in the VPC where the firewall is hosted.<br/>C. Enable enhanced networking on the EC2 instance running the proprietary firewall<br/>D. Deploy a scheduled AWS Lambda function in the VPC to monitor the primary firewall and change the route table to use the secondary firewall in case of failure.<br/>E. Monitor the firewall instance health in Amazon EventBridge (Amazon CloudWatch Events). Trigger an event rule to restart the primary firewall upon a detected failure.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample570' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_543'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_337'>Random</a></p><div class='collapse' id='collapseExample570'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Deploy a scheduled AWS Lambda function in the VPC to monitor the primary firewall and change the route table to use the secondary firewall in case of failure.
<br><b>E. </b>Monitor the firewall instance health in Amazon EventBridge (Amazon CloudWatch Events). Trigger an event rule to restart the primary firewall upon a detected failure.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 68%;" aria-valuenow="68" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_543><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 543</p><br/>A solutions architect must create a highly available bastion host architecture. The solution needs to be resilient within a single AWS Region and should require only minimal effort to maintain.<br/><br/>What should the solutions architect do to meet these requirements?<br/><br/>A. Create a Network Load Balancer backed by an Auto Scaling group with a UDP listener.<br/>B. Create a Network Load Balancer backed by the existing serves in different Availability Zones as the target.<br/>C. Create a Network Load Balancer backed by a Spot Fleet with instances in a group with instances in a partition placement group.<br/>D. Create a Network Load Balancer backed by an Auto Scaling with instances in multiple Availability zones as the target.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample513' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_544'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_715'>Random</a></p><div class='collapse' id='collapseExample513'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Create a Network Load Balancer backed by an Auto Scaling with instances in multiple Availability zones as the target.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 68%;" aria-valuenow="68" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_544><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 544</p><br/>A company captures clickstream data from multiple websites and analyzes it using batch processing. The data is loaded nightly into Amazon Redshift and is consumed by business analysts. The company wants to move towards near&#8211;real&#8211;time data processing for timely insights. The solution should process the streaming data with minimal effort and operational overhead.<br/><br/>Which combination of AWS services are MOST cost&#8211;effective for this solution? (Choose two.)<br/><br/>A. Amazon EC2<br/>B. AWS Lambda<br/>C. Amazon Kinesis Data Streams<br/>D. Amazon Kinesis Data Firehose<br/>E. Amazon Kinesis Data Analytics<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample4' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation4' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_545'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_200'>Random</a></p><div class='collapse' id='collapseExample4'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Amazon EC2
<br><b>D. </b>Amazon Kinesis Data Firehose</div></div></div><div class='collapse' id='explanation4'><div class='card card&#45;body'><div>
Kinesis Data Streams and Kinesis Client Library (KCL) – Data from the data source can be continuously captured and streamed in near real-time using Kinesis Data Streams. With the Kinesis Client Library (KCL), you can build your own application that can preprocess the streaming data as they arrive and emit the data for generating incremental views and downstream analysis. Kinesis Data Analytics – This service provides the easiest way to process the data that is streaming through Kinesis Data Stream or Kinesis Data Firehose using SQL. This enables customers to gain actionable insight in near real-time from the incremental stream before storing it in Amazon S3.

Lambda architecture building blocks on AWS

References:

Evolve from batch to real-time analytics</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 68%;" aria-valuenow="68" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_545><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 545</p><br/>Does DynamoDB support in&#8211;place atomic updates?<br/><br/>A. Yes<br/>B. No<br/>C. It does support in&#8211;place non&#8211;atomic updates<br/>D. It is not defined<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample765' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation765' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_546'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_133'>Random</a></p><div class='collapse' id='collapseExample765'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Yes</div></div></div><div class='collapse' id='explanation765'><div class='card card&#45;body'><div>
DynamoDB supports in-place atomic updates.

References:

Amazon DynamoDB > Developer Guide > Working with Items and Attributes</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 68%;" aria-valuenow="68" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_546><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 546</p><br/>A company is building a website that relies on reading and writing to an Amazon DynamoDB database. The traffic associated with the website predictably peaks during business hours on weekdays and declines overnight and during weekends. A solutions architect needs to design a cost&#8211;effective solution that can handle the load.<br/><br/>What should the solutions architect do to meet these requirements?<br/><br/>A. Enable DynamoDB Accelerator (DAX) to cache the data.<br/>B. Enable Multi&#8211;AZ replication for the DynamoDB database.<br/>C. Enable DynamoDB auto scaling when creating the tables.<br/>D. Enable DynamoDB On&#8211;Demand capacity allocation when creating the tables.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample214' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_547'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_777'>Random</a></p><div class='collapse' id='collapseExample214'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Enable DynamoDB auto scaling when creating the tables.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 69%;" aria-valuenow="69" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_547><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 547</p><br/>A Solutions Architect must design a web application that will be hosted on AWS, allowing users to purchase access to premium, shared content that is stored in an S3 bucket. Upon payment, content will be available for download for 14 days before the user is denied access.<br/><br/>Which of the following would be the LEAST complicated implementation?<br/><br/>A. Use an Amazon CloudFront distribution with an origin access identity (OAI). Configure the distribution with an Amazon S3 origin to provide access to the file through signed URLs. Design a Lambda function to remove data that is older than 14 days.<br/>B. Use an S3 bucket and provide direct access to the file. Design the application to track purchases in a DynamoDB table. Configure a Lambda function to remove data that is older than 14 days based on a query to Amazon DynamoDB.<br/>C. Use an Amazon CloudFront distribution with an OAI. Configure the distribution with an Amazon S3 origin to provide access to the file through signed URLs. Design the application to set an expiration of 14 days for the URL.<br/>D. Use an Amazon CloudFront distribution with an OAI. Configure the distribution with an Amazon S3 origin to provide access to the file through signed URLs. Design the application to set an expiration of 60 minutes for the URL and recreate the URL as necessary.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample265' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_548'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_237'>Random</a></p><div class='collapse' id='collapseExample265'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Use an Amazon CloudFront distribution with an OAI. Configure the distribution with an Amazon S3 origin to provide access to the file through signed URLs. Design the application to set an expiration of 14 days for the URL.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 69%;" aria-valuenow="69" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_548><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 548</p><br/>An application running on AWS generates audit logs of operational activities Compliance requirements mandate that the application retain the logs for 5 years.<br/><br/>How can these requirements be met?<br/><br/>A. Save the togs in an Amazon S3 bucket and enable MFA Delete on the bucket<br/>B. Save the togs In an Amazon Elastic File System (Amazon EFS) volume and use Network File System version 4 (NFSv4) locking with the volume<br/>C. Save the togs in an Amazon S3 Glacier vault and define a vault lock policy<br/>D. Save the logs in an Amazon Elastic Block Store (Amazon EBS) volume and take monthly snapshots<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample567' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_549'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_570'>Random</a></p><div class='collapse' id='collapseExample567'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Save the togs in an Amazon S3 bucket and enable MFA Delete on the bucket</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 69%;" aria-valuenow="69" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_549><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 549</p><br/>A company hosts an application on multiple Amazon EC2 instances. The application processes messages from an Amazon SQS queue writes to an Amazon RDS table and deletes the message from the queue Occasional duplicate records are found in the RDS table. The SQS queue does not contain any duplicate messages.<br/><br/>What should a solutions architect do to ensure messages are being processed once only?<br/><br/>A. Use the CreateQueue API call to create a new queue<br/>B. Use the Add Permission API call to add appropriate permissions<br/>C. Use the ReceiveMessage API call to set an appropriate wail time<br/>D. Use the ChangeMessageVisibility API call to increase the visibility timeout<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample445' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_550'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_94'>Random</a></p><div class='collapse' id='collapseExample445'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Use the ChangeMessageVisibility APi call to increase the visibility timeout</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 69%;" aria-valuenow="69" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_550><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 550</p><br/>A company is building a cloud storage and sharing application for photos.<br/><br/>Users can upload photos from their computers and mobile phones to be stored durably in the cloud.<br/><br/>After photos are uploaded, most are shared and downloaded frequently for the first 40&#8211;90 days. The photos are generally accessed less often after 90 days but some photos maintain a high access rate.<br/><br/>The application initially stores photos n Amazon S3 Standard.<br/><br/>A solutions architect needs to reduce the application's operational costs without sacrificing user experience or data durability.<br/><br/>Which strategy should the solutions architect use to meet these requirements MOST cost&#8211; effectively?<br/><br/>A. Define an S3 Lifecycle rule to transition objects to S3 Intelligent&#8211;Tiering immediately<br/>B. Define an S3 Lifecycle rule to transition objects from S3 Standard to S3 Glacier after 90 days<br/>C. Define an S3 Lifecycle rule to transition objects from S3 Standard to S3 Standard Infrequent Access (S3 Standard&#8211;IA) after 65 days<br/>D. Define an S3 Lifecycle rule to transition objects from S3 Standard to S3 One Zone&#8211;Infrequent Access (S3 One zone&#8211;IA) after 90 days<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample655' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_551'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_385'>Random</a></p><div class='collapse' id='collapseExample655'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Define an S3 Lifecycle rule to transition objects to S3 Intelligent-Tiering immediately</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 69%;" aria-valuenow="69" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_551><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 551</p><br/>A solutions architect is designing a new service behind Amazon API Gateway. The request patterns for the service will be unpredictable and can change suddenly from 0 requests to over 500 per second. The total size of the data that needs to be persisted in a backend database is currently less than 1 GB with unpredictable future growth. Data can be queried using simple key&#8211;value requests.<br/><br/>Which combination of AWS services would meet these requirements? (Choose two.)<br/><br/>A. AWS Fargate<br/>B. AWS Lambda<br/>C. Amazon DynamoDB<br/>D. Amazon EC2 Auto Scaling<br/>E. MySQL&#8211;compatible Amazon Aurora<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample260' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation260' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_552'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_444'>Random</a></p><div class='collapse' id='collapseExample260'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>AWS Lambda
<br><b>C. </b>Amazon DynamoDB</div></div></div><div class='collapse' id='explanation260'><div class='card card&#45;body'><div>
In this case AWS Lambda can perform the computation and store the data in an Amazon DynamoDB table. Lambda can scale concurrent executions to meet demand easily and DynamoDB is built for key-value data storage requirements and is also serverless and easily scalable. This is therefore a cost effective solution for unpredictable workloads.

CORRECT: "AWS Lambda" is a correct answer. CORRECT: "Amazon DynamoDB" is also a correct answer.

INCORRECT: "AWS Fargate" is incorrect as containers run constantly and therefore incur costs even when no requests are being made.

INCORRECT: "Amazon EC2 Auto Scaling" is incorrect as this uses EC2 instances which will incur costs even when no requests are being made.

INCORRECT: "Amazon RDS" is incorrect as this is a relational database not a No-SQL database. It is therefore not suitable for key-value data storage requirements.

References:

AWS Lambda Features
Amazon DynamoDB</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 69%;" aria-valuenow="69" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_552><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 552</p><br/>A company has a custom application with embedded credentials that retrieves information from an Amazon RDS MySQL DB instance. Management says the application must be made more secure with the least amount of programming effort.<br/><br/>What should a solutions architect do to meet these requirements?<br/><br/>A. Use AWS Key Management Service (AWS KMS) customer master keys (CMKs) to create keys. Configure the application to load the database credentials from AWS KMS. Enable automatic key rotation.<br/>B. Create credentials on the RDS for MySQL database for the application user and store the credentials in AWS Secrets Manager. Configure the application to load the database credentials from Secrets Manager. Create an AWS Lambda function that rotates the credentials in Secret Manager.<br/>C. Create credentials on the RDS for MySQL database for the application user and store the credentials in AWS Secrets Manager. Configure the application to load the database credentials from Secrets Manager. Set up a credentials rotation schedule for the application user in the RDS for MySQL database using Secrets Manager.<br/>D. Create credentials on the RDS for MySQL database for the application user and store the credentials in AWS Systems Manager Parameter Store. Configure the application to load the database credentials from Parameter Store. Set up a credentials rotation schedule for the application user in the RDS for MySQL database using Parameter Store.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample341' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_553'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_270'>Random</a></p><div class='collapse' id='collapseExample341'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Create credentials on the RDS for MySQL database for the application user and store the credentials in AWS Systems Manager Parameter Store. Configure the application to load the database credentials from Parameter Store. Set up a credentials rotation schedule for the application user in the RDS for MySQL database using Parameter Store.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 69%;" aria-valuenow="69" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_553><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 553</p><br/>A company is launching an eCommerce website on AWS. This website is built with a three&#8211;tier architecture that includes a MySQL database in a Multi&#8211;AZ deployment of Amazon Aurora MySQL. The website application must be highly available and will initially be launched in an AWS Region with three Availability Zones The application produces a metric that describes the load the application experiences.<br/><br/>Which solution meets these requirements?<br/><br/>A. Configure an Application Load Balancer (ALB) with Amazon EC2 Auto Scaling behind the ALB with scheduled scaling<br/>B. Configure an Application Load Balancer (ALB) and Amazon EC2 Auto Scaling behind the ALB with a simple scaling policy.<br/>C. Configure a Network Load Balancer (NLB) and launch a Spot Fleet with Amazon EC2 Auto Scaling behind the NLB.<br/>D. Configure an Application Load Balancer (ALB) and Amazon EC2 Auto Scaling behind the ALB with a target tracking scaling policy.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample323' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_554'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_732'>Random</a></p><div class='collapse' id='collapseExample323'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Configure an Application Load Balancer (ALB) and Amazon EC2 Auto Scaling behind the ALB with a simple scaling policy.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 70%;" aria-valuenow="70" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_554><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 554</p><br/>A company runs a web service on Amazon EC2 instances behind an Application Load Balancer. The instances run in an Amazon EC2 Auto Scaling group across two Availability Zones. The company needs a minimum of four instances at all times to meet the required service level agreement (SLA) while keeping costs low.<br/><br/>If an Availability Zone fails, how can the company remain compliant with the SLA?<br/><br/>A. Add a target tracking scaling policy with a short cooldown period.<br/>B. Change the Auto Scaling group launch configuration to use a larger instance type.<br/>C. Change the Auto Scaling group to use six servers across three Availability Zones.<br/>D. Change the Auto Scaling group to use eight servers across two Availability Zones.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample206' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_555'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_239'>Random</a></p><div class='collapse' id='collapseExample206'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Add a target tracking scaling policy with a short cooldown period.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 70%;" aria-valuenow="70" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_555><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 555</p><br/>A company has applications hosted on Amazon EC2 instances with IPv6 addresses. The applications must initiate communications with other external applications using the internet. However, the company's security policy states that any external service cannot initiate a connection to the EC2 instances. What should a solutions architect recommend to resolve this issue?<br/><br/>A. Create a NAT gateway and make it the destination of the subnet's route table.<br/>B. Create an internet gateway and make it the destination of the subnet's route table.<br/>C. Create a virtual private gateway and make it the destination of the subnet's route table.<br/>D. Create an egress&#8211;only internet gateway and make it the destination of the subnet's route table.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample334' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_556'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_269'>Random</a></p><div class='collapse' id='collapseExample334'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Create an egress-only internet gateway and make it the destination of the subnet's route table.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 70%;" aria-valuenow="70" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_556><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 556</p><br/>A company has several Amazon EC2 instances set up in a private subnet for security reasons. These instances host applications that read and write large amounts of data to and from Amazon S3 regularly.<br/><br/>Currently, subnet routing directs all the traffic destined for the internet through a NAT gateway. The company wants to optimize the overall cost without impacting the ability of the application to communicate with Amazon S3 or the outside internet.<br/><br/>What should a solutions architect do to optimize costs?<br/><br/>A. Create an additional NAT gateway. Update the route table to route to the NAT gateway. Update the network ACL to allow S3 traffic.<br/>B. Create an internet gateway. Update the route table to route traffic to the internet gateway. Update the network ACL to allow S3 traffic.<br/>C. Create a VPC endpoint for Amazon S3. Attach an endpoint policy to the endpoint. Update the route table to direct traffic to the VPC endpoint.<br/>D. Create an AWS Lambda function outside of the VPC to handle S3 requests. Attach an IAM policy to the EC2 instances, allowing them to invoke the Lambda function.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample357' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_557'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_433'>Random</a></p><div class='collapse' id='collapseExample357'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Create a VPC endpoint for Amazon S3. Attach an endpoint policy to the endpoint. Update the route table to direct traffic to the VPC endpoint.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 70%;" aria-valuenow="70" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_557><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 557</p><br/>Organizers for a global event want to put daily reports online as static HTML pages. The pages are expected to generate millions of views from users around the work. The files are stored in an Amazon S3 Bucket A solutions architect has been asked to design an efficient and effective solution<br/><br/>Which action should the solutions architect take to accomplish this?<br/><br/>A. Generate presigned URLs for the files<br/>B. Use cross&#8211;Region replication to all Regions<br/>C. Use the geoproximity feature of Amazon Route 53<br/>D. Use Amazon CloudFront with the S3 bucket as its origin<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample455' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_558'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_121'>Random</a></p><div class='collapse' id='collapseExample455'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Use Amazon CloudFront with the S3 bucket as its ongin</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 70%;" aria-valuenow="70" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_558><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 558</p><br/>A company has multiple AWS accounts for various departments. One of the departments wants to share an Amazon S3 bucket with all other departments.<br/><br/>Which solution will require the LEAST amount of effort?<br/><br/>A. Enable cross&#8211;account S3 replication for the bucket.<br/>B. Create a pre&#8211;signed URL for the bucket and share it with other departments.<br/>C. Set the S3 bucket policy to allow cross&#8211;account access to other departments.<br/>D. Create IAM users for each of the departments and configure a read&#8211;only IAM policy.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample112' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation112' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_559'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_175'>Random</a></p><div class='collapse' id='collapseExample112'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Set the S3 bucket policy to allow cross-account access to other departments.</div></div></div><div class='collapse' id='explanation112'><div class='card card&#45;body'><div>
S3 standard is the best choice in this scenario for a short term storage solution. In this case the size and number of logs is unknown and it would be difficult to fully assess the access patterns at this stage. Therefore, using S3 standard is best as it is cost-effective, provides immediate access, and there are no retrieval fees or minimum capacity charge per object.

CORRECT: "Amazon S3 Standard" is the correct answer.

INCORRECT: "Amazon S3 Intelligent-Tiering" is incorrect as there is an additional fee for using this service and for a short-term requirement it may not be beneficial.

INCORRECT: "Amazon S3 One Zone-Infrequent Access (S3 One Zone-IA)" is incorrect as this storage class has a minimum capacity charge per object (128 KB) and a per GB retrieval fee. INCORRECT: "Amazon S3 Glacier Deep Archive" is incorrect as this storage class is used for archiving data. There are retrieval fees and it take hours to retrieve data from an archive.

References:

Amazon S3 Storage Classes</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 70%;" aria-valuenow="70" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_559><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 559</p><br/>A company runs a multi&#8211;tier web application that hosts news content. The application runs on Amazon EC2 instances behind an Application Load Balancer. The instances run in an EC2 Auto Scaling group across multiple Availability Zones and use an Amazon Aurora database. A solutions architect needs to make the application more resilient to periodic increases in request rates.<br/><br/>Which architecture should the solutions architect implement? (Choose two.)<br/><br/>A. Add AWS Shield.<br/>B. Add Aurora Replica.<br/>C. Add AWS Direct Connect.<br/>D. Add AWS Global Accelerator.<br/>E. Add an Amazon CloudFront distribution in front of the Application Load Balancer.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample6' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation6' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_560'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_420'>Random</a></p><div class='collapse' id='collapseExample6'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Add Aurora Replica.
<br><b>E. </b>Add an Amazon CloudFront distribution in front of the Application Load Balancer.</div></div></div><div class='collapse' id='explanation6'><div class='card card&#45;body'><div>
AWS Global Accelerator: Acceleration for latency-sensitive applications. Many applications, especially in areas such as gaming, media, mobile apps, and financials, require very low latency for a great user experience. To improve the user experience, Global Accelerator directs user traffic to the application endpoint that is nearest to the client, which reduces internet latency and jitter.
Global Accelerator routes traffic to the closest edge location by using Anycast, and then routes it to the closest regional endpoint over the AWS global network. Global Accelerator quickly reacts to changes in network performance to improve your users' application performance.

Amazon CloudFront: Amazon CloudFront is a fast content delivery network (CDN) service that securely delivers data, videos, applications, and APIs to customers globally with low latency, high transfer speeds, all within a developer-friendly environment.

The architecture is already highly resilient but the may be subject to performance degradation if there are sudden increases in request rates. To resolve this situation Amazon Aurora Read Replicas can be used to serve read traffic which offloads requests from the main database. On the frontend an Amazon CloudFront distribution can be placed in front of the ALB and this will cache content for better performance and also offloads requests from the backend.

CORRECT: "Add Amazon Aurora Replicas" is the correct answer.

CORRECT: "Add an Amazon CloudFront distribution in front of the ALB" is the correct answer.

INCORRECT: "Add and Amazon WAF in front of the ALB" is incorrect. A web application firewall protects applications from malicious attacks. It does not improve performance.

INCORRECT: "Add an Amazon Transit Gateway to the Availability Zones" is incorrect as this is used to connect on-premises networks to VPCs.

INCORRECT: "Add an Amazon Global Accelerator endpoint" is incorrect as this service is used for directing users to different instances of the application in different regions based on latency.

References:

Amazon Aurora > User Guide for Aurora > Replication with Amazon Aurora
Amazon CloudFront > Developer Guide > What is Amazon CloudFront?</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 70%;" aria-valuenow="70" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_560><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 560</p><br/>A company recently launched a new service that involves medical images. The company scans the images and sends them from its on&#8211;premises data center through an AWS Direct Connect connection to Amazon EC2 instances. After processing is complete, the images are stored in an Amazon S3 bucket.<br/><br/>A company requirement states that the EC2 instances cannot be accessible through the internet. The EC2 instances run in a private subnet, which has a default route back to the on&#8211;premises data center for outbound internet access.<br/><br/>Usage of the new service is increasing rapidly. A solutions architect must recommend a solution that meets the company's requirements and reduces the Direct Connect charges.<br/><br/>Which solution accomplishes these goals MOST cost&#8211;effectively?<br/><br/>A. Configure a VPC endpoint for Amazon S3. Add an entry to the private subnet's route table for the S3 endpoint.<br/>B. Configure a NAT gateway in a public subnet. Configure the private subnet's route table to use the NAT gateway.<br/>C. Configure Amazon S3 as a file system mount point on the EC2 instances. Access Amazon S3 through the mount.<br/>D. Move the EC2 instances into a public subnet. Configure the public subnet route table to point to an internet gateway.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample420' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_561'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_567'>Random</a></p><div class='collapse' id='collapseExample420'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Configure a NAT gateway in a public subnet. Configure the private subnet's route table to use the NAT gateway.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 70%;" aria-valuenow="70" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_561><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 561</p><br/>A company wants to migrate its 1PB on&#8211;premises image repository to AWS.<br/><br/>The images will be used by a serverless web application Images stored in the repository are rarely accessed, but they must be immediately available. Additionally, the images must be encrypted at rest and protected from accidental deletion.<br/><br/>Which solution meets these requirements?<br/><br/>A. Implement client&#8211;side encryption and store the images in an Amazon S3 Glacier vault. Set a vault lock to prevent accidental deletion.<br/>B. Store the images in an Amazon S3 bucket in the S3 Standard&#8211;Infrequent Access (S3 Standard&#8211; IA) storage class. Enable versioning: default encryption, and MFA Delete on the S3 bucket<br/>C. Store the images in an Amazon FSx for Windows File Server file share. Configure the Amazon FSx file share to use an AWS Key Management Service (AWS KMS) customer master key (CMK) to encrypt the images in the file share. Use NTFS permission sets on the images to prevent accidental deletion<br/>D. Store the images in an Amazon Elastic File System (Amazon EFS) file share in the Infrequent Access storage class. Configure the EFS file share to use an AWS Key Management Service (AWS KMS) customer master key (CMK) to encrypt the images in the file share. Use NFS permission set on the images to prevent accidental deletion.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample643' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_562'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_174'>Random</a></p><div class='collapse' id='collapseExample643'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Store the images in an Amazon S3 bucket in the S3 Standard-Infrequent Access (S3 Standard- IA) storage class. Enable versioning: default encryption, and MFA Delete on the S3 bucket</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 71%;" aria-valuenow="71" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_562><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 562</p><br/>A company has many applications on Amazon EC2 instances running in Auto Scaling groups. Company policy requires that the data on the attached Amazon Elastic Block Store (Amazon EBS) volumes be retained.<br/><br/>Which action will meet these requirements without impacting performance?<br/><br/>A. Enable termination protection on the Amazon EC2 instances.<br/>B. Disable the DeleteOnTermination attribute for the Amazon EBS volumes.<br/>C. Use Amazon EC2 user data to set up a synchronization job for root volume.<br/>D. Change the Auto scaling health check to point to a source on the root volume.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample615' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_563'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_190'>Random</a></p><div class='collapse' id='collapseExample615'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Disable the DeleteOnTermination attribute for the Amazon EBS volumes.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 71%;" aria-valuenow="71" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_563><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 563</p><br/>A company running an on&#8211;premises application is migrating the application to AWS to increase its elasticity and availability. The current architecture uses a Microsoft SQL Server database with heavy read activity.<br/>The company wants to explore alternate database options and migrate database engines, if needed. Every 4 hours, the development team does a full copy of the production database to populate a test database.<br/><br/>During this period, users experience latency. What should a solutions architect recommend as replacement database?<br/><br/>A. Use Amazon Aurora with Multi&#8211;AZ Aurora Replicas and restore from mysqldump for the test database.<br/>B. Use Amazon Aurora with Multi&#8211;AZ Aurora Replicas and restore snapshots from Amazon RDS for the test database.<br/>C. Use Amazon RDS for MySQL with a Multi&#8211;AZ deployment and read replicas, and use the standby instance for the test database.<br/>D. Use Amazon RDS for SQL Server with a Multi&#8211;AZ deployment and read replicas, and restore snapshots from RDS for the test database.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample70' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_564'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_129'>Random</a></p><div class='collapse' id='collapseExample70'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Use Amazon RDS for SQL Server with a Multi-AZ deployment and read replicas, and restore snapshots from RDS for the test database.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 71%;" aria-valuenow="71" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_564><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 564</p><br/>A company needs to share an Amazon S3 bucket with an external vendor. The bucket owner must be able to access all objects.<br/><br/>Which action should be taken to share the S3 bucket?<br/><br/>A. Update the bucket to be a Requester Pays bucket<br/>B. Update the bucket to enable cross&#8211;origin resource sharing (CPORS)<br/>C. Create a bucket policy to require users to grant bucket&#8211;owner&#8211;full when uploading objects<br/>D. Create an IAM policy to require users to grant bucket&#8211;owner&#8211;full control when uploading objects.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample730' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_565'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_765'>Random</a></p><div class='collapse' id='collapseExample730'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Create a bucket policy to require users to grant bucket-owner-full when uploading objects</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 71%;" aria-valuenow="71" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_565><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 565</p><br/>The financial application at a company stores monthly reports in an Amazon S3 bucket. The vice president of finance has mandated that all access to these reports be logged and that any modifications to the log files be detected.<br/><br/>Which actions can a solutions architect take to meet these requirements?<br/><br/>A. Use S3 server access logging on the bucket that houses the reports with the read and write data events and log file validation options enabled.<br/>B. Use S3 server access logging on the bucket that houses the reports with the read and write management events and log file validation options enabled<br/>C. Use AWS CloudTrail to create a new trail. Configure the trail to log read and write data events on the S3 bucket that houses the reports Log these events to a new bucket, and enable log file validation<br/>D. Use AWS CloudTrail to create a new trail. Configure the trail to log read and write management events on the S3 bucket that houses the reports. Log these events to a new bucket, and enable log file validation.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample510' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_566'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_667'>Random</a></p><div class='collapse' id='collapseExample510'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Use AWS CloudTrail to create a new trail. Configure the trail to log read and write data events on the S3 bucket that houses the reports Log these events to a new bucket, and enable log file validation

References:

Amazon Simple Storage Service > User Guide > Enabling CloudTrail event logging for S3 buckets and objects</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 71%;" aria-valuenow="71" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_566><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 566</p><br/>A solutions architect is designing a new API using Amazon API Gateway that will receive requests from users. The volume of requests is highly variable; several hours can pass without receiving a single request.<br/><br/>The data processing will take place asynchronously, but should be completed within a few seconds after a request is made.<br/><br/>Which compute service should the solutions architect have the API invoke to deliver the requirements at the lowest cost?<br/><br/>A. An AWS Glue job<br/>B. An AWS Lambda function<br/>C. A containerized service hosted in Amazon Elastic Kubernetes Service (Amazon EKS)<br/>D. A containerized service hosted in Amazon ECS with Amazon EC2<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample245' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_567'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_631'>Random</a></p><div class='collapse' id='collapseExample245'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>An AWS Lambda function</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 71%;" aria-valuenow="71" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_567><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 567</p><br/>A solutions architect is designing the storage architecture for a new web application used for storing and viewing engineering drawings. All application components will be deployed on the AWS infrastructure.<br/><br/>The application design must support caching to minimize the amount of time that users wait for the engineering drawings to load. The application must be able to store petabytes of data. Which combination of storage and caching should the solutions architect use?<br/><br/>A. Amazon S3 with Amazon CloudFront<br/>B. Amazon S3 Glacier with Amazon ElastiCache<br/>C. Amazon Elastic Block Store (Amazon EBS) volumes with Amazon CloudFront<br/>D. AWS Storage Gateway with Amazon ElastiCache<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample213' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation213' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_568'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_686'>Random</a></p><div class='collapse' id='collapseExample213'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Amazon S3 with Amazon CloudFront</div></div></div><div class='collapse' id='explanation213'><div class='card card&#45;body'><div>
CloudFront for caching and S3 as the origin. Glacier is used for archiving which is not the case for this scenario.
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 71%;" aria-valuenow="71" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_568><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 568</p><br/>A company stores 200 GB of data each month in Amazon S3. The company needs to perform analytics on this data at the end of each month to determine the number of items sold in each sales region for the previous month.<br/><br/>Which analytics strategy is MOST cost&#8211;effective for the company to use?<br/><br/>A. Create an Amazon Elasticsearch Service (Amazon ES) cluster. Query the data in Amazon ES. Visualize the data by using Kibana.<br/>B. Create a table in the AWS Glue Data Catalog. Query the data in Amazon S3 by using Amazon Athena. Visualize the data in Amazon QuickSight.<br/>C. Create an Amazon EMR cluster. Query the data by using Amazon EMR, and store the results in Amazon S3. Visualize the data in Amazon QuickSight.<br/>D. Create an Amazon Redshift cluster. Query the data in Amazon Redshift, and upload the results to Amazon S3. Visualize the data in Amazon QuickSight.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample328' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_569'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_300'>Random</a></p><div class='collapse' id='collapseExample328'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Create an Amazon Elasticsearch Service (Amazon ES) cluster. Query the data in Amazon ES. Visualize the data by using Kibana.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 71%;" aria-valuenow="71" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_569><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 569</p><br/>A development team runs monthly resource&#8211;intensive tests on its general purpose Amazon RDS (or MySQL DB instance with Performance insights enabled. The testing lasts for 48 hours once a month and is the only process that uses the database. The team wants to reduce the cost of running the tests without reducing the compute and memory attributes of the DB instance.<br/><br/>Which solution meets these requirements MOST cost&#8211;effectively?<br/><br/>A. Stop the DB instance when tests are completed Restart the DB instance when required<br/>B. Use an Auto Scaling policy with my DB instance to automatically scale when tests are completed<br/>C. Create a snapshot when tests are completed Terminate the DB instance and restore the snapshot when required<br/>D. Modify the DB instance to a low&#8211;capacity instance when tests are completed Modify the DB instance again when required<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample550' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_570'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_373'>Random</a></p><div class='collapse' id='collapseExample550'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Create a snapshot when tests are completed Terminate the DB instance and restore the snapshot when required</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 72%;" aria-valuenow="72" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_570><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 570</p><br/>A company has an application that scans millions of connected devices for security threats and pushes the scan logs to an Amazon S3 bucket.<br/><br/>A total of 70 GB of data is generated each week, and the company needs to store 3 years of data for historical reporting.<br/><br/>The company must process, aggregate, and enrich the data from Amazon S3 by performing complex analytical queries and joins in the least amount of time.<br/><br/>The aggregated dataset is visualized on an Amazon QuickSight dashboard. What should a solutions architect recommend to meet these requirements?<br/><br/>A. Create and run an ETL job in AWS Glue to process the data from Amazon S3 and load it into Amazon Redshift. Perform the aggregation queries on Amazon Redshift.<br/>B. Use AWS Lambda functions based on S3 PutObject event triggers to copy the incremental changes to Amazon DynamoDB. Perform the aggregation queries on DynamoDB.<br/>C. Use AWS Lambda functions based on S3 PutObject event triggers to copy the incremental changes to Amazon Aurora MySQL. Perform the aggregation queries on Aurora MySQL<br/>D. Use AWS Glue to catalog the data in Amazon S3. Perform the aggregation queries on the cataloged tables by using Amazon Athena.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample524' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_571'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_173'>Random</a></p><div class='collapse' id='collapseExample524'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Create and run an ETL job in AWS Glue to process the data from Amazon S3 and load it into Amazon Redshift. Perform the aggregation queries on Amazon Redshift.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 72%;" aria-valuenow="72" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_571><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 571</p><br/>A company hosts an application on multiple Amazon EC2 instances. The application processes messages from an Amazon SQS queue, writes for an Amazon RDS table, and deletes the message from the queue. Occasional duplicate records are found in the RDS table. The SQS queue does not contain any duplicate messages.<br/><br/>What should a solutions architect do to ensure messages are being processed once only?<br/><br/>A. Use the CreateQueue API call to create a new queue.<br/>B. Use the AddPermission API call to add appropriate permissions.<br/>C. Use the ReceiveMessage API call to set an appropriate wait time.<br/>D. Use the ChangeMessageVisibility API call to increase the visibility timeout.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample154' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation154' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_572'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_389'>Random</a></p><div class='collapse' id='collapseExample154'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Use the ChangeMessageVisibility API call to increase the visibility timeout.</div></div></div><div class='collapse' id='explanation154'><div class='card card&#45;body'><div>
Keyword: SQS queue writes to an Amazon RDS

From this, Option D best suite & other Options ruled out [Option A – You can't introduce one more Queue in the existing one; Option B – only Permission & Option C – Only Retrieves Messages]

FIFO queues are designed to never introduce duplicate messages. However, your message producer might introduce duplicates in certain scenarios: for example, if the producer sends a message, does not receive a response, and then resends the same message. Amazon SQS APIs provide deduplication functionality that prevents your message producer from sending duplicates. Any duplicates introduced by the message producer are removed within a 5-minute deduplication interval.

For standard queues, you might occasionally receive a duplicate copy of a message (at least once delivery). If you use a standard queue, you must design your applications to be idempotent (that is, they must not be affected adversely when processing the same message more than once).

CreateQueue – You can't change the queue type after you create it and you can't convert an existing standard queue into a FIFO queue. You must either create a new FIFO queue for your application or delete your existing standard queue and recreate it as a FIFO queue.

AddPermission – You create a queue, you have full control access rights for the queue. Only you, the owner of the queue, can grant or deny permissions to the queue.

ReceiveMessage – Retrieves one or more messages (up to 10), from the specified queue.

FIFO queues provide exactly-once processing, which means that each message is delivered once and remains available until a consumer processes it and deletes it.

References:

Amazon Simple Queue Service
Amazon SQS FAQs
Amazon Simple Queue Service > Developer Guide > What is Amazon Simple Queue Service?

</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 72%;" aria-valuenow="72" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_572><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 572</p><br/>The following IAM policy is attached to an IAM group.<br/>What are the effective IAM permissions of this policy for group members?<br/>This is the only policy applied to the group.<br/><br/>What are the effective IAM permissions of this policy for group members?<br/><br/>A. Group members are permitted any Amazon EC2 action within the us&#8211;east&#8211;1 Region. Statements after the Allow permission are not applied.<br/>B. Group members are denied any Amazon EC2 permissions in the us&#8211;east&#8211;1 Region unless they are logged in with multi&#8211;factor authentication (MFA).<br/>C. Group members are allowed the ec2 Stoplnstances and ec2. TerminateInstances permissions for all Regions when logged in with multi&#8211;factor authentication (MFA) Group members are permitted any other Amazon EC2 action.<br/>D. Group members are allowed the ec2 Stoplnstances and ec2. Terminate instances permissions for the us&#8211;east&#8211;1 Region only when logged in with multi&#8211;factor authentication (MFA) Group members are permitted any other Amazon EC2 action within the us&#8211;east&#8211;1 Region.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample474' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_573'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_249'>Random</a></p><div class='collapse' id='collapseExample474'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Group members are allowed the ec2 Stoplnstances and ec2. Terminate instances permissions for the us-east-1 Region only when logged in with multi-factor authentication (MFA) Group members are permitted any other Amazon EC2 action within the us-east-1 Region.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 72%;" aria-valuenow="72" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_573><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 573</p><br/>A solutions architect is designing a shared storage solution for a web application that is deployed across multiple Availability Zones.<br/><br/>The web application runs on Amazon EC2 instances in an Auto Scaling group.<br/><br/>The company anticipates making frequent changes to the content, so the solution must have strong consistency.<br/><br/>Which solution meets these requirements?<br/><br/>A. Create an Amazon S3 bucket to store the web content Use Amazon CloudFront to deliver the content.<br/>B. Create an Amazon Elastic File System (Amazon EFS) file system and mount it on the individual EC2 instances.<br/>C. Create a shared Amazon Elastic Block Store (Amazon EBS) volume and mount it on the individual EC2 instances.<br/>D. Use AWS DataSync to perform continuous synchronization of data between EC2 hosts in the Auto Scaling group.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample654' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_574'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_343'>Random</a></p><div class='collapse' id='collapseExample654'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Create an Amazon Elastic File System (Amazon EFS) file system and mount it on the individual EC2 instances.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 72%;" aria-valuenow="72" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_574><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 574</p><br/>A company uses Amazon S3 as its object storage solution. The company has thousands of S3 buckets it uses to store data. Some of the S3 buckets have data that is accessed less frequently than others. A solutions architect found that lifecycle policies are not consistently implemented or are implemented partially, resulting in data being stored in high&#8211;cost storage.<br/><br/>Which solution will lower costs without compromising the availability of objects?<br/><br/>A. Use S3 ACLs.<br/>B. Use Amazon Elastic Block Store (Amazon EBS) automated snapshots.<br/>C. Use S3 Intelligent&#8211;Tiering storage.<br/>D. Use S3 One Zone&#8211;Infrequent Access (S3 One Zone&#8211;IA).<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample374' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_575'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_599'>Random</a></p><div class='collapse' id='collapseExample374'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Use S3 Intelligent-Tiering storage.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 72%;" aria-valuenow="72" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_575><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 575</p><br/>A major finance organization has engaged your company to set up a large data mining application. Using AWS you decide the best service for this is Amazon Elastic MapReduce(EMR) which you know uses Hadoop. Which of the following statements best describes Hadoop?<br/><br/>A. Hadoop is 3rd Party software which can be installed using AMI<br/>B. Hadoop is an open source python web framework<br/>C. Hadoop is an open source Java software framework<br/>D. Hadoop is an open source javascript framework<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample738' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation738' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_576'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_596'>Random</a></p><div class='collapse' id='collapseExample738'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Hadoop is an open source Java software framework</div></div></div><div class='collapse' id='explanation738'><div class='card card&#45;body'><div>
Amazon EMR uses Apache Hadoop as its distributed data processing engine. Hadoop is an open source, Java software framework that supports data-intensive distributed applications running on large clusters of commodity hardware. Hadoop implements a programming model named "MapReduce," where the data is divided into many small fragments of work, each of which may be executed on any node in the cluster.

This framework has been widely used by developers, enterprises and startups and has proven to be a reliable software platform for processing up to petabytes of data on clusters of thousands of commodity machines.

References:

Amazon EMR FAQs</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 72%;" aria-valuenow="72" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_576><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 576</p><br/>A company has a highly dynamic batch processing job that uses many Amazon EC2 instances to complete it. The job is stateless in nature, can be started and stopped at any given time with no negative impact, and typically takes upwards of 60 minutes total to complete. The company has asked a solutions architect to design a scalable and cost&#8211;effective solution that meets the requirements of the job.<br/><br/>What should the solutions architect recommend?<br/><br/>A. Implement EC2 Spot Instances.<br/>B. Purchase EC2 Reserved Instances.<br/>C. Implement EC2 On&#8211;Demand Instances.<br/>D. Implement the processing on AWS Lambda.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample230' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_577'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_59'>Random</a></p><div class='collapse' id='collapseExample230'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Implement EC2 Spot Instances.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 72%;" aria-valuenow="72" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_577><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 577</p><br/>A company wants to migrate a workload to AWS. The chief information security officer requires that all data be encrypted at rest when stored in the cloud. The company wants complete control of encryption key lifecycle management.<br/><br/>The company must be able to immediately remove the key material and audit key usage independently of AWS CloudTrail. The chosen services should integrate with other storage services that will be used on AWS.<br/><br/>Which services satisfies these security requirements?<br/><br/>A. AWS CloudHSM with the CloudHSM client<br/>B. AWS Key Management Service (AWS KMS) with AWS CloudHSM<br/>C. AWS Key Management Service (AWS KMS) with an external key material origin<br/>D. AWS Key Management Service (AWS KMS) with AWS managed customer master keys (CMKs)<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample82' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation82' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_578'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_274'>Random</a></p><div class='collapse' id='collapseExample82'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>AWS Key Management Service (AWS KMS) with AWS CloudHSM</div></div></div><div class='collapse' id='explanation82'><div class='card card&#45;body'><div>
Took a bit of reading. Key points in question:

"The company must be able to immediately remove the key material and audit key usage independently"

"The chosen services should integrate with other storage services that will be used on AWS" Point 1: Q: Can I use CloudHSM to store keys or encrypt data used by other AWS services? Ans: Yes. You can do all encryption in your CloudHSM-integrated application. In this case, AWS services such as Amazon S3 or Amazon Elastic Block Store (EBS) would only see your data encrypted.

Point 2: AWS manages the hardware security module (HSM) appliance, but does not have access to your keys. You control and manage your own keys

References:

AWS CloudHSM features
AWS CloudHSM FAQs</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 73%;" aria-valuenow="73" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_578><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 578</p><br/>An application allows users at a company's headquarters to access product data. The product data is stored in an Amazon RDS MySQL DB instance. The operations team has isolated an application performance slowdown and wants to separate read traffic from write traffic. A solutions architect needs to optimize the application's performance quickly.<br/><br/>What should the solutions architect recommend?<br/><br/>A. Change the existing database to a Multi&#8211;AZ deployment. Serve the read requests from the primary Availability Zone.<br/>B. Change the existing database to a Multi&#8211;AZ deployment. Serve the read requests from the secondary Availability Zone.<br/>C. Create read replicas for the database. Configure the read replicas with half of the compute and storage resources as the source database.<br/>D. Create read replicas for the database. Configure the read replicas with the same compute and storage resources as the source database.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample395' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_579'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_458'>Random</a></p><div class='collapse' id='collapseExample395'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Create read replicas for the database. Configure the read replicas with the same compute and storage resources as the source database.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 73%;" aria-valuenow="73" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_579><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 579</p><br/>A company has a service that produces event data. The company wants to use AWS to process the event data as it is received. The data is written in a specific order that must be maintained throughout processing.<br/><br/>The company wants to implement a solution that minimizes operational overhead.<br/><br/>How should a solution architect accomplish this?<br/><br/>A. Create an Amazon Simple Queue Service (Amazon SQS) FIFO queue to hold messages. Set up an AWS Lambda function to process messages from the queue.<br/>B. Create an Amazon Simple Notification Service (Amazon SNS) topic to deliver notifications containing payloads to process. Configure an AWS Lambda function as a subscriber.<br/>C. Create an Amazon Simple Queue Service (Amazon SQS) standard queue to hold messages. Set up an AWS Lambda function to process messages from the queue independently.<br/>D. Create an Amazon Simple Notification Service (Amazon SNS) topic to deliver notifications containing payloads to process. Configure an Amazon Simple Queue Service (Amazon SQS) queue as a subscriber.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample303' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_580'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_179'>Random</a></p><div class='collapse' id='collapseExample303'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Create an Amazon Simple Queue Service (Amazon SQS) FIFO queue to hold messages. Set up an AWS Lambda function to process messages from the queue.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 73%;" aria-valuenow="73" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_580><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 580</p><br/>A company has developed a database in Amazon RDS for MySQL.<br/><br/>Due to increased support team is reporting slow reads against the DB instance and recommends adding a read replica.<br/><br/>Which combination of actions should a solutions architect take before implementing this change? (Select TWO.)<br/><br/>A. Enable binlog replication on the RDS master.<br/>B. Choose a failover priority for the source DB instance.<br/>C. Allow long&#8211;running transactions to complete on the source DB instance.<br/>D. Create a global table and specify the AWS Regions where the table will be available.<br/>E. Enable automatic backups on the source instance by settings the backup retention period to a value other than 0.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample605' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_581'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_303'>Random</a></p><div class='collapse' id='collapseExample605'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Allow long-running transactions to complete on the source DB instance.
<br><b>E. </b>Enable automatic backups on the source instance by settings the backup retention period to a value other than 0.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 73%;" aria-valuenow="73" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_581><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 581</p><br/>A company manages a data lake in an Amazon S3 bucket that numerous application share. The S3 bucket contain unique folders with a prefix for each application.<br/><br/>The company wants to restrict each application to its specific folder and have more granular control of the objects in each folder.<br/><br/>Which solution met these requirements with the LEAST amount of effort?<br/><br/>A. Create dedicated S3 access points and access point policies for each application.<br/>B. Create anS3 Batch Operations job to set the ACL permissions for each object in the S3 bucket.<br/>C. Update theS3 S3 bucket policy to grant access to each application based on its specific folder in the S3 bucket.<br/>D. Replicate the objects in the S3 bucket to new S3 buckets for each application. Create replication rules by prefix.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample599' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_582'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_209'>Random</a></p><div class='collapse' id='collapseExample599'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Create anS3 Batch Operations job to set the ACL permissions for each object in the S3 bucket.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 73%;" aria-valuenow="73" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_582><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 582</p><br/>A solutions architect is designing the cloud architecture for a new application being deployed to AWS. The application allows users to interactively download and upload files. Files older than 2 years will be accessed less frequently. The solutions architect needs to ensure that the application can scale to any number of files while maintaining high availability and durability.<br/><br/>Which scalable solutions should the solutions architect recommend? (Choose two.)<br/><br/>A. Store the files on Amazon S3 with a lifecycle policy that moves objects older than 2 years to S3 Glacier.<br/>B. Store the files on Amazon S3 with a lifecycle policy that moves objects older than 2 years to S3 Standard&#8211;Infrequent Access (S3 Standard&#8211;IA)<br/>C. Store the files on Amazon Elastic File System (Amazon EFS) with a lifecycle policy that moves objects older than 2 years to EFS Infrequent Access (EFS IA).<br/>D. Store the files in Amazon Elastic Block Store (Amazon EBS) volumes. Schedule snapshots of the volumes. Use the snapshots to archive data older than 2 years.<br/>E. Store the files in RAID&#8211;striped Amazon Elastic Block Store (Amazon EBS) volumes. Schedule snapshots of the volumes. Use the snapshots to archive data older than 2 years.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample104' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_583'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_382'>Random</a></p><div class='collapse' id='collapseExample104'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Store the files on Amazon S3 with a lifecycle policy that moves objects older than 2 years to S3 Glacier.
<br><b>C. </b>Store the files on Amazon Elastic File System (Amazon EFS) with a lifecycle policy that moves objects older than 2 years to EFS Infrequent Access (EFS IA).</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 73%;" aria-valuenow="73" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_583><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 583</p><br/>A company expects its user base to increase five times over one year. Its application is hosted in one region and uses an Amazon RDS for MySQL database, and Application Load Balance Amazon Elastic Container Service (Amazon ECS) to host the website and its microservices.<br/><br/>Which design changes should a solutions architect recommend to support the expected growth? (Select TWO.)<br/><br/>A. Move static files from Amazon ECS to Amazon S3<br/>B. Use an Amazon Route 53 geolocation routing policy.<br/>C. Scale the environment based on real&#8211;time AWS CloudTrail logs.<br/>D. Create a dedicated Elastic Load Balancer for each microservice.<br/>E. Create RDS lead replicas and change the application to use these replicas.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample539' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_584'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_340'>Random</a></p><div class='collapse' id='collapseExample539'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Move static files from Amazon ECS to Amazon S3
<br><b>E. </b>Create RDS lead replicas and change the application to use these replicas.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 73%;" aria-valuenow="73" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_584><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 584</p><br/>A company's near&#8211;real&#8211;time streaming application is running on AWS. As the data is ingested, a job runs on the data and takes 30 minutes to complete. The workload frequently experiences high latency due to large amounts of incoming data. A solutions architect needs to design a scalable and serverless solution to enhance performance.<br/><br/>Which combination of steps should the solutions architect take? (Choose two.)<br/><br/>A. Use Amazon Kinesis Data Firehose to ingest the data.<br/>B. Use AWS Lambda with AWS Step Functions to process the data.<br/>C. Use AWS Database Migration Service (AWS DMS) to ingest the data.<br/>D. Use Amazon EC2 instances in an Auto Scaling group to process the data.<br/>E. Use AWS Fargate with Amazon Elastic Container Service (Amazon ECS) to process the data.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample135' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_585'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_722'>Random</a></p><div class='collapse' id='collapseExample135'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Use Amazon Kinesis Data Firehose to ingest the data.
<br><b>E. </b>Use AWS Fargate with Amazon Elastic Container Service (Amazon ECS) to process the data.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 73%;" aria-valuenow="73" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_585><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 585</p><br/>A company is building a RESTful serverless web application on AWS by using Amazon API Gateway and AWS Lambda.<br/><br/>The users of this web application will be geographically disturbed, and the company wants to reduce the latency of API requests to these users.<br/><br/>Which type of endpoint should a solutions architect use to meet these requirements?<br/><br/>A. Private endpoint<br/>B. Regional endpoint<br/>C. Interface VPC endpoint<br/>D. Edge&#8211;optimized endpoint<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample611' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_586'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_349'>Random</a></p><div class='collapse' id='collapseExample611'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Private endpoint</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 74%;" aria-valuenow="74" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_586><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 586</p><br/>A company wants to use an AWS Region as a disaster recovery location for its on&#8211;premises infrastructure. The company has 10 TB of existing data, and the on&#8211;premise data center has a 1 Gbps internet connection. A solutions architect must find a solution so the company can have its existing data on AWS in 72 hours without transmitting it using an unencrypted channel.<br/><br/>Which solution should the solutions architect select?<br/><br/>A. Send the initial 10 TB of data to AWS using FTP.<br/>B. Send the initial 10 TB of data to AWS using AWS Snowball.<br/>C. Establish a VPN connection between Amazon VPC and the company's data center.<br/>D. Establish an AWS Direct Connect connection between Amazon VPC and the company's data center<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample732' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation732' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_587'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_501'>Random</a></p><div class='collapse' id='collapseExample732'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Establish a VPN connection between Amazon VPC and the company's data center.</div></div></div><div class='collapse' id='explanation732'><div class='card card&#45;body'><div>
Keyword: AWS Region as DR for On-premises DC (Existing Data=10TB) + 1G Internet Connection
Condition: 10TB on AWS in 72 Hours + Without Unencrypted Channel Without Unencrypted Channel = VPN
FTP = Unencrypted Channel
Options – A – Out of race, since this is unencrypted channel & not matching the condition Options – B – Out of race due to the timebound target & order /delivering AWS Snowball device will take time
Options – C – Win the race, using the existing 1G Internet Link we can transfer this 10TB data within 24Hrs using encrypted Channel
Options – D – Out of race due to the timebound target & order /delivering AWS Direct Connect will take time
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 74%;" aria-valuenow="74" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_587><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 587</p><br/>A company manages its own Amazon EC2 instances that run MySQL databases. The company is manually managing replication and scaling as demand increases or decreases. The company needs a new solution that simplifies the process of adding or removing compute capacity to or from its database tier as needed.<br/><br/>The solution also must offer improved performance, scaling, and durability with minimal effort from operations.<br/><br/>Which solution meets these requirements?<br/><br/>A. Migrate the databases to Amazon Aurora Serverless for Aurora MySQL.<br/>B. Migrate the databases to Amazon Aurora Serverless for Aurora PostgreSQL.<br/>C. Combine the databases into one larger MySQL database. Run the larger database on larger EC2 instances.<br/>D. Create an EC2 Auto Scaling group for the database tier. Migrate the existing databases to the new environment.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample308' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_588'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_625'>Random</a></p><div class='collapse' id='collapseExample308'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Create an EC2 Auto Scaling group for the database tier. Migrate the existing databases to the new environment.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 74%;" aria-valuenow="74" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_588><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 588</p><br/>A company is building a media sharing application and decides to use Amazon S3 for storage. When a media file is uploaded, the company starts a multi&#8211;step process to create thumbnails, identify objects in the images, transcode videos into standard formats and resolutions, and extract and store the metadata to an Amazon DynamoDB table. The metadata is used for searching and navigation.<br/><br/>The amount of traffic is variable. The solution must be able to scale to handle spikes in load without unnecessary expenses.<br/><br/>What should a solutions architect recommend to support this workload?<br/><br/>A. Build the processing into the website or mobile app used to upload the content to Amazon S3. Save the required data to the DynamoDB table when the objects are uploaded.<br/>B. Trigger AWS Step Functions when an object is stored in the S3 bucket. Have the Step Functions perform the steps needed to process the object and then write the metadata to the DynamoDB table.<br/>C. Trigger an AWS Lambda function when an object is stored in the S3 bucket. Have the Lambda function start AWS Batch to perform the steps to process the object. Place the object data in the DynamoDB table when complete.<br/>D. Trigger an AWS Lambda function to store an initial entry in the DynamoDB table when an object is uploaded to Amazon S3. Use a program running on an Amazon EC2 instance in an Auto Scaling group to poll the index for unprocessed items, and use the program to perform the processing.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample225' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_589'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_162'>Random</a></p><div class='collapse' id='collapseExample225'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Trigger an AWS Lambda function when an object is stored in the S3 bucket. Have the Lambda function start AWS Batch to perform the steps to process the object. Place the object data in the DynamoDB table when complete.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 74%;" aria-valuenow="74" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_589><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 589</p><br/>A company is backing up on&#8211;premises databases to local file server shares using the SMB protocol. The company requires immediate access to 1 week of backup files to meet recovery objectives. Recovery after a week is less likely to occur, and the company can tolerate a delay in accessing those older backup files.<br/><br/>What should a solutions architect do to meet these requirements with the LEAST operational effort?<br/><br/>A. Deploy Amazon FSx for Windows File Server to create a file system with exposed file shares with sufficient storage to hold all the desired backups.<br/>B. Deploy an AWS Storage Gateway file gateway with sufficient storage to hold 1 week of backups. Point the backups to SMB shares from the file gateway.<br/>C. Deploy Amazon Elastic File System (Amazon EFS) to create a file system with exposed NFS shares with sufficient storage to hold all the desired backups.<br/>D. Continue to back up to the existing file shares. Deploy AWS Database Migration Service (AWS DMS) and define a copy task to copy backup files older than 1 week to Amazon S3, and delete the backup files from the local file store.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample284' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_590'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_213'>Random</a></p><div class='collapse' id='collapseExample284'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Deploy Amazon FSx for Windows File Server to create a file system with exposed file shares with sufficient storage to hold all the desired backups.

References:

AWS Storage Blog > Back up your on-premises applications to the cloud using AWS Storage Gateway</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 74%;" aria-valuenow="74" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_590><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 590</p><br/>A company has a multi&#8211;tier application that runs six front&#8211;end web servers in an Amazon EC2 Auto Scaling group in a single Availability Zone behind an Application Load Balancer (ALB). A solutions architect needs to modify the infrastructure to be highly available without modifying the application.<br/><br/>Which architecture should the solutions architect choose that provides high availability?<br/><br/>A. Create an Auto Scaling group that uses three instances across each of two Regions.<br/>B. Modify the Auto Scaling group to use three instances across each of two Availability Zones.<br/>C. Create an Auto Scaling template that can be used to quickly create more instances in another Region.<br/>D. Change the ALB in front of the Amazon EC2 instances in a round&#8211;robin configuration to balance traffic to the web tier.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample36' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation36' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_591'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_64'>Random</a></p><div class='collapse' id='collapseExample36'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Modify the Auto Scaling group to use three instances across each of two Availability Zones.</div></div></div><div class='collapse' id='explanation36'><div class='card card&#45;body'><div>
Expanding Your Scaled and Load-Balanced Application to an Additional Availability Zone.

When one Availability Zone becomes unhealthy or unavailable, Amazon EC2 Auto Scaling launches new instances in an unaffected zone. When the unhealthy Availability Zone returns to a healthy state, Amazon EC2 Auto Scaling automatically redistributes the application instances evenly across all of the zones for your Auto Scaling group. Amazon EC2 Auto Scaling does this by attempting to launch new instances in the Availability Zone with the fewest instances. If the attempt fails, however, Amazon EC2 Auto Scaling attempts to launch in other Availability Zones until it succeeds.

You can expand the availability of your scaled and load-balanced application by adding an Availability Zone to your Auto Scaling group and then enabling that zone for your load balancer. After you've enabled the new Availability Zone, the load balancer begins to route traffic equally among all the enabled zones.

High availability can be enabled for this architecture quite simply by modifying the existing Auto Scaling group to use multiple availability zones. The ASG will automatically balance the load so you don't actually need to specify the instances per AZ.

The architecture for the web tier will look like the one below:

CORRECT: "Modify the Auto Scaling group to use four instances across each of two Availability Zones" is the correct answer.

INCORRECT: "Create an Auto Scaling group that uses four instances across each of two Regions" is incorrect as EC2 Auto Scaling does not support multiple regions.

INCORRECT: "Create an Auto Scaling template that can be used to quickly create more instances in another Region" is incorrect as EC2 Auto Scaling does not support multiple regions. INCORRECT: "Create an Auto Scaling group that uses four instances across each of two subnets" is incorrect as the subnets could be in the same AZ.

References:

Amazon EC2 Auto Scaling</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 74%;" aria-valuenow="74" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_591><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 591</p><br/>A company is running its application in a single region on Amazon EC2 with Amazon Elastic Block Store (Amazon EBS) and S3 as part of the storage design.<br/><br/>What should be done to reduce data transfer costs?<br/><br/>A. Create a copy of the compute environment in another AWS Region<br/>B. Convert the application to run on Lambda@Edge<br/>C. Create an Amazon CloudFront distribution with Amazon S3 as the origin<br/>D. Replicate Amazon S3 data to buckets in AWS Regions closer to the requester<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample659' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_592'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_230'>Random</a></p><div class='collapse' id='collapseExample659'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Create an Amazon CloudFront distribution with Amazon S3 as the origin</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 74%;" aria-valuenow="74" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_592><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 592</p><br/>A company has deployed an API in a VPC behind an internet&#8211;facing Application Load Balancer (ALB). An application that consumes the API as a client is deployed in a second account in private subnets behind a NAT gateway. When requests to the client application increase, the NAT gateway costs are higher than expected. A solutions architect has configured the ALB to be internal.<br/><br/>Which combination of architectural changes will reduce the NAT gateway costs? (Choose two.)<br/><br/>A. Configure a VPC peering connection between the two VPCs. Access the API using the private address.<br/>B. Configure an AWS Direct Connect connection between the two VPCs. Access the API using the private address.<br/>C. Configure a ClassicLink connection for the API into the client VPC. Access the API using the ClassicLink address.<br/>D. Configure a PrivateLink connection for the API into the client VPC. Access the API using the PrivateLink address.<br/>E. Configure an AWS Resource Access Manager connection between the two accounts. Access the API using the private address.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample151' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation151' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_593'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_176'>Random</a></p><div class='collapse' id='collapseExample151'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Configure a VPC peering connection between the two VPCs. Access the API using the private address.
<br><b>D. </b>Configure a PrivateLink connection for the API into the client VP<br><b>C. </b>Access the API using the PrivateLink address.</div></div></div><div class='collapse' id='explanation151'><div class='card card&#45;body'><div>
PrivateLink makes it easy to connect services across different accounts and VPCs to significantly simplify the network architecture. There is no API listed in shareable resources for RAM.

References:

AWS Resource Access Manager > User Guide > Shareable AWS resources
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 74%;" aria-valuenow="74" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_593><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 593</p><br/>A company hosts a training site on a fleet of Amazon EC2 instances. The company anticipates that its new course, which consists of dozens of training videos on the site, will be extremely popular when it is released in 1 week.<br/><br/>What should a solutions architect do to minimize the anticipated server load?<br/><br/>A. Store the videos in Amazon ElastiCache for Redis. Update the web servers to serve the videos using the ElastiCache API.<br/>B. Store the videos in Amazon Elastic File System (Amazon EFS). Create a user data script for the web servers to mount the EFS volume.<br/>C. Store the videos in an Amazon S3 bucket. Create an Amazon CloudFront distribution with an origin access identity (OAI) of that S3 bucket. Restrict Amazon S3 access to the OAI.<br/>D. Store the videos in an Amazon S3 bucket. Create an AWS Storage Gateway file gateway to access the S3 bucket. Create a user data script for the web servers to mount the file gateway.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample237' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_594'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_4'>Random</a></p><div class='collapse' id='collapseExample237'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Store the videos in an Amazon S3 bucket. Create an Amazon CloudFront distribution with an origin access identity (OAI) of that S3 bucket. Restrict Amazon S3 access to the OAI.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 75%;" aria-valuenow="75" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_594><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 594</p><br/>A development team needs to host a website that will be accessed by other teams. The website contents consist of HTML, CSS, client&#8211;side JavaScript, and images.<br/><br/>Which method is the MOST cost&#8211;effective for hosting the website?<br/><br/>A. Containerize the website and host it in AWS Fargate.<br/>B. Create an Amazon S3 bucket and host the website there.<br/>C. Deploy a web server on an Amazon EC2 instance to host the website.<br/>D. Configure an Application Load Balancer with an AWS Lambda target that uses the Express is framework.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample270' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_595'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_731'>Random</a></p><div class='collapse' id='collapseExample270'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Create an Amazon S3 bucket and host the website there.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 75%;" aria-valuenow="75" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_595><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 595</p><br/>A company fails an AWS security review conducted by a third party.<br/><br/>The review finds that some of the company's methods to access the Amazon EMR API are not secure.<br/><br/>Developers are using AWS Cloud9, and access keys are connecting to the Amazon EMR API through the public internet.<br/><br/>Which combination of steps should the company take to MOST improve its security? (Select TWO)<br/><br/>A. Set up a VPC peering connection to the Amazon EMR API<br/>B. Set up VPC endpoints to connect to the Amazon EMR API<br/>C. Set up a NAT gateway to connect to the Amazon EMR API.<br/>D. Set up IAM roles to be used to connect to the Amazon EMR API<br/>E. Set up each developer with AWS Secrets Manager to store access keys<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample532' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_596'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_431'>Random</a></p><div class='collapse' id='collapseExample532'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Set up VPC endpoints to connect to the Amazon EMR API
<br><b>D. </b>Set up IAM roles to be used to connect to the Amazon EMR API</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 75%;" aria-valuenow="75" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_596><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 596</p><br/>A company has an eCommerce application running in a single VPC. The application stack has a single web server and an Amazon RDS Multi&#8211;AZ DB instance.<br/><br/>The company launches new products twice a month. This increases website traffic by approximately 400% for a minimum of 72 hours. During product launches, users experience slow response times and frequent timeout errors in their browsers.<br/><br/>What should a solutions architect do to mitigate the slow response times and timeout errors while minimizing operational overhead?<br/><br/>A. Increase the instance size of the web server.<br/>B. Add an Application Load Balancer and an additional web server.<br/>C. Add Amazon EC2 Auto Scaling and an Application Load Balancer.<br/>D. Deploy an Amazon ElastiCache cluster to store frequently accessed data.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample296' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_597'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_748'>Random</a></p><div class='collapse' id='collapseExample296'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Increase the instance size of the web server.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 75%;" aria-valuenow="75" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_597><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 597</p><br/>A company is reviewing its AWS Cloud deployment to ensure its data is not accessed by anyone without appropriate authorization. A solutions architect is tasked with identifying all open Amazon S3 buckets and recording any S3 bucket configuration changes.<br/><br/>What should the solutions architect do to accomplish this?<br/><br/>A. Enable AWS Config service with the appropriate rules<br/>B. Enable AWS Trusted Advisor with the appropriate checks.<br/>C. Write a script using an AWS SDK to generate a bucket report<br/>D. Enable Amazon S3 server access logging and configure Amazon CloudWatch Events.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample99' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_598'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_37'>Random</a></p><div class='collapse' id='collapseExample99'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Enable AWS Config service with the appropriate rules</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 75%;" aria-valuenow="75" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_598><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 598</p><br/>You need to import several hundred megabytes of data from a local Oracle database to an Amazon RDS DB instance. What does AWS recommend you use to accomplish this?<br/><br/>A. Oracle export/import utilities<br/>B. Oracle SQL Developer<br/>C. Oracle Data Pump<br/>D. DBMS_FILE_TRANSFER<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample759' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation759' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_599'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_339'>Random</a></p><div class='collapse' id='collapseExample759'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Oracle Data Pump</div></div></div><div class='collapse' id='explanation759'><div class='card card&#45;body'><div>
How you import data into an Amazon RDS DB instance depends on the amount of data you have and the number and variety of database objects in your database. For example, you can use Oracle SQL Developer to import a simple, 20 MB database; you want to use Oracle Data Pump to import complex databases or databases that are several hundred megabytes or several terabytes in size.

References:

Amazon Relational Database Service > User Guide > Importing data into Oracle on Amazon RDS</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 75%;" aria-valuenow="75" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_599><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 599</p><br/>A company wants to build a scalable key management infrastructure to support developers who need to encrypt data in their applications.<br/><br/>What should a solutions architect do to reduce the operational burden?<br/><br/>A. Use multi&#8211;factor authentication (MFA) to protect the encryption keys<br/>B. Use AWS Key Management Service (AWS KMS) to protect the encryption keys<br/>C. Use AWS Certificate Manager (ACM) to create, store and assign the encryption keys<br/>D. Use an IAM policy to limit the scope of users who have access permissions to protect the encryption keys<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample682' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_600'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_185'>Random</a></p><div class='collapse' id='collapseExample682'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Use AWS Key Management Service (AWS KMS) to protect the encryption keys</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 75%;" aria-valuenow="75" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_600><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 600</p><br/>A company is deploying a public&#8211;facing global application on AWS using Amazon CloudFront. The application communicates with an external system. A solutions architect needs to ensure the data is secured during end&#8211;to&#8211;end transit and at rest.<br/><br/>Which combination of steps will satisfy these requirements? (Select TWO)<br/><br/>A. Create a public certificate for the required domain in AWS Certificate Manager and deploy it to CloudFront, an Application Load Balancer, and Amazon EC2 instances.<br/>B. Acquire a public certificate from a third&#8211;party vendor and deploy it to CloudFront, an Application Load Balancer, and Amazon EC2 instances.<br/>C. Provision Amazon EBS encrypted volumes using AWS KMS and ensure explicit encryption of data when writing to Amazon EBS.<br/>D. Use SSL or encrypt data while communicating with the external system using a VPN.<br/>E. Communicate with the external system using plaintext and use the VPN to encrypt the data in transit.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample688' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_601'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_538'>Random</a></p><div class='collapse' id='collapseExample688'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Provision Amazon EBS encrypted volumes using AWS KMS and ensure explicit encryption of data when writing to Amazon EBS.
<br><b>D. </b>Use SSL or encrypt data while communicating with the external system using a VPN.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 75%;" aria-valuenow="75" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_601><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 601</p><br/>In DynamoDB, could you use IAM to grant access to Amazon DynamoDB resources and API actions?<br/><br/>A. In DynamoDB there is no need to grant access<br/>B. Depended to the type of access<br/>C. No<br/>D. Yes<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample742' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation742' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_602'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_297'>Random</a></p><div class='collapse' id='collapseExample742'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Yes</div></div></div><div class='collapse' id='explanation742'><div class='card card&#45;body'><div>
Amazon DynamoDB integrates with AWS Identity and Access Management (IAM). You can use AWS IAM to grant access to Amazon DynamoDB resources and API actions. To do this, you first write an AWS IAM policy, which is a document that explicitly lists the permissions you want to grant. You then attach that policy to an AWS IAM user or role.

References:

Amazon DynamoDB > Developer Guide > Identity and Access Management in Amazon DynamoDB</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 76%;" aria-valuenow="76" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_602><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 602</p><br/>A company has two applications it wants to migrate to AWS. Both applications process a large set of files by accessing the same files at the same time. Both applications need to read the files with low latency.<br/><br/>Which architecture should a solutions architect recommend for this situation?<br/><br/>A. Configure two AWS Lambda functions to run the applications. Create an Amazon EC2 instance with an instance store volume to store the data.<br/>B. Configure two AWS Lambda functions to run the applications. Create an Amazon EC2 instance with an Amazon Elastic Block Store (Amazon EBS) volume to store the data.<br/>C. Configure one memory optimized Amazon EC2 instance to run both applications simultaneously. Create an Amazon Elastic Block Store (Amazon EBS) volume with Provisioned IOPS to store the data.<br/>D. Configure two Amazon EC2 instances to run both applications. Configure Amazon Elastic File System (Amazon EFS) with General Purpose performance mode and Bursting Throughput mode to store the data.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample67' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_603'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_401'>Random</a></p><div class='collapse' id='collapseExample67'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Configure two Amazon EC2 instances to run both applications. Configure Amazon Elastic File System (Amazon EFS) with General Purpose performance mode and Bursting Throughput mode to store the data.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 76%;" aria-valuenow="76" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_603><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 603</p><br/>A solutions architect must design a database solution for a high&#8211;traffic eCommerce web application. The database stores customer profiles and shopping cart information. The database must support a peak load of several million requests each second and deliver responses in milliseconds. The operational overhead form an aging and scaling the database must be minimized.<br/><br/>Which database solution should the solutions architect recommend?<br/><br/>A. Amazon Aurora<br/>B. Amazon DynamoDB<br/>C. Amazon RDS<br/>D. Amazon Redshift<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample318' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_604'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_351'>Random</a></p><div class='collapse' id='collapseExample318'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Amazon Aurora</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 76%;" aria-valuenow="76" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_604><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 604</p><br/>A user wants to list the IAM role that is attached to their Amazon EC2 instance. The user has login access to the EC2 instance but does not have IAM permissions.<br/><br/>What should a solutions architect do to retrieve this information?<br/><br/>A. Run the following EC2 command: curl http://169.254.169.254/latest/meta&#8211;data/iam/info<br/>B. Run the following EC2 command: curl http://169.254.169.254/latest/user&#8211;data/iam/info<br/>C. Run the following EC2 command: http://169.254.169.254/latest/dynamic/instance&#8211;identity/<br/>D. Run the following AWS CLI command: aws iam get&#8211;instance&#8211;profile &#8211;&#8211;instance&#8211;profile&#8211;name ExampleInstanceProfile<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample289' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_605'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_718'>Random</a></p><div class='collapse' id='collapseExample289'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Run the following EC2 command: curl http://169.254.169.254/latest/meta-data/iam/info

References:

Amazon Elastic Compute Cloud > User Guide for Linux Instances > IAM roles for Amazon EC2</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 76%;" aria-valuenow="76" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_605><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 605</p><br/>A company is planning to make a series of schema changes to tables on its Amazon Aurora DB cluster.<br/><br/>A solutions architect needs to test the changes in the most cost&#8211;effective manner possible.<br/><br/>What should the solutions architect do to meet these requirements?<br/><br/>A. Create a clone of the current Aurora DB cluster. Perform the schema changes on the clone. Once the changes are tested and performance is acceptable, apply the same changes on the original cluster. Delete the clone.<br/>B. Create an Amazon RDS for MySQL replica. Perform the schema changes on the replica. Once the changes are tested and performance is acceptable, apply the same changes on the replica. Once the changes are tested and performance is acceptable, apply the same changes on the primary DB instance. Delete the replica.<br/>C. Create an additional Aurora Replica Perform the schema changes on the Aurora Replica. Once the changes are tested and performance is acceptable, apply the same changes on the primary DB instance. Delete the Aurora Replica.<br/>D. Take a snapshot of the current Aurora DB cluster. Restore the snapshot of the cluster to a new cluster. Perform the schema changes on the restored cluster. Once the changes are tested and performance is acceptable, apply the same changes on the origin cluster. Delete the restored cluster.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample527' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_606'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_580'>Random</a></p><div class='collapse' id='collapseExample527'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Create a clone of the current Aurora DB cluster. Perform the schema changes on the clone. Once the changes are tested and performance is acceptable, apply the same changes on the original cluster. Delete the clone.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 76%;" aria-valuenow="76" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_606><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 606</p><br/>One of the criteria for a new deployment is that the customer wants to use AWS Storage Gateway. However you are not sure whether you should use gateway&#8211;cached volumes or gateway&#8211;stored volumes or even what the differences are.<br/><br/>Which statement below best describes those differences?<br/><br/>A. Gateway&#8211;cached lets you store your data in Amazon Simple Storage Service (Amazon S3) and retain a copy of frequently accessed data subsets locally. Gateway&#8211;stored enables you to configure your on&#8211;premises gateway to store all your data locally and then asynchronously back up point&#8211;in&#8211;time snapshots of this data to Amazon S3.<br/>B. Gateway&#8211;cached is free whilst gateway&#8211;stored is not.<br/>C. Gateway&#8211;cached is up to 10 times faster than gateway&#8211;stored.<br/>D. Gateway&#8211;stored lets you store your data in Amazon Simple Storage Service (Amazon S3) and retain a copy of frequently accessed data subsets locally. Gateway&#8211;cached enables you to configure your on&#8211;premises gateway to store all your data locally and then asynchronously back up point&#8211;in&#8211;time snapshots of this data to Amazon S3.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample777' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation777' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_607'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_355'>Random</a></p><div class='collapse' id='collapseExample777'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Gateway-cached lets you store your data in Amazon Simple Storage Service (Amazon S3) and retain a copy of frequently accessed data subsets locally. Gateway-stored enables you to configure your on-premises gateway to store all your data locally and then asynchronously back up point-in-time snapshots of this data to Amazon S3.</div></div></div><div class='collapse' id='explanation777'><div class='card card&#45;body'><div>
Volume gateways provide cloud-backed storage volumes that you can mount as Internet Small Computer System Interface (iSCSI) devices from your on-premises application servers. The gateway supports the following volume configurations:

Gateway-cached volumes? You store your data in Amazon Simple Storage Service (Amazon S3) and retain a copy of frequently accessed data subsets locally. Gateway-cached volumes offer a substantial cost savings on primary storage and minimize the need to scale your storage on-premises. You also retain low-latency access to your frequently accessed data. Gateway-stored volumes? If you need low-latency access to your entire data set, you can configure your on-premises gateway to store all your data locally and then asynchronously back up point-in-time snapshots of this data to Amazon S3. This configuration provides durable and inexpensive off-site backups that you can recover to your local data center or Amazon EC2. For example, if you need replacement capacity for disaster recovery, you can recover the backups to Amazon EC2.

References:

AWS Storage Gateway > User Guide > What is AWS Storage Gateway?</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 76%;" aria-valuenow="76" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_607><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 607</p><br/>A client needs you to import some existing infrastructure from a dedicated hosting provider to AWS to try and save on the cost of running his current website. He also needs an automated process that manages backups, software patching, automatic failure detection, and recovery. You are aware that his existing setup currently uses an Oracle database.<br/><br/>Which of the following AWS databases would be best for accomplishing this task?<br/><br/>A. Amazon RDS<br/>B. Amazon Redshift<br/>C. Amazon SimpleDB<br/>D. Amazon ElastiCache<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample771' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation771' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_608'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_116'>Random</a></p><div class='collapse' id='collapseExample771'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Amazon RDS</div></div></div><div class='collapse' id='explanation771'><div class='card card&#45;body'><div>
Amazon RDS gives you access to the capabilities of a familiar MySQL, Oracle, SQL Server, or PostgreSQL database engine. This means that the code, applications, and tools you already use today with your existing databases can be used with Amazon RDS. Amazon RDS automatically patches the database software and backs up your database, storing the backups for a user- defined retention period and enabling point-in-time recovery.

References:

Amazon Relational Database Service > User Guide > What is Amazon Relational Database Service (Amazon RDS)?
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 76%;" aria-valuenow="76" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_608><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 608</p><br/>A solutions architect is designing a solution that involves orchestrating a series of Amazon Elastic Container Service (Amazon ECS) task types running on Amazon EC2 instances that are part of an ECS cluster. The output and state data for all tasks needs to be stored. The amount of data output by each task is approximately 10 MB, and there could be hundreds of tasks running at a time. The system should be optimized for high&#8211;frequency reading and writing. As old outputs are archived and deleted, the storage size is not expected to exceed 1 TB.<br/><br/>Which storage solution should the solutions architect recommend?<br/><br/>A. An Amazon DynamoDB table accessible by all ECS cluster instances.<br/>B. An Amazon Elastic File System (Amazon EFS) with Provisioned Throughput mode.<br/>C. An Amazon Elastic File System (Amazon EFS) file system with Bursting Throughput mode.<br/>D. An Amazon Elastic Block Store (Amazon EBS) volume mounted to the ECS cluster instances.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample137' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_609'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_39'>Random</a></p><div class='collapse' id='collapseExample137'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>An Amazon Elastic File System (Amazon EFS) file system with Bursting Throughput mode.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 76%;" aria-valuenow="76" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_609><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 609</p><br/>A company is preparing to launch a public&#8211;facing web application in the AWS Cloud. The architecture consists of Amazon EC2 instances within a VPC behind an Elastic Load Balancer (ELB). A third party service is used for the DNS. The company's solutions architect must recommend a solution to detect and protect against largescale DDoS attacks.<br/><br/>Which solution meets these requirements?<br/><br/>A. Enable Amazon GuardDuty on the account.<br/>B. Enable Amazon Inspector on the EC2 instances.<br/>C. Enable AWS Shield and assign Amazon Route 53 to it.<br/>D. Enable AWS Shield Advanced and assign the ELB to it.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample401' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_610'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_537'>Random</a></p><div class='collapse' id='collapseExample401'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Enable AWS Shield and assign Amazon Route 53 to it.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 77%;" aria-valuenow="77" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_610><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 610</p><br/>A company previously migrated its data warehouse solution to AWS. The company also has an AWS Direct Connect connection. Corporate office users query the data warehouse using a visualization tool. The average size of a query returned by the data warehouse is 50 MB and each webpage sent by the visualization tool is approximately 500 KB. Result sets returned by the data warehouse are not cached.<br/><br/>Which solution provides the LOWEST data transfer egress cost for the company?<br/><br/>A. Host the visualization tool on&#8211;premises and query the data warehouse directly over the internet.<br/>B. Host the visualization tool in the same AWS Region as the data warehouse. Access it over the internet.<br/>C. Host the visualization tool on&#8211;premises and query the data warehouse directly over a Direct Connect connection at a location in the same AWS Region.<br/>D. Host the visualization tool in the same AWS Region as the data warehouse and access it over a DirectConnect connection at a location in the same Region.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample403' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_611'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_368'>Random</a></p><div class='collapse' id='collapseExample403'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Host the visualization tool on premises and query the data warehouse directly over the internet.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 77%;" aria-valuenow="77" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_611><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 611</p><br/>A company has an automobile sales website that stores its listings in a database on Amazon RDS. When an automobile is sold, the listing needs to be removed from the website and the data must be sent to multiple target systems.<br/><br/>Which design should a solutions architect recommend?<br/><br/>A. Create an AWS Lambda function triggered when the database on Amazon RDS is updated to send the information to an Amazon Simple Queue Service (Amazon SQS) queue for the targets to consume.<br/>B. Create an AWS Lambda function triggered when the database on Amazon RDS is updated to send the information to an Amazon Simple Queue Service (Amazon SQS) FIFO queue for the targets to consume.<br/>C. Subscribe to an RDS event notification and send an Amazon Simple Queue Service (Amazon SQS) queue fanned out to multiple Amazon Simple Notification Service (Amazon SNS) topics. Use AWS Lambda functions to update the targets.<br/>D. Subscribe to an RDS event notification and send an Amazon Simple Notification Service (Amazon SNS) topic fanned out to multiple Amazon Simple Queue Service (Amazon SQS) queues. Use AWS Lambda functions to update the targets.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample224' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation224' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_612'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_451'>Random</a></p><div class='collapse' id='collapseExample224'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Create an AWS Lambda function triggered when the database on Amazon RDS is updated to send the information to an Amazon Simple Queue Service (Amazon SQS) queue for the targets to consume.</div></div></div><div class='collapse' id='explanation224'><div class='card card&#45;body'><div>
You can use AWS Lambda to process event notifications from an Amazon Relational Database Service (Amazon RDS) database. Amazon RDS sends notifications to an Amazon Simple Notification Service (Amazon SNS) topic, which you can configure to invoke a Lambda function. Amazon SNS wraps the message from Amazon RDS in its own event document and sends it to your function.

References:

AWS Lambda > Developer Guide > Using AWS Lambda with Amazon SNS
AWS Compute Blog > Messaging Fanout Pattern for Serverless Architectures Using Amazon SNS</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 77%;" aria-valuenow="77" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_612><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 612</p><br/>A company needs to implement a relational database with a multi&#8211;Region disaster recovery Recovery Point Objective (RPO) of 1 second and a Recovery Time Objective (RTO) of 1 minute.<br/><br/>Which AWS solution can achieve this?<br/><br/>A. Amazon Aurora Global Database<br/>B. Amazon DynamoDB global tables<br/>C. Amazon RDS for MySQL with Multi&#8211;AZ enabled<br/>D. Amazon RDS for MySQL with a cross&#8211;Region snapshot copy<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample98' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation98' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_613'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_752'>Random</a></p><div class='collapse' id='collapseExample98'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Amazon Aurora Global Database</div></div></div><div class='collapse' id='explanation98'><div class='card card&#45;body'><div>
Cross-Region Disaster Recovery: If your primary region suffers a performance degradation or outage, you can promote one of the secondary regions to take read/write responsibilities. An Aurora cluster can recover in less than 1 minute even in the event of a complete regional outage. This provides your application with an effective Recovery Point Objective (RPO) of 1 second and a Recovery Time Objective (RTO) of less than 1 minute, providing a strong foundation for a global business continuity plan.
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 77%;" aria-valuenow="77" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_613><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 613</p><br/>A company wants to use an AWS Region as a disaster recovery location for its on&#8211;premises infrastructure. The company has 10 TB of existing data, and the on&#8211;premise data center has a 1 Gbps internet connection. A solutions architect must find a solution so the company can have its existing data on AWS in 72 hours without transmitting it using an unencrypted channel.<br/><br/>Which solution should the solutions architect select?<br/><br/>A. Send the initial 10 TB of data to AWS using FTP.<br/>B. Send the initial 10 TB of data to AWS using AWS Snowball.<br/>C. Establish a VPN connection between Amazon VPC and the company's data center.<br/>D. Establish an AWS Direct Connect connection between Amazon VPC and the company's data center.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample733' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation733' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_614'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_97'>Random</a></p><div class='collapse' id='collapseExample733'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Establish a VPN connection between Amazon VPC and the company's data center.</div></div></div><div class='collapse' id='explanation733'><div class='card card&#45;body'><div>
Keyword: AWS Region as DR for On-premises DC (Existing Data=10TB) + 1G Internet Connection

Condition: 10TB on AWS in 72 Hours + Without Unencrypted Channel Without Unencrypted Channel = VPN

FTP = Unencrypted Channel

Options – A – Out of race, since this is unencrypted channel & not matching the condition Options – B – Out of race due to the timebound target & order /delivering AWS Snowball device will take time

Options – C – Win the race, using the existing 1G Internet Link we can transfer this 10TB data within 24Hrs using encrypted Channel

Options – D – Out of race due to the timebound target & order /delivering AWS Direct Connect will take time

References:

AWS Snowball > User Guide > Shipping an AWS Snowball device
AWS Direct Connect
Amazon VPC</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 77%;" aria-valuenow="77" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_614><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 614</p><br/>A solutions architect is implementing a document review application using an Amazon S3 bucket for storage. The solution must prevent an accidental deletion of the documents and ensure that all versions of the documents are available. Users must be able to download, modify, and upload documents.<br/><br/>Which combination of actions should be taken to meet these requirements? (Choose two.)<br/><br/>A. Enable a read&#8211;only bucket ACL.<br/>B. Enable versioning on the bucket.<br/>C. Attach an IAM policy to the bucket.<br/>D. Enable MFA Delete on the bucket.<br/>E. Encrypt the bucket using AWS KMS.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample186' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation186' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_615'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_193'>Random</a></p><div class='collapse' id='collapseExample186'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Enable versioning on the bucket.
<br><b>D. </b>Enable MFA Delete on the bucket.</div></div></div><div class='collapse' id='explanation186'><div class='card card&#45;body'><div>
Object Versioning
Use Amazon S3 Versioning to keep multiple versions of an object in one bucket. For example, you could store my-image.jpg (version 111111) and my-image.jpg (version 222222) in a single bucket. S3 Versioning protects you from the consequences of unintended overwrites and deletions. You can also use it to archive objects so that you have access to previous versions.

To customize your data retention approach and control storage costs, use object versioning with Object lifecycle management. For information about creating S3 Lifecycle policies using the AWS Management Console, see How Do I Create a Lifecycle Policy for an S3 Bucket? in the Amazon Simple Storage Service Console User Guide.

If you have an object expiration lifecycle policy in your non-versioned bucket and you want to maintain the same permanent delete behavior when you enable versioning, you must add a noncurrent expiration policy. The noncurrent expiration lifecycle policy will manage the deletes of the noncurrent object versions in the version-enabled bucket. (A version-enabled bucket maintains one current and zero or more noncurrent object versions.)

You must explicitly enable S3 Versioning on your bucket. By default, S3 Versioning is disabled. Regardless of whether you have enabled Versioning, each object in your bucket has a version ID. If you have not enabled Versioning, Amazon S3 sets the value of the version ID to null. If S3 Versioning is enabled, Amazon S3 assigns a version ID value for the object. This value distinguishes it from other versions of the same key.

Enabling and suspending versioning is done at the bucket level. When you enable versioning on an existing bucket, objects that are already stored in the bucket are unchanged. The version IDs (null), contents, and permissions remain the same. After you enable S3 Versioning for a bucket, each object that is added to the bucket gets a version ID, which distinguishes it from other versions of the same key.

Only Amazon S3 generates version IDs, and they can't be edited. Version IDs are Unicode, UTF-8 encoded, URL-ready, opaque strings that are no more than 1,024 bytes long. The following is an example: 3/L4kqtJlcpXroDTDmJ+rmSpXd3dIbrHY+MTRCxf3vjVBH40Nr8X8gdRQBpUMLUo.

Using MFA delete
If a bucket's versioning configuration is MFA Delete–enabled, the bucket owner must include the x-amz-mfa request header in requests to permanently delete an object version or change the versioning state of the bucket. Requests that include x-amz-mfa must use HTTPS. The header's value is the concatenation of your authentication device's serial number, a space, and the authentication code displayed on it. If you do not include this request header, the request fails.

None of the options present a good solution for specifying permissions required to write and modify objects so that requirement needs to be taken care of separately. The other requirements are to prevent accidental deletion and the ensure that all versions of the document are available. The two solutions for these requirements are versioning and MFA delete. Versioning will retain a copy of each version of the document and multi-factor authentication delete (MFA delete) will prevent any accidental deletion as you need to supply a second factor when attempting a delete. CORRECT: "Enable versioning on the bucket" is a correct answer.

CORRECT: "Enable MFA Delete on the bucket" is also a correct answer.

INCORRECT: "Set read-only permissions on the bucket" is incorrect as this will also prevent any writing to the bucket which is not desired.

INCORRECT: "Attach an IAM policy to the bucket" is incorrect as users need to modify documents which will also allow delete. Therefore, a method must be implemented to just control deletes.

INCORRECT: "Encrypt the bucket using AWS SSE-S3" is incorrect as encryption doesn't stop you from deleting an object.

References:

Amazon Simple Storage Service > User Guide > Using versioning in S3 buckets
Amazon Simple Storage Service > User Guide > Deleting an object from an MFA delete-enabled bucket</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 77%;" aria-valuenow="77" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_615><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 615</p><br/>A company has a live chat application running on its on&#8211;premises servers that use WebSockets. The company wants to migrate the application to AWS. Application traffic is inconsistent, and the company expects there to be more traffic with sharp spikes in the future.<br/><br/>The company wants a highly scalable solution with no server maintenance nor advanced capacity planning.<br/><br/>Which solution meets these requirements?<br/><br/>A. Use Amazon API Gateway and AWS Lambda with an Amazon DynamoDB table as the data store. Configure the DynamoDB table for provisioned capacity.<br/>B. Use Amazon API Gateway and AWS Lambda with an Amazon DynamoDB table as the data store. Configure the DynamoDB table for on&#8211;demand capacity.<br/>C. Run Amazon EC2 instances behind an Application Load Balancer in an Auto Scaling group with an Amazon DynamoDB table as the data store. Configure the DynamoDB table for on&#8211;demand capacity.<br/>D. Run Amazon EC2 instances behind a Network Load Balancer in an Auto Scaling group with an Amazon DynamoDB table as the data store. Configure the DynamoDB table for provisioned capacity.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample235' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_616'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_744'>Random</a></p><div class='collapse' id='collapseExample235'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Use Amazon API Gateway and AWS Lambda with an Amazon DynamoDB table as the data store. Configure the DynamoDB table for on-demand capacity.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 77%;" aria-valuenow="77" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_616><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 616</p><br/>A solutions architect is designing a highly available website that is served by multiple web servers hosted outside of AWS.<br/>If an instance becomes unresponsive, the architect needs to remove it from the rotation.<br/><br/>What is the MOST efficient way to fulfill this requirement?<br/><br/>A. Use Amazon CloudWatch to monitor utilization.<br/>B. Use Amazon API Gateway to monitor availability.<br/>C. Use an Amazon Elastic Load Balancer.<br/>D. Use Amazon Route 53 health checks.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample673' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_617'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_112'>Random</a></p><div class='collapse' id='collapseExample673'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Use an Amazon Elastic Load Balancer.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 77%;" aria-valuenow="77" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_617><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 617</p><br/>A company is running an eCommerce application on Amazon EC2. The application consists of a stateless web tier that requires a minimum of 10 instances, and a peak of 250 instances to support the application's usage. The application requires 50 instances 80% of the time.<br/><br/>Which solution should be used to minimize costs?<br/><br/>A. Purchase Reserved Instances to cover 250 instances.<br/>B. Purchase Reserved Instances to cover 80 instances. Use Spot Instances to cover the remaining instances.<br/>C. Purchase On&#8211;Demand Instances to cover 40 instances. Use Spot Instances to cover the remaining instances.<br/>D. Purchase Reserved Instances to cover 50 instances. Use On&#8211;Demand and Spot Instances to cover the remaining instances.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample185' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation185' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_618'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_664'>Random</a></p><div class='collapse' id='collapseExample185'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Purchase Reserved Instances to cover 50 instances. Use On-Demand and Spot Instances to cover the remaining instances.</div></div></div><div class='collapse' id='explanation185'><div class='card card&#45;body'><div>
Reserved Instances
Having 50 EC2 RIs provide a discounted hourly rate and an optional capacity reservation for EC2 instances. AWS Billing automatically applies your RI's discounted rate when attributes of EC2 instance usage match attributes of an active RI.

If an Availability Zone is specified, EC2 reserves capacity matching the attributes of the RI. The capacity reservation of an RI is automatically utilized by running instances matching these attributes.

You can also choose to forego the capacity reservation and purchase an RI that is scoped to a region. RIs that are scoped to a region automatically apply the RI's discount to instance usage across AZs and instance sizes in a region, making it easier for you to take advantage of the RI's discounted rate.

On-Demand Instance
On-Demand instances let you pay for compute capacity by the hour or second (minimum of 60 seconds) with no long-term commitments. This frees you from the costs and complexities of planning, purchasing, and maintaining hardware and transforms what are commonly large fixed costs into much smaller variable costs.

The pricing below includes the cost to run private and public AMIs on the specified operating system ("Windows Usage" prices apply to Windows Server 2003 R2, 2008, 2008 R2, 2012, 2012 R2, 2016, and 2019). Amazon also provides you with additional instances for Amazon EC2 running Microsoft Windows with SQL Server, Amazon EC2 running SUSE Linux Enterprise Server, Amazon EC2 running Red Hat Enterprise Linux and Amazon EC2 running IBM that are priced differently.

Spot Instances
A Spot Instance is an unused EC2 instance that is available for less than the On-Demand price. Because Spot Instances enable you to request unused EC2 instances at steep discounts, you can lower your Amazon EC2 costs significantly. The hourly price for a Spot Instance is called a Spot price. The Spot price of each instance type in each Availability Zone is set by Amazon EC2, and adjusted gradually based on the long-term supply of and demand for Spot Instances. Your Spot Instance runs whenever capacity is available and the maximum price per hour for your request exceeds the Spot price.
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 78%;" aria-valuenow="78" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_618><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 618</p><br/>A solutions architect needs to design a low&#8211;latency solution for a static single&#8211;page application accessed by users utilizing a custom domain name. The solution must be serverless, encrypted in transit, and cost&#8211;effective.<br/><br/>Which combination of AWS services and features should the solutions architect use? (Choose two.)<br/><br/>A. Amazon S3<br/>B. Amazon EC2<br/>C. AWS Fargate<br/>D. Amazon CloudFront<br/>E. Elastic Load Balancer<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample168' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_619'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_556'>Random</a></p><div class='collapse' id='collapseExample168'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Amazon S3
<br><b>D. </b>Amazon CloudFront</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 78%;" aria-valuenow="78" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_619><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 619</p><br/>A company is preparing to deploy a data lake on AWS. A solutions architect must define the encryption strategy tor data at rest m Amazon S3/ The company's security policy states:<br/><br/>Keys must be rotated every 90 days.<br/>Strict separation of duties between key users and key administrators must be implemented.<br/>Auditing key usage must be possible.<br/>What should the solutions architect recommend?<br/><br/>A. Server&#8211;side encryption with AWS KMS managed keys (SSE&#8211;KMS) with customer managed customer master keys (CMKs)<br/>B. Server&#8211;side encryption with AWS KMS managed keys (SSE&#8211;KMS) with AWS managed customer master keys (CMKs)<br/>C. Server&#8211;side encryption with Amazon S3 managed keys (SSE&#8211;S3) with customer managed customer master keys (CMKs)<br/>D. Server&#8211;side encryption with Amazon S3 managed keys (SSE&#8211;S3) with AWS managed customer master keys (CMKs)<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample346' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_620'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_483'>Random</a></p><div class='collapse' id='collapseExample346'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Server-side encryption with AWS KMS managed keys (SSE-KMS) with customer managed customer master keys (CMKs)</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 78%;" aria-valuenow="78" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_620><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 620</p><br/>A company has two VPCs that are located in the us&#8211;west&#8211;2 Region within the same AWS account. The company needs to allow network traffic between these VPCs. Approximately 500 GB of data transfer will occur between the VPCs each month.<br/><br/>What is the MOST cost&#8211;effective solution to connect these VPCs?<br/><br/>A. Implement AWS Transit Gateway to connect the VPCs Update the route tables of each VPC to use the transit gateway for inter&#8211;VPC communication<br/>B. Implement an AWS Site&#8211;to&#8211;Site VPN tunnel between the VPCs. Update the route tables of each VPC to use the VPN tunnel for inter&#8211;VPC communication<br/>C. Set up a VPC peering connection between the VPCs. Update the route tables of each VPC to use the VPC peering connection for inter&#8211;VPC communication.<br/>D. Set up a 1 GB AWS Direct Connect connection between the VPCs. Update the route tables of each VPC to use the Direct Connect connection for inter&#8211;VPC communication.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample461' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_621'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_629'>Random</a></p><div class='collapse' id='collapseExample461'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Set up a VPC peering connection between the VPCs. Update the route tables of each VPC to use the VPC peering connection for inter-VPC communication.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 78%;" aria-valuenow="78" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_621><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 621</p><br/>Can you specify the security group that you created for a VPC when you launch an instance in EC2&#8211;Classic?<br/><br/>A. No, you can specify the security group created for EC2&#8211;Classic when you launch a VPC instance.<br/>B. No<br/>C. Yes<br/>D. No, you can specify the security group created for EC2&#8211;Classic to a non&#8211;VPC based instance only.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample749' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation749' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_622'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_610'>Random</a></p><div class='collapse' id='collapseExample749'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>No</div></div></div><div class='collapse' id='explanation749'><div class='card card&#45;body'><div>
If you're using EC2-Classic, you must use security groups created specifically for EC2-Classic. When you launch an instance in EC2-Classic, you must specify a security group in the same region as the instance. You can't specify a security group that you created for a VPC when you launch an instance in EC2-Classic.

References:

Amazon Elastic Compute Cloud > User Guide for Linux Instances > Amazon EC2 security groups for Linux instances</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 78%;" aria-valuenow="78" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_622><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 622</p><br/>After you recommend Amazon Redshift to a client as an alternative solution to paying data warehouses to analyze his data, your client asks you to explain why you are recommending Redshift.<br/><br/>Which of the following would be a reasonable response to his request?<br/><br/>A. It has high performance at scale as data and query complexity grows.<br/>B. It prevents reporting and analytic processing from interfering with the performance of OLTP workloads.<br/>C. You don't have the administrative burden of running your own data warehouse and dealing with setup, durability, monitoring, scaling, and patching.<br/>D. All answers listed are a reasonable response to his question<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample778' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation778' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_623'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_264'>Random</a></p><div class='collapse' id='collapseExample778'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>All answers listed are a reasonable response to his question</div></div></div><div class='collapse' id='explanation778'><div class='card card&#45;body'><div>
Amazon Redshift delivers fast query performance by using columnar storage technology to improve I/O efficiency and parallelizing queries across multiple nodes. Redshift uses standard PostgreSQL JDBC and ODBC drivers, allowing you to use a wide range of familiar SQL clients. Data load speed scales linearly with cluster size, with integrations to Amazon S3, Amazon DynamoDB, Amazon Elastic MapReduce, Amazon Kinesis or any SSH-enabled host. AWS recommends Amazon Redshift for customers who have a combination of needs, such as:

High performance at scale as data and query complexity grows Desire to prevent reporting and analytic processing from interfering with the performance of OLTP workloads Large volumes of structured data to persist and query using standard SQL and existing BI tools Desire to the administrative burden of running one's own data warehouse and dealing with setup, durability, monitoring, scaling and patching.

References:

AWS Cloud Databases</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 78%;" aria-valuenow="78" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_623><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 623</p><br/>A Solutions Architect must design a web application that will be hosted on AWS, allowing users to purchase access to premium, shared content that is stored in an S3 bucket. Upon payment, content will be available for download for 14 days before the user is denied access.<br/><br/>Which of the following would be the LEAST complicated implementation?<br/><br/>A. Use an Amazon CloudFront distribution with an origin access identity (OAI). Configure the distribution with an Amazon S3 origin to provide access to the file through signed URLs. Design a Lambda function to remove data that is older than 14 days.<br/>B. Use an S3 bucket and provide direct access to the file. Design the application to track purchases in a DynamoDB table. Configure a Lambda function to remove data that is older than 14 days based on a query to Amazon DynamoDB.<br/>C. Use an Amazon CloudFront distribution with an OAI. Configure the distribution with an Amazon S3 origin to provide access to the file through signed URLs. Design the application to set an expiration of 14 days for the URL.<br/>D. Use an Amazon CloudFront distribution with an OAI. Configure the distribution with an Amazon S3 origin to provide access to the file through signed URLs. Design the application to set an expiration of 60 minutes for the URL and recreate the URL as necessary.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample160' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_624'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_716'>Random</a></p><div class='collapse' id='collapseExample160'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Use an Amazon CloudFront distribution with an OAI. Configure the distribution with an Amazon S3 origin to provide access to the file through signed URLs. Design the application to set an expiration of 14 days for the URL.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 78%;" aria-valuenow="78" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_624><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 624</p><br/>A company that hosts its web application on AWS wants to ensure all Amazon EC2 instances, Amazon RDS DB instances, and Amazon Redshift clusters are configured with tags. The company wants to minimize the effort of configuring and operating this check.<br/><br/>What should a solutions architect do to accomplish this?<br/><br/>A. Use AWS Config rules to define and detect resources that are not properly tagged.<br/>B. Use Cost Explorer to display resources that are not properly tagged. Tag those resources manually.<br/>C. Write API calls to check all resources for proper tag allocation. Periodically run the code on an EC2 instance.<br/>D. Write API calls to check all resources for proper tag allocation. Schedule an AWS Lambda function through Amazon CloudWatch to periodically run the code.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample234' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_625'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_540'>Random</a></p><div class='collapse' id='collapseExample234'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Use AWS Config rules to define and detect resources that are not properly tagged.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 78%;" aria-valuenow="78" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_625><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 625</p><br/>A company has an application mat provides marketing services to stores. The services are based on previous purchases by store customers.<br/><br/>The stores upload transaction data to the company through SFTP, and the data is processed and analyzed to generate new marketing offers.<br/><br/>Some of the files can exceed 200 GB in size.<br/><br/>Recently, the company discovered that some of the stores have uploaded tiles that contain personally identifiable information (PII) mat should not have been included.<br/><br/>The company wants administrators to be alerted if Pll is shared again. The company also wants to automate remediation.<br/><br/>What should a solutions architect do to meet these requirements with the LEAS F development effort?<br/><br/>A. Use an Amazon S3 bucket as a secure transfer point Use Amazon inspector to scan the objects in the bucket If objects contain Pll, trigger an S3 Lifecycle policy to remove the objects that contain Pll.<br/>B. Use an Amazon S3 bucket as a secure transfer point Use Amazon Macie to scan the objects in the bucket If objects contain Pll, use Amazon Simple Notification Service (Amazon SNS) to trigger a notification to the administrators to remove the objects that contain Pll.<br/>C. Implement custom scanning algorithms in an AWS Lambda function. Trigger the function when objects are loaded into the bucket. If objects contain PLL, use Amazon Simple Notification Service (Amazon SNS) to trigger a notification to the administrators to remove the objects that contain PII.<br/>D. Implement custom scanning algorithms in an AWS Lambda function. Trigger the function when objects are loaded into the bucket. If objects contain Pll, use Amazon Simple Email Service (Amazon SES) to Trigger a notification to the administrators and trigger an S3 Lifecycle policy to remove the objects that contain Pll.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample589' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_626'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_90'>Random</a></p><div class='collapse' id='collapseExample589'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Use an Amazon S3 bucket as a secure transfer point Use Amazon inspector to scan the objects in the bucket If objects contain Pll, trigger an S3 Lifecycle policy to remove the objects that contain Pll.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 79%;" aria-valuenow="79" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_626><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 626</p><br/>A company is building an online multiplayer game. The game communicates by using UDP, and low latency between the client and the backend is important. The backend is hosted on Amazon EC2 instances that can be deployed to multiple AWS Regions to meet demand. The company needs the game to be highly available so that users around the world can access the game at all times.<br/><br/>What should a solutions architect do to meet these requirements?<br/><br/>A. Deploy Amazon CloudFront to support the global traffic. Configure CloudFront with an origin group to allow access to EC2 instances in multiple Regions.<br/>B. Deploy an Application Load Balancer in one Region to distribute traffic to EC2 instances in each Region that hosts the game's backend instances.<br/>C. Deploy Amazon CloudFront to support an origin access identity (OAI). Associate the OAI with EC2 instances in each Region to support global traffic.<br/>D. Deploy a Network Load Balancer in each Region to distribute the traffic. Use AWS Global Accelerator to route traffic to the correct Regional endpoint.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample421' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_627'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_144'>Random</a></p><div class='collapse' id='collapseExample421'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Deploy Amazon CloudFront to support an origin access identity (OAI). Associate the OAI with EC2 instances in each Region to support global traffic.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 79%;" aria-valuenow="79" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_627><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 627</p><br/>A company is running a publicly accessible serverless application that uses Amazon API Gateway and AWS Lambda.<br/><br/>The application's traffic recently spiked due to fraudulent requests from botnets.<br/><br/>Which steps should a solutions architect take to block requests from unauthorized users? (Select TWO.)<br/><br/>A. Create a usage plan with an API key that is shared with genuine users only.<br/>B. Integrate logic within the Lambda function to ignore the requests from fraudulent addresses.<br/>C. Implement an AWS WAF rule to target malicious requests and trigger actions to filter them out.<br/>D. Convert the existing public API to a private API. Update the DNS records to redirect users to the new API endpoint.<br/>E. Create an IAM role for each user attempting to access the API. A user will assume the role when making the API call.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample606' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_628'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_184'>Random</a></p><div class='collapse' id='collapseExample606'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Integrate logic within the Lambda function to ignore the requests from fraudulent addresses.
<br><b>E. </b>Create an IAM role for each user attempting to access the API. A user will assume the role when making the API call.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 79%;" aria-valuenow="79" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_628><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 628</p><br/>A company needs to connect several VPCs in the us&#8211;east Region that span hundreds of AWS accounts.<br/><br/>The company's networking team as its own AWS account to manage the cloud network.<br/><br/>What is the MOST operationally efficient solution to connect the VPCs?<br/><br/>A. Set up VPC peering connections between each VPC. Update each associated subnet's route table.<br/>B. Configure a NAT gateway and an internal gateway in each VPC in connected each VPC through the internal.<br/>C. Create an AWS Transit Gateway in the networking team's AWS account. Configure static routes from each VPC.<br/>D. Deploy VPN gateway in each VPC. Configure create a transit VPC in the networking team's AWS account to connect to each VPC.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample601' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_629'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_348'>Random</a></p><div class='collapse' id='collapseExample601'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Create an AWS Transit Gateway in the networking team's AWS account. Configure static routes from each VPC.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 79%;" aria-valuenow="79" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_629><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 629</p><br/>A company needs to provide its employees with secure access to confidential and sensitive files. The company wants to ensure that the tiles can be accessed only by authorized users. The files must be downloaded securely to the employees' devices.<br/><br/>The tiles are stored in an on&#8211;premises Windows file server. However, due to an increase in remote usage, the file server is running out of capacity.<br/><br/>Which solution will meet these requirements?<br/><br/>A. Migrate the file server to an Amazon EC2 instance in a public subnet. Configure the security group to limit inbound traffic to the employees' IP addresses.<br/>B. Migrate the files to an Amazon FSx for Windows File Server file system. Integrate the Amazon FSx file system with the on&#8211;premises Active Directory. Configure AWS Client VP<br/>C. Migrate the tiles to Amazon S3, and create a private VPC endpoint. Create a signed URL to allow download.<br/>D. Migrate the tiles to Amazon S3, and create a public VPC endpoint. Allow employees to sign on with AWS Single Sign&#8211;On.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample449' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_630'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_515'>Random</a></p><div class='collapse' id='collapseExample449'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Migrate the tiles to Amazon S3, and create a public VPC endpoint. Allow employees to sign on with AWS Single Sign-On.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 79%;" aria-valuenow="79" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_630><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 630</p><br/>A solutions architect must analyze and update a company's existing 1AM policies prior to deploying a new workload.<br/>The solutions architect created the following policy:<br/>A solutions architect must analyze and update a company's existing 1AM policies prior to deploying a new workload.<br/>What is the net effect of this policy?<br/><br/>A. Users will be allowed all actions except s3 PutObject if multi&#8211;factor authentication (MFA) is enabled<br/>B. Users win be allowed all actions except s3 PutObject if multi&#8211;factor authentication (MFA) is not enabled<br/>C. Users will be denied all actions except s3;PutObject if multi&#8211;factor authentication (MFA) is enabled.<br/>D. Users win be denied all actions except s3:PutObject if multi&#8211;factor authentication (MFA) is not enabled.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample507' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_631'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_103'>Random</a></p><div class='collapse' id='collapseExample507'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Users will be denied all actions except s3;PutObject if multi-factor authentication (MFA) is enabled.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 79%;" aria-valuenow="79" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_631><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 631</p><br/>Management has decided to deploy all AWS VPCs with IPv6 enabled. After some time, a solutions architect tries to launch a new instance and receives an error stating that there is not enough IP address space available in the subnet.<br/><br/>What should the solutions architect do to fix this?<br/><br/>A. Check to make sure that only IPv6 was used during the VPC creation.<br/>B. Create a new IPv4 subnet with a larger range, and then launch the instance.<br/>C. Create a new IPv6&#8211;only subnet with a large range, and then launch the instance.<br/>D. Disable the IPv4 subnet and migrate all instances to IPv6 only. Once that is complete, launch the instance.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample239' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation239' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_632'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_333'>Random</a></p><div class='collapse' id='collapseExample239'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Create a new IPv4 subnet with a larger range, and then launch the instance.</div></div></div><div class='collapse' id='explanation239'><div class='card card&#45;body'><div>
First of all, there is no IPv6-only VPC on AWS. A VPC is always IPv4 enabled, but you can optionally enable IPv6 (dual-stack).

References:

Getting started with IPv6 on AWS</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 79%;" aria-valuenow="79" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_632><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 632</p><br/>A solutions architect wants all new users to have specific complexity requirements and mandatory rotation periods for IAM user passwords. What should the solutions architect do to accomplish this?<br/><br/>A. Set an overall password policy for the entire AWS account<br/>B. Set a password policy for each IAM user in the AWS account.<br/>C. Use third&#8211;party vendor software to set password requirements.<br/>D. Attach an Amazon CloudWatch rule to the Create_newuser event to set the password with the appropriate requirements.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample293' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_633'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_740'>Random</a></p><div class='collapse' id='collapseExample293'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Set an overall password policy for the entire AWS account</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 80%;" aria-valuenow="80" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_633><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 633</p><br/>A company has a media catalog with metadata for each item in the catalog. Different types of metadata are extracted from the media items by an application running on AWS Lambda.<br/><br/>Metadata is extracted according to a number of rules, with the output stored in an Amazon ElastiCache for Redis cluster. The extraction process is done in batches and takes around 40 minutes to complete. The update process is triggered manually whenever the metadata extraction rules change.<br/><br/>The company wants to reduce the amount of time it takes to extract metadata from its media catalog. To achieve this, a solutions architect has split the single metadata extraction Lambda function into a Lambda function for each type of metadata.<br/><br/>Which additional steps should the solutions architect take to meet the requirements?<br/><br/>A. Create an AWS Step Functions workflow to run the Lambda functions in parallel. Create another Step Functions workflow that retrieves a list of media items and executes a metadata extraction workflow for each one.<br/>B. Create an AWS Batch compute environment for each Lambda function. Configure an AWS Batch job queue for the compute environment. Create a Lambda function to retrieve a list of media items and write each item to the job queue.<br/>C. Create an AWS Step Functions workflow to run the Lambda functions in parallel. Create a Lambda function to retrieve a list of media items and write each item to an Amazon SQS queue. Configure the SQS queue as an input to the Step Functions workflow.<br/>D. Create a Lambda function to retrieve a list of media items and write each item to an Amazon SQS queue. Subscribe the metadata extraction Lambda functions to the SQS queue with a large batch size.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample689' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_634'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_470'>Random</a></p><div class='collapse' id='collapseExample689'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Create an AWS Step Functions workflow to run the Lambda functions in parallel. Create a Lambda function to retrieve a list of media items and write each item to an Amazon SQS queue. Configure the SQS queue as an input to the Step Functions workflow.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 80%;" aria-valuenow="80" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_634><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 634</p><br/>A company recently launched Linux&#8211;based application instances on Amazon EC2 in a private subnet and launched a Linux&#8211;based bastion host on an Amazon EC2 instance in a public subnet of a VPC. A solutions architect needs to connect from the on&#8211;premises network, though the company's internet connection, to the bastion host, and to the application servers. The solutions architect must make sure that the security groups of all the EC2 instances will allow that access.<br/><br/>Which combination of steps should the solutions architect take to meet these requirements? (Choose two.)<br/><br/>A. Replace the current security group of the bastion host with one that only allows inbound access from the application instances.<br/>B. Replace the current security group of the bastion host with one that only allows inbound access from the internal IP range for the company.<br/>C. Replace the current security group of the bastion host with one that only allows inbound access from the external IP range for the company.<br/>D. Replace the current security group of the application instances with one that allows inbound SSH access from only the private IP address of the bastion host.<br/>E. Replace the current security group of the application instances with one that allows inbound SSH access from only the public IP address of the bastion host.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample311' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_635'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_684'>Random</a></p><div class='collapse' id='collapseExample311'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Replace the current security group of the bastion host with one that only allows inbound access from the application instances.
<br><b>C. </b>Replace the current security group of the bastion host with one that only allows inbound access from the external IP range for the company.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 80%;" aria-valuenow="80" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_635><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 635</p><br/>A company hosts an online shopping application that stores all orders in an Amazon RDS for PostgreSQL Single&#8211;AZ DB instance.<br/><br/>Management wants to eliminate single points of failure and has asked a solutions architect to recommend an approach to minimize database downtime without requiring any changes to the application code.<br/><br/>Which solution meets these requirements?<br/><br/>A. Convert the existing database instance to a Multi&#8211;AZ deployment by modifying the database instance and specifying the Multi&#8211;AZ option.<br/>B. Create a new RDS Multi&#8211;AZ deployment. Take a snapshot of the current RDS instance and restore the new Multi&#8211;AZ deployment with the snapshot.<br/>C. Create a read&#8211;only replica of the PostgreSQL database in another Availability Zone. Use Amazon Route 53 weighted record sets to distribute requests across the databases.<br/>D. Place the RDS for PostgreSQL database in an Amazon EC2 Auto Scaling group with a minimum group size of two. Use Amazon Route 53 weighted record sets to distribute requests across instances.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample131' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_636'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_548'>Random</a></p><div class='collapse' id='collapseExample131'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Convert the existing database instance to a Multi-AZ deployment by modifying the database instance and specifying the Multi-AZ option.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 80%;" aria-valuenow="80" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_636><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 636</p><br/>A company is planning to use an Amazon DynamoDB table for data storage. The company is concerned about cost optimization. The table will not be used on most mornings in the evenings, the read and write traffic will often be unpredictable. When traffic spikes occur they will happen very quickly.<br/><br/>What should a solutions architect recommend?<br/><br/>A. Create a DynamoDB table in on&#8211;demand capacity mode.<br/>B. Create a DynamoDB table with a global secondary index.<br/>C. Create a DynamoDB table with provisioned capacity and auto scaling.<br/>D. Create a DynamoDB table in provisioned capacity mode, and configure it as a global table.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample390' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_637'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_614'>Random</a></p><div class='collapse' id='collapseExample390'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Create a DynamoDB table in on-demand capacity mode.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 80%;" aria-valuenow="80" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_637><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 637</p><br/>A company is Re&#8211;architecting a strongly coupled application to be loosely coupled Previously the application used a request/response pattern to communicate between tiers. The company plans to use Amazon Simple Queue Service (Amazon SQS) to achieve decoupling requirements. The initial design contains one queue for requests and one for responses However, this approach is not processing all the messages as the application scales.<br/><br/>What should a solutions architect do to resolve this issue?<br/><br/>A. Configure a dead&#8211;letter queue on the ReceiveMessage API action of the SQS queue.<br/>B. Configure a FIFO queue, and use the message deduplication ID and message group I<br/>C. Create a temporary queue, with the Temporary Queue Client to receive each response message.<br/>D. Create a queue for each request and response on startup for each producer, and use a correlation ID message attribute.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample483' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_638'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_186'>Random</a></p><div class='collapse' id='collapseExample483'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Configure a dead-letter queue on the ReceiveMessage API action of the SQS queue.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 80%;" aria-valuenow="80" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_638><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 638</p><br/>A company is migrating from an on&#8211;premises infrastructure to the AWS Cloud. One of the company's applications stores files on a Windows file server farm that uses Distributed File System Replication (DFSR) to keep data in sync. A solutions architect needs to replace the file server farm.<br/><br/>Which service should the solutions architect use?<br/><br/>A. Amazon EFS<br/>B. Amazon FSx<br/>C. Amazon S3<br/>D. AWS Storage Gateway<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample2' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation2' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_639'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_624'>Random</a></p><div class='collapse' id='collapseExample2'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Amazon FSx</div></div></div><div class='collapse' id='explanation2'><div class='card card&#45;body'><div>
Migrating Existing Files to Amazon FSx for Windows File Server Using AWS DataSync

We recommend using AWS DataSync to transfer data between Amazon FSx for Windows File Server file systems. DataSync is a data transfer service that simplifies, automates, and accelerates moving and replicating data between on-premises storage systems and other AWS storage services over the internet or AWS Direct Connect. DataSync can transfer your file system data and metadata, such as ownership, time stamps, and access permissions.

Amazon FSx for Windows File Server provides fully managed, highly reliable file storage that is accessible over the industry-standard Server Message Block (SMB) protocol.

Amazon FSx is built on Windows Server and provides a rich set of administrative features that include end-user file restore, user quotas, and Access Control Lists (ACLs).

Additionally, Amazon FSX for Windows File Server supports Distributed File System Replication (DFSR) in both Single-AZ and Multi-AZ deployments as can be seen in the feature comparison table below.

CORRECT: "Amazon FSx" is the correct answer.

INCORRECT: "Amazon EFS" is incorrect as EFS only supports Linux systems. INCORRECT: "Amazon S3" is incorrect as this is not a suitable replacement for a Microsoft filesystem.

INCORRECT: "AWS Storage Gateway" is incorrect as this service is primarily used for connecting on-premises storage to cloud storage. It consists of a software device installed on-premises and can be used with SMB shares but it actually stores the data on S3. It is also used for migration. However, in this case the company need to replace the file server farm and Amazon FSx is the best choice for this job.

References:

Amazon FSx for Windows File Server > Windows User Guide > Availability and durability: Single-AZ and Multi-AZ file systems</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 80%;" aria-valuenow="80" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_639><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 639</p><br/>A company receives data from millions of users totaling about 1 TB each flay. The company provides its user's with usage reports gang back 12 months Al usage data must be stored for at least 5 years to comply with regulatory and auditing requirements<br/><br/>Which storage solution is MOST cost&#8211;effective?<br/><br/>A. Store the data in Amazon S3 Standard. Set a lifecycle &#8211;rule to transition the data to S3 Glacier Deep Archive after 1 year. Set a Recycle rule to delete the data after5 years.<br/>B. Store. The data in Amazon S3 One Zone&#8211;Infrequent Access (S3 One Zone&#8211;IA). Set a lifecycle rule to transition the data to S3 Glacier after 1 year Set the lifecycle rule to delete the data after 5 years.<br/>C. Store the data in Amazon S3 Standard Set a lifecycle rule to transition the data to S3 Standard&#8211;infrequent Access (S3 Standard&#8211;IA) after 1 year Sol a lifecycle rule to delete the data after 5 years.<br/>D. Store the data in Amazon S3 Standard Set a lifecycle &#8211;rule to transition the data to S3 One Zone&#8211;infrequent Access (S3 One Zone&#8211;IA) after 1 year, Set a Lifecycle rule to delete the data after 5 years.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample496' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_640'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_654'>Random</a></p><div class='collapse' id='collapseExample496'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Store the data in Amazon S3 Standard. Set a lifecycle -rule to transition the data to S3 Glacier Deep Archive after 1 year. Set a Recycle rule to delete the data after5 years.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 80%;" aria-valuenow="80" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_640><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 640</p><br/>A company has a web application hosted over 10 Amazon CC2 instances with traffic directed by Amazon Route 53.<br/><br/>The company occasionally experiences a timeout error when attempting to browse the application.<br/><br/>The networking team finds that some DNS queries return IP addresses of unhealthy instances, resulting in the timeout error.<br/><br/>What should a solutions architect implement to overcome these timeout errors?<br/><br/>A. Create a Route 53 simple touting policy record lot each EC2 instance Associate a hearth check with each record<br/>B. Create a Route 53 failover routing policy record for each EC2 instance Associate a health check with each record<br/>C. Create an Amazon CloudFront distribution with EC2 instances as its origin Associate a health check with the EC2 instances<br/>D. Create an Application Load Balancer (ALB) with a health check in front of the EC2 instances Route to the ALB from Route 53<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample596' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_641'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_617'>Random</a></p><div class='collapse' id='collapseExample596'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Create a Route 53 simple touting policy record lot each EC2 instance Associate a hearth check with each record</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 81%;" aria-valuenow="81" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_641><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 641</p><br/>A company is planning to migrate a TCP&#8211;based application into the company's VPC. The application is publicly accessible on a nonstandard TCP port through a hardware appliance in the company's data center. This public endpoint can process up to 3 million requests per second with low latency. The company requires the same level of performance for the new public endpoint in AWS.<br/><br/>What should a solutions architect recommend to meet this requirement?<br/><br/>A. Deploy a Network Load Balancer (NLB). Configure the NLB to be publicly accessible over the TCP port that the application requires.<br/>B. Deploy an Application Load Balancer (ALB). Configure the ALB to be publicly accessible over the TCP port that the application requires.<br/>C. Deploy an Amazon CloudFront distribution that listens on the TCP port that the application requires. Use an Application Load Balancer as the origin.<br/>D. Deploy an Amazon API Gateway API that is configured with the TCP port that the application requires. Configure AWS Lambda functions with provisioned concurrency to process the requests.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample427' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_642'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_502'>Random</a></p><div class='collapse' id='collapseExample427'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Deploy an Amazon CloudFront distribution that listens on the TCP port that the application requires. Use an Application Load Balancer as the origin.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 81%;" aria-valuenow="81" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_642><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 642</p><br/>A company stores project information in a shared spreadsheet. The company wants to create a web application to replace the spreadsheet. The company has chosen Amazon DynamoDB to store the spreadsheet's data and is designing the web application to display the project information that is obtained from DynamoDB.<br/><br/>A solutions architect must design the web application's backend by using managed services that require minimal operational maintenance.<br/><br/>Which architectures meet these requirements? (Select TWO.)<br/><br/>A. An Amazon API Gateway REST API accesses the project information that is in DynamoD<br/>B. An Elastic Load Balancer forwards requests to a target group with DynamoDB set up as the target.<br/>C. An Amazon API Gateway REST API invokes an AWS Lambda function. The Lambda function accesses DynamoD<br/>D. An Amazon Route 53 hosted zone routes requests to an AWS Lambda endpoint to invoke a Lambda function that accesses DynamoD<br/>E. An Elastic Load Balancer forwards requests to a target group of Amazon EC2 instances. The EC2 instances run an application that accesses DynamoD<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample467' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_643'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_23'>Random</a></p><div class='collapse' id='collapseExample467'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>An Amazon API Gateway REST API accesses the project information that is in DynamoD
<br><b>E. </b>An Elastic Load Balancer forwards requests to a target group of Amazon EC2 instances. The EC2 instances run an application that accesses DynamoD</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 81%;" aria-valuenow="81" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_643><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 643</p><br/>A company has an application that calls AWS Lambda functions. A recent code review found database credentials stored in the source code. The database credentials need to be removed from the Lambda source code. The credentials must then be securely stored and rotated on an ongoing basis to meet security policy requirements.<br/><br/>What should a solutions architect recommend to meet these requirements?<br/><br/>A. Store the password in AWS CloudHSM. Associate the Lambda function with a role that can retrieve the password from CloudHSM given its key ID.<br/>B. Store the password in AWS Secrets Manager. Associate the Lambda function with a role that can retrieve the password from Secrets Manager given its secret ID.<br/>C. Move the database password to an environment variable associated with the Lambda function. Retrieve the password from the environment variable upon execution.<br/>D. Store the password in AWS Key Management Service (AWS KMS). Associate the Lambda function with a role that can retrieve the password from AWS KMS given its key ID.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample190' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_644'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_28'>Random</a></p><div class='collapse' id='collapseExample190'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Store the password in AWS Secrets Manager. Associate the Lambda function with a role that can retrieve the password from Secrets Manager given its secret ID.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 81%;" aria-valuenow="81" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_644><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 644</p><br/>A solutions architect is designing an architecture to run a third&#8211;party database server. The database software is memory intensive and has a CPU&#8211;based licensing model where the cost increases with the number of vCPU cores within the operating system. The solutions architect must select an Amazon EC2 instance with sufficient memory to run the database software, but the selected instance has a large number of vCPUs. The solutions architect must ensure that the vCPUs will not be underutilized and must minimize costs.<br/><br/>Which solution meets these requirements?<br/><br/>A. Select and launch a smaller EC2 instance with an appropriate number of vCPUs.<br/>B. Configure the CPU cores and threads on the selected EC2 instance during instance launch.<br/>C. Create a new EC2 instance and ensure multithreading is enabled when configuring the instance details.<br/>D. Create a new Capacity Reservation and select the appropriate instance type. Launch the instance into this new Capacity Reservation.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample297' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_645'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_40'>Random</a></p><div class='collapse' id='collapseExample297'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Select and launch a smaller EC2 instance with an appropriate number of vCPUs.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 81%;" aria-valuenow="81" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_645><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 645</p><br/>A company's web site receives 50,000 requests each second.<br/><br/>The company wants to use multiple applications to analyze the navigation patterns of the website users so that the experience can be personalized.<br/><br/>Which AWS services or feature should a solutions architect use to collect page clicks for the website and process them sequentially for each user?<br/><br/>A. Amazon Kinesis Data Streams<br/>B. Amazon Simple Queue Service (Amazon SQS) standard queue<br/>C. Amazon Simple Queue Service (Amazon SQS) FIFO queue<br/>D. AWS CloudTrail<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample603' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_646'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_18'>Random</a></p><div class='collapse' id='collapseExample603'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Amazon Kinesis Data Streams</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 81%;" aria-valuenow="81" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_646><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 646</p><br/>A solutions architect has configured the following IAM policy.<br/><br/>A solutions architect has configured the following IAM policy.<br/><br/>A solutions architect has configured the following IAM policy.<br/><br/>Which action will be allowed by the policy?<br/><br/>A. An AWS Lambda function can be deleted from any network.<br/>B. An AWS Lambda function can be created from any network.<br/>C. An AWS Lambda function can be deleted from the 100.220.0.0/20 network.<br/>D. An AWS Lambda function can be deleted from the 220.100.16.0/20 network.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample101' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_647'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_188'>Random</a></p><div class='collapse' id='collapseExample101'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>An AWS Lambda function can be deleted from the 100.220.0.0/20 network.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 81%;" aria-valuenow="81" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_647><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 647</p><br/>A development team needs to host a website that will be accessed by other teams. The website contents consist of HTML. CSS, client&#8211;side JavaScript, and images.<br/><br/>Which method is the MOST cost&#8211;effective for hosting the website?<br/><br/>A. Containerize the website and host it in AWS Fargate.<br/>B. Create an Amazon S3 bucket and host the website there<br/>C. Deploy a web server on an Amazon EC2 instance to host the website.<br/>D. Configure an Application Load Balancer with an AWS Lambda target that uses the Express js framework.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample444' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_648'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_583'>Random</a></p><div class='collapse' id='collapseExample444'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Create an Amazon S3 bucket and host the website there</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 81%;" aria-valuenow="81" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_648><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 648</p><br/>A company wants to build an immutable infrastructure for its software applications. The company wants to test the software applications before sending traffic to them. The company seeks an efficient solution that limits the effects of application bugs<br/><br/>Which combination of steps should a solutions architect recommend? {Select TWO)<br/><br/>A. Use AWS Cloud Formation to update the production infrastructure and roll back the stack if the update fails<br/>B. Apply Amazon Route 53 weighted routing to test the staging environment and gradually increase the traffic as the tests pass<br/>C. Apply Amazon Route 53 failover routing to test the staging environment and fail over to the production environment if the tests pass<br/>D. Use AWS Cloud Formation with a parameter set to the staging value in a separate environment other than the production environment<br/>E. Use AWS Cloud Formation to deploy the staging environment with a snapshot deletion policy and reuse the resources in the production environment if the tests pass<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample466' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_649'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_317'>Random</a></p><div class='collapse' id='collapseExample466'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Use AWS Cloud Formation to update the production infrastructure and roll back the stack if the update fails
<br><b>B. </b>Apply Amazon Route 53 weighted routing to test the staging environment and gradually increase the traffic as the tests pass</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 82%;" aria-valuenow="82" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_649><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 649</p><br/>A company wants to launch a new application using Amazon Route 53, an Application Load Balancer (ALB), and an Amazon EC2 Auto Scaling group. The company is preparing to perform user experience testing and has a limited budget for this phase of the project. Although the company plans to do a load test in the future, it wants to prevent users from load testing at this time because it wants to limit unnecessary EC2 automatic scaling.<br/><br/>What should a solutions architect do to minimize costs of the user experience testing?<br/><br/>A. Configure AWS Shield's client request threshold to 100 connections per client.<br/>B. Deploy AWS WAF on the ALB with a rate&#8211;based rule configured to limit the number of requests each client can make.<br/>C. Configure the ALB with an advanced request routing policy to throttle the client connections being sent to the Auto Scaling group.<br/>D. Deploy Amazon Simple Queue Service (Amazon SQS) between the ALB and Auto Scaling group to queue client requests and change the Auto Scaling group maximum size to one.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample534' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_650'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_402'>Random</a></p><div class='collapse' id='collapseExample534'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Deploy AWS WAF on the ALB with a rate-based rule configured to limit the number of requests each client can make.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 82%;" aria-valuenow="82" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_650><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 650</p><br/>A company's order fulfillment service uses a MySQL database.<br/><br/>The database needs to support a large number of concurrent queries and transactions Developers are spending time patching and tuning the database.<br/><br/>This is causing delays in releasing new product features.<br/><br/>The company wants to use cloud&#8211;based services to help address this new challenge.<br/><br/>The solution must allow the developers to migrate the database with little or no code changes and must optimize performance.<br/><br/>Which service should a solutions architect use to meet these requirements?<br/><br/>A. Amazon Aurora<br/>B. Amazon DynamoDB<br/>C. Amazon ElastiCache<br/>D. MySQL on Amazon EC2<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample669' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_651'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_199'>Random</a></p><div class='collapse' id='collapseExample669'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Amazon Aurora</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 82%;" aria-valuenow="82" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_651><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 651</p><br/>A company is building a web application that servers a content management system.<br/><br/>The content management system runs on Amazon EC2 instances behind an Application Load Balancer (ALB).<br/><br/>The EC2 instances run in an Auto Scaling group across Availability Zones.<br/><br/>Users are constantly adding and updating files, blogs, and other website assets in the content management system.<br/><br/>Which solution meets these requirements?<br/><br/>A. Update the EC2 user data in the Auto Scaling group lifecycle policy to copy the website assets from the EC2 instance that was launched most recently. Configure the ALB to make changes to the websites assets only in the newest EC2 instance.<br/>B. Copy the website assets to an Amazon Elastic File System (Amazon EFS) Me system. Configure each EC2 instance to mount the EFS m system locally. Configure the website hosting application to reference the website assets that are stored in the EFS file system.<br/>C. Copy the website assets to an Amazon S3 bucket. Ensure that each EC2 instance downloads the website assets from the S3 bucket to the attached Amazon Basic Block Store (Amazon EBS) volume. Run the S3 sync command once each hour to keep files up to date.<br/>D. Restore an Amazon Elastic Block Store (Amazon EBS) snapshot w.th the website assets. Attach the EBS snapshot as a secondary EBS volume when a new EBS EC2 instance is launched. Configure the website hosting application to reference the website assets that are stored in the secondary EBS volume.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample602' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_652'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_332'>Random</a></p><div class='collapse' id='collapseExample602'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Copy the website assets to an Amazon S3 bucket. Ensure that each EC2 instance downloads the website assets from the S3 bucket to the attached Amazon Basic Block Store (Amazon EBS) volume. Run the S3 sync command once each hour to keep files up to date.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 82%;" aria-valuenow="82" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_652><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 652</p><br/>A company purchased Amazon EC2 Partial Upfront Reserved Instances for a 1&#8211;year term. A solutions architect wants to analyze how much the daily effective cost is with all possible discounts.<br/><br/>Which view must the solutions architect choose in the advanced options of Cost Explorer to get the correct values?<br/><br/>A. Show net amortized costs<br/>B. Show net unblended costs<br/>C. Show amortized costs<br/>D. Show blended costs<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample640' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_653'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_459'>Random</a></p><div class='collapse' id='collapseExample640'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Show amortized costs</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 82%;" aria-valuenow="82" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_653><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 653</p><br/>A company's web application is using multiple Linux Amazon EC2 instances and storing data on Amazon EBS volumes. The company is looking for a solution to increase the resiliency of the application in case of a failure and to provide storage that complies with atomicity, consistency, isolation, and durability (ACID).<br/><br/>What should a solutions architect do to meet these requirements?<br/><br/>A. Launch the application on EC2 instances in each Availability Zone. Attach EBS volumes to each EC2 instance.<br/>B. Create an Application Load Balancer with Auto Scaling groups across multiple Availability Zones. Mount an instance store on each EC2 instance.<br/>C. Create an Application Load Balancer with Auto Scaling groups across multiple Availability Zones. Store data on Amazon EFS and mount a target on each instance.<br/>D. Create an Application Load Balancer with Auto Scaling groups across multiple Availability Zones. Store data using Amazon S3 One Zone&#8211;Infrequent Access (S3 One Zone&#8211;IA).<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample29' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation29' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_654'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_201'>Random</a></p><div class='collapse' id='collapseExample29'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Create an Application Load Balancer with Auto Scaling groups across multiple Availability Zones. Store data on Amazon EFS and mount a target on each instance.</div></div></div><div class='collapse' id='explanation29'><div class='card card&#45;body'><div>
How Amazon EFS Works with Amazon EC2
The following illustration shows an example VPC accessing an Amazon EFS file system. Here, EC2 instances in the VPC have file systems mounted.

In this illustration, the VPC has three Availability Zones, and each has one mount target created in it. We recommend that you access the file system from a mount target within the same Availability Zone. One of the Availability Zones has two subnets. However, a mount target is created in only one of the subnets.



Benefits of Auto Scaling
Better fault tolerance. Amazon EC2 Auto Scaling can detect when an instance is unhealthy, terminate it, and launch an instance to replace it. You can also configure Amazon EC2 Auto Scaling to use multiple Availability Zones. If one Availability Zone becomes unavailable, Amazon EC2 Auto Scaling can launch instances in another one to compensate.

Better availability. Amazon EC2 Auto Scaling helps ensure that your application always has the right amount of capacity to handle the current traffic demand.

Better cost management. Amazon EC2 Auto Scaling can dynamically increase and decrease capacity as needed. Because you pay for the EC2 instances you use, you save money by launching instances when they are needed and terminating them when they aren't.

To increase the resiliency of the application the solutions architect can use Auto Scaling groups to launch and terminate instances across multiple availability zones based on demand. An application load balancer (ALB) can be used to direct traffic to the web application running on the EC2 instances.

Lastly, the Amazon Elastic File System (EFS) can assist with increasing the resilience of the application by providing a shared file system that can be mounted by multiple EC2 instances from multiple availability zones.

CORRECT: "Create an Application Load Balancer with Auto Scaling groups across multiple Availability Zones. Store data on Amazon EFS and mount a target on each instance" is the correct answer.

INCORRECT: "Launch the application on EC2 instances in each Availability Zone. Attach EBS volumes to each EC2 instance" is incorrect as the EBS volumes are single points of failure which are not shared with other instances.

INCORRECT: "Create an Application Load Balancer with Auto Scaling groups across multiple Availability Zones. Mount an instance store on each EC2 instance" is incorrect as instance stores are ephemeral data stores which means data is lost when powered down. Also, instance stores cannot be shared between instances.

INCORRECT: "Create an Application Load Balancer with Auto Scaling groups across multiple Availability Zones. Store data using Amazon S3 One Zone-Infrequent Access (S3 One Zone-IA)" is incorrect as there are data retrieval charges associated with this S3 tier. It is not a suitable storage tier for application files.

References:

Amazon Elastic File System Documentation
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 82%;" aria-valuenow="82" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_654><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 654</p><br/>A solution architect is designing the infrastructure for an application.<br/><br/>The application must have a managed MySQL database mat is highly available. The database will be (censed only by resources in the same VPC.<br/><br/>The database also must have auto scaling for storage and compute. Which solution meets these requirements?<br/><br/>A. Amazon RDS tor MySQL<br/>B. Amazon Aurora with MySQL compatibility<br/>C. Amazon Aurora Serverless with MySQL compatibility<br/>D. MySQL on Amazon EC2 instances with Amazon Elastic File System (Amazon EFS)<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample590' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_655'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_220'>Random</a></p><div class='collapse' id='collapseExample590'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Amazon RDS tor MySQL</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 82%;" aria-valuenow="82" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_655><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 655</p><br/>A company is using Site&#8211;to&#8211;Site VPN connection for secure connectivity to its AWS cloud resource from on&#8211;premises. Due to an increase in traffic across the VPN connections to the Amazon EC2 instances, users are experiencing slower VPN connectivity.<br/><br/>Which solution will improve the VPN throughput?<br/><br/>A. Implement multiple customer gateways for the same network to scale the throughput<br/>B. Use a Transit Gateway with equal cost multipath routing and add additional VPN tunnels.<br/>C. Configure a virtual gateway with equal cost multipath routing and multiple channels.<br/>D. Increase the number of tunnels in the VPN configuration to scale the throughput beyond the default limit.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample704' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_656'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_609'>Random</a></p><div class='collapse' id='collapseExample704'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Use a Transit Gateway with equal cost multipath routing and add additional VPN tunnels.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 82%;" aria-valuenow="82" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_656><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 656</p><br/>A company's website provides users with downloadable historical performance reports. The website needs a solution that will scale to meet the company's website demands globally. The solution should be cost effective, limit the provisioning of infrastructure resources, and provide the fastest possible response time.<br/><br/>Which combination should a solutions architect recommend to meet these requirements?<br/><br/>A. Amazon CloudFront and Amazon S3<br/>B. AWS Lambda and Amazon DynamoDB<br/>C. Application Load Balancer with Amazon EC2 Auto Scaling<br/>D. Amazon Route 53 with internal Application Load Balancers<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample88' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_657'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_394'>Random</a></p><div class='collapse' id='collapseExample88'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Amazon CloudFront and Amazon S3</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 83%;" aria-valuenow="83" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_657><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 657</p><br/>An image hosting company uploads its large assets to Amazon S3 Standard buckets.<br/><br/>The company uses multipart upload in parallel by using S3 APIs and overwrites if the same object is uploaded again.<br/><br/>For the first 30 days after upload the objects will be accessed frequently.<br/><br/>The objects will be used less frequently after 30 days but the access patterns for each object will be inconsistent.<br/><br/>The company must optimize its S3 storage costs while maintaining high availability and resiliency of stored assets.<br/><br/>Which combination of actions should a solutions architect recommend to meet these requirements? (Select TWO.)<br/><br/>A. Move assets to S3 Intelligent&#8211;Tiering after 30 days<br/>B. Configure an S3 Lifecycle policy to clean up incomplete multipart uploads<br/>C. Configure an S3 L lifecycle policy to clean up expired object delete markers<br/>D. Move ass ts to S3 Standard&#8211;Infrequent Access (S3 Standard&#8211;iA) after 30 days<br/>E. Move ass ts to S3 One Zone infrequent Access (S3 One Zone&#8211;IA) after 30 days<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample580' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_658'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_410'>Random</a></p><div class='collapse' id='collapseExample580'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Configure an S3 Lifecycle policy to clean up expired object delete markers
<br><b>D. </b>Move ass ts to S3 Standard-Infrequent Access (S3 Standard-iA) after 30 days</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 83%;" aria-valuenow="83" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_658><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 658</p><br/>A company runs a high performance computing (HPC) workload on AWS. The workload required low latency network performance and high network throughput with tightly coupled node&#8211;to&#8211;node communication. The Amazon EC2 instances are properly sized for compute and storage capacity, and are launched using default options.<br/><br/>What should a solutions architect propose to improve the performance of the workload?<br/><br/>A. Choose a cluster placement group while launching Amazon EC2 instances.<br/>B. Choose dedicated instance tenancy while launching Amazon EC2 instances.<br/>C. Choose an Elastic Inference accelerator while launching Amazon EC2 instances.<br/>D. Choose the required capacity reservation while launching Amazon EC2 instances.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample143' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_659'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_34'>Random</a></p><div class='collapse' id='collapseExample143'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Choose a cluster placement group while launching Amazon EC2 instances.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 83%;" aria-valuenow="83" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_659><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 659</p><br/>A company is running a batch application on Amazon EC2 instances.<br/><br/>The application consists of a backend with multiple Amazon RDS databases. The application is causing a high number of reads on the databases.<br/><br/>A solutions architect must reduce the number of database reads while ensuring high availability.<br/><br/>What should the solutions architect do to meet this requirement?<br/><br/>A. Add Amazon RDS read replicas.<br/>B. Use Amazon ElastiCache for Redis<br/>C. Use Amazon Route 53 DNS caching<br/>D. Use Amazon ElastiCache for Memcached<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample637' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_660'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_419'>Random</a></p><div class='collapse' id='collapseExample637'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Add Amazon RDS read replicas.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 83%;" aria-valuenow="83" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_660><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 660</p><br/>A company wants to deploy a shared file system for its .NET application servers and Microsoft SQL Server databases running on Amazon EC2 instances with Windows Server 2016. The solution must be able to be integrated into the corporate Active Directory domain, be highly durable, be managed by AWS, and provide high levels of throughput and IOPS.<br/><br/>Which solution meets these requirements?<br/><br/>A. Use Amazon FSx for Windows File Server.<br/>B. Use Amazon Elastic File System (Amazon EFS).<br/>C. Use AWS Storage Gateway in file gateway mode.<br/>D. Deploy a Windows file server on two On Demand instances across two Availability Zones.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample89' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_661'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_656'>Random</a></p><div class='collapse' id='collapseExample89'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Use Amazon FSx for Windows File Server.

References:

Amazon FSx for Windows File Server</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 83%;" aria-valuenow="83" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_661><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 661</p><br/>A company wants to migrate its MySQL database from on&#8211;premises to AWS. The company recently experienced a database outage that significantly impacted the business. To ensure this does not happen again, the company wants a reliable database solution on AWS that minimizes data loss and stores every transaction on at least two nodes.<br/><br/>Which solution meets these requirements?<br/><br/>A. Create an Amazon RDS DB instance with synchronous replication to three nodes in three Availability Zones.<br/>B. Create an Amazon RDS MySQL DB instance with Multi&#8211;AZ functionality enabled to synchronously replicate the data.<br/>C. Create an Amazon RDS MySQL DB instance with Multi&#8211;AZ and the create a read replica in a separate AWS Region that synchronously replicates the data.<br/>D. Create an Amazon EC2 instance with a MySQL engine installed that triggers an AWS Lambda function to synchronously replicate the data to an Amazon RDS MySQL DB instance.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample698' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_662'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_539'>Random</a></p><div class='collapse' id='collapseExample698'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Create an Amazon RDS MySQL DB instance with Multi-AZ functionality enabled to synchronously replicate the data.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 83%;" aria-valuenow="83" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_662><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 662</p><br/>A company is developing a serverless web application that gives users the ability to interact with real&#8211;time analytics from online games. The data from the games must be streamed in real time. The company needs a durable, low&#8211;latency database option for user data. The company does not know how many users will use the application Any design considerations must provide response times of single&#8211;digit milliseconds as the application scales.<br/><br/>Which combination of AWS services will meet these requirements? (Select TWO.)<br/><br/>A. Amazon CloudFront<br/>B. Amazon DynamoDB<br/>C. Amazon Kinesis<br/>D. Amazon RDS<br/>E. AWS Global Accelerator<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample471' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_663'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_734'>Random</a></p><div class='collapse' id='collapseExample471'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Amazon CloudFront
<br><b>B. </b>Amazon DynamoDB</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 83%;" aria-valuenow="83" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_663><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 663</p><br/>A monolithic application was recently migrated to AWS and is now running on a single Amazon EC2 instance. Due to application limitations, it is not possible to use automatic scaling to scale out the application. The chief technology officer (CTO) wants an automated solution to restore the EC2 instance in the unlikely event the underlying hardware fails.<br/><br/>What would allow for automatic recovery of the EC2 instance as quickly as possible?<br/><br/>A. Configure an Amazon CloudWatch alarm that triggers the recovery of the EC2 instance if it becomes impaired.<br/>B. Configure an Amazon CloudWatch alarm to trigger an SNS message that alerts the CTO when the EC2 instance is impaired.<br/>C. Configure AWS CloudTrail to monitor the health of the EC2 instance, and if it becomes impaired, trigger instance recovery.<br/>D. Configure an Amazon EventBridge event to trigger an AWS Lambda function once an hour that checks the health of the EC2 instance and triggers instance recovery if the EC2 instance is unhealthy.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample170' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_664'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_140'>Random</a></p><div class='collapse' id='collapseExample170'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Configure an Amazon CloudWatch alarm that triggers the recovery of the EC2 instance if it becomes impaired.

References:

Amazon Elastic Compute Cloud > User Guide for Linux Instances > Recover your instance</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 83%;" aria-valuenow="83" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_664><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 664</p><br/>A company is using an Amazon S3 bucket to store data uploaded by different departments from multiple locations.<br/><br/>During an AWS Well&#8211;Architected review the financial manager notices that 10 TB of S3 Standard storage data has been charged each month.<br/><br/>However, in the AWS Management Console for Amazon S3, using the command to select all files and folders shows a total size of 5 TB.<br/><br/>What are the possible causes for this difference? (Select TWO )<br/><br/>A. Some files are stored with deduplication<br/>B. The S3 bucket has versioning enabled<br/>C. There are incomplete S3 multipart uploads<br/>D. The S3 bucket has AWS Key Management Service (AWS KMS) enabled<br/>E. The S3 bucket has Intelligent&#8211;Tiering enabled<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample652' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_665'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_418'>Random</a></p><div class='collapse' id='collapseExample652'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>The S3 bucket has versioning enabled
<br><b>C. </b>There are incomplete S3 multipart uploads</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 84%;" aria-valuenow="84" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_665><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 665</p><br/>You are in the process of creating a Route 53 DNS failover to direct traffic to two EC2 zones. Obviously, if one fails, you would like Route 53 to direct traffic to the other region. Each region has an ELB with some instances being distributed.<br/><br/>What is the best way for you to configure the Route 53 health check?<br/><br/>A. Route 53 doesn't support ELB with an internal health check. You need to create your own Route 53 health check of the ELB<br/>B. Route 53 natively supports ELB with an internal health check. Turn "Evaluate target health" off and "Associate with Health Check" on and R53 will use the ELB's internal health check.<br/>C. Route 53 doesn't support ELB with an internal health check. You need to associate your resource record set for the ELB with your own health check<br/>D. Route 53 natively supports ELB with an internal health check. Turn "Evaluate target health" on and "Associate with Health Check" off and R53 will use the ELB's internal health check.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample756' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation756' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_666'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_725'>Random</a></p><div class='collapse' id='collapseExample756'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Route 53 natively supports ELB with an internal health check. Turn "Evaluate target health" on and "Associate with Health Check" off and R53 will use the ELB's internal health check.</div></div></div><div class='collapse' id='explanation756'><div class='card card&#45;body'><div>
With DNS Failover, Amazon Route 53 can help detect an outage of your website and redirect your end users to alternate locations where your application is operating properly. When you enable this feature, Route 53 uses health checks–regularly making Internet requests to your application's endpoints from multiple locations around the world–to determine whether each endpoint of your application is up or down. To enable DNS Failover for an ELB endpoint, create an Alias record pointing to the ELB and set the "Evaluate Target Health" parameter to true. Route 53 creates and manages the health checks for your ELB automatically. You do not need to create your own Route 53 health check of the ELB. You also do not need to associate your resource record set for the ELB with your own health check, because Route 53 automatically associates it with the health checks that Route 53 manages on your behalf. The ELB health check will also inherit the health of your backend instances behind that ELB.

References:

Amazon Route 53 Adds Elastic Load Balancer Integration for DNS Failover</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 84%;" aria-valuenow="84" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_666><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 666</p><br/>A company's application runs on Amazon EC2 instances behind an Application Load Balancer (ALB). The instances run in an Amazon EC2 Auto Scaling group across multiple Availability Zones. On the first day of every month at midnight, the application becomes much slower when the month&#8211;end financial calculation batch executes. This causes the CPU utilization of the EC2 instances to immediately peak to 100%, which disrupts the application.<br/><br/>What should a solutions architect recommend to ensure the application is able to handle the workload and avoid downtime?<br/><br/>A. Configure an Amazon CloudFront distribution in front of the ALB.<br/>B. Configure an EC2 Auto Scaling simple scaling policy based on CPU utilization.<br/>C. Configure an EC2 Auto Scaling scheduled scaling policy based on the monthly schedule.<br/>D. Configure Amazon ElastiGache to remove some of the workload from the EC2 instances.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample413' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_667'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_635'>Random</a></p><div class='collapse' id='collapseExample413'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Configure an EC2 Auto Scaling scheduled scaling policy based on the monthly schedule.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 84%;" aria-valuenow="84" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_667><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 667</p><br/>An eCommerce website is deploying its web application as Amazon Elastic Container Service (Amazon ECS) container instances behind an Application Load Balancer (ALB). During periods of high activity, the website slows down and availability is reduced.<br/><br/>A solutions architect uses Amazon CloudWatch alarms to receive notifications whenever there is an availability issue so they can scale out resources. Company management wants a solution that automatically responds to such events.<br/><br/>Which solution meets these requirements?<br/><br/>A. Set up AWS Auto Scaling to scale out the ECS service when there are timeouts on the ALB. Set up AWS Auto Scaling to scale out the ECS cluster when the CPU or memory reservation is too high.<br/>B. Set up AWS Auto Scaling to scale out the ECS service when the ALB CPU utilization is too high. Set up AWS Auto Scaling to scale out the ECS cluster when the CPU or memory reservation is too high.<br/>C. Sot up AWS Auto Scaling to scale out the ECS service when the service's CPU utilization is too high. Set up AWS Auto Scaling to scale out the ECS cluster when the CPU or memory reservation is too high.<br/>D. Set up AWS Auto Scaling to scale out the ECS service when the ALB target group CPU utilization is too high. Set up AWS Auto Scaling to scale out the ECS cluster when the CPU or memory reservation is too high.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample674' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_668'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_672'>Random</a></p><div class='collapse' id='collapseExample674'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Set up AWS Auto Scaling to scale out the ECS service when there are timeouts on the AL<br><b>B. </b>Set up AWS Auto Scaling to scale out the ECS cluster when the CPU or memory reservation is too high.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 84%;" aria-valuenow="84" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_668><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 668</p><br/>A company's website is used to sell products to the public. The site runs on Amazon EC2 instances in an Auto Scaling group behind an Application Load Balancer (ALB). There is also an Amazon CloudFront distribution, and AWS WAF is being used to protect against SQL injection attacks. The ALB is the origin for the CloudFront distribution. A recent review of security logs revealed an external malicious IP that needs to be blocked from accessing the website.<br/><br/>What should a solutions architect do to protect the application?<br/><br/>A. Modify the network ACL on the CloudFront distribution to add a deny rule for the malicious IP address.<br/>B. Modify the configuration of AWS WAF to add an IP match condition to block the malicious IP address.<br/>C. Modify the network ACL for the EC2 instances in the target groups behind the ALB to deny the malicious IP address.<br/>D. Modify the security groups for the EC2 instances in the target groups behind the ALB to deny the malicious IP address.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample21' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation21' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_669'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_238'>Random</a></p><div class='collapse' id='collapseExample21'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Modify the configuration of AWS WAF to add an IP match condition to block the malicious IP address.</div></div></div><div class='collapse' id='explanation21'><div class='card card&#45;body'><div>
If you want to allow or block web requests based on the IP addresses that the requests originate from, create one or more IP match conditions. An IP match condition lists up to 10,000 IP addresses or IP address ranges that your requests originate from. Later in the process, when you create a web ACL, you specify whether to allow or block requests from those IP addresses.

AWS Web Application Firewall (WAF) – Helps to protect your web applications from common application layer exploits that can affect availability or consume excessive resources. As you can see in my post (New – AWS WAF), WAF allows you to use access control lists (ACLs), rules, and conditions that define acceptable or unacceptable requests or IP addresses. You can selectively allow or deny access to specific parts of your web application and you can also guard against various SQL injection attacks. We launched WAF with support for Amazon CloudFront.

A new version of the AWS Web Application Firewall was released in November 2019. With AWS WAF classic you create "IP match conditions", whereas with AWS WAF (new version) you create "IP set match statements". Look out for wording on the exam.

The IP match condition / IP set match statement inspects the IP address of a web request's origin against a set of IP addresses and address ranges.

Use this to allow or block web requests based on the IP addresses that the requests originate from.

AWS WAF supports all IPv4 and IPv6 address ranges. An IP set can hold up to 10,000 IP addresses or IP address ranges to check.

CORRECT: "Modify the configuration of AWS WAF to add an IP match condition to block the malicious IP address" is the correct answer.

INCORRECT: "Modify the network ACL on the CloudFront distribution to add a deny rule for the malicious IP address" is incorrect as CloudFront does not sit within a subnet so network ACLs do not apply to it.

INCORRECT: "Modify the network ACL for the EC2 instances in the target groups behind the ALB to deny the malicious IP address" is incorrect as the source IP addresses of the data in the EC2 instances' subnets will be the ELB IP addresses.

INCORRECT: "Modify the security groups for the EC2 instances in the target groups behind the ALB to deny the malicious IP address." is incorrect as you cannot create deny rules with security groups.

References:

AWS WAF, AWS Firewall Manager, and AWS Shield Advanced > Developer Guide > What are AWS WAF, AWS Shield, and AWS Firewall Manager?

</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 84%;" aria-valuenow="84" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_669><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 669</p><br/>A company is processing data on a daily basis. The results of the operations are stored in an Amazon S3 bucket, analyzed daily for one week, and then must remain immediately accessible for occasional analysis.<br/><br/>What is the MOST cost&#8211;effective storage solution alternative to the current configuration?<br/><br/>A. Configure a lifecycle policy to delete the objects after 30 days.<br/>B. Configure a lifecycle policy to transition the objects to Amazon S3 Glacier after 30 days.<br/>C. Configure a lifecycle policy to transition the objects to Amazon S3 Standard&#8211;Infrequent Access (S3 Standard&#8211;IA) after 30 days.<br/>D. Configure a lifecycle policy to transition the objects to Amazon S3 One Zone&#8211;Infrequent Access (S3 One Zone&#8211;IA) after 30 days.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample266' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_670'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_434'>Random</a></p><div class='collapse' id='collapseExample266'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Configure a lifecycle policy to transition the objects to Amazon S3 One Zone-Infrequent Access (S3 One Zone-IA) after 30 days.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 84%;" aria-valuenow="84" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_670><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 670</p><br/>A company has a mobile game that reads most of its metadata from an Amazon RDS DB instance. As the game increased in popularity developers noticed slowdowns related to the game's metadata load times.<br/><br/>Performance metrics indicate that simply scaling the database will not help. A solutions architect must explore all options that include capabilities for snapshots replication and sub&#8211;millisecond response times.<br/><br/>What should the solutions architect recommend to solve these issues?<br/><br/>A. Migrate the database to Amazon Aurora with Aurora Replicas.<br/>B. Migrate the database to Amazon DyramoDB with global tables.<br/>C. Add an Amazon ElastiCache for Redis layer in front of the database.<br/>D. Add an Amazon ElastiCache for Memcached layer in front of the database.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample410' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_671'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_102'>Random</a></p><div class='collapse' id='collapseExample410'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Migrate the database to Amazon DyramoDB with global tables.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 84%;" aria-valuenow="84" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_671><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 671</p><br/>A company has thousands of edge devices that collectively generate 1 TB of status alerts each day. Each alert is approximately 2 KB in size. A solutions architect needs to implement a solution to ingest and store the alerts for future analysis.<br/><br/>The company wants a highly available solution. However, the company needs to minimize costs and does not want to manage additional infrastructure. Additionally, the company wants to keep 14 days of data available for immediate analysis and archive any data older than 14 days.<br/><br/>What is the MOST operationally efficient solution that meets these requirements?<br/><br/>A. Create an Amazon Kinesis Data Firehose delivery stream to ingest the alerts. Configure the Kinesis Data Firehose stream to deliver the alerts to an Amazon S3 bucket. Set up an S3 Lifecycle configuration to transition data to Amazon S3 Glacier after 14 days.<br/>B. Launch Amazon EC2 instances across two Availability Zones and place them behind an Elastic Load Balancer to ingest the alerts. Create a script on the EC2 instances that will store the alerts in an Amazon S3 bucket. Set up an S3 Lifecycle configuration to transition data to Amazon S3 Glacier after 14 days.<br/>C. Create an Amazon Kinesis Data Firehose delivery stream to ingest the alerts. Configure the Kinesis Data Firehose stream to deliver the alerts to an Amazon Elasticsearch Service (Amazon ES) cluster. Set up the Amazon ES cluster to take manual snapshots every day and delete data from the cluster that is older than 14 days.<br/>D. Create an Amazon Simple Queue Service (Amazon SQS) standard queue to ingest the alerts, and set the message retention period to 14 days. Configure consumers to poll the SQS queue, check the age of the message, and analyze the message data as needed. If the message is 14 days old, the consumer should copy the message to an Amazon S3 bucket and delete the message from the SQS queue.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample307' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_672'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_578'>Random</a></p><div class='collapse' id='collapseExample307'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Create an Amazon Kinesis Data Firehose delivery stream to ingest the alerts. Configure the Kinesis Data Firehose stream to deliver the alerts to an Amazon S3 bucket. Set up an S3 Lifecycle configuration to transition data to Amazon S3 Glacier after 14 days.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 84%;" aria-valuenow="84" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_672><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 672</p><br/>A company's application runs on Amazon EC2 instances behind an Application Load Balancer (ALB). The instances run in an Amazon EC2 Auto Scaling group across multiple Availability Zones. On the first day of every month at midnight, the application becomes much slower when the month&#8211;end financial calculation batch executes. This causes the CPU utilization of the EC2 instances to immediately peak to 100%, which disrupts the application.<br/><br/>What should a solutions architect recommend to ensure the application is able to handle the workload and avoid downtime?<br/><br/>A. Configure an Amazon CloudFront distribution in front of the ALB.<br/>B. Configure an EC2 Auto Scaling simple scaling policy based on CPU utilization.<br/>C. Configure an EC2 Auto Scaling scheduled scaling policy based on the monthly schedule.<br/>D. Configure Amazon ElastiCache to remove some of the workload from the EC2 instances.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample5' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation5' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_673'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_219'>Random</a></p><div class='collapse' id='collapseExample5'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Configure an EC2 Auto Scaling scheduled scaling policy based on the monthly schedule.</div></div></div><div class='collapse' id='explanation5'><div class='card card&#45;body'><div>
Scheduled Scaling for Amazon EC2 Auto Scaling
Scheduled scaling allows you to set your own scaling schedule. For example, let's say that every week the traffic to your web application starts to increase on Wednesday, remains high on Thursday, and starts to decrease on Friday. You can plan your scaling actions based on the predictable traffic patterns of your web application. Scaling actions are performed automatically as a function of time and date.

Scheduled scaling allows you to set your own scaling schedule. In this case the scaling action can be scheduled to occur just prior to the time that the reports will be run each month. Scaling actions are performed automatically as a function of time and date. This will ensure that there are enough EC2 instances to serve the demand and prevent the application from slowing down.

CORRECT: "Configure an EC2 Auto Scaling scheduled scaling policy based on the monthly schedule" is the correct answer.

INCORRECT: "Configure an Amazon CloudFront distribution in front of the ALB" is incorrect as this would be more suitable for providing access to global users by caching content.

INCORRECT: "Configure an EC2 Auto Scaling simple scaling policy based on CPU utilization" is incorrect as this would not prevent the slow-down from occurring as there would be a delay between when the CPU hits 100% and the metric being reported and additional instances being launched.

INCORRECT: "Configure Amazon ElastiCache to remove some of the workload from the EC2 instances" is incorrect as ElastiCache is a database cache, it cannot replace the compute functions of an EC2 instance.

References:

Amazon EC2 Auto Scaling > User Guide > Scheduled scaling for Amazon EC2 Auto Scaling</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 85%;" aria-valuenow="85" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_673><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 673</p><br/>A company is using a tape backup solution to store its key application data offsite. The daily data volume is around 50 TB. The company needs to retain the backups for 7 years for regulatory purposes. The backups are rarely accessed, and a week's notice is typically given if a backup needs to be restored.<br/><br/>The company is now considering a cloud&#8211;based option to reduce the storage costs and operational burden of managing tapes. The company also wants to make sure that the transition from tape backups to the cloud minimizes disruptions.<br/><br/>Which storage solution is MOST cost&#8211;effective?<br/><br/>A. Use Amazon Storage Gateway to back up to Amazon Glacier Deep Archive.<br/>B. Use AWS Snowball Edge to directly integrate the backups with Amazon S3 Glacier.<br/>C. Copy the backup data to Amazon S3 and create a lifecycle policy to move the data to Amazon S3 Glacier.<br/>D. Use Amazon Storage Gateway to back up to Amazon S3 and create a lifecycle policy to move the backup to Amazon S3 Glacier.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample172' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_674'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_694'>Random</a></p><div class='collapse' id='collapseExample172'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Use Amazon Storage Gateway to back up to Amazon Glacier Deep Archive.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 85%;" aria-valuenow="85" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_674><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 674</p><br/>A company is migrating a Linux&#8211;based web server group to AWS. The web servers must access files in a shared file store for some content to meet the migration date, minimal changes can be made.<br/><br/>What should a solutions architect do to meet these requirements?<br/><br/>A. Create an Amazon S3 Standard bucket with access to the web server.<br/>B. Configure an Amazon CloudFront distribution with an Amazon S3 bucket as the origin.<br/>C. Create an Amazon Elastic File System (Amazon EFS) volume and mount it on all web servers.<br/>D. Configure Amazon Elastic Block Store (Amazon EBS) Provisioned IOPS SSD (io1) volumes and mount them on all web servers.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample693' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_675'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_182'>Random</a></p><div class='collapse' id='collapseExample693'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Create an Amazon Elastic File System (Amazon EFS) volume and mount it on all web servers.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 85%;" aria-valuenow="85" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_675><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 675</p><br/>A company wants to migrate la accounting system from an on&#8211;premises data center to the AWS Cloud in a single AWS Region Data security and an immutable audit log are the top priorities.<br/><br/>The company must monitor all AWS activities for compliance auditing. The company has enabled AWS CloudTrail but wants to make sure it meets these requirements.<br/><br/>Which actions should a solutions architect take to protect and secure CloudTrail? (Select TWO.)<br/><br/>A. Enable CloudTrail log tile validation<br/>B. Install the CloudTrail Processing Library<br/>C. Enable logging of insights events in CloudTrail<br/>D. Enable custom logging from the on&#8211;premises resources<br/>E. Create an AWS Config rule to monitor whether CloudTrail is configured to use server&#8211;side encryption with AWS KMS managed encryption keys (SSE&#8211;KMS)<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample593' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_676'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_47'>Random</a></p><div class='collapse' id='collapseExample593'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Enable logging of insights events in CloudTrail
<br><b>E. </b>Create an AWS Config rule to monitor whether CloudTrail is configured to use server-side encryption with AWS KMS managed encryption keys (SSE-KMS)</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 85%;" aria-valuenow="85" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_676><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 676</p><br/>You are setting up a VPC and you need to set up a public subnet within that VPC. Which following requirement must be met for this subnet to be considered a public subnet?<br/><br/>A. Subnet's traffic is not routed to an internet gateway but has its traffic routed to a virtual private gateway.<br/>B. Subnet's traffic is routed to an internet gateway.<br/>C. Subnet's traffic is not routed to an internet gateway.<br/>D. None of these answers can be considered a public subnet.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample750' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation750' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_677'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_436'>Random</a></p><div class='collapse' id='collapseExample750'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Subnet's traffic is routed to an internet gateway.</div></div></div><div class='collapse' id='explanation750'><div class='card card&#45;body'><div>
A virtual private cloud (VPC) is a virtual network dedicated to your AWS account. It is logically isolated from other virtual networks in the AWS cloud. You can launch your AWS resources, such as Amazon EC2 instances, into your VPC. You can configure your VPC: you can select its IP address range, create subnets, and configure route tables, network gateways, and security settings. A subnet is a range of IP addresses in your VPC. You can launch AWS resources into a subnet that you select. Use a public subnet for resources that must be connected to the internet, and a private subnet for resources that won't be connected to the Internet. If a subnet's traffic is routed to an internet gateway, the subnet is known as a public subnet. If a subnet doesn't have a route to the internet gateway, the subnet is known as a private subnet. If a subnet doesn't have a route to the internet gateway, but has its traffic routed to a virtual private gateway, the subnet is known as a VPN-only subnet.

References:

Amazon Virtual Private Cloud > User Guide > VPCs and subnets</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 85%;" aria-valuenow="85" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_677><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 677</p><br/>A company is deploying a multi&#8211;instance application within AWS that requires minimal latency between the instances.<br/><br/>What should a solutions architect recommend?<br/><br/>A. Use an Auto Scaling group with a cluster placement group.<br/>B. Use an Auto Scaling group with single Availability Zone in the same AWS Region.<br/>C. Use an Auto Scaling group with multiple Availability Zones in the same AWS Region.<br/>D. Use a Network Load Balancer with multiple Amazon EC2 Dedicated Hosts as the targets.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample277' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_678'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_267'>Random</a></p><div class='collapse' id='collapseExample277'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Use an Auto Scaling group with a cluster placement group.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 85%;" aria-valuenow="85" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_678><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 678</p><br/>A company is deploying an application that processes large quantities of data in parallel. The company plans to use Amazon EC2 instances for the workload.<br/><br/>The network architecture must be configurable to provide the lowest possible latency between nodes.<br/><br/>Which combination of network solutions will meet these requirements? (Select TWO)<br/><br/>A. Distribute the EC2 instances across multiple Availability Zones<br/>B. Attach an Elastic Fabric Adapter (EFA) to each EC2 instance<br/>C. Place the EC2 instances in a single Availability Zone<br/>D. Use Amazon Elastic Block Store (Amazon EBS) optimized instance types<br/>E. Run the EC2 instances in a cluster placement group<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample632' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_679'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_86'>Random</a></p><div class='collapse' id='collapseExample632'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Place the EC2 instances in a single Availability Zone
<br><b>E. </b>Run the EC2 instances in a cluster placement group</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 85%;" aria-valuenow="85" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_679><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 679</p><br/>A company is using a VPC peering strategy to connect its VPCs in a single Region to allow for cross&#8211; communication. A recent increase in account creations and VPCs has made it difficult to maintain the VPC peering strategy, and the company expects to grow to hundreds of VPCs.<br/><br/>There are also new requests to create site&#8211;to&#8211;site VPNs with some of the VPCs. A solutions architect has been tasked with creating a centrally networking setup for multiple accounts, VPNS, and VPNs.<br/><br/>Which networking solution meets these requirements?<br/><br/>A. Configure shared VPCs and VPNs and share with each other<br/>B. Configure a hub&#8211;and&#8211;spoke and route all traffic through VPC peering.<br/>C. Configure an AWS Direct Connect between all VPCs and VPNs.<br/>D. Configure a transit gateway with AWS Transit Gateway and connected all VPCs and VPNs.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample727' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_680'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_665'>Random</a></p><div class='collapse' id='collapseExample727'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Configure a transit gateway with AWS Transit Gateway and connected all VPCs and VPNs.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 85%;" aria-valuenow="85" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_680><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 680</p><br/>A company is running an application on AWS to process weather sensor data that is stored in an Amazon S3 bucket.<br/><br/>Three batch jobs run hourly to process the data in the S3 bucket for different purposes.<br/><br/>The company wants to reduce the overall processing time by running the three applications in parallel using an event&#8211;based approach.<br/><br/>What should a solutions architect do to meet these requirements?<br/><br/>A. Enable S3 Event Notifications for new objects to an Amazon Simple Queue Service (Amazon SQS) FIFO queue. Subscribe all applications to the queue for processing<br/>B. Enable S3 Event Notifications for new objects to an Amazon Simple Queue Service (Amazon SQS) standard queue. Create an additional SQS queue for all applications and subscribe all applications to the initial queue for processing<br/>C. Enable S3 Event Notifications for new objects to separate Amazon Simple Queue Service (Amazon SQS) FIFO queues. Create an additional SQS queue for each application and subscribe each queue to the initial topic for processing<br/>D. Enable S3 Event Notifications for new objects to an Amazon Simple Notification Service (Amazon SNS) topic. Create an Amazon Simple Queue Service (Amazon SQS) queue for each application and subscribe each queue to the topic for processing<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample629' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_681'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_780'>Random</a></p><div class='collapse' id='collapseExample629'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Enable S3 Event Notifications for new objects to separate Amazon Simple Queue Service (Amazon SQS) FIFO queues. Create an additional SQS queue for each application and subscribe each queue to the initial topic for processing</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 86%;" aria-valuenow="86" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_681><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 681</p><br/>The following IAM policy is attached to an IAM group. This is the only policy applied to the group.<br/>The following IAM policy is attached to an IAM group. This is the only policy applied to the group.<br/>What are the effective IAM permissions of this policy for group members?<br/><br/>A. Group members are permitted any Amazon EC2 action within the us&#8211;east&#8211;1 Region. Statements after. The Allow permission are not applied<br/>B. Group member are denied any Amazon EC2 permissions in the us&#8211;east&#8211;1 Region unless they are tagged in with multi&#8211;factor authentication (MFA).<br/>C. Group members are allowed the ec2:StopInstances and ec2:Terminatelnstances permissions for all Regions when logged in with multi&#8211;factor authentication (MFA). Group members authorized any other Amazon EC2 action.<br/>D. Group members are allowed the ec2:Stoplnstances and ec2:Terminatelnstances permissions for the us&#8211;east&#8211;1 Region only when logged in with multi&#8211;factor authentication (MFA). Groups are permitted any other Amazon EC2 action within the us&#8211;east&#8211;1 Region<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample491' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_682'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_35'>Random</a></p><div class='collapse' id='collapseExample491'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Group members are allowed the ec2:Stoplnstances and ec2:Terminatelnstances permissions for the us-east-1 Region only when logged in with multi-factor authentication (MFA). Groups are permitted any other Amazon EC2 action within the us-east-1 Region</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 86%;" aria-valuenow="86" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_682><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 682</p><br/>A company has migrated an on&#8211;premises Oracle database to an Amazon RDS for Oracle Multi&#8211;AZ DB instance in the us&#8211;east&#8211;l Region. A solutions architect is designing a disaster recovery strategy to have the database provisioned in the us&#8211;west&#8211;2 Region in case the database becomes unavailable in the us&#8211;east&#8211;1 Region. The design must ensure the database is provisioned in the us&#8211;west&#8211;2 Region in a maximum of 2 hours, with a data loss window of no more than 3 hours.<br/><br/>How can these requirements be met?<br/><br/>A. Edit the DB instance and create a read replica in us&#8211;west&#8211;2. Promote the read replica to master in us&#8211;west&#8211;2 in case the disaster recovery environment needs to be activated.<br/>B. Select the multi&#8211;Region option to provision a standby instance in us&#8211;west&#8211;2. The standby instance will be automatically promoted to master in us&#8211;west&#8211;2 in case the disaster recovery environment needs to be created.<br/>C. Take automated snapshots of the database instance and copy them to us&#8211;west&#8211;2 every 3 hours. Restore the latest snapshot to provision another database instance in us&#8211;west&#8211;2 in case the disaster recovery environment needs to be activated.<br/>D. Create a multimaster read/write instances across multiple AWS Regions Select VPCs in us&#8211;east&#8211;1 and us&#8211;west&#8211;2 to make that deployment. Keep the master read/write instance in us&#8211;west&#8211;2 available to avoid having to activate a disaster recovery environment.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample169' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_683'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_757'>Random</a></p><div class='collapse' id='collapseExample169'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Edit the DB instance and create a read replica in us-west-2. Promote the read replica to master in us-west-2 in case the disaster recovery environment needs to be activated.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 86%;" aria-valuenow="86" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_683><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 683</p><br/>A company is using Amazon S3 as its local repository for weekly analysis reports. One of the company&#8211;wide requirements is to secure data at rest using encryption. The company chooses Amazon 53 server&#8211;side encryption (SSE)<br/><br/>How can the object be decrypted when a GET request is issued?<br/><br/>A. the user needs a Put request to decrypt the object<br/>B. The user needs to decrypt the object using a private Key<br/>C. Amazon S3 manages encryption and decryption automatically<br/>D. Amazon S3 provides a server&#8211;side key for decrypting the object<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample588' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_684'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_254'>Random</a></p><div class='collapse' id='collapseExample588'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Amazon S3 provides a server-side key for decrypting the object</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 86%;" aria-valuenow="86" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_684><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 684</p><br/>After setting up a Virtual Private Cloud (VPC) network, a more experienced cloud engineer suggests that to achieve low network latency and high network throughput you should look into setting up a placement group. You know nothing about this, but begin to do some research about it and are especially curious about its limitations.<br/><br/>Which of the below statements is wrong in describing the limitations of a placement group?<br/><br/>A. Although launching multiple instance types into a placement group is possible, this reduces the likelihood that the required capacity will be available for your launch to succeed.<br/>B. A placement group can span multiple Availability Zones.<br/>C. You can't move an existing instance into a placement group.<br/>D. A placement group can span peered VPCs<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample774' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation774' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_685'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_379'>Random</a></p><div class='collapse' id='collapseExample774'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>A placement group can span peered VPCs</div></div></div><div class='collapse' id='explanation774'><div class='card card&#45;body'><div>
A placement group is a logical grouping of instances within a single Availability Zone. Using placement groups enables applications to participate in a low-latency, 10 Gbps network.

Placement groups are recommended for applications that benefit from low network latency, high network throughput, or both. To provide the lowest latency, and the highest packet-per-second network performance for your placement group, choose an instance type that supports enhanced networking.

Placement groups have the following limitations: The name you specify for a placement group a name must be unique within your AWS account. A placement group can't span multiple Availability Zones. Although launching multiple instance types into a placement group is possible, this reduces the likelihood that the required capacity will be available for your launch to succeed. We recommend using the same instance type for all instances in a placement group. You can't merge placement groups. Instead, you must terminate the instances in one placement group, and then relaunch those instances into the other placement group. A placement group can span peered VPCs; however, you will not get full-bisection bandwidth between instances in peered VPCs. For more information about VPC peering connections, see VPC Peering in the Amazon VPC User Guide. You can't move an existing instance into a placement group. You can create an AMI from your existing instance, and then launch a new instance from the AMI into a placement group.

References:

Amazon Elastic Compute Cloud > User Guide for Linux Instances > Placement groups</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 86%;" aria-valuenow="86" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_685><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 685</p><br/>A social media company is building a feature for its website. The feature will give users the ability to upload photos. The company expects significant increases in demand during large events and must ensure that the website can handle the upload traffic from users.<br/><br/>Which solution meets these requirements with the MOST scalability?<br/><br/>A. Upload files from the user's browser to the application servers Transfer the files to an Amazon S3 bucket.<br/>B. Provision an AWS Storage Gateway file gateway. Upload files directly from the user's browser to the file gateway.<br/>C. Generate Amazon S3 presigned URLs in the application. Upload files directly from the user's browser into an S3 bucket<br/>D. Provision an Amazon Elastic File System (Amazon EFS) file system. Upload files directly from the user's browser to the file system.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample443' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_686'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_283'>Random</a></p><div class='collapse' id='collapseExample443'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Generate Amazon S3 presigned URLs in the application. Upload files directly from the user's browser into an S3 bucket</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 86%;" aria-valuenow="86" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_686><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 686</p><br/>A company wants to identify underutilized instances for Amazon EX2 and Amazon RDS.<br/><br/>The company needs to report on the cost of all underutilized instances and the utilization metrics for each resource.<br/><br/>Which combination of tools and services will provide this data? (Select TWO.)<br/><br/>A. Cost Explorer<br/>B. AWS Cost and Usage Report<br/>C. AWS Budgets<br/>D. Amazon CloudWarch<br/>E. AWS CloudTrail<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample594' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_687'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_692'>Random</a></p><div class='collapse' id='collapseExample594'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Cost Explorer
<br><b>D. </b>Amazon CloudWarch</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 86%;" aria-valuenow="86" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_687><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 687</p><br/>A company is running a multi&#8211;tier web application on AWS. The application runs its database tier on Amazon Aurora MySQL. The application and database tiers are in the us&#8211;east&#8211;1 Region. A database administrator who regularly monitors the Aurora DB cluster finds that an intermittent increase in read traffic is creating high CPU utilization on the read replica and causing increased read latency of the application.<br/><br/>What should a solutions architect do to improve read scalability?<br/><br/>A. Reboot the Aurora DB cluster.<br/>B. Create a cross&#8211;Region read replica<br/>C. Increase the instance class of the read replica.<br/>D. Configure Aurora Auto Scaling for the read replica.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample342' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_688'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_347'>Random</a></p><div class='collapse' id='collapseExample342'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Configure Aurora Auto Scaling for the read replica.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 86%;" aria-valuenow="86" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_688><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 688</p><br/>A development team is deploying a new product on AWS and is using AWS Lambda as part of the deployment. The team allocates 512 MB of memory for one of the Lambda functions. With this memory allocation, the function is completed in 2 minutes. The function runs millions of times monthly, and the development team is concerned about cost. The team conducts tests to see how different Lambda memory allocations affect the cost of the function.<br/><br/>Which steps will reduce the Lambda costs for the product? (Choose two.)<br/><br/>A. Increase the memory allocation for this Lambda function to 1,024 MB if this change causes the execution time of each function to be less than 1 minute.<br/>B. Increase the memory allocation for this Lambda function to 1,024 MB if this change causes the execution time of each function to be less than 90 seconds.<br/>C. Reduce the memory allocation for this Lambda function to 256 MB if this change causes the execution time of each function to be less than 4 minutes.<br/>D. Increase the memory allocation for this Lambda function to 2,048 MB if this change causes the execution time of each function to be less than 1 minute.<br/>E. Reduce the memory allocation for this Lambda function to 256 MB if this change causes the execution time of each function to be less than 5 minutes.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample367' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_689'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_183'>Random</a></p><div class='collapse' id='collapseExample367'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Increase the memory allocation for this Lambda function to 1,024 MB if this change causes the execution time of each function to be less than 1 minute.
<br><b>E. </b>Reduce the memory allocation for this Lambda function to 256 MB if this change causes the execution time of each function to be less than 5 minutes.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 87%;" aria-valuenow="87" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_689><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 689</p><br/>A company has 150 TB of archived image data stored on&#8211;premises that needs to be moved to the AWS Cloud within the next month. The company's current network connection allows up to 100 Mbps uploads for this purpose during the night only.<br/><br/>What is the MOST cost&#8211;effective mechanism to move this data and meet the migration deadline?<br/><br/>A. Use AWS Snowmobile to ship the data to AWS.<br/>B. Order multiple AWS Snowball devices to ship the data to AWS.<br/>C. Enable Amazon S3 Transfer Acceleration and securely upload the data.<br/>D. Create an Amazon S3 VPC endpoint and establish a VPN to upload the data.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample52' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_690'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_41'>Random</a></p><div class='collapse' id='collapseExample52'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Order multiple AWS Snowball devices to ship the data to AWS.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 87%;" aria-valuenow="87" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_690><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 690</p><br/>A company has an image processing workload running on Amazon Elastic Container Service (Amazon ECS) in two private subnets. Each private subnet uses a NAT instance for internet access. All images are stored in Amazon S3 buckets. The company is concerned about the data transfer costs between Amazon ECS and Amazon S3.<br/><br/>What should a solutions architect do to reduce costs?<br/><br/>A. Configure a NAT gateway to replace the NAT instances.<br/>B. Configure a gateway endpoint for traffic destined to Amazon S3.<br/>C. Configure an interface endpoint for traffic destined to Amazon S3.<br/>D. Configure Amazon CloudFront for the S3 bucket storing the images.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample240' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation240' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_691'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_623'>Random</a></p><div class='collapse' id='collapseExample240'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Configure an interface endpoint for traffic destined to Amazon S3.</div></div></div><div class='collapse' id='explanation240'><div class='card card&#45;body'><div>
S3 and Dynamo DB does not support interface endpoints. Both S3 and DynamoDB are routed via Gateway endpoint.
Interface Endpoint only supports services that are integrated with PrivateLink.

References:

Amazon Virtual Private Cloud > AWS PrivateLink > VPC endpoints
Amazon Virtual Private Cloud > AWS PrivateLink > AWS services that integrate with AWS PrivateLink</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 87%;" aria-valuenow="87" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_691><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 691</p><br/>A company is experiencing growth as demand for its product has increased. The company's existing purchasing application is slow when traffic spikes. The application is a monolithic three&#8211;tier application that uses synchronous transactions and sometimes sees bottlenecks in the application tier. A solutions architect needs to design a solution that can meet required application response times while accounting for traffic volume spikes.<br/><br/>Which solution will meet these requirements?<br/><br/>A. Vertically scale the application instance using a larger Amazon EC2 instance size.<br/>B. Scale the application's persistence layer horizontally by introducing Oracle RAC on AWS.<br/>C. Scale the web and application tiers horizontally using Auto Scaling groups and an Application Load Balancer.<br/>D. Decouple the application and data tiers using Amazon Simple Queue Service (Amazon SQS) with asynchronous AWS Lambda calls.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample220' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation220' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_692'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_122'>Random</a></p><div class='collapse' id='collapseExample220'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Scale the web and application tiers horizontally using Auto Scaling groups and an Application Load Balancer.</div></div></div><div class='collapse' id='explanation220'><div class='card card&#45;body'><div>
The Application uses synchronous transactions each operation is dependent on the previous one. Using asynchronous lambda calls may not work here.
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 87%;" aria-valuenow="87" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_692><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 692</p><br/>A company has a three&#8211;tier image&#8211;sharing application. It uses an Amazon EC2 instance for the front&#8211;end layer, another for the backend tier, and a third for the MySQL database. A solutions architect has been tasked with designing a solution that is highly available, and requires the least amount of changes to the application.<br/><br/>Which solution meets these requirements?<br/><br/>A. Use Amazon S3 to host the front&#8211;end layer and AWS Lambda functions for the backend layer. Move the database to an Amazon DynamoDB table and use Amazon S3 to store and serve users' images.<br/>B. Use load&#8211;balanced Multi&#8211;AZ AWS Elastic Beanstalk environments for the front&#8211;end and backend layers. Move the database to an Amazon RDS instance with multiple read replicas to store and serve users' images.<br/>C. Use Amazon S3 to host the front&#8211;end layer and a fleet of Amazon EC2 instances in an Auto Scaling group for the backend layer. Move the database to a memory optimized instance type to store and serve users' images.<br/>D. Use load&#8211;balanced Multi&#8211;AZ AWS Elastic Beanstalk environments for the front&#8211;end and backend layers. Move the database to an Amazon RDS instance with a Multi&#8211;AZ deployment. Use Amazon S3 to store and serve users' images.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample155' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation155' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_693'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_682'>Random</a></p><div class='collapse' id='collapseExample155'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Use load-balanced Multi-AZ AWS Elastic Beanstalk environments for the front-end and backend layers. Move the database to an Amazon RDS instance with a Multi-AZ deployment. Use Amazon S3 to store and serve users' images.</div></div></div><div class='collapse' id='explanation155'><div class='card card&#45;body'><div>
Keyword: Highly available + Least amount of changes to the application High Availability = Multi-AZ

Least amount of changes to the application = Elastic Beanstalk Automatically handles the deployment, from capacity provisioning, Load Balancing, Auto Scaling to application health monitoring

Option – D will be the right choice and Option – A; Option – B and Option – C out of race due to Cost & inter-operability.

HA with Elastic Beanstalk and RDS

AWS Elastic Beanstalk

AWS Elastic Beanstalk is an easy-to-use service for deploying and scaling web applications and services developed with Java, .NET, PHP, Node.js, Python, Ruby, Go, and Docker on familiar servers such as Apache, Nginx, Passenger, and IIS.

You can simply upload your code and Elastic Beanstalk automatically handles the deployment, from capacity provisioning, load balancing, auto-scaling to application health monitoring. At the same time, you retain full control over the AWS resources powering your application and can access the underlying resources at any time.

There is no additional charge for Elastic Beanstalk – you pay only for the AWS resources needed to store and run your applications.

AWS RDS
Amazon Relational Database Service (Amazon RDS) makes it easy to set up, operate, and scale a relational database in the cloud. It provides cost-efficient and resizable capacity while automating time-consuming administration tasks such as hardware provisioning, database setup, patching and backups. It frees you to focus on your applications so you can give them the fast performance, high availability, security and compatibility they need.

Amazon RDS is available on several database instance types – optimized for memory, performance or I/O – and provides you with six familiar database engines to choose from, including Amazon Aurora, PostgreSQL, MySQL, MariaDB, Oracle Database, and SQL Server. You can use the AWS Database Migration Service to easily migrate or replicate your existing databases to Amazon RDS.

AWS S3
Amazon Simple Storage Service (Amazon S3) is an object storage service that offers industry-leading scalability, data availability, security, and performance. This means customers of all sizes and industries can use it to store and protect any amount of data for a range of use cases, such as websites, mobile applications, backup and restore, archive, enterprise applications, IoT devices, and big data analytics. Amazon S3 provides easy-to-use management features so you can organize your data and configure finely-tuned access controls to meet your specific business, organizational, and compliance requirements. Amazon S3 is designed for 99.999999999% (11 9's) of durability, and stores data for millions of applications for companies all around the world.

References:

AWS Elastic Beanstalk
Amazon Relational Database Service (RDS)
Amazon S3</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 87%;" aria-valuenow="87" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_693><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 693</p><br/>A company is designing a new web service that will run on Amazon EC2 instances behind an Elastic Load Balancer. However, many of the web service clients can only reach IP addresses whitelisted on their firewalls.<br/><br/>What should a solutions architect recommend to meet the clients' needs?<br/><br/>A. A Network Load Balancer with an associated Elastic IP address.<br/>B. An Application Load Balancer with an associated Elastic IP address<br/>C. An A record in an Amazon Route 53 hosted zone pointing to an Elastic IP address<br/>D. An EC2 instance with a public IP address running as a proxy in front of the load balancer<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample119' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation119' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_694'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_787'>Random</a></p><div class='collapse' id='collapseExample119'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>An A record in an Amazon Route 53 hosted zone pointing to an Elastic IP address</div></div></div><div class='collapse' id='explanation119'><div class='card card&#45;body'><div>
Route 53 routes end users to Internet applications so the correct answer is C. Map one of the whitelisted IP addresses using an A record to the Elastic IP address.
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 87%;" aria-valuenow="87" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_694><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 694</p><br/>A disaster response team is using drones to collect images of recent storm damage. The response team's laptops lack the storage and compute capacity to transfer the images and process the data. While the team has Amazon EC2 instances for processing and Amazon S3 buckets for storage, network connectivity is intermittent and unreliable. The images need to be processed to evaluate the damage.<br/><br/>What should a solutions architect recommend?<br/><br/>A. Use AWS Snowball Edge devices to process and store the images.<br/>B. Upload the images to Amazon Simple Queue Service (Amazon SQS) during intermittent connectivity to EC2 instances.<br/>C. Configure Amazon Kinesis Data Firehose to create multiple delivery streams aimed separately at the S3 buckets for storage and the EC2 instances for processing the images.<br/>D. Use AWS Storage Gateway pre&#8211;installed on a hardware appliance to cache the images locally for Amazon S3 to process the images when connectivity becomes available.<br/><br/><br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample360' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation360' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_695'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_134'>Random</a></p><div class='collapse' id='collapseExample360'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Use AWS Snowball Edge devices to process and store the images.</div></div></div><div class='collapse' id='explanation360'><div class='card card&#45;body'><div>
<br/>CORRECT: "Use AWS Snowball Edge devices to process the data locally" is the correct answer.
<br/>INCORRECT: "Upload the data to Amazon SQS in batches and process the messages using Amazon EC2 instances" is incorrect. The internet connectivity is unreliable so this could result in data loss and delays for the team.
<br/>INCORRECT: "Configure Amazon Kinesis Data Firehose to load data directly to a Snowball device and process locally with Lambda@Edge" is incorrect. KDF cannot load data to Snowball devices and Lambda@Edge is used with CloudFront for processing data.
<br/>INCORRECT: "Use AWS DataSync on the scientists’ laptops to synchronize the data to Amazon S3. Process the data with Amazon EC2 instances" is incorrect. Due to the unreliable connectivity this does not solve the problem.
<br/>https://aws.amazon.com/blogs/storage/hurricane-dorian-disaster-response-in-the-bahamas-using-aws-snowball-edge/
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 87%;" aria-valuenow="87" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_695><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 695</p><br/>A company stores user data in AWS. The data is used continuously with peak usage during business hours.<br/><br/>Access patterns vary, with some data not being used for months at a time.<br/><br/>A solution architect must choose a cost that maintains the highest level of durability while maintaining high availability.<br/><br/>Which storage solution meets these requirements?<br/><br/>A. Amazon S3 Standard<br/>B. Amazon S3 intelligent Tiering<br/>C. Amazon S3 Glacier Deep Archive<br/>D. Amazon S3 One Zone&#8211;Infrequent Access (S3 One Zone&#8211;IA)<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample671' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_696'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_367'>Random</a></p><div class='collapse' id='collapseExample671'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Amazon S3 Standard</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 87%;" aria-valuenow="87" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_696><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 696</p><br/>A company has a website running on Amazon EC2 instances across two Availability Zones. The company is expecting spikes in traffic on specific holidays, and wants to provide a consistent user experience. How can a solutions architect meet this requirement?<br/><br/>A. Use step scaling.<br/>B. Use simple scaling.<br/>C. Use lifecycle hooks.<br/>D. Use scheduled scaling.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample61' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_697'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_54'>Random</a></p><div class='collapse' id='collapseExample61'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Use scheduled scaling.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 88%;" aria-valuenow="88" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_697><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 697</p><br/>Amazon EBS provides the ability to create backups of any Amazon EC2 volume into what is known as ________ .<br/><br/>A. snapshots<br/>B. images<br/>C. instance backups<br/>D. mirrors<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample780' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation780' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_698'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_235'>Random</a></p><div class='collapse' id='collapseExample780'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>snapshots</div></div></div><div class='collapse' id='explanation780'><div class='card card&#45;body'><div>
Amazon allows you to make backups of the data stored in your EBS volumes through snapshots that can later be used to create a new EBS volume.

References:

Amazon Elastic Compute Cloud > User Guide for Linux Instances > Storage</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 88%;" aria-valuenow="88" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_698><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 698</p><br/>A company's facility has badge readers at every entrance throughout the building. When badges are scanned, the readers send a message over HTTPS to indicate who attempted to access that particular entrance.<br/><br/>A solutions architect must design a system to process these messages from the sensors. The solution must be highly available, and the results must be made available for the company's security team to analyze.<br/><br/>Which system architecture should the solutions architect recommend?<br/><br/>A. Launch an Amazon EC2 instance to serve as the HTTPS endpoint and to process the messages. Configure the EC2 instance to save the results to an Amazon S3 bucket.<br/>B. Create an HTTPS endpoint in Amazon API Gateway. Configure the API Gateway endpoint to invoke an AWS Lambda function to process the messages and save the results to an Amazon DynamoDB table.<br/>C. Use Amazon Route 53 to direct incoming sensor messages to an AWS Lambda function. Configure the Lambda function to process the messages and save the results to an Amazon DynamoDB table.<br/>D. Create a gateway VPC endpoint for Amazon S3. Configure a Site&#8211;to&#8211;Site VPN connection from the facility network to the VPC so that sensor data can be written directly to an S3 bucket by way of the VPC endpoint.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample432' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_699'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_263'>Random</a></p><div class='collapse' id='collapseExample432'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Create an HTTPS endpoint in Amazon API Gateway. Configure the API Gateway endpoint to invoke an AWS Lambda function to process the messages and save the results to an Amazon DynamoDB table.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 88%;" aria-valuenow="88" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_699><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 699</p><br/>You have been given a scope to deploy some AWS infrastructure for a large organization. The requirements are that you will have a lot of EC2 instances but may need to add more when the average utilization of your Amazon EC2 fleet is high and conversely remove them when CPU utilization is low.<br/><br/>Which AWS services would be best to use to accomplish this?<br/><br/>A. Auto Scaling, Amazon CloudWatch and AWS Elastic Beanstalk<br/>B. Auto Scaling, Amazon CloudWatch and Elastic Load Balancing.<br/>C. Amazon CloudFront, Amazon CloudWatch and Elastic Load Balancing.<br/>D. AWS Elastic Beanstalk, Amazon CloudWatch and Elastic Load Balancing.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample744' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation744' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_700'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_746'>Random</a></p><div class='collapse' id='collapseExample744'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Auto Scaling, Amazon CloudWatch and Elastic Load Balancing.</div></div></div><div class='collapse' id='explanation744'><div class='card card&#45;body'><div>
Auto Scaling enables you to follow the demand curve for your applications closely, reducing the need to manually provision Amazon EC2 capacity in advance. For example, you can set a condition to add new Amazon EC2 instances in increments to the Auto Scaling group when the average utilization of your Amazon EC2 fleet is high; and similarly, you can set a condition to remove instances in the same increments when CPU utilization is low. If you have predictable load changes, you can set a schedule through Auto Scaling to plan your scaling activities. You can use Amazon CloudWatch to send alarms to trigger scaling activities and Elastic Load Balancing to help distribute traffic to your instances within Auto Scaling groups. Auto Scaling enables you to run your Amazon EC2 fleet at optimal utilization.

References:

AWS Auto Scaling</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 88%;" aria-valuenow="88" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_700><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 700</p><br/>A company provides an online service for posting video content and transcoding it for use by any mobile platform. The application architecture uses Amazon Elastic File System (Amazon EFS) Standard to collect and store the videos so that multiple Amazon EC2 Linux instances can access the video content for processing. As the popularity of the service has grown over time, the storage costs have become too expensive.<br/><br/>Which storage solution is MOST cost&#8211;effective?<br/><br/>A. Use AWS Storage Gateway for files to store and process the video content.<br/>B. Use AWS Storage Gateway for volumes to store and process the video content.<br/>C. Use Amazon EFS for storing the video content. Once processing is complete, transfer the files to Amazon Elastic Block Store (Amazon EBS).<br/>D. Use Amazon S3 for storing the video content. Move the files temporarily over to an Amazon ElasticBlock Store (Amazon EBS) volume attached to the server for processing.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample335' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_701'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_677'>Random</a></p><div class='collapse' id='collapseExample335'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Use AWS Storage Gateway for files to store and process the video content.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 88%;" aria-valuenow="88" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_701><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 701</p><br/>A company is running an online transaction processing (OLTP) workload on AWS. This workload uses an unencrypted Amazon RDS DB instance in a Multi&#8211;AZ deployment. Daily database snapshots are taken from this instance.<br/><br/>What should a solutions architect do to ensure the database and snapshots are always encrypted moving forward?<br/><br/>A. Encrypt a copy of the latest DB snapshot. Replace existing DB instance by restoring the encrypted snapshot.<br/>B. Create a new encrypted Amazon Elastic Block Store (Amazon EBS) volume and copy the snapshots to it. Enable encryption on the DB instance.<br/>C. Copy the snapshots and enable encryption using AWS Key Management Service (AWS KMS). Restore encrypted snapshot to an existing DB instance.<br/>D. Copy the snapshots to an Amazon S3 bucket that is encrypted using server&#8211;side encryption with AWS Key Management Service (AWS KMS) managed keys (SSE&#8211;KMS).<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample402' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_702'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_484'>Random</a></p><div class='collapse' id='collapseExample402'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Encrypt a copy of the latest DB snapshot. Replace existing DB instance by restoring the encrypted snapshot.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 88%;" aria-valuenow="88" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_702><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 702</p><br/>A company is using Amazon CloudFront with its website.<br/><br/>The company has enabled logging on the CloudFront distribution, and logs are saved in one of the company's Amazon S3 buckets.<br/><br/>The company needs to perform advanced analysis on the logs and build visualizations.<br/><br/>What should a solutions architect do to meet these requirements?<br/><br/>A. Use standard SQL queries in Amazon Athena to analyze CloudFront logs in the S3 bucket. Visualize the results with AWS Glue.<br/>B. Use standard SQL queries in Amazon Athena to analyze the CloudFront logs in the S3 bucket. Visual the results with Amazon QuickSight.<br/>C. Use standard queries in Amazon DynamoDB to analyze the Cloudfront logs in the S3 bucket. Visualize the results with the AWS Glue.<br/>D. Use standard SQL queries in Amazon DynamoDB to analyze the CloudFront logs in the S3 bucket. Visualize the results with Amazon QuickSight.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample608' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_703'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_464'>Random</a></p><div class='collapse' id='collapseExample608'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Use standard SQL queries in Amazon DynamoDB to analyze the CloudFront logs in the S3 bucket. Visualize the results with Amazon QuickSight.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 88%;" aria-valuenow="88" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_703><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 703</p><br/>A photo&#8211;sharing website running on AWS allows users to generate thumbnail images of photos stored in Amazon S3. An Amazon DynamoDB table maintains the locations of photos, and thumbnails are easily re&#8211;created from the originals if they are accidentally deleted.<br/><br/>How should the thumbnail images be stored to ensure the LOWEST cost?<br/><br/>A. Amazon S3 Standard&#8211;Infrequent Access (S3 Standard&#8211;IA) with cross&#8211;region replication<br/>B. Amazon S3<br/>C. Amazon Glacier<br/>D. Amazon S3 with cross&#8211;region replication<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample788' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_704'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_551'>Random</a></p><div class='collapse' id='collapseExample788'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Amazon S3</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 88%;" aria-valuenow="88" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_704><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 704</p><br/>A company has thousands of edge devices that collectively generate 1 TB of status averts each day Each alert s approximately 2 KB in size. A solutions architect needs to implement a solution to ingest and store the alerts for future analysis.<br/><br/>The company wants a highly available solution However the company needs to minimize costs and does not want to manage additional infrastructure Additionally, the company wants to keep 14 days of data available for immediate analysis and archive any data older than 14 days.<br/><br/>What is the MOST operationally efficient solution that meets these requirements?<br/><br/>A. Create an Amazon Kinesis Data Firehose delivery stream to ingest the alerts Configure the Kinesis Data Firehose stream to deliver the alerts to an Amazon S3 bucket Set up an S3 Lifecycle configuration to transition data to Amazon S3 Glacier after 14 days<br/>B. Launch Amazon EC2 instances across two Availability Zones and place them behind an Elastic Load Balancer to ingest the alerts Create a script on the EC2 instances that will store the alerts m an Amazon S3 bucket Set up an S3 Lifecycle configuration to transition data to Amazon S3 Glacier after 14 days<br/>C. Create an Amazon Kinesis Data Firehose delivery stream to ingest the alerts Configure the Kinesis Data Firehose stream to deliver the alerts to an Amazon Elasticsearch Service (Amazon ES) duster Set up the Amazon ES cluster to take manual snapshots every day and delete data from the duster that is older than 14 days<br/>D. Create an Amazon Simple Queue Service (Amazon SQS I standard queue to ingest the alerts and set the message retention period to 14 days Configure consumers to poll the SQS queue check the age of the message and analyze the message data as needed If the message is 14 days old the consumer should copy the message to an Amazon S3 bucket and delete the message from the SQS queue<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample469' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_705'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_218'>Random</a></p><div class='collapse' id='collapseExample469'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Create an Amazon Kinesis Data Firehose delivery stream to ingest the alerts Configure the Kinesis Data Firehose stream to deliver the alerts to an Amazon S3 bucket Set up an S3 Lifecycle configuration to transition data to Amazon S3 Glacier after 14 days</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 89%;" aria-valuenow="89" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_705><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 705</p><br/>A company is running an ASP.NET MVC application on a single Amazon EC2 instance. A recent increase in application traffic is causing slow response times for users during lunch hours. The company needs to resolve this concern with the least amount of configuration.<br/><br/>What should a solutions architect recommend to meet these requirements?<br/><br/>A. Move the application to AWS Elastic Beanstalk. Configure load&#8211;based auto scaling and time&#8211;based scaling to handle scaling during lunch hours.<br/>B. Move the application to Amazon Elastic Container Service (Amazon ECS). Create an AWS Lambda function to handle scaling during lunch hours.<br/>C. Move the application to Amazon Elastic Container Service (Amazon ECS). Configure scheduled scaling for AWS Application Auto Scaling during lunch hours.<br/>D. Move the application to AWS Elastic Beanstalk. Configure load&#8211;based auto scaling, and create an AWS Lambda function to handle scaling during lunch hours.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample429' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_706'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_545'>Random</a></p><div class='collapse' id='collapseExample429'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Move the application to AWS Elastic Beanstalk. Configure load-based auto scaling and time-based scaling to handle scaling during lunch hours.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 89%;" aria-valuenow="89" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_706><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 706</p><br/>In EC2, what happens to the data in an instance store if an instance reboots (either intentionally or unintentionally)?<br/><br/>A. Data is deleted from the instance store for security reasons.<br/>B. Data persists in the instance store.<br/>C. Data is partially present in the instance store.<br/>D. Data in the instance store will be lost.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample751' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation751' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_707'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_416'>Random</a></p><div class='collapse' id='collapseExample751'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Data persists in the instance store.</div></div></div><div class='collapse' id='explanation751'><div class='card card&#45;body'><div>
The data in an instance store persists only during the lifetime of its associated instance. If an instance reboots (intentionally or unintentionally), data in the instance store persists. However, data on instance store volumes is lost under the following circumstances.

Failure of an underlying drive
Stopping an Amazon EBS-backed instance Terminating an instance
References:

Amazon Elastic Compute Cloud > User Guide for Linux Instances > Amazon EC2 instance store
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 89%;" aria-valuenow="89" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_707><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/>https://pupuweb.com/aws&#8211;saa&#8211;c02&#8211;actual&#8211;exam&#8211;question&#8211;answer&#8211;dumps/<div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample1' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_708'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_265'>Random</a></p><div class='collapse' id='collapseExample1'><div class='card card&#45;body'><div class=' border border&#45;success'></div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 89%;" aria-valuenow="89" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_708><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 708</p><br/>A manufacturing company wants to implement predictive maintenance on its machinery equipment. The company will install thousands of IoT sensors that will send data to AWS in real time. A solutions architect is tasked with implementing a solution that will receive events in an ordered manner for each machinery asset and ensure that data is saved for further processing at a later time.<br/><br/>Which solution would be MOST efficient?<br/><br/>A. Use Amazon Kinesis Data Streams for real&#8211;time events with a partition for each equipment asset. Use Amazon Kinesis Data Firehose to save data to Amazon S3.<br/>B. Use Amazon Kinesis Data Streams for real&#8211;time events with a shard for each equipment asset. Use Amazon Kinesis Data Firehose to save data to Amazon EBS.<br/>C. Use an Amazon SQS FIFO queue for real&#8211;time events with one queue for each equipment asset. Trigger an AWS Lambda function for the SQS queue to save data to Amazon EFS.<br/>D. Use an Amazon SQS standard queue for real&#8211;time events with one queue for each equipment asset. Trigger an AWS Lambda function from the SQS queue to save data to Amazon S3.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample146' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation146' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_709'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_587'>Random</a></p><div class='collapse' id='collapseExample146'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Use Amazon Kinesis Data Streams for real-time events with a partition for each equipment asset. Use Amazon Kinesis Data Firehose to save data to Amazon S3.</div></div></div><div class='collapse' id='explanation146'><div class='card card&#45;body'><div>
Amazon SQS Introduces FIFO Queues with Exactly-Once Processing and Lower Prices for Standard Queues

You can now use Amazon Simple Queue Service (SQS) for applications that require messages to be processed in a strict sequence and exactly once using First-in, First-out (FIFO) queues. FIFO queues are designed to ensure that the order in which messages are sent and received is strictly preserved and that each message is processed exactly once.

Amazon SQS is a reliable and highly-scalable managed message queue service for storing messages in transit between application components. FIFO queues complement the existing Amazon SQS standard queues, which offer high throughput, best-effort ordering, and at-least-once delivery. FIFO queues have essentially the same features as standard queues, but provide the added benefits of supporting ordering and exactly-once processing. FIFO queues provide additional features that help prevent unintentional duplicates from being sent by message producers or from being received by message consumers. Additionally, message groups allow multiple separate ordered message streams within the same queue.

Amazon Kinesis Data Streams collect and process data in real time. A Kinesis data stream is a set of shards. Each shard has a sequence of data records. Each data record has a sequence number that is assigned by Kinesis Data Streams. A shard is a uniquely identified sequence of data records in a stream.

A partition key is used to group data by shard within a stream. Kinesis Data Streams segregates the data records belonging to a stream into multiple shards. It uses the partition key that is associated with each data record to determine which shard a given data record belongs to.

For this scenario, the solutions architect can use a partition key for each device. This will ensure the records for that device are grouped by shard and the shard will ensure ordering. Amazon S3 is a valid destination for saving the data records.

CORRECT: "Use Amazon Kinesis Data Streams for real-time events with a partition key for each device. Use Amazon Kinesis Data Firehose to save data to Amazon S3" is the correct answer.

INCORRECT: "Use Amazon Kinesis Data Streams for real-time events with a shard for each device. Use Amazon Kinesis Data Firehose to save data to Amazon EBS" is incorrect as you cannot save data to EBS from Kinesis.

INCORRECT: "Use an Amazon SQS FIFO queue for real-time events with one queue for each device. Trigger an AWS Lambda function for the SQS queue to save data to Amazon EFS" is incorrect as SQS is not the most efficient service for streaming, real time data.

INCORRECT: "Use an Amazon SQS standard queue for real-time events with one queue for each device. Trigger an AWS Lambda function from the SQS queue to save data to Amazon S3" is incorrect as SQS is not the most efficient service for streaming, real time data.

References:

Amazon Kinesis Data Streams > Developer Guide > Amazon Kinesis Data Streams Terminology and Concepts</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 89%;" aria-valuenow="89" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_709><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 709</p><br/>A security team to limit access to specific services or actions in all of the team's AWS accounts. All accounts belong to a large organization in AWS Organizations. The solution must be scalable and there must be a single point where permissions can be maintained.<br/><br/>What should a solutions architect do to accomplish this?<br/><br/>A. Create an ACL to provide access to the services or actions.<br/>B. Create a security group to allow accounts and attach it to user groups.<br/>C. Create cross&#8211;account roles in each account to deny access to the services or actions.<br/>D. Create a service control policy in the root organizational unit to deny access to the services or actions.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample263' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation263' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_710'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_285'>Random</a></p><div class='collapse' id='collapseExample263'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Create a service control policy in the root organizational unit to deny access to the services or actions.</div></div></div><div class='collapse' id='explanation263'><div class='card card&#45;body'><div>
Service Control Policy concepts
SCPs offer central access controls for all IAM entities in your accounts. You can use them to enforce the permissions you want everyone in your business to follow. Using SCPs, you can give your developers more freedom to manage their own permissions because you know they can only operate within the boundaries you define.

You create and apply SCPs through AWS Organizations. When you create an organization, AWS Organizations automatically creates a root, which forms the parent container for all the accounts in your organization. Inside the root, you can group accounts in your organization into organizational units (OUs) to simplify management of these accounts. You can create multiple OUs within a single organization, and you can create OUs within other OUs to form a hierarchical structure. You can attach SCPs to the organization root, OUs, and individual accounts. SCPs attached to the root and OUs apply to all OUs and accounts inside of them.

SCPs use the AWS Identity and Access Management (IAM) policy language; however, they do not grant permissions. SCPs enable you set permission guardrails by defining the maximum available permissions for IAM entities in an account. If a SCP denies an action for an account, none of the entities in the account can take that action, even if their IAM permissions allow them to do so. The guardrails set in SCPs apply to all IAM entities in the account, which include all users, roles, and the account root user.

Service control policies (SCPs) offer central control over the maximum available permissions for all accounts in your organization, allowing you to ensure your accounts stay within your organization's access control guidelines.

SCPs alone are not sufficient for allowing access in the accounts in your organization. Attaching an SCP to an AWS Organizations entity (root, OU, or account) defines a guardrail for what actions the principals can perform. You still need to attach identity-based or resource-based policies to principals or resources in your organization's accounts to actually grant permissions to them.

CORRECT: "Create a service control policy in the root organizational unit to deny access to the services or actions" is the correct answer.

INCORRECT: "Create an ACL to provide access to the services or actions" is incorrect as access control lists are not used for permissions associated with IAM. Permissions policies are used with IAM.

INCORRECT: "Create a security group to allow accounts and attach it to user groups" is incorrect as security groups are instance level firewalls. They do not limit service actions.

INCORRECT: "Create cross-account roles in each account to deny access to the services or actions" is incorrect as this is a complex solution and does not provide centralized control.

References:

AWS Organizations > User Guide > Service control policies (SCPs)</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 89%;" aria-valuenow="89" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_710><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 710</p><br/>Your EBS volumes do not seem to be performing as expected and your team leader has requested you look into improving their performance. Which of the following is not a true statement relating to the performance of your EBS volumes?<br/><br/>A. Frequent snapshots provide a higher level of data durability and they will not degrade the performance of your application while the snapshot is in progress.<br/>B. General Purpose (SSD) and Provisioned IOPS (SSD) volumes have a throughput limit of 128 MB/s per volume.<br/>C. There is a relationship between the maximum performance of your EBS volumes, the amount of I/O you are driving to them, and the amount of time it takes for each transaction to complete.<br/>D. There is a 5 to 50 percent reduction in IOPS when you first access each block of data on a newly created or restored EBS volume<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample740' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation740' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_711'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_546'>Random</a></p><div class='collapse' id='collapseExample740'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Frequent snapshots provide a higher level of data durability and they will not degrade the performance of your application while the snapshot is in progress.</div></div></div><div class='collapse' id='explanation740'><div class='card card&#45;body'><div>
Several factors can affect the performance of Amazon EBS volumes, such as instance configuration, I/O characteristics, workload demand, and storage configuration. Frequent snapshots provide a higher level of data durability, but they may slightly degrade the performance of your application while the snapshot is in progress. This trade off becomes critical when you have data that changes rapidly. Whenever possible, plan for snapshots to occur during off-peak times in order to minimize workload impact.

References:

Amazon Elastic Compute Cloud > User Guide for Linux Instances > Amazon EBS volume performance on Linux instances</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 89%;" aria-valuenow="89" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_711><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 711</p><br/>An application uses an Amazon RDS MySQL DB instance. The RDS database is becoming low on disk space. A solutions architect wants to increase the disk space without downtime. Which solution meets these requirements with the LEAST amount of effort?<br/><br/>A. Enable storage auto scaling in RDS.<br/>B. Increase the RDS database instance size.<br/>C. Change the RDS database instance storage type to Provisioned IOPS.<br/>D. Back up the RDS database, increase the storage capacity, restore the database and stop the previous instance.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample349' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_712'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_313'>Random</a></p><div class='collapse' id='collapseExample349'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Change the RDS database instance storage type to Provisioned IOPS.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 90%;" aria-valuenow="90" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_712><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 712</p><br/>A company hosts its core network services, including directory services and DNS, in its on&#8211;premises data center. The data center is connected to the AWS Cloud using AWS Direct Connect (DX). Additional AWS accounts are planned that will require quick, cost&#8211;effective, and consistent access to these network services.<br/><br/>What should a solutions architect implement to meet these requirements with the LEAST amount of operational overhead?<br/><br/>A. Create a DX connection in each new account. Route the network traffic to the on&#8211;premises servers.<br/>B. Configure VPC endpoints in the DX VPC for all required services. Route the network traffic to the on&#8211;premises servers.<br/>C. Create a VPN connection between each new account and the DX VPC. Route the network traffic to the on&#8211;premises servers.<br/>D. Configure AWS Transit Gateway between the accounts. Assign DX to the transit gateway and route network traffic to the on&#8211;premises servers.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample176' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_713'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_51'>Random</a></p><div class='collapse' id='collapseExample176'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Configure AWS Transit Gateway between the accounts. Assign DX to the transit gateway and route network traffic to the on-premises servers.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 90%;" aria-valuenow="90" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_713><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 713</p><br/>A company is migrating a NoSQL database cluster to Amazon EC2. The database automatically replicates data to maintain at least three copies of the data. I/O throughput of the servers is the highest priority. Which instance type should a solutions architect recommend for the migration?<br/><br/>A. Storage optimized instances with instance store<br/>B. Burstable general purpose instances with an Amazon Elastic Block Store (Amazon EBS) volume<br/>C. Memory optimized instances with Amazon Elastic Block Store (Amazon EBS) optimization enabled<br/>D. Compute optimized instances with Amazon Elastic Block Store (Amazon EBS) optimization enabled<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample123' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_714'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_17'>Random</a></p><div class='collapse' id='collapseExample123'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Storage optimized instances with instance store</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 90%;" aria-valuenow="90" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_714><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 714</p><br/>An eCommerce website is deploying its web application as Amazon Elastic Container Service (Amazon ECS) container instance behind an Application Load Balancer (ALB). During periods of high activity, the website slows down and availability is reduced.<br/><br/>A solutions architect uses Amazon CloudWatch alarms to receive notifications whenever there is an availability issues so they can scale out resource Company management wants a solution that automatically responds to such events.<br/><br/>Which solution meets these requirements?<br/><br/>A. Set up AWS Auto Scaling to scale out the ECS service when there are timeouts on the ALB. Set up AWS Auto Scaling to scale out the ECS cluster when the CPU or memory reservation is too high.<br/>B. Set up AWS Auto Scaling to scale out the ECS service when the ALB CPU utilization is too high. Set up AWS Auto Scaling to scale out the ECS cluster when the CPU or memory reservation is too high.<br/>C. Set up AWS Auto Scaling to scale out the ECS service when the service's CPU utilization is too high. Set up AWS Auto Scaling to scale out the ECS cluster when the CPU or memory reservation is too high.<br/>D. Set up AWS Auto Scaling to scale out the ECS service when the ALB target group CPU utilization is too high. Set up AWS Auto Scaling to scale out the ECS cluster when the CPU or memory reservation is too high.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample696' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_715'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_773'>Random</a></p><div class='collapse' id='collapseExample696'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Set up AWS Auto Scaling to scale out the ECS service when the ALB target group CPU utilization is too high. Set up AWS Auto Scaling to scale out the ECS cluster when the CPU or memory reservation is too high.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 90%;" aria-valuenow="90" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_715><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 715</p><br/>A company maintains about 300 TB in Amazon S3 Standard storage month after month. The S3 objects are each typically around 50 GB in size and are frequently replaced with multipart uploads by their global application. The number and size of S3 objects remain constant but the company's S3 storage costs are increasing each month.<br/><br/>How should a solutions architect reduce costs in this situation?<br/><br/>A. Switch from multipart uploads to Amazon S3 Transfer Acceleration<br/>B. Enable an S3 Lifecycle policy that deletes incomplete multipart uploads<br/>C. Configure S3 inventory to prevent objects from being archived too quickly<br/>D. Configure Amazon CloudFront to reduce the number of objects stored in Amazon S3<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample440' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_716'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_3'>Random</a></p><div class='collapse' id='collapseExample440'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Enable an S3 Lifecycle policy that deletes incomplete multipart uploads</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 90%;" aria-valuenow="90" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_716><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 716</p><br/>A company is using Amazon EC2 to run its big data analytics workloads. These variable workloads run each night, and it is critical they finish by the start of business the following day. A solutions architect has been tasked with designing the MOST cost&#8211;effective solution.<br/><br/>Which solution will accomplish this?<br/><br/>A. Spot Fleet<br/>B. Spot Instances<br/>C. Reserved Instances<br/>D. On&#8211;Demand Instances<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample200' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_717'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_602'>Random</a></p><div class='collapse' id='collapseExample200'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Spot Fleet</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 90%;" aria-valuenow="90" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_717><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 717</p><br/>A company is automating an order management application. The company's development team has decided to use SFTP to transfer and store the business&#8211;critical information files. The files must be encrypted and must be highly available. The files also must be automatically deleted a month after they are created.<br/><br/>Which solution meets these requirements with the LEAST operational overhead?<br/><br/>A. Configure an Amazon S3 bucket with encryption enabled. Use AWS transfer for SFTP to securely transfer the files to the S3 bucket Apply an AWS Transfer for SFTP file retention policy to delete the files after a month<br/>B. Install an SFTP service on an Amazon EC2 instance Mount an Amazon Elastic File System (Amazon EFS) file share on the EC2 instance. Enable cron to delete the files after a month<br/>C. Configure an Amazon Elastic File System (Amazon EFS) file system with encryption enabled. Use AWS Transfer for SFTP to securely transfer the files to the EFS file system. Apply an EFS lifecycle policy to automatically delete the files after a month.<br/>D. Configure an Amazon S3 bucket with encryption enabled. Use AWS Transfer for SFTP to securely transfer the files to the S3 bucket. Apply S3 Lifecycle rules to automatically delete the files after a month.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample454' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_718'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_627'>Random</a></p><div class='collapse' id='collapseExample454'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Configure an Amazon S3 bucket with encryption enabled. Use AWS Transfer for SFTP to securely transfer the files to the S3 bucket. Apply S3 Lifecycle rules to automatically delete the files after a month.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 90%;" aria-valuenow="90" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_718><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 718</p><br/>A solution architect is creating a new Amazon CloudFront distribution for an application Some of Ine information submitted by users is sensitive. The application uses HTTPS but needs another layer" of security. The sensitive information should be protected throughout the entire application stack end access to the information should be restricted to certain applications<br/><br/>Which action should the solutions architect take?<br/><br/>A. Configure a CloudFront signed URL<br/>B. Configure a CloudFront signed cookie.<br/>C. Configure a CloudFront field&#8211;level encryption profile<br/>D. Configure CloudFront and set the Origin Protocol Policy setting to HTTPS Only for the Viewer Protocol Policy<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample476' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_719'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_643'>Random</a></p><div class='collapse' id='collapseExample476'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Configure a CloudFront field-level encryption profile</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 90%;" aria-valuenow="90" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_719><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 719</p><br/>A company runs a photo processing application mat needs to frequently upload and download pictures from Amazon S3 buckets that are located in the same AWS Region A solutions architect has noticed an increased cost in data transfer lees and needs to implement a solution to reduce these costs<br/><br/>How can the solutions architect meet this requirement?<br/><br/>A. Deploy Amazon API Gateway into a public subnet and adjust the route table to route S3 calls through it<br/>B. Deploy a NAT gateway into a public subnet and attach an endpoint policy that allows access to the S3 buckets<br/>C. Deploy the application into a public subnet and allow it to route through an internet gateway to access the S3 buckets<br/>D. Deploy an S3 VPC gateway endpoint into the VPC and attach an endpoint policy that allows access to the S3 buckets<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample478' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_720'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_95'>Random</a></p><div class='collapse' id='collapseExample478'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Deploy the application into a public subnet and allow it to route through an internet gateway to access the S3 buckets</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 91%;" aria-valuenow="91" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_720><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 720</p><br/>A company has an application that ingests incoming messages. These messages are then quickly consumed by dozens of other applications and microservices. The number of messages varies drastically and sometimes spikes as high as 100,000 each second. The company wants to decouple the solution and increase scalability.<br/><br/>Which solution meets these requirements?<br/><br/>A. Persist the messages to Amazon Kinesis Data Analytics. All the applications will read and process the messages.<br/>B. Deploy the application on Amazon EC2 instances in an Auto Scaling group, which scales the number of EC2 instances based on CPU metrics.<br/>C. Write the messages to Amazon Kinesis Data Streams with a single shard. All applications will read from the stream and process the messages.<br/>D. Publish the messages to an Amazon Simple Notification Service (Amazon SNS) topic with one or more Amazon Simple Queue Service (Amazon SQS) subscriptions. All applications then process the messages from the queues.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample283' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation283' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_721'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_608'>Random</a></p><div class='collapse' id='collapseExample283'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Publish the messages to an Amazon Simple Notification Service (Amazon SNS) topic with one or more Amazon Simple Queue Service (Amazon SQS) subscriptions. All applications then process the messages from the queues.</div></div></div><div class='collapse' id='explanation283'><div class='card card&#45;body'><div>
Q: How large can Amazon SQS message queues be?
A single Amazon SQS message queue can contain an unlimited number of messages. However, there is a 120,000 quota for the number of inflight messages for a standard queue and 20,000 for a FIFO queue. Messages are inflight after they have been received from the queue by a consuming component, but have not yet been deleted from the queue.

References:

Amazon SQS FAQs</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 91%;" aria-valuenow="91" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_721><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 721</p><br/>A solutions architect is designing a customer&#8211;facing application. The application is expected to have a variable amount of reads and writes depending on the time of year and clearly defined access patterns throughout the year. Management requires that database auditing and scaling be managed in the AWS Cloud. The Recovery Point Objective (RPO) must be less than 5 hours.<br/><br/>Which solutions can accomplish this? (Choose two.)<br/><br/>A. Use Amazon DynamoDB with auto scaling. Use on&#8211;demand backups and AWS CloudTrail.<br/>B. Use Amazon DynamoDB with auto scaling. Use on&#8211;demand backups and Amazon DynamoDB Streams.<br/>C. Use Amazon Redshift Configure concurrency scaling. Enable audit logging. Perform database snapshots every 4 hours.<br/>D. Use Amazon RDS with Provisioned IOPS. Enable the database auditing parameter. Perform database snapshots every 5 hours.<br/>E. Use Amazon RDS with auto scaling. Enable the database auditing parameter. Configure the backup retention period to at least 1 day.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample203' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation203' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_722'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_203'>Random</a></p><div class='collapse' id='collapseExample203'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Use Amazon DynamoDB with auto scaling. Use on-demand backups and AWS CloudTrail.
<br><b>E. </b>Use Amazon RDS with auto scaling. Enable the database auditing parameter. Configure the backup retention period to at least 1 day.</div></div></div><div class='collapse' id='explanation203'><div class='card card&#45;body'><div>

Use Amazon DynamoDB with auto scaling. Use on-demand backups and AWS CloudTrail. CORRECT – Scalable, with backup and AWS Managed Auditing
Use Amazon DynamoDB with auto scaling. Use on-demand backups and Amazon DynamoDB Streams.
INCORRECT – AWS DDB Streams can be used for auditing, but its not AWS managed auditing.

Use Amazon Redshift Configure concurrency scaling. Enable audit logging. Perform database snapshots every 4

INCORRECT – Not a database. Data lake

Use Amazon RDS with Provisioned IOPS. Enable the database auditing parameter. Perform database snapshots every 5

INCORRECT – This does not scale

Use Amazon RDS with auto scaling. Enable the database auditing parameter. Configure the backup retention period to at least 1

CORRECT – Scalable, AWS managed auditing and backup. The backup frequency is not stated but have no technical limitation which states it cannot be less 5 hours (1 day is retention period of the backup).
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 91%;" aria-valuenow="91" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_722><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 722</p><br/>A global company plans to track and store information about local allergens in an Amazon DynamoOB table and query this data from its website.<br/><br/>The company anticipates that website traffic will fluctuate.<br/>The company estimates that the combined read and write capacity units will range from 10.<br/>10.000 per second, depending on the severity of the conditions for the given day.<br/>A solutions architect must design a solution that avoids throttling issues and manages capacity efficiently.<br/>What should the solutions architect do to meet these requirements MOST cost&#8211;effectively?<br/><br/>A. Use provisioned capacity mode. Set the table's read capacity units to 10,000.<br/>B. Use provisioned capacity mode and a scaling policy in DynamoDB auto scaling<br/>C. Use on&#8211;demand capacity made for a couple of months. Then switch to provisioned capacity mode<br/>D. Use on&#8211;demand capacity mode only. Configure DynamoDB Accelerator (DAX) to be in front of the tab<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample521' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_723'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_362'>Random</a></p><div class='collapse' id='collapseExample521'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Use provisioned capacity mode and a scaling policy in DynamoDB auto scaling</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 91%;" aria-valuenow="91" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_723><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 723</p><br/>An Elastic IP address (EIP) is a static IP address designed for dynamic cloud computing. With an EIP, you can mask the failure of an instance or software by rapidly remapping the address to another instance in your account. Your EIP is associated with your AWS account, not a particular EC2 instance, and it remains associated with your account until you choose to explicitly release it. By default how many EIPs is each AWS account limited to on a per region basis?<br/><br/>A. 1<br/>B. 5<br/>C. Unlimited<br/>D. 10<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample753' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation753' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_724'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_519'>Random</a></p><div class='collapse' id='collapseExample753'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>5</div></div></div><div class='collapse' id='explanation753'><div class='card card&#45;body'><div>
By default, all AWS accounts are limited to 5 Elastic IP addresses per region for each AWS account, because public (IPv4) Internet addresses are a scarce public resource. AWS strongly encourages you to use an EIP primarily for load balancing use cases, and use DNS hostnames for all other inter-node communication.

If you feel your architecture warrants additional EIPs, you would need to complete the Amazon EC2 Elastic IP Address Request Form and give reasons as to your need for additional addresses.

References:

Amazon Elastic Compute Cloud > User Guide for Linux Instances > Elastic IP address limit</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 91%;" aria-valuenow="91" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_724><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 724</p><br/>A company recently deployed a two&#8211;tier application in two Availability Zones in the us&#8211;east&#8211;1 Region. The databases are deployed in a private subnet while the web servers are deployed in a public subnet. An internet gateway is attached to the VPC. The application and database run on Amazon EC2 instances. The database servers are unable to access patches on the internet. A solutions architect needs to design a solution that maintains database security with the least operational overhead.<br/><br/>Which solution meets these requirements?<br/><br/>A. Deploy a NAT gateway inside the public subnet for each Availability Zone and associate it with an Elastic IP address. Update the routing table of the private subnet to use it as the default route.<br/>B. Deploy a NAT gateway inside the private subnet for each Availability Zone and associate it with an Elastic IP address. Update the routing table of the private subnet to use it as the default route.<br/>C. Deploy two NAT instances inside the public subnet for each Availability Zone and associate them with Elastic IP addresses. Update the routing table of the private subnet to use it as the default route.<br/>D. Deploy two NAT instances inside the private subnet for each Availability Zone and associate them with Elastic IP addresses. Update the routing table of the private subnet to use it as the default route.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample167' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation167' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_725'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_756'>Random</a></p><div class='collapse' id='collapseExample167'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Deploy a NAT gateway inside the public subnet for each Availability Zone and associate it with an Elastic IP address. Update the routing table of the private subnet to use it as the default route.</div></div></div><div class='collapse' id='explanation167'><div class='card card&#45;body'><div>
VPC with public and private subnets (NAT)

The configuration for this scenario includes a virtual private cloud (VPC) with a public subnet and a private subnet. We recommend this scenario if you want to run a public-facing web application, while maintaining back-end servers that aren't publicly accessible. A common example is a multi-tier website, with the web servers in a public subnet and the database servers in a private subnet. You can set up security and routing so that the web servers can communicate with the database servers.

The instances in the public subnet can send outbound traffic directly to the Internet, whereas the instances in the private subnet can't. Instead, the instances in the private subnet can access the Internet by using a network address translation (NAT) gateway that resides in the public subnet. The database servers can connect to the Internet for software updates using the NAT gateway, but the Internet cannot establish connections to the database servers.

References:

Amazon Virtual Private Cloud > User Guide > VPC with public and private subnets (NAT)</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 91%;" aria-valuenow="91" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_725><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 725</p><br/>A solutions architect is designing a hybrid application using the AWS cloud. The network between the on premises data center and AWS will use an AWS Direct Connect (DX) connection. The application connectivity between AWS and the on&#8211;premises data center must be highly resilient.<br/><br/>Which DX configuration should be implemented to meet these requirements?<br/><br/>A. Configure a DX connection with a VPN on top of it.<br/>B. Configure DX connections at multiple DX locations.<br/>C. Configure a DX connection using the most reliable DX partner.<br/>D. Configure multiple virtual interfaces on top of a DX connection.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample85' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_726'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_148'>Random</a></p><div class='collapse' id='collapseExample85'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Configure DX connections at multiple DX locations.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 91%;" aria-valuenow="91" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_726><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 726</p><br/>A solution architect is designing a shared storage solution for an Auto Scaling web application. The company anticipates making frequent changes to the content, so the solution must have strong consistency.<br/><br/>Which solution requires the LEAST amount of effort?<br/><br/>A. Create an Amazon S3 bucket to store the web content and use Amazon Cloudfront to deliver the content<br/>B. Create an Amazon Elastic File system (Amazon EFS) file system and mount it on the individual Amazon EC2 instance<br/>C. Create a shared Amazon Elastic Block Store (Amazon EBS) volume and mount it on the individual Amazon EC2 instance<br/>D. Use AWS Datasync to perform continuous synchronization of data between Amazon EC2 hosts in the Auto scaling group.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample710' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_727'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_586'>Random</a></p><div class='collapse' id='collapseExample710'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Create an Amazon Elastic File system ( Amazon EFS ) file system and mount it on the individual Amazon EC2 instance</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 91%;" aria-valuenow="91" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_727><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 727</p><br/>A development team is creating an event&#8211;based application that uses AWS Lambda functions. Events will be generated when files are added to an Amazon S3 bucket.<br/><br/>The development team currently has Amazon Simple Notification Service (Amazon SNS) configured as the event target from Amazon S3.<br/><br/>What should a solution architect do to process the events from Amazon S3 in a scalable way?<br/><br/>A. Create an SNS subscription that processes the event in Amazon Elastic Container Service (Amazon ECS) before the event runs in Lambda.<br/>B. Create an SNS subscription that processes the event in Amazon Elastic Kubernetes Service (Amazon EKS) before the event runs in Lambda.<br/>C. Create on SNS subscription that sends the event to AWS Server Migration Service (AWS SQS). Configure the SQS queue to trigger a Lambda function.<br/>D. Create an SNS subscription that sends the event to AWS Server Migration Service (AWS SMS). Configure the Lambda function to poll from the SMS event<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample578' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_728'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_210'>Random</a></p><div class='collapse' id='collapseExample578'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Create an SNS subscription that sends the event to AWS Server Migration Service (AWS SMS). Configure the Lambda function to poll from the SMS event</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 92%;" aria-valuenow="92" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_728><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 728</p><br/>A company Is creating a new application that will store a large amount of data.<br/><br/>The data will be analyzed hourly and will be modified by several Amazon EC2 Linux instances that are deployed across multiple Availability Zones.<br/><br/>The needed amount of storage space will continue to grow for the next 6 months<br/><br/>Which storage solution should a solutions architect recommend to meet these requirements?<br/><br/>A. Store the data in Amazon S3 Glacier Update the S3 Glacier vault policy to allow access to the application instances.<br/>B. Store the data in an Amazon Elastic Block Store (Amazon EBS) volume Mount the EBS volume on the application instances.<br/>C. Store the data in an Amazon Elastic File System (Amazon EFS) file system. Mount the file system on the application instances<br/>D. Store the data in an Amazon Elastic Block Store (Amazon ESS) Provisioned IOPS volume shared between the application instances<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample573' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_729'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_563'>Random</a></p><div class='collapse' id='collapseExample573'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Store the data in Amazon S3 Glacier Update the S3 Glacier vault policy to allow access to the application instances.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 92%;" aria-valuenow="92" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_729><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 729</p><br/>A company receives data from different sources and implements multiple applications to consume this data.<br/><br/>There are many short&#8211;running jobs that run only on the weekend. The data arrives in batches rather than throughout the entire weekend.<br/><br/>The company needs an environment on AWS to ingest and process this data while maintaining the order of the transactions.<br/><br/>Which combination of AWS services meets these requirements in the MOST cost&#8211;effective manner?<br/><br/>A. Amazon Kinesis Data Streams with AWS Lambda<br/>B. Amazon Kinesis Data Streams with Amazon EC2 Auto Scaling<br/>C. Amazon Simple Queue Service (Amazon SQS) with AWS Lambda<br/>D. Amazon Simple Queue Service (Amazon SQS) with Amazon EC2 Auto Scaling<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample522' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_730'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_595'>Random</a></p><div class='collapse' id='collapseExample522'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Amazon Simple Queue Service (Amazon SQS) with AWS Lambda</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 92%;" aria-valuenow="92" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_730><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 730</p><br/>A company runs a website on Amazon EC2 instances behind an ELB Application Load Balancer. Amazon Route 53 is used for the DNS. The company wants to set up a backup website with a message including a phone number and email address that users can reach if the primary website is down.<br/><br/>How should the company deploy this solution?<br/><br/>A. Use Amazon S3 website hosting for the backup website and Route 53 failover routing policy.<br/>B. Use Amazon S3 website hosting for the backup website and Route 53 latency routing policy.<br/>C. Deploy the application in another AWS Region and use ELB health checks for failover routing.<br/>D. Deploy the application in another AWS Region and use server&#8211;side redirection on the primary website.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample74' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_731'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_106'>Random</a></p><div class='collapse' id='collapseExample74'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Use Amazon S3 website hosting for the backup website and Route 53 failover routing policy.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 92%;" aria-valuenow="92" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_731><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 731</p><br/>A company's web application uses an Amazon RDS PostgreSQL DB instance to store its application data.<br/><br/>During the financial closing period at the start of every month, Accountants run large queries that impact the database's performance due to high usage. The company wants to minimize the impact that the reporting activity has on the web application.<br/><br/>What should a solutions architect do to reduce the impact on the database with the LEAST amount of effort?<br/><br/>A. Create a read replica and direct reporting traffic to the replica.<br/>B. Create a Multi&#8211;AZ database and direct reporting traffic to the standby.<br/>C. Create a cross&#8211;Region read replica and direct reporting traffic to the replica.<br/>D. Create an Amazon Redshift database and direct reporting traffic to the Amazon Redshift database.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample15' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation15' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_732'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_63'>Random</a></p><div class='collapse' id='collapseExample15'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Create a read replica and direct reporting traffic to the replica.</div></div></div><div class='collapse' id='explanation15'><div class='card card&#45;body'><div>
Amazon RDS uses the MariaDB, MySQL, Oracle, PostgreSQL, and Microsoft SQL Server DB engines' built-in replication functionality to create a special type of DB instance called a read replica from a source DB instance. Updates made to the source DB instance are asynchronously copied to the read replica. You can reduce the load on your source DB instance by routing read queries from your applications to the read replica.

When you create a read replica, you first specify an existing DB instance as the source. Then Amazon RDS takes a snapshot of the source instance and creates a read-only instance from the snapshot. Amazon RDS then uses the asynchronous replication method for the DB engine to update the read replica whenever there is a change to the source DB instance. The read replica operates as a DB instance that allows only read-only connections. Applications connect to a read replica the same way they do to any DB instance.

Amazon RDS replicates all databases in the source DB instance.

References:

Amazon Relational Database Service > User Guide > Working with read replicas</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 92%;" aria-valuenow="92" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_732><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 732</p><br/>A company is relocating its data center and wants to securely transfer 50 TB of data to AWS within 2 weeks.<br/><br/>The existing data center has a Site&#8211;to&#8211;Site VPN connection to AWS that is 90% utilized.<br/><br/>Which AWS service should a solutions architect use to meet these requirements?<br/><br/>A. AWS DataSync with a VPC endpoint<br/>B. AWS Direct Connect<br/>C. AWS Snowball Edge Storage Optimized<br/>D. AWS Storage Gateway<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample641' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_733'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_104'>Random</a></p><div class='collapse' id='collapseExample641'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>AWS Snowball Edge Storage Optimized</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 92%;" aria-valuenow="92" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_733><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 733</p><br/>A start&#8211;up company has a web application based in the us&#8211;east&#8211;1 Region with multiple Amazon EC2 instances running behind an Application Load Balancer across multiple Availability Zones. As the company's user base grows in the us&#8211;west&#8211;1 Region, it needs a solution with low latency and high availability.<br/><br/>What should a solutions architect do to accomplish this?<br/><br/>A. Provision EC2 instances in us&#8211;west&#8211;1. Switch the Application Load Balancer to a Network Load Balancer to achieve cross&#8211;Region load balancing.<br/>B. Provision EC2 instances and an Application Load Balancer in us&#8211;west&#8211;1. Make the load balancer distribute the traffic based on the location of the request.<br/>C. Provision EC2 instances and configure an Application Load Balancer in us&#8211;west&#8211;1. Create an accelerator in AWS Global Accelerator that uses an endpoint group that includes the load balancer endpoints in both Regions.<br/>D. Provision EC2 instances and configure an Application Load Balancer in us&#8211;west&#8211;1. Configure Amazon Route 53 with a weighted routing policy. Create alias records in Route 53 that point to the Application Load Balancer.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample11' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation11' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_734'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_673'>Random</a></p><div class='collapse' id='collapseExample11'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Provision EC2 instances and configure an Application Load Balancer in us-west-1. Create an accelerator in AWS Global Accelerator that uses an endpoint group that includes the load balancer endpoints in both Regions.</div></div></div><div class='collapse' id='explanation11'><div class='card card&#45;body'><div>
Register endpoints for endpoint groups: You register one or more regional resources, such as Application Load Balancers, Network Load Balancers, EC2 Instances, or Elastic IP addresses, in each endpoint group. Then you can set weights to choose how much traffic is routed to each endpoint.

Endpoints in AWS Global Accelerator: Endpoints in AWS Global Accelerator can be Network Load Balancers, Application Load Balancers, Amazon EC2 instances, or Elastic IP addresses. A static IP address serves as a single point of contact for clients, and Global Accelerator then distributes incoming traffic across healthy endpoints. Global Accelerator directs traffic to endpoints by using the port (or port range) that you specify for the listener that the endpoint group for the endpoint belongs to.

Each endpoint group can have multiple endpoints. You can add each endpoint to multiple endpoint groups, but the endpoint groups must be associated with different listeners.

Global Accelerator continually monitors the health of all endpoints that are included in an endpoint group. It routes traffic only to the active endpoints that are healthy. If Global Accelerator doesn't have any healthy endpoints to route traffic to, it routes traffic to all endpoints.

ELB provides load balancing within one Region, AWS Global Accelerator provides traffic management across multiple Regions […] AWS Global Accelerator complements ELB by extending these capabilities beyond a single AWS Region, allowing you to provision a global interface for your applications in any number of Regions. If you have workloads that cater to a global client base, we recommend that you use AWS Global Accelerator. If you have workloads hosted in a single AWS Region and used by clients in and around the same Region, you can use an Application Load Balancer or Network Load Balancer to manage your resources.

References:

AWS Global Accelerator FAQs
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 92%;" aria-valuenow="92" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_734><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 734</p><br/>A company is planning to migrate 40 servers hosted on&#8211;premises in VMware to the AWS Cloud. The migration process must be implemented with minimal downtime.<br/><br/>The company also wants to test the servers before the cutover date.<br/><br/>Which solution meets these requirements?<br/><br/>A. Deploy the AWS DataSync agent into the on&#8211;premises environment. Use DataSync to migrate the servers.<br/>B. Deploy an AWS Snowball device connected by way of RJ45 to the on&#8211;premises network. Use Snowball to migrate the servers.<br/>C. Deploy an AWS Database Migration Service (AWS DMS) replication instance into AWS. Use AWS DMS to migrate the servers.<br/>D. Deploy the AWS Server Migration Service (AWS SMS) connector into the on&#8211;premises environment. Use AWS SMS to migrate the servers.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample610' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_735'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_24'>Random</a></p><div class='collapse' id='collapseExample610'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Deploy the AWS DataSync agent into the on-premises environment. Use DataSync to migrate the servers.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 92%;" aria-valuenow="92" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_735><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 735</p><br/>A company hosts a popular web application. The web application connects to a database running in a private VPC subnet.<br/><br/>The web servers must be accessible only to customers on an SSL connection.<br/><br/>The Amazon RDS for MySQL database services be accessible only from the web servers.<br/><br/>How should a solution architect design a solution to meet the requirements without impacting applications?<br/><br/>A. Create a network ACL on the web server's subnet and allow HTTPS inbound and MySQL outbound. Place both database and web servers on the same subnet.<br/>B. Open an HTTPS port on the security group for web server and set the source to 0. 0. 0.0/0. Open the MySQL port on the database security group and attach it to the MySQL instance. Set the source to web server security group.<br/>C. Create a network ACL on the web server's subnet, allow HTTP, allow inbound and specify the source as 0 .0 .0 .0/0. Create a network ACL on a database subnet allow MySQL port inbound for web servers and deny all outbound traffic.<br/>D. Open the MySQL port on the security group for web servers and set the source to 0.0.0.0/0. Open the HTTPS port on the database security group and attach it to the MySQL instance. Set the source to web server security group.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample620' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_736'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_258'>Random</a></p><div class='collapse' id='collapseExample620'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Open an HTTPS port on the security group for web server and set the source to 0. 0. 0.0/0. Open the MySQL port on the database security group and attach it to the MySQL instance. Set the source to web server security group.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 93%;" aria-valuenow="93" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_736><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 736</p><br/>A company runs an application on an Amazon EC2 instance backed by Amazon Elastic Block Store (Amazon EBS). The instance needs to be available for 12 hours daily. The company wants to save costs by making the instance unavailable outside the window required for the application. However, the contents of the instance's memory must be preserved whenever the instance is unavailable.<br/><br/>What should a solutions architect do to meet this requirement?<br/><br/>A. Stop the instance outside the application's availability window. Start up the instance again when required.<br/>B. Hibernate the instance outside the application's availability window. Start up the instance again when required.<br/>C. Use Auto Scaling to scale down the instance outside the application's availability window. Scale up the instance when required.<br/>D. Terminate the instance outside the application's availability window. Launch the instance by using a preconfigured Amazon Machine Image (AMI) when required.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample248' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_737'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_707'>Random</a></p><div class='collapse' id='collapseExample248'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Stop the instance outside the application's availability window. Start up the instance again when required.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 93%;" aria-valuenow="93" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_737><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 737</p><br/>A company runs analytics software on Amazon EC2 instances.<br/><br/>The software accepts job requests from users to process data that has been uploaded to Amazon S3.<br/><br/>Users report that some submitted data is not being processed Amazon CloudWatch reveals that the EC2 instances have a consistent CPU utilization at or near 100%.<br/><br/>The company wants to improve system performance and scale the system based on user load. What should a solutions architect do to meet these requirements?<br/><br/>A. Create a copy of the instance. Place all instances behind an Application Load Balancer<br/>B. Create an S3 VPC endpoint for Amazon S3 Update the software to reference the endpoint.<br/>C. Stop the EC2 instances Modify the instance type to one with a more powerful CPU and more memory. Restart the instances<br/>D. Route incoming requests to Amazon Simple Queue Service (Amazon SQS) Configure an EC2 Auto Scaling group based on queue size. Update the software to read from the queue<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample627' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_738'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_301'>Random</a></p><div class='collapse' id='collapseExample627'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Create a copy of the instance. Place all instances behind an Application Load Balancer</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 93%;" aria-valuenow="93" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_738><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 738</p><br/>A solutions architect is designing a solution that requires frequent updates to a website that is hosted on Amazon S3 with versioning enabled. For compliance reasons, the older versions of the objects will not be accessed frequently and will need to be deleted after 2 years.<br/><br/>What should the solutions architect recommend to meet these requirements at the LOWEST cost?<br/><br/>A. Use S3 batch operations to replace object tags. Expire the objects based on the modified tags.<br/>B. Configure an S3 Lifecycle policy to transition older versions of objects to S3 Glacier. Expire the objects after 2 years.<br/>C. Enable S3 Event Notifications on the bucket that sends older objects to the Amazon Simple Queue Service (Amazon SQS) queue for further processing.<br/>D. Replicate older object versions to a new bucket. Use an S3 Lifecycle policy to expire the objects in the new bucket after 2 years.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample369' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_739'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_729'>Random</a></p><div class='collapse' id='collapseExample369'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Configure an S3 Lifecycle policy to transition older versions of objects to S3 Glacier. Expire the objects after 2 years.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 93%;" aria-valuenow="93" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_739><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 739</p><br/>A company is selling up an application to use an Amazon RDS MySQL DB instance. The database must be architected for high availability across Availability Zones and AWS Regions with minimal downtime.<br/><br/>How should a solutions architect meet this requirement?<br/><br/>A. Set up an RDS MySQL Multi&#8211;AZ DB instance. Configure an appropriate backup window.<br/>B. Set up an RDS MySQL Multi&#8211;AZ DB instance. Configure a read replica in a different Region.<br/>C. Set up an RDS MySQL Single&#8211;AZ DB instance. Configure a read replica in a different Region.<br/>D. Set up an RDS MySQL Single&#8211;AZ DB instance. Copy automated snapshots to at least one other Region.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample344' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_740'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_295'>Random</a></p><div class='collapse' id='collapseExample344'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Set up an RDS MySQL Single-AZ DB instance. Configure a read replica in a different Region.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 93%;" aria-valuenow="93" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_740><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 740</p><br/>A company is building an application on Amazon EC2 instances that generates temporary transactional data. The application requires access to data storage that can provide configurable and consistent IOPS.<br/><br/>What should a solutions architect recommend?<br/><br/>A. Provision an EC2 instance with a Throughput Optimized HDD (st1) root volume and a Cold HDD (sc1) data volume.<br/>B. Provision an EC2 instance with a Throughput Optimized HDD (st1) volume that will serve as the root and data volume.<br/>C. Provision an EC2 instance with a General Purpose SSD (gp2) root volume and Provisioned IOPS SSD (io1) data volume.<br/>D. Provision an EC2 instance with a General Purpose SSD (gp2) root volume. Configure the application to store its data in an Amazon S3 bucket.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample253' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_741'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_100'>Random</a></p><div class='collapse' id='collapseExample253'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Provision an EC2 instance with a General Purpose SSD (gp2) root volume and Provisioned IOPS SSD (io1) data volume.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 93%;" aria-valuenow="93" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_741><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 741</p><br/>A company's dynamic website is hosted using on&#8211;premises servers in the United States. The company is launching its product in Europe and it wants to optimize site loading times for new European users. The site's backend must remain in the United States.<br/><br/>The product is being launched in a few days, and an immediate solution is needed<br/><br/>What should the solutions architect recommend?<br/><br/>A. Launch an Amazon EC2 instance in us&#8211;east&#8211;1 and migrate the site to it<br/>B. Move the website to Amazon S3 Use cross&#8211;Region replication between Regions.<br/>C. Use Amazon CloudFront with a custom origin pointing to the on&#8211;premises servers<br/>D. Use an Amazon Route 53 geoproximity routing policy pointing to on&#8211;premises servers<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample509' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_742'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_309'>Random</a></p><div class='collapse' id='collapseExample509'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Use Amazon CloudFront with a custom origin pointing to the on-premises servers</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 93%;" aria-valuenow="93" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_742><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 742</p><br/>A company is developing a video conversion application hosted on AWS. The application will be available in two tiers: a free tier and a paid tier. Users in the paid tier will have their videos converted first and then the tree tier users will have their videos converted.<br/><br/>Which solution meets these requirements and is MOST cost&#8211;effective?<br/><br/>A. One FIFO queue for the paid tier and one standard queue for the free tier.<br/>B. A single FIFO Amazon Simple Queue Service (Amazon SQS) queue for all file types.<br/>C. A single standard Amazon Simple Queue Service (Amazon SQS) queue for all file types.<br/>D. Two standard Amazon Simple Queue Service (Amazon SQS) queues with one for the paid tier and one for the free tier.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample397' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation397' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_743'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_88'>Random</a></p><div class='collapse' id='collapseExample397'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Two standard Amazon Simple Queue Service (Amazon SQS) queues with one for the paid tier and one for the free tier.</div></div></div><div class='collapse' id='explanation397'><div class='card card&#45;body'><div>
In AWS, the queue service is the Simple Queue Service (SQS). Multiple SQS queues may be prepared to prepare queues for individual priority levels (with a priority queue and a secondary queue). Moreover, you may also use the message Delayed Send function to delay process execution.
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 93%;" aria-valuenow="93" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_743><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 743</p><br/>A company observes an increase in Amazon EC2 costs in its most recent bill.<br/><br/>The billing team notices unwanted vertical scaling of instance types for a couple of EC2 instances.<br/><br/>A solutions architect needs to create a graph comparing the last 2 months of EC2 costs and perform an in&#8211;depth analysis to identify the root cause of the vertical scaling.<br/><br/>How should the solutions architect generate the information with the LEAST operational overhead?<br/><br/>A. Use AWS Budgets to create a budget report and compare costs based on instance types.<br/>B. Use Cost Explorer's granular filtering feature to perform an in&#8211;depth analysis of EC2 costs based on instance types.<br/>C. Use graphs from the AWS Billing and Cost Management dashboard to compare EC2 costs based on instance types for the least 2 months.<br/>D. Use AWS Cost and Usage Report to create a report and send it to an Amazon S3 bucket. Use Amazon QuickSight Amazon S3 as a source to generate an interactive graph based on instance types.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample614' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_744'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_393'>Random</a></p><div class='collapse' id='collapseExample614'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Use graphs from the AWS Billing and Cost Management dashboard to compare EC2 costs based on instance types for the least 2 months.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 94%;" aria-valuenow="94" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_744><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 744</p><br/>A media streaming company collects real&#8211;time data and stores it in a disk&#8211;optimized database system. The company is not getting the expected throughput and wants an in&#8211;memory database storage solution that performs faster and provides high availability using data replication.<br/><br/>Which database should a solutions architect recommend?<br/><br/>A. Amazon RDS for MySQL<br/>B. Amazon RDS for PostgreSQL.<br/>C. Amazon ElastiCache for Redis<br/>D. Amazon ElastiCache for Memcached<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample38' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation38' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_745'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_524'>Random</a></p><div class='collapse' id='collapseExample38'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Amazon ElastiCache for Redis</div></div></div><div class='collapse' id='explanation38'><div class='card card&#45;body'><div>
In-memory databases on AWS Amazon Elasticache for Redis.
Amazon ElastiCache for Redis is a blazing fast in-memory data store that provides submillisecond latency to power internet-scale, real-time applications. Developers can use ElastiCache for Redis as an in-memory nonrelational database. The ElastiCache for Redis cluster configuration supports up to 15 shards and enables customers to run Redis workloads with up to 6.1 TB of in-memory capacity in a single cluster.

ElastiCache for Redis also provides the ability to add and remove shards from a running cluster. You can dynamically scale out and even scale in your Redis cluster workloads to adapt to changes in demand.

Amazon ElastiCache is an in-memory database. With ElastiCache Memcached there is no data replication or high availability. As you can see in the diagram, each node is a separate partition of data:

Therefore, the Redis engine must be used which does support both data replication and clustering. The following diagram shows a Redis architecture with cluster mode enabled:

CORRECT: "Amazon ElastiCache for Redis" is the correct answer.

INCORRECT: "Amazon ElastiCache for Memcached" is incorrect as Memcached does not support data replication or high availability.

INCORRECT: "Amazon RDS for MySQL" is incorrect as this is not an in-memory database. INCORRECT: "Amazon RDS for PostgreSQL" is incorrect as this is not an in-memory database.

References:

Amazon ElastiCache for Redis</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 94%;" aria-valuenow="94" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_745><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 745</p><br/>A company wants to use an AWS Region as a disaster recovery location for its on&#8211;premises infrastructure.<br/><br/>The company has 10 TB of existing data, and the on&#8211;premise data center has a 1 Gbps internet connection.<br/><br/>A solutions architect must find a solution so the company can have its existing data on AWS in 72 hours without transmitting it using an unencrypted channel.<br/><br/>Which solution should the solutions architect select?<br/><br/>A. Send the initial 10 TB of data to AWS using FTP.<br/>B. Send the initial 10 TB of data to AWS using AWS Snowball.<br/>C. Establish a VPN connection between Amazon VPC and the company's data center.<br/>D. Establish an AWS Direct Connect connection between Amazon VPC and the company's data center.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample208' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_746'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_574'>Random</a></p><div class='collapse' id='collapseExample208'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Establish a VPN connection between Amazon VPC and the company's data center.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 94%;" aria-valuenow="94" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_746><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 746</p><br/>A company built a food ordering application that captures user data and stores it for future analysis. The application's static front end is deployed on an Amazon EC2 instance. The front&#8211;end application sends the requests to the backend application running on separate EC2 instance. The backend application then stores the data in Amazon RDS.<br/><br/>What should a solutions architect do to decouple the architecture and make it scalable?<br/><br/>A. Use Amazon S3 to serve the front&#8211;end application, which sends requests to Amazon EC2 to execute the backend application. The backend application will process and store the data in Amazon RDS.<br/>B. Use Amazon S3 to serve the front&#8211;end application and write requests to an Amazon Simple Notification Service (Amazon SNS) topic. Subscribe Amazon EC2 instances to the HTTP/HTTPS endpoint of the topic, and process and store the data in Amazon RDS.<br/>C. Use an EC2 instance to serve the front end and write requests to an Amazon SQS queue. Place the backend instance in an Auto Scaling group, and scale based on the queue depth to process and store the data in Amazon RDS.<br/>D. Use Amazon S3 to serve the static front&#8211;end application and send requests to Amazon API Gateway, which writes the requests to an Amazon SQS queue. Place the backend instances in an Auto Scaling group, and scale based on the queue depth to process and store the data in Amazon RDS.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample43' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation43' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_747'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_400'>Random</a></p><div class='collapse' id='collapseExample43'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Use Amazon S3 to serve the static front-end application and send requests to Amazon API Gateway, which writes the requests to an Amazon SQS queue. Place the backend instances in an Auto Scaling group, and scale based on the queue depth to process and store the data in Amazon RDS.</div></div></div><div class='collapse' id='explanation43'><div class='card card&#45;body'><div>
Keyword: Static + Decouple + Scalable Static=S3

Decouple=SQS Queue Scalable=ASG

Option B will not be there in the race due to Auto-Scaling unavailability. Option A will not be there in the race due to Decouple unavailability.

Option C & D will be in the race and Option D will be correct answers due to all 3 combination matches [Static=S3; Decouple=SQS Queue; Scalable=ASG] & Option C will loose due to Static option unavailability
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 94%;" aria-valuenow="94" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_747><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 747</p><br/>An application runs on Amazon EC2 instances across multiple Availability Zones. The instances run in an Amazon EC2 Auto Scaling group behind an Application Load Balancer. The application performs best when the CPU utilization of the EC2 instances is at or near 40%.<br/><br/>What should a solutions architect do to maintain the desired performance across all instances in the group?<br/><br/>A. Use a simple scaling policy to dynamically scale the Auto Scaling group.<br/>B. Use a target tracking policy to dynamically scale the Auto Scaling group.<br/>C. Use an AWS Lambda function to update the desired Auto Scaling group capacity.<br/>D. Use scheduled scaling actions to scale up and scale down the Auto Scaling group.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample148' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation148' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_748'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_75'>Random</a></p><div class='collapse' id='collapseExample148'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Use a target tracking policy to dynamically scale the Auto Scaling group.</div></div></div><div class='collapse' id='explanation148'><div class='card card&#45;body'><div>
"With target tracking scaling policies, you select a scaling metric and set a target value. Amazon EC2 AutoScaling creates and manages the CloudWatch alarms that trigger the scaling policy and calculates the scaling adjustment based on the metric and the target value. The scaling policy adds or removes capacity as required to keep the metric at, or close to, the specified target value. In addition to keeping the metric close to the target value, a target tracking scaling policy also adjusts to changes in the metric due to a changing load pattern. For example, you can use target tracking scaling to: Configure a target tracking scaling policy to keep the average aggregate CPU utilization of your Auto Scaling group at 40 percent. Configure a target tracking scaling policy to keep the request count per target of your Application Load Balancer target group at 1000 for your AutoScaling group."

With target tracking scaling policies, you select a scaling metric and set a target value. Amazon EC2 Auto Scaling creates and manages the CloudWatch alarms that trigger the scaling policy and calculates the scaling adjustment based on the metric and the target value.

The scaling policy adds or removes capacity as required to keep the metric at, or close to, the specified target value. In addition to keeping the metric close to the target value, a target tracking scaling policy also adjusts to the changes in the metric due to a changing load pattern.

CORRECT: "Use a target tracking policy to dynamically scale the Auto Scaling group" is the correct answer.

INCORRECT: "Use a simple scaling policy to dynamically scale the Auto Scaling group" is incorrect as target tracking is a better way to keep the aggregate CPU usage at around 40% INCORRECT: "Use an AWS Lambda function to update the desired Auto Scaling group capacity" is incorrect as this can be done automatically.

INCORRECT: "Use scheduled scaling actions to scale up and scale down the Auto Scaling group" is incorrect as dynamic scaling is required to respond to changes in utilization.

References:

Amazon EC2 Auto Scaling > User Guide > Target tracking scaling policies for Amazon EC2 Auto Scaling</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 94%;" aria-valuenow="94" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_748><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 748</p><br/>A company operates a two&#8211;tier application for image processing. The application uses two Availability Zones, each with one public subnet and one private subnet. An Application Load Balancer (ALB) for the web tier uses the public subnets.<br/><br/>Amazon EC2 instances for the application tier use the private subnets.<br/><br/>Users report that the application is running more slowly than expected. A security audit of the web server log files shows that the application is receiving millions of illegitimate requests from a small number of IP addresses. A solutions architect needs to resolve the immediate performance problem while the company investigates a more permanent solution.<br/><br/>What should the solutions architect recommend to meet this requirement?<br/><br/>A. Modify the inbound security group for the web tier. Add a deny rule for the IP addresses that are consuming resources.<br/>B. Modify the network ACL for the web tier subnets. Add an inbound deny rule for the IP addresses that are consuming resources.<br/>C. Modify the inbound security group for the application tier. Add a deny rule for the IP addresses that are consuming resources.<br/>D. Modify the network ACL for the application tier subnets. Add an inbound deny rule for the IP addresses that are consuming resources.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample426' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_749'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_585'>Random</a></p><div class='collapse' id='collapseExample426'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Modify the inbound security group for the web tier. Add a deny rule for the IP addresses that are consuming resources.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 94%;" aria-valuenow="94" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_749><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 749</p><br/>A company is using Amazon DynamoDB to stage its product catalog which is 1 GB.<br/><br/>Since a product entry on average consists of100 KB of data, and the average traffic is about 250 requests per second, the database administrator has provisioned 3.000 RCUs of read capacity throughput.<br/><br/>However, some products are very popular and users are experiencing delays or timeouts due to throttling.<br/><br/>What improvement offers a long&#8211;term solution to this problem?<br/><br/>A. Increase the throughput provisioning to 6.000 read capacity units (RCUs)<br/>B. Use Amazon DynamoDB Accelerator to maintain the frequently read items<br/>C. Augment Amazon DynamoDB by storing only the key product attributes, with the details stored on Amazon S3<br/>D. Change the partition key to consist of a hash of product key and product type instead of just the product key<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample668' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_750'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_19'>Random</a></p><div class='collapse' id='collapseExample668'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Use Amazon DynamoDB Accelerator to maintain the frequently read items</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 94%;" aria-valuenow="94" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_750><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 750</p><br/>A company has a large dataset for its online advertising business stored in an Amazon RDS for MySQL DB instance in a single Availability Zone. The company wants business reporting queries to run without impacting the write operations to the production DB instance.<br/><br/>Which solution meets these requirements?<br/><br/>A. Deploy RDS read replicas to process the business reporting queries.<br/>B. Scale out the DB instance horizontally by placing it behind an Elastic Load Balancer<br/>C. Scale up the DB instance to a larger instance type to handle write operations and queries.<br/>D. Deploy the DB instance in multiple Availability Zones to process the business reporting queries.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample638' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_751'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_490'>Random</a></p><div class='collapse' id='collapseExample638'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Deploy RDS read replicas to process the business reporting queries.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 94%;" aria-valuenow="94" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_751><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 751</p><br/>A solutions architect is optimizing a website for an upcoming musical event. Videos of the performances will be streamed in real time and then will be available on demand. The event is expected to attract a global online audience.<br/><br/>Which service will improve the performance of both the real&#8211;time and on&#8211;demand streaming?<br/><br/>A. Amazon CloudFront<br/>B. AWS Global Accelerator<br/>C. Amazon Route S3<br/>D. Amazon S3 Transfer Acceleration<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample42' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_752'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_383'>Random</a></p><div class='collapse' id='collapseExample42'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Amazon CloudFront</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 95%;" aria-valuenow="95" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_752><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 752</p><br/>A restaurant reservation application needs to access a waiting list.<br/><br/>When a customer tries to reserve a table, and none are available, the customer application will put the user on the waiting list, and the application will notify the customer when a table becomes free.<br/><br/>The waiting list must preserve the order in which customers were added to the waiting list. Which service should the solutions architect recommend to store this waiting list?<br/><br/>A. Amazon Simple Notification Service (Amazon SNS)<br/>B. AWS Step Functions invoking AWS Lambda functions<br/>C. A FIFO queue in Amazon Simple Queue Service (Amazon SQS)<br/>D. A standard queue in Amazon Simple Queue Service (Amazon SQS)<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample530' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_753'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_703'>Random</a></p><div class='collapse' id='collapseExample530'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>A FIFO queue in Amazon Simple Queue Service (Amazon SQS)</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 95%;" aria-valuenow="95" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_753><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 753</p><br/>A solutions architect needs to design a managed storage solution for a company's application that includes high&#8211;performance machine learning. This application runs on AWS Fargate, and the connected storage needs to have concurrent access to files and deliver high performance.<br/><br/>Which storage option should the solutions architect recommend?<br/><br/>A. Create an Amazon S3 bucket for the application and establish an IAM role for Fargate to communicate with Amazon S3.<br/>B. Create an Amazon FSx for Lustre file share and establish an IAM role that allows Fargate to communicate with FSx for Lustre.<br/>C. Create an Amazon Elastic File System (Amazon EFS) file share and establish an IAM role that allows Fargate to communicate with Amazon EFS.<br/>D. Create an Amazon Elastic Block Store (Amazon EBS) volume for the application and establish an IAM role that allows Fargate to communicate with Amazon EBS.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample264' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation264' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_754'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_325'>Random</a></p><div class='collapse' id='collapseExample264'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Create an Amazon FSx for Lustre file share and establish an IAM role that allows Fargate to communicate with FSx for Lustre.</div></div></div><div class='collapse' id='explanation264'><div class='card card&#45;body'><div>
Keyword: Concurrent Access to files + Deliver High Performance
Amazon FSx: A high-performance file system optimized for fast processing of workloads. Lustre is a popular open-source parallel file system. Also supports concurrent access to the same file or directory from thousands of compute instances.

Amazon IAM with FSx: Amazon FSx is integrated with AWS Identity and Access Management (IAM). This integration means that you can control the actions your AWS IAM users and groups can take to manage your file systems (such as creating and deleting file systems). You can also tag your Amazon FSx resources and control the actions that your IAM users and groups can take based on those.

Fargate Launch Type – So, Answer C & D Ruled-out as per Neal David. Fargate automatically provisions resources Fargate provisions and manages compute Charged for running tasks. No EFS and EBS integration Fargate handles cluster optimization.

Limited control, infrastructure is automated

References:

Amazon Elastic File System</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 95%;" aria-valuenow="95" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_754><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 754</p><br/>A company currently operates a web application backed by an Amazon RDS MySQL database. It has automated backups that are run daily and are not encrypted. A security audit requires future backups to be encrypted and the unencrypted backups to be destroyed. The company will make at least one encrypted backup before destroying the old backups.<br/><br/>What should be done to enable encryption for future backups?<br/><br/>A. Enable default encryption for the Amazon S3 bucket where backups are stored.<br/>B. Modify the backup section of the database configuration to toggle the Enable encryption check box.<br/>C. Create a snapshot of the database. Copy it to an encrypted snapshot. Restore the database from the encrypted snapshot.<br/>D. Enable an encrypted read replica on RDS for MySQL. Promote the encrypted read replica to primary. Remove the original database instance.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample147' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation147' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_755'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_465'>Random</a></p><div class='collapse' id='collapseExample147'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Create a snapshot of the database. Copy it to an encrypted snapshot. Restore the database from the encrypted snapshot.</div></div></div><div class='collapse' id='explanation147'><div class='card card&#45;body'><div>
However, because you can encrypt a copy of an unencrypted DB snapshot, you can effectively add encryption to an unencrypted DB instance. That is, you can create a snapshot of your DB instance, and then create an encrypted copy of that snapshot. You can then restore a DB instance from the encrypted snapshot, and thus you have an encrypted copy of your original DB instance.

DB instances that are encrypted can't be modified to disable encryption.

You can't have an encrypted read replica of an unencrypted DB instance or an unencrypted read replica of an encrypted DB instance.

Encrypted read replicas must be encrypted with the same key as the source DB instance when both are in the same AWS Region.

You can't restore an unencrypted backup or snapshot to an encrypted DB instance.

To copy an encrypted snapshot from one AWS Region to another, you must specify the KMS key identifier of the destination AWS Region. This is because KMS encryption keys are specific to the AWS Region that they are created in.

Amazon RDS uses snapshots for backup. Snapshots are encrypted when created only if the database is encrypted and you can only select encryption for the database when you first create it. In this case the database, and hence the snapshots, ad unencrypted.

However, you can create an encrypted copy of a snapshot. You can restore using that snapshot which creates a new DB instance that has encryption enabled. From that point on encryption will be enabled for all snapshots.

CORRECT: "Create a snapshot of the database. Copy it to an encrypted snapshot. Restore the database from the encrypted snapshot" is the correct answer. INCORRECT: "Enable an encrypted read replica on RDS for MySQL. Promote the encrypted read replica to primary.

Remove the original database instance" is incorrect as you cannot create an encrypted read replica from an unencrypted master.

INCORRECT: "Modify the backup section of the database configuration to toggle the Enable encryption check box" is incorrect as you cannot add encryption for an existing database.

INCORRECT: "Enable default encryption for the Amazon S3 bucket where backups are stored" is incorrect because you do not have access to the S3 bucket in which snapshots are stored.

References:

Amazon Relational Database Service > User Guide > Encrypting Amazon RDS resources</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 95%;" aria-valuenow="95" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_755><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 755</p><br/>A company has multiple applications that use Amazon RDS for MySQL as is database. The company recently discovered that a new custom reporting application has increased the number of Queries on the database. This is slowing down performance.<br/><br/>How should a solutions architect resolve this issue with the LEAST amount of application changes?<br/><br/>A. Add a secondary DB instance using Multi&#8211;AZ.<br/>B. Set up a road replica and Multi&#8211;AZ on Amazon RDS.<br/>C. Set up a standby replica and Multi&#8211;AZ on Amazon RDS.<br/>D. Use caching on Amazon RDS to improve the overall performance.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample326' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_756'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_261'>Random</a></p><div class='collapse' id='collapseExample326'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Use caching on Amazon RDS to improve the overall performance.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 95%;" aria-valuenow="95" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_756><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 756</p><br/>A company is rolling out a new web service, but is unsure how many customers the service will attract.<br/><br/>However, the company is unwilling to accept any downtime.<br/><br/>What could a solutions architect recommend to the company to keep?<br/><br/>A. Amazon EC2<br/>B. Amazon RDS<br/>C. AWS CtoudTrail<br/>D. Amazon DynamoDB<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample531' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_757'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_334'>Random</a></p><div class='collapse' id='collapseExample531'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Amazon RDS</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 95%;" aria-valuenow="95" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_757><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 757</p><br/>A company has migrated an on&#8211;premises Oracle database to an Amazon RDS for Oracle Multi&#8211;AZ DB instance in the us&#8211;east&#8211;l Region. A solutions architect is designing a disaster recovery strategy to have the database provisioned in the us&#8211;west&#8211;2 Region in case the database becomes unavailable in the us&#8211;east&#8211;1 Region. The design must ensure the database is provisioned in the us&#8211;west&#8211;2 Region in a maximum of 2 hours, with a data loss window of no more than 3 hours.<br/><br/>How can these requirements be met?<br/><br/>A. Edit the DB instance and create a read replica in us&#8211;west&#8211;2. Promote the read replica to master in us&#8211;west&#8211;2 in case the disaster recovery environment needs to be activated.<br/>B. Select the multi&#8211;Region option to provision a standby instance in us&#8211;west&#8211;2. The standby instance will be automatically promoted to master in us&#8211;west&#8211;2 in case the disaster recovery environment needs to be created.<br/>C. Take automated snapshots of the database instance and copy them to us&#8211;west&#8211;2 every 3 hours. Restore the latest snapshot to provision another database instance in us&#8211;west&#8211;2 in case the disaster recovery environment needs to be activated.<br/>D. Create a multimaster read/write instances across multiple AWS Regions. Select VPCs in us&#8211;east&#8211;1 and us&#8211;west&#8211;2 to make that deployment. Keep the master read/write instance in us&#8211;west&#8211;2 available to avoid having to activate a disaster recovery environment.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample269' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_758'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_639'>Random</a></p><div class='collapse' id='collapseExample269'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Select the multi-Region option to provision a standby instance in us-west-2. The standby instance will be automatically promoted to master in us-west-2 in case the disaster recovery environment needs to be created.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 95%;" aria-valuenow="95" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_758><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 758</p><br/>A solutions architect is designing a new workload in which an AWS Lambda function will access an Amazon DynamoDB table.<br/><br/>What is the MOST secure means of granting the Lambda function access to the DynamoDB labia?<br/><br/>A. Create an IAM role with the necessary permissions to access the DynamoDB table. Assign the role to the Lambda function.<br/>B. Create a DynamoDB user name and password and give them to the developer to use in the Lambda function.<br/>C. Create an IAM user, and create access and secret keys for the user. Give the user the necessary permissions to access the DynarnoOB table. Have the developer use these keys to access the resources.<br/>D. Create an IAM role allowing access from AWS Lambda. Assign the role to the DynamoDB table<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample540' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_759'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_139'>Random</a></p><div class='collapse' id='collapseExample540'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Create an IAM role with the necessary permissions to access the DynamoDB table. Assign the role to the Lambda function.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 95%;" aria-valuenow="95" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_759><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 759</p><br/>A solutions architect is designing storage for a high performance computing (HPC) environment based on Amazon Linux. The workload stores and processes a large amount of engineering drawings that require shared storage and heavy computing.<br/><br/>Which storage option would be the optimal solution?<br/><br/>A. Amazon Elastic File System (Amazon EFS)<br/>B. Amazon FSx for Lustre<br/>C. Amazon EC2 instance store<br/>D. Amazon EBS Provisioned IOPS SSD (io1)<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample184' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation184' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_760'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_396'>Random</a></p><div class='collapse' id='collapseExample184'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Amazon FSx for Lustre</div></div></div><div class='collapse' id='explanation184'><div class='card card&#45;body'><div>
Amazon FSx for Lustre is a new, fully managed service provided by AWS based on the Lustre file system.

Amazon FSx for Lustre provides a high-performance file system optimized for fast processing of workloads such as machine learning, high performance computing (HPC), video processing, financial modeling, and electronic design automation (EDA).

FSx for Lustre allows customers to create a Lustre filesystem on demand and associate it to an Amazon S3 bucket. As part of the filesystem creation, Lustre reads the objects in the buckets and adds that to the file system metadata. Any Lustre client in your VPC is then able to access the data, which gets cached on the high-speed Lustre filesystem. This is ideal for HPC workloads, because you can get the speed of an optimized Lustre file system without having to manage the complexity of deploying, optimizing, and managing the Lustre cluster.

Additionally, having the filesystem work natively with Amazon S3 means you can shut down the Lustre filesystem when you don't need it but still access objects in Amazon S3 via other AWS Services. FSx for Lustre also allows you to also write the output of your HPC job back to Amazon S3.
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 96%;" aria-valuenow="96" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_760><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 760</p><br/>A start&#8211;up company has a web application based in the us&#8211;east&#8211;1 Region with multiple Amazon EC2 instances running behind an Application Load Balancer across multiple Availability Zones As the company's user base grows in the us&#8211;west&#8211;1 Region, it needs 3 solution with low latency and high availability.<br/><br/>What should a solutions architect do to accomplish this?<br/><br/>A. Provision EC2 instances in us&#8211;west&#8211;1. Switch my Application Load Balancer to a Network Load Balancer to achieve cross&#8211;Region load balancing.<br/>B. Provision EC2 instances and an Application Load Balancer in us&#8211;west&#8211;1 Make the load balancer distribute the traffic based on the location of the request<br/>C. Provision EC2 instances and configure an Application Load Balancer in us&#8211;west&#8211;1. Create an accelerator in AWS Global Accelerator that uses an endpoint group that includes the load balancer endpoints in both Regions.<br/>D. Provision EC2 Instances and configure an Application Load Balancer in us&#8211;west&#8211;1 Configure Amazon Route 53 with a weighted routing policy. Create alias records in Route 53 that point to the Application Load Balancer<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample489' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation489' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_761'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_415'>Random</a></p><div class='collapse' id='collapseExample489'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Provision EC2 instances and configure an Application Load Balancer in us-west-1. Create an accelerator in AWS Global Accelerator that uses an endpoint group that includes the load balancer endpoints in both Regions.</div></div></div><div class='collapse' id='explanation489'><div class='card card&#45;body'><div>
ELB provides load balancing within one Region, AWS Global Accelerator provides traffic management across multiple Regions […] AWS Global Accelerator complements ELB by extending these capabilities beyond a single AWS Region, allowing you to provision a global interface for your applications in any number of Regions. If you have workloads that cater to a global client base, we recommend that you use AWS Global Accelerator. If you have workloads hosted in a single AWS Region and used by clients in and around the same Region, you can use an Application Load Balancer or Network Load Balancer to manage your resources.

References:
AWS Global Accelerator FAQs
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 96%;" aria-valuenow="96" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_761><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 761</p><br/>A company uses Amazon S3 for storing a variety of files.<br/><br/>A solutions architect needs to design a feature that will allow users to instantly restore any deleted files within 30 days of deletion.<br/><br/>Which is the MOST cost&#8211;efficient solution?<br/><br/>A. Create lifecycle policies that move the objects to Amazon S3 Glacier and delete them after 30 days<br/>B. Enable Cross&#8211;Region Replication Empty the replica bucket every 30 days using an AWS Lambda function<br/>C. Enable versioning and create a lifecycle policy to remove expired versions after 30 days.<br/>D. Enable versioning and MFA Delete Using a Lambda function remove MFA Delete from objects more than 30 days old<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample626' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_762'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_575'>Random</a></p><div class='collapse' id='collapseExample626'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Create lifecycle policies that move the objects to Amazon S3 Glacier and delete them after 30 days</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 96%;" aria-valuenow="96" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_762><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 762</p><br/>53 latency&#8211;based routing to route requests to its UDP&#8211;based application tor users around the world the application is hosted on redundant servers in the company's on&#8211;premises data centers in the United States Asia, and Europe The company's compliance requirements state that the application must be hosted on&#8211;premises. The company wants to improve the performance and availability of the application.<br/><br/>What should a solutions architect do to meet these requirements?<br/><br/>A. Configure throe Network Load Balancers (NLBs) in the three AWS Regions to address the on&#8211;premises endpoints. Create an accelerator by using AWS Global Accelerator, and register the NLBs as its endpoints. Provide access to the application by using a CNAML that points to the accelerator DNS.<br/>B. Configure three Application Load Balancers (ALGs) in the three AWS Regions to wireless the on&#8211;premises endpoints. Create an accelerator by using AWS Global Accelerator, and register the ALBs as its endpoints. Provide access to the application by using a CNAK1L that points to the accelerator UNS<br/>C. Configure three Network Load Balancers (NLOs) in the three AWS Regions to address the on&#8211;premises endpoints in Route 53. Create latency&#8211;based record that points to the three NLBs. and use it as an origin for an Amazon CloudFront distribution. Provide access to the application by using a CNAML that points to the CloudFront DNS.<br/>D. Configure three Application Load Balancers (ALBs) in the three AWS Regions to address the on&#8211;premises endpoint. in Route 53.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample535' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_763'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_498'>Random</a></p><div class='collapse' id='collapseExample535'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Configure three Network Load Balancers (NLOs) in the three AWS Regions to address the on-premises endpoints in Route 53. Create latency-based record that points to the three NLBs. and use it as an origin for an Amazon CloudFront distribution. Provide access to the application by using a CNAML that points to the CloudFront DNS.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 96%;" aria-valuenow="96" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_763><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 763</p><br/>A company has a two&#8211;tier application architecture that runs in public and private subnets. Amazon EC2 instances running the web application are in the public subnet and a database runs on the private subnet.<br/><br/>The web application instances and the database are running in a single Availability Zone (AZ).<br/><br/>Which combination of steps should a solutions architect take to provide high availability for this architecture? (Choose two.)<br/><br/>A. Create new public and private subnets in the same AZ for high availability.<br/>B. Create an Amazon EC2 Auto Scaling group and Application Load Balancer spanning multiple AZs.<br/>C. Add the existing web application instances to an Auto Scaling group behind an Application Load Balancer.<br/>D. Create new public and private subnets in a new AZ. Create a database using Amazon EC2 in one AZ.<br/>E. Create new public and private subnets in the same VPC, each in a new AZ. Migrate the database to an Amazon RDS multi&#8211;AZ deployment.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample152' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation152' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_764'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_438'>Random</a></p><div class='collapse' id='collapseExample152'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Create an Amazon EC2 Auto Scaling group and Application Load Balancer spanning multiple AZs.
<br><b>E. </b>Create new public and private subnets in the same VPC, each in a new AZ. Migrate the database to an Amazon RDS multi-AZ deployment.</div></div></div><div class='collapse' id='explanation152'><div class='card card&#45;body'><div>

You would the EC2 instances to have high availability by placing them in multiple AZs.
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 96%;" aria-valuenow="96" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_764><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 764</p><br/>You are building infrastructure for a data warehousing solution and an extra request has come through that there will be a lot of business reporting queries running all the time and you are not sure if your current DB instance will be able to handle it.<br/><br/>What would be the best solution for this?<br/><br/>A. DB Parameter Groups<br/>B. Read Replicas<br/>C. Multi&#8211;AZ DB Instance deployment<br/>D. Database Snapshots<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample743' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation743' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_765'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_753'>Random</a></p><div class='collapse' id='collapseExample743'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Read Replicas</div></div></div><div class='collapse' id='explanation743'><div class='card card&#45;body'><div>
Read Replicas make it easy to take advantage of MySQL's built-in replication functionality to elastically scale out beyond the capacity constraints of a single DB Instance for read-heavy database workloads. There are a variety of scenarios where deploying one or more Read Replicas for a given source DB Instance may make sense. Common reasons for deploying a Read Replica include:

Scaling beyond the compute or I/O capacity of a single DB Instance for read-heavy database workloads. This excess read traffic can be directed to one or more Read Replicas. Serving read traffic while the source DB Instance is unavailable. If your source DB Instance cannot take I/O requests (e.g. due to I/O suspension for backups or scheduled maintenance), you can direct read traffic to your Read Replica(s). For this use case, keep in mind that the data on the Read Replica

may be "stale" since the source DB Instance is unavailable. Business reporting or data warehousing scenarios; you may want business reporting queries to run against a Read Replica, rather than your primary, production DB Instance.

References:

Amazon RDS FAQs</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 96%;" aria-valuenow="96" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_765><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 765</p><br/>A company has been running a web application with an Oracle relational database in an on&#8211;premises data center for the past 15 years. The company must migrate the database to AWS. The company needs to reduce operational overhead without having to modify the application's code.<br/><br/>Which solution meets these requirements?<br/><br/>A. Use AWS Database Migration Service (AWS DMS) to migrate the database servers to Amazon RDS.<br/>B. Use Amazon EC2 instances to migrate and operate the database servers.<br/>C. Use AWS Database Migration Service (AWS DMS) to migrate the database servers to Amazon DynamoDB.<br/>D. Use an AWS Snowball Edge Storage Optimized device to migrate the data from Oracle to Amazon Aurora.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample434' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_766'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_386'>Random</a></p><div class='collapse' id='collapseExample434'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Use AWS Database Migration Service (AWS DMS) to migrate the database servers to Amazon RDS.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 96%;" aria-valuenow="96" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_766><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 766</p><br/>A company wants to migrate its web application to AWS. The legacy web application consists of a web tier, an application tier, and a MySQL database.<br/><br/>The re&#8211;architected application must consist of technologies that do not require the administration team to manage instances or clusters.<br/><br/>Which combination of services should a solutions architect include in the overall architecture? (Select TWO)<br/><br/>A. Amazon Aurora Serverless<br/>B. Amazon EC2 Spot Instances<br/>C. Amazon Elasticsearch Service (Amazon ES)<br/>D. Amazon RDS for MySQL<br/>E. AWS Fargate<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample675' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_767'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_161'>Random</a></p><div class='collapse' id='collapseExample675'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Amazon RDS for MySQL
<br><b>E. </b>AWS Fargate</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 96%;" aria-valuenow="96" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_767><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 767</p><br/>A company has an application that uses Amazon Elastic File System (Amazon EFS) to store data. The files are 1 GB in size or larger and are accessed often only for the first few days after creation. The application data is shared across a cluster of Linux servers. The company wants to reduce storage costs for the application.<br/><br/>What should a solutions architect do to meet these requirements?<br/><br/>A. Implement Amazon FSx and mount the network drive on each server.<br/>B. Move the fees from Amazon EFS and store them locally on each Amazon EC2 instance.<br/>C. Configure a Lifecycle policy to move the files to the EFS Infrequent Access (IA) swage class after 7 days.<br/>D. Move the files to Amazon S3 with S3 lifecycle policies enabled. Rewrite the application to support mounting the S3 bucket.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample302' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_768'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_206'>Random</a></p><div class='collapse' id='collapseExample302'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Configure a Lifecycle policy to move the files to the EFS Infrequent Access (IA) swage class after 7 days.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 97%;" aria-valuenow="97" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_768><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 768</p><br/>A company's application is running on Amazon EC2 instances within an Auto Scaling group behind an Elastic Load Balancer. Based on the application's history the company anticipates a spike in traffic during a holiday each year. A solutions architect must design a strategy to ensure that the Auto Scaling group proactively increases capacity to minimize any performance impact on application users.<br/><br/>Which solution will meet these requirements?<br/><br/>A. Create an Amazon CloudWatch alarm to scale up the EC2 instances when CPU utilization exceeds 90%.<br/>B. Create a recurring scheduled action to scale up the Auto Scaling group before the expected period of peak demand.<br/>C. Increase the minimum and maximum number of EC2 instances in the Auto Scaling group during the peak demand period.<br/>D. Configure an Amazon Simple Notification Service (Amazon SNS) notification to send alerts when there are autoscaling EC2_INSTANCE_LAUNCH events.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample40' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation40' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_769'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_496'>Random</a></p><div class='collapse' id='collapseExample40'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Create a recurring scheduled action to scale up the Auto Scaling group before the expected period of peak demand.</div></div></div><div class='collapse' id='explanation40'><div class='card card&#45;body'><div>
AWS Auto Scaling monitors your applications and automatically adjusts capacity to maintain steady, predictable performance at the lowest possible cost. AWS Auto Scaling refers to a collection of Auto Scaling capabilities across several AWS services.

The services within the AWS Auto Scaling family include: Amazon EC2 (known as Amazon EC2 Auto Scaling).

Amazon ECS. Amazon DynamoDB. Amazon Aurora.

The scaling options define the triggers and when instances should be provisioned/de-provisioned. There are four scaling options:

Maintain – keep a specific or minimum number of instances running. Manual – use maximum, minimum, or a specific number of instances.

Scheduled – increase or decrease the number of instances based on a schedule. Dynamic – scale based on real-time system metrics (e.g. CloudWatch metrics).

The following table describes the scaling options available and when to use them:

The scaling options are configured through Scaling Policies which determine when, if, and how the ASG scales and shrinks.

The following table describes the scaling policy types available for dynamic scaling policies and when to use them (more detail further down the page):

The diagram below depicts an Auto Scaling group with a Scaling policy set to a minimum size of 1 instance, a desired capacity of 2 instances, and a maximum size of 4 instances:

Amazon EC2 Auto Scaling supports sending Amazon SNS notifications when the following events occur.
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 97%;" aria-valuenow="97" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_769><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 769</p><br/>A company is running a three&#8211;tier web application to process credit card payments. The front&#8211;end user interface consists of static webpages. The application tier can have long&#8211;running processes. The database tier uses MySQL.<br/><br/>The application is currently running on a single, general&#8211;purpose large Amazon EC2 instance. A solutions architect needs to decouple the services to make the web application highly available.<br/><br/>Which solution would provide the HIGHEST availability?<br/><br/>A. Move static assets to Amazon CloudFront. Leave the application in EC2 in an Auto Scaling group. Move the database to Amazon RDS to deploy Multi&#8211;AZ.<br/>B. Move static assets and the application into a medium EC2 instance. Leave the database on the large instance. Place both instances in an Auto Scaling group.<br/>C. Move static assets to Amazon S3, Move the application to AWS Lambda with the concurrency limit set. Move the database to Amazon DynamoDB with on&#8211;demand enabled.<br/>D. Move static assets to Amazon S3. Move the application to Amazon Elastic Container Service (Amazon ECS) containers with Auto Scaling enabled. Move the database to Amazon RDS to deploy Multi&#8211;AZ.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample103' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_770'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_391'>Random</a></p><div class='collapse' id='collapseExample103'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Move static assets and the application into a medium EC2 instance. Leave the database on the large instance. Place both instances in an Auto Scaling group.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 97%;" aria-valuenow="97" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_770><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 770</p><br/>A development team stores its Amazon RDS MySQL DB instance user name and password credentials in a configuration file. The configuration file is stored as plaintext on the root device volume of the team's Amazon EC2 instance. When the team's application needs to reach the database, it reads the file and loads the credentials into the code. The team has modified the permissions of the configuration file so that only the application can read its content. A solution architect must design a more secure solution.<br/><br/>What should the solutions architect do to meet this requirement?<br/><br/>A. Store the configuration file in Amazon S3. Grant the application access to read the configuration file.<br/>B. Create an IAM role with permission to access the database. Attach this IAM role to the EC2 instance.<br/>C. Enable SSL connections on the database instance. Alter the database user to require SSL when logging in.<br/>D. Move the configuration file to an EC2 instance store, and create an Amazon Machine Image (AMI) of the instance. Launch new instances from this AMI.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample316' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_771'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_601'>Random</a></p><div class='collapse' id='collapseExample316'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Move the configuration file to an EC2 instance store, and create an Amazon Machine Image (AMI) of the instance. Launch new instances from this AMI.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 97%;" aria-valuenow="97" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_771><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 771</p><br/>A solutions architect at an eCommerce company wants to back up application log data to Amazon S3. The solutions architect is unsure how frequently the logs will be accessed or which logs will be accessed the most. The company wants to keep costs as low as possible by using the appropriate S3 storage class.<br/><br/>Which S3 storage class should be implemented to meet these requirements?<br/><br/>A. S3 Glacier<br/>B. S3 Intelligent&#8211;Tiering<br/>C. S3 Standard&#8211;Infrequent Access (S3 Standard&#8211;IA)<br/>D. S3 One Zone&#8211;Infrequent Access (S3 One Zone&#8211;IA)<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample183' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation183' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_772'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_429'>Random</a></p><div class='collapse' id='collapseExample183'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>S3 Intelligent-Tiering</div></div></div><div class='collapse' id='explanation183'><div class='card card&#45;body'><div>
S3 Intelligent-Tiering is a new Amazon S3 storage class designed for customers who want to optimize storage costs automatically when data access patterns change, without performance impact or operational overhead. S3 Intelligent-Tiering is the first cloud object storage class that delivers automatic cost savings by moving data between two access tiers – frequent access and infrequent access – when access patterns change, and is ideal for data with unknown or changing access patterns.

S3 Intelligent-Tiering stores objects in two access tiers: one tier that is optimized for frequent access and another lower-cost tier that is optimized for infrequent access. For a small monthly monitoring and automation fee per object, S3 Intelligent-Tiering monitors access patterns and moves objects that have not been accessed for 30 consecutive days to the infrequent access tier.

There are no retrieval fees in S3 Intelligent-Tiering. If an object in the infrequent access tier is accessed later, it is automatically moved back to the frequent access tier. No additional tiering fees apply when objects are moved between access tiers within the S3 Intelligent-Tiering storage class. S3 Intelligent-Tiering is designed for 99.9% availability and 99.999999999% durability, and offers the same low latency and high throughput performance of S3 Standard.
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 97%;" aria-valuenow="97" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_772><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 772</p><br/>A user is storing a large number of objects on AWS S3. The user wants to implement the search functionality among the objects. How can the user achieve this?<br/><br/>A. Use the indexing feature of S3.<br/>B. Tag the objects with the metadata to search on that.<br/>C. Use the query functionality of S3.<br/>D. Make your own DB system which stores the S3 metadata for the search functionality.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample775' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation775' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_773'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_517'>Random</a></p><div class='collapse' id='collapseExample775'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Make your own DB system which stores the S3 metadata for the search functionality.</div></div></div><div class='collapse' id='explanation775'><div class='card card&#45;body'><div>
In Amazon Web Services, AWS S3 does not provide any query facility. To retrieve a specific object the user needs to know the exact bucket/object key. In this case it is recommended to have an own DB system which manages the S3 metadata and key mapping.

References:

Storage Options in the AWS Cloud </div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 97%;" aria-valuenow="97" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_773><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 773</p><br/>A solutions architect needs to design a resilient solution for Windows users' home directories. The solution must provide fault tolerance, file&#8211;level backup and recovery, and access control, based upon the company's Active Directory.<br/><br/>Which storage solution meets these requirements?<br/><br/>A. Configure Amazon S3 to store the users' home directories. Join Amazon S3 to Active Directory.<br/>B. Configure a Multi&#8211;AZ file system with Amazon FSx for Windows File Server. Join Amazon FSx to Active Directory.<br/>C. Configure Amazon Elastic File System (Amazon EFS) for the users' home directories. Configure AWS Single Sign&#8211;On with Active Directory.<br/>D. Configure Amazon Elastic Block Store (Amazon EFS) to store the users' home directories. Configure AWS Single Sign&#8211;On with Active Directory.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample254' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_774'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_177'>Random</a></p><div class='collapse' id='collapseExample254'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Configure Amazon Elastic File System (Amazon EFS) for the users' home directories. Configure AWS Single Sign-On with Active Directory.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 97%;" aria-valuenow="97" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_774><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 774</p><br/>A company's security policy requires that alt AWS API activity in its AWS accounts be recorded for periodic auditing. The company needs to ensure that AWS CloudTrail is enabled on all of its current and future AWS accounts using AWS Organizations.<br/><br/>Which solution is MOST secure?<br/><br/>A. At the organization's root define and attach a service control policy (SCP) that permits enabling CloudTrail only<br/>B. Create IAM groups in the organization's master account as needed Define and attach an IAM policy to the groups that prevents users from disabling CloudTrail<br/>C. Organize accounts into organizational units (OUs) At the organization's root, define and attach a service control policy (SCP) that prevents users from disabling CloudTrail<br/>D. Add all existing accounts under the organization's root Define and attach a service control policy (SCP) to every account that prevents users from disabling CloudTrail<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample568' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_775'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_730'>Random</a></p><div class='collapse' id='collapseExample568'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Add all existing accounts under the organization's root Define and attach a service control policy (SCP) to every account that prevents users from disabling CloudTrail</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 97%;" aria-valuenow="97" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_775><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 775</p><br/>A Solutions Architect is creating an application running in an Amazon VPC that needs to access AWS Systems Manager Parameter Store. Network security rules prohibit any route table entry with a 0.0.0.0/0 destination.<br/><br/>What infrastructure addition will allow access to the AWS service while meeting the requirements?<br/><br/>A. VPC peering<br/>B. NAT instance<br/>C. NAT gateway<br/>D. AWS PrivateLink<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample789' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation789' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_776'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_409'>Random</a></p><div class='collapse' id='collapseExample789'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>AWS PrivateLink</div></div></div><div class='collapse' id='explanation789'><div class='card card&#45;body'><div>
To publish messages to Amazon SNS topics from an Amazon VPC, create an interface VPC endpoint. Then, you can publish messages to SNS topics while keeping the traffic within the network that you manage with the VPC. This is the most secure option as traffic does not need to traverse the Internet.

CORRECT: "Use AWS PrivateLink" is the correct answer.

INCORRECT: "Use an Internet Gateway" is incorrect. Internet Gateways are used by instances in public subnets to access the Internet and this is less secure than an VPC endpoint.

INCORRECT: "Use a proxy instance" is incorrect. A proxy instance will also use the public Internet and so is less secure than a VPC endpoint.

INCORRECT: "Use a NAT gateway" is incorrect. A NAT Gateway is used by instances in private subnets to access the Internet and this is less secure than an VPC endpoint.

References:

Amazon Simple Notification Service > Developer Guide > What is Amazon SNS?</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 98%;" aria-valuenow="98" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_776><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 776</p><br/>A company is planning to deploy an Amazon RDS DB instance running Amazon Aurora. The company has a backup retention policy requirement of 90 days. Which solution should a solutions architect recommend?<br/><br/>A. Set the backup retention period to 90 days when creating the RDS DB instance.<br/>B. Configure RDS to copy automated snapshots to a user&#8211;managed Amazon S3 bucket with a lifecycle policy set to delete after 90 days.<br/>C. Create an AWS Backup plan to perform a daily snapshot of the RDS database with the retention set to 90 days. Create an AWS Backup job to schedule the execution of the backup plan daily.<br/>D. Use a daily scheduled event with Amazon CloudWatch Events to execute a custom AWS Lambda function that makes a copy of the RDS automated snapshot. Purge snapshots older than 90 days.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample121' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_777'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_225'>Random</a></p><div class='collapse' id='collapseExample121'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Configure RDS to copy automated snapshots to a user-managed Amazon S3 bucket with a lifecycle policy set to delete after 90 days.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 98%;" aria-valuenow="98" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_777><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 777</p><br/>A company's website provides users with downloadable historical performance reports. The website needs a solution that will scale to meet the company's website demands globally. The solution should be cost effective, limit the? provisioning of Into and provide the fastest possible response time.<br/><br/>Which combination should a solutions architect recommend to meet these requirements?<br/><br/>A. Amazon CloudFront and Amazon S3<br/>B. AWS Lambda and Amazon Dynamo<br/>C. Application Load Balancer with Amazon EC2 Auto Scaling<br/>D. Amazon Route 53 with internal Application Load Balances<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample731' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_778'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_315'>Random</a></p><div class='collapse' id='collapseExample731'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Amazon CloudFront and Amazon S3</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 98%;" aria-valuenow="98" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_778><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 778</p><br/>A solutions architect is creating a new VPC design. There are two public subnets for the load balancer, two private subnets for web servers, and two private subnets for MySQL. The web servers use only HTTPS.<br/><br/>The solutions architect has already created a security group for the load balancer allowing port 443 from 0.0.0.0/0. Company policy requires that each resource has the least access required to still be able to perform its tasks.<br/><br/>Which additional configuration strategy should the solutions architect use to meet these requirements?<br/><br/>A. Create a security group for the web servers and allow port 443 from 0.0.0.0/0. Create a security group for the MySQL servers and allow port 3306 from the web servers security group.<br/>B. Create a network ACL for the web servers and allow port 443 from 0.0.0.0/0. Create a network ACL for the MySQL servers and allow port 3306 from the web servers security group.<br/>C. Create a security group for the web servers and allow port 443 from the load balancer. Create a security group for the MySQL servers and allow port 3306 from the web servers security group.<br/>D. Create a network ACL for the web servers and allow port 443 from the load balancer. Create a network ACL for the MySQL servers and allow port 3306 from the web servers security group.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample249' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_779'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_113'>Random</a></p><div class='collapse' id='collapseExample249'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Create a network ACL for the web servers and allow port 443 from 0.0.0.0/0. Create a network ACL for the MySQL servers and allow port 3306 from the web servers security group.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 98%;" aria-valuenow="98" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_779><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 779</p><br/>A company has a Microsoft Windows&#8211;based application that must be migrated to AWS. This application requires the use of a shared Windows file system attached to multiple Amazon EC2 Windows instances.<br/><br/>What should a solutions architect do to accomplish this?<br/><br/>A. Configure a volume using Amazon EFS. Mount the EFS volume to each Windows instance.<br/>B. Configure AWS Storage Gateway in Volume Gateway mode. Mount the volume to each Windows instance.<br/>C. Configure Amazon FSx for Windows File Server. Mount the Amazon FSx volume to each Windows instance.<br/>D. Configure an Amazon EBS volume with the required size. Attach each EC2 instance to the volume. Mount the file system within the volume to each Windows instance.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample72' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_780'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_479'>Random</a></p><div class='collapse' id='collapseExample72'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Configure Amazon FSx for Windows File Server. Mount the Amazon FSx volume to each Windows instance.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 98%;" aria-valuenow="98" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_780><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 780</p><br/>Which of the below mentioned options is not available when an instance is launched by Auto Scaling with EC2 Classic?<br/><br/>A. Public IP<br/>B. Elastic IP<br/>C. Private DNS<br/>D. Private IP<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample745' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation745' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_781'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_552'>Random</a></p><div class='collapse' id='collapseExample745'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Elastic IP</div></div></div><div class='collapse' id='explanation745'><div class='card card&#45;body'><div>
Auto Scaling supports both EC2 classic and EC2-VPC. When an instance is launched as a part of EC2 classic, it will have the public IP and DNS as well as the private IP and DNS.

References:

Amazon EC2 Auto Scaling > User Guide > Getting started with Amazon EC2 Auto Scaling</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 98%;" aria-valuenow="98" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_781><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 781</p><br/>A company has several business systems that require access to data stored in a file share. the business systems will access the file share using the Server Message Block (SMB) protocol. The file share solution should be accessible from both of the company's legacy on&#8211;premises environment and with AWS.<br/><br/>Which services mod the business requirements? (Select TWO)<br/><br/>A. Amazon EBS<br/>B. Amazon EFS<br/>C. Amazon FSx for Windows<br/>D. Amazon S3<br/>E. AWS Storage Gateway file gateway<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample723' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation723' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_782'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_749'>Random</a></p><div class='collapse' id='collapseExample723'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Amazon FSx for Windows
<br><b>E. </b>AWS Storage Gateway file gateway</div></div></div><div class='collapse' id='explanation723'><div class='card card&#45;body'><div>

Keyword: SMB + On-premises

Condition: File accessible from both on-premises and AWS

Amazon FSx for Windows File Server

Amazon FSx for Windows File Server provides fully managed, highly reliable, and scalable file storage that is accessible over the industry-standard Server Message Block (SMB) protocol. It is built on Windows Server, delivering a wide range of administrative features such as user quotas, end-user file restore, and Microsoft Active Directory (AD) integration. It offers single-AZ and multi-AZ deployment options, fully managed backups, and encryption of data at rest and in transit. You can optimize cost and performance for your workload needs with SSD and HDD storage options; and you can scale storage and change the throughput performance of your file system at any time. Amazon FSx file storage is accessible from Windows, Linux, and macOS compute instances and devices running on AWS or on-premises.

How FSx for Windows File Server works

AWS Storage Gateway

AWS Storage Gateway is a hybrid cloud storage service that gives you on-premises access to virtually unlimited cloud storage. Customers use Storage Gateway to simplify storage management and reduce costs for key hybrid cloud storage use cases. These include moving backups to the cloud, using on-premises file shares backed by cloud storage, and providing low latency access to data in AWS for on-premises applications.

To support these use cases, Storage Gateway offers three different types of gateways – File Gateway, Tape Gateway, and Volume Gateway – that seamlessly connect on-premises applications to cloud storage, caching data locally for low-latency access. Your applications connect to the service through a virtual machine or gateway hardware appliance using standard storage protocols, such as NFS, SMB, and iSCSI. The gateway connects to AWS storage services, such as Amazon S3, Amazon S3 Glacier, Amazon S3 Glacier Deep Archive, Amazon EBS, and AWS Backup, providing storage for files, volumes, snapshots, and virtual tapes in AWS. The service includes a highly-optimized and efficient data transfer mechanism, with bandwidth management and automated network resilience.

How Storage Gateway works

The table below shows the different gateways available and the interfaces and use cases:

CORRECT: "Amazon FSx for Windows" is the correct answer. CORRECT: "Amazon Storage File Gateway" is the correct answer.

INCORRECT: "Amazon EBS" is incorrect as unsupported NFS/SMB. INCORRECT: "Amazon EFS" is incorrect as unsupported NFS/SMB. INCORRECT: "Amazon S3" is incorrect as unsupported NFS/SMB.

References:

Amazon FSx for Windows File Server
AWS Storage Gateway
AWS News Blog > File Interface to AWS Storage Gateway

</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 98%;" aria-valuenow="98" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_782><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 782</p><br/>A company has thousands of files stored in an Amazon S3 bucket that has a well&#8211;defined access pattern. The files are accessed by an application multiple times a day for the first 30 days. Files are rarely accessed within the next 90 days. After that, the files are never accessed again. During the first 120 days, accessing these files should never take more than a few seconds.<br/><br/>Which lifecycle policy should be used for the S3 objects to minimize costs based on the access pattern?<br/><br/>A. Use Amazon S3 Standard&#8211;Infrequent Access (S3 Standard&#8211;IA) storage for the first 30 days. Then move the files to the GLACIER storage class for the next 90 days. Allow the data to expire after that.<br/>B. Use Amazon S3 Standard storage for the first 30 days. Then move the files to Amazon S3 Standard&#8211; Infrequent Access (S3 Standard&#8211;IA) for the next 90 days. Allow the data to expire after that.<br/>C. Use Amazon S3 Standard storage for first 30 days. Then move the files to the GLACIER storage class for the next 90 days. Allow the data to expire after that.<br/>D. Use Amazon S3 Standard&#8211;Infrequent Access (S3 Standard&#8211;IA) for the first 30 days. After that, move the data to the GLACIER storage class, where is will be deleted automatically.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample792' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation792' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_783'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_79'>Random</a></p><div class='collapse' id='collapseExample792'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Use Amazon S3 Standard storage for the first 30 days. Then move the files to Amazon S3 Standard- Infrequent Access (S3 Standard-IA) for the next 90 days. Allow the data to expire after that.</div></div></div><div class='collapse' id='explanation792'><div class='card card&#45;body'><div>
It is mentioned that they need to access data in few seconds during the 120 days.
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 98%;" aria-valuenow="98" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_783><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 783</p><br/>A company is concerned that two NAT instances in use will no longer be able to support the traffic needed for the company's application. A solutions architect wants to implement a solution that is highly available fault tolerant, and automatically scalable.<br/><br/>What should the solutions architect recommend?<br/><br/>A. Remove the two NAT instances and replace them with two NAT gateways in the same Availability Zone.<br/>B. Use Auto Scaling groups with Network Load Balancers for the NAT instances in different Availability Zones.<br/>C. Remove the two NAT instances and replace them with two NAT gateways in different Availability Zones.<br/>D. Replace the two NAT instances with Spot Instances in different Availability Zones and deploy a Network Load Balancer.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample376' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_784'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_56'>Random</a></p><div class='collapse' id='collapseExample376'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Remove the two NAT instances and replace them with two NAT gateways in different Availability Zones.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 99%;" aria-valuenow="99" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_784><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 784</p><br/>A VPC contains multiple subnets, where each subnet can span multiple Availability Zones.<br/><br/>A. This is true only if requested during the set&#8211;up of VPC.<br/>B. This is true.<br/>C. This is false.<br/>D. This is true only for US regions.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample770' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation770' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_785'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_65'>Random</a></p><div class='collapse' id='collapseExample770'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>This is false.</div></div></div><div class='collapse' id='explanation770'><div class='card card&#45;body'><div>
A VPC can span several Availability Zones. In contrast, a subnet must reside within a single Availability Zone.

References:

Amazon VPC FAQs</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 99%;" aria-valuenow="99" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_785><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 785</p><br/>A company runs an application in the AWS Cloud and uses Amazon DynamoDB as the database. The company deploys Amazon EC2 instances to a private network to process data from the database.<br/><br/>The company uses two NAT instances to provide connectivity to DynamoDB. The company wants to retire the NAT instances.<br/><br/>A solutions architect must implement a solution that provides connectivity to DynamoDB and that does not require ongoing management.<br/><br/>What is the MOST cost&#8211;effective solution that meets these requirements?<br/><br/>A. Create a gateway VPC endpoint to provide connectivity to DynamoDB<br/>B. Configure a managed NAT gateway to provide connectivity to DynamoDB<br/>C. Establish an AWS Direct Connect connection between the private network and DynamoDB<br/>D. Deploy an AWS PrivateLink endpoint service between the private network and DynamoDB<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample660' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_786'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_747'>Random</a></p><div class='collapse' id='collapseExample660'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Create a gateway VPC endpoint to provide connectivity to DynamoDB</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 99%;" aria-valuenow="99" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_786><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 786</p><br/>A company has an on&#8211;premises application that collects data and stores it to an on&#8211;premises NFS server.<br/><br/>The company recently set up a 10 Gbps AWS Direct Connect connection. The company is running out of storage capacity on&#8211;premises. The company needs to migrate the application data from on&#8211;premises to the AWS Cloud while maintaining low&#8211;latency access to the data from the on&#8211;premises application.<br/><br/>What should a solutions architect do to meet these requirements?<br/><br/>A. Deploy AWS Storage Gateway for the application data, and use the file gateway to store the data in Amazon S3. Connect the on&#8211;premises application servers to the file gateway using NFS.<br/>B. Attach an Amazon Elastic File System (Amazon EFS) file system to the NFS server, and copy the application data to the EFS file system. Then connect the on&#8211;premises application to Amazon EFS.<br/>C. Configure AWS Storage Gateway as a volume gateway. Make the application data available to the on&#8211;premises application from the NFS server and with Amazon Elastic Block Store (Amazon EBS) snapshots.<br/>D. Create an AWS DataSync agent with the NFS server as the source location and an Amazon Elastic File System (Amazon EFS) file system as the destination for application data transfer. Connect the on&#8211;premises application to the EFS file system.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample383' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_787'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_284'>Random</a></p><div class='collapse' id='collapseExample383'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Deploy AWS Storage Gateway for the application data, and use the file gateway to store the data in Amazon S3. Connect the on-premises application servers to the file gateway using NFS.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 99%;" aria-valuenow="99" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_787><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 787</p><br/>A solutions architect is helping a developer design a new eCommerce shopping cart application using AWS services. The developer is unsure of the current database schema and expects to make changes as the eCommerce site grows. The solution needs to be highly resilient and capable of automatically scaling read and write capacity.<br/><br/>Which database solution meets these requirements?<br/><br/>A. Amazon Aurora PostgreSQL<br/>B. Amazon DynamoDB with on&#8211;demand enabled<br/>C. Amazon DynamoDB with DynamoDB Streams enabled<br/>D. Amazon SQS and Amazon Aurora PostgreSQL<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample96' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_788'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_20'>Random</a></p><div class='collapse' id='collapseExample96'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Amazon DynamoDB with on-demand enabled

References:

Anúncio do Amazon DynamoDB sob demanda</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 99%;" aria-valuenow="99" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_788><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 788</p><br/>A company is deploying an application in three AWS Regions using an Application Load Balancer Amazon Route 53 will be used to distribute traffic between these Regions.<br/><br/>Which Route 53 configuration should a solutions architect use to provide the MOST high&#8211;performing experience?<br/><br/>A. Create an A record with a latency policy.<br/>B. Create an A record with a geolocation policy.<br/>C. Create a CNAME record with a failover policy.<br/>D. Create a CNAME record with a geoproximity policy.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample411' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_789'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_408'>Random</a></p><div class='collapse' id='collapseExample411'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Create an A record with a latency policy.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 99%;" aria-valuenow="99" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_789><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 789</p><br/>A user is launching an EC2 instance in the US East region. Which of the below mentioned options is recommended by AWS with respect to the selection of the availability zone?<br/><br/>A. Always select the AZ while launching an instance<br/>B. Always select the US&#8211;East&#8211;1&#8211;a zone for HA<br/>C. Do not select the AZ; instead let AWS select the AZ<br/>D. The user can never select the availability zone while launching an instance<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample776' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation776' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#All_790'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_508'>Random</a></p><div class='collapse' id='collapseExample776'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Do not select the AZ; instead let AWS select the AZ</div></div></div><div class='collapse' id='explanation776'><div class='card card&#45;body'><div>
When launching an instance with EC2, AWS recommends not to select the availability zone (AZ). AWS specifies that the default Availability Zone should be accepted. This is because it enables AWS to select the best Availability Zone based on the system health and available capacity. If the user launches additional instances, only then an Availability Zone should be specified. This is to specify the same or different AZ from the running instances.

References:

Amazon Elastic Compute Cloud > User Guide for Linux Instances > What is Amazon EC2?</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 99%;" aria-valuenow="99" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=All_790><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>All Question 790</p><br/>A company provides an API to its users that automates inquiries for tax computations based on item prices.<br/><br/>The company experiences a larger number of inquiries during the holiday season only that cause slower response times. A solutions architect needs to design a solution that is scalable and elastic.<br/><br/>What should the solutions architect do to accomplish this?<br/><br/>A. Provide an API hosted on an Amazon EC2 instance. The EC2 instance performs the required computations when the API request is made.<br/>B. Design a REST API using Amazon API Gateway that accepts the item names. API Gateway passes item names to AWS Lambda for tax computations.<br/>C. Create an Application Load Balancer that has two Amazon EC2 instances behind it. The EC2 instances will compute the tax on the received item names.<br/>D. Design a REST API using Amazon API Gateway that connects with an API hosted on an Amazon EC2 instance. API Gateway accepts and passes the item names to the EC2 instance for tax computations.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample226' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#All_791'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#All_91'>Random</a></p><div class='collapse' id='collapseExample226'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Design a REST API using Amazon API Gateway that accepts the item names. API Gateway passes item names to AWS Lambda for tax computations.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 100%;" aria-valuenow="100" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#All'>All</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><a id=S3><h2>S3</h2></a> - 155 Questions <br><a href='#S3'>S3(155)</a> <a href='#' <i class='bi bi&#45;house'> &nbsp;Home</i><hr> </a><div class='row' id=S3_1><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 1</p><br/>A company runs a photo processing application that needs to frequently upload and download pictures from Amazon S3 buckets that are located in the same AWS Region.<br/><br/>A solutions architect has noticed an increased cost in data transfer fees and needs to implement a solution to reduce these costs.<br/><br/>How can the solutions architect meet this requirement?<br/><br/>A. Deploy Amazon API Gateway into a public subnet and adjust the route table to route S3 calls through It.<br/>B. Deploy a NAT gateway into a public subnet and attach an end point policy that allows access to the S3 buckets.<br/>C. Deploy the application Into a public subnet and allow it to route through an internet gateway to access the S3 Buckets<br/>D. Deploy an S3 VPC gateway endpoint into the VPC and attach an endpoint policy that allows access to the S3 buckets.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample575' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_2'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_39'>Random</a></p><div class='collapse' id='collapseExample575'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Deploy a NAT gateway into a public subnet and attach an end point policy that allows access to the S3 buckets.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 0%;" aria-valuenow="0" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_2><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 2</p><br/>A company is building a payment application that must be highly available even during regional service disruptions. A solutions architect must design a data storage solution that can be easily replicated and used in other AWS Regions. The application also requires low&#8211;latency atomicity, consistency, isolation, and durability (ACID) transactions that need to be immediately available to generate reports The development team also needs to use SQL.<br/><br/>Which data storage solution meets these requirements?<br/><br/>A. Amazon Aurora Global Database<br/>B. Amazon DynamoDB global tables<br/>C. Amazon S3 with cross&#8211;Region replication and Amazon Athena<br/>D. MySQL on Amazon EC2 instances with Amazon Elastic Block Store (Amazon EBS) snapshot replication<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample338' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_3'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_94'>Random</a></p><div class='collapse' id='collapseExample338'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Amazon S3 with cross-Region replication and Amazon Athena</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 1%;" aria-valuenow="1" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_3><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 3</p><br/>A company is processing data on a daily basis. The results of the operations are stored in an Amazon S3 bucket, analyzed daily for one week, and then must remain immediately accessible for occasional analysis.<br/><br/>What is the MOST cost&#8211;effective storage solution alternative to the current configuration?<br/><br/>A. Configure a lifecycle policy to delete the objects after 30 days.<br/>B. Configure a lifecycle policy to transition the objects to Amazon S3 Glacier after 30 days.<br/>C. Configure a lifecycle policy to transition the objects to Amazon S3 Standard&#8211;Infrequent Access (S3 Standard&#8211;IA) after 30 days.<br/>D. Configure a lifecycle policy to transition the objects to Amazon S3 One Zone&#8211;Infrequent Access (S3 One Zone&#8211;IA) after 30 days.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample266' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_4'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_36'>Random</a></p><div class='collapse' id='collapseExample266'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Configure a lifecycle policy to transition the objects to Amazon S3 One Zone-Infrequent Access (S3 One Zone-IA) after 30 days.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 1%;" aria-valuenow="1" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_4><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 4</p><br/>A company needs to store data for 6 years. The company will need to have immediate and highly available access to the data at any point in time, but will not require frequent access.<br/><br/>What lifecycle action should be taken to meet these requirements while reducing costs?<br/><br/>A. Transition objects from Amazon S3 Standard to Amazon S3 Standard Infrequent Access (S3 Standard IA)<br/>B. Transition objects to expire after 5 years<br/>C. Transition objects from Amazon S3 Standard to Amazon S3 One Zone&#8211;Infrequent Access (S3 One Zone IA)<br/>D. Transition objects from Amazon S3 Standard to the Amazon S3 Glacier<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample663' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_5'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_113'>Random</a></p><div class='collapse' id='collapseExample663'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Transition objects from Amazon S3 Standard to Amazon S3 Standard Infrequent Access (S3 Standard IA)</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 2%;" aria-valuenow="2" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_5><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 5</p><br/>A Solutions Architect must design a web application that will be hosted on AWS, allowing users to purchase access to premium, shared content that is stored in an S3 bucket. Upon payment, content will be available for download for 14 days before the user is denied access.<br/><br/>Which of the following would be the LEAST complicated implementation?<br/><br/>A. Use an Amazon CloudFront distribution with an origin access identity (OAI). Configure the distribution with an Amazon S3 origin to provide access to the file through signed URLs. Design a Lambda function to remove data that is older than 14 days.<br/>B. Use an S3 bucket and provide direct access to the file. Design the application to track purchases in a DynamoDB table. Configure a Lambda function to remove data that is older than 14 days based on a query to Amazon DynamoDB.<br/>C. Use an Amazon CloudFront distribution with an OAI. Configure the distribution with an Amazon S3 origin to provide access to the file through signed URLs. Design the application to set an expiration of 14 days for the URL.<br/>D. Use an Amazon CloudFront distribution with an OAI. Configure the distribution with an Amazon S3 origin to provide access to the file through signed URLs. Design the application to set an expiration of 60 minutes for the URL and recreate the URL as necessary.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample160' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_6'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_20'>Random</a></p><div class='collapse' id='collapseExample160'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Use an Amazon CloudFront distribution with an OAI. Configure the distribution with an Amazon S3 origin to provide access to the file through signed URLs. Design the application to set an expiration of 14 days for the URL.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 3%;" aria-valuenow="3" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_6><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 6</p><br/>A company mandates that an Amazon S3 gateway endpoint must allow traffic to trusted buckets only.<br/><br/>Which method should a solutions architect implement to meet this requirement?<br/><br/>A. Create a bucket policy for each of the company's trusted S3 buckets that allows traffic only from the company's trusted VPCs.<br/>B. Create a bucket policy for each of the company's trusted S3 buckets that allows traffic only from the company's S3 gateway endpoint IDs.<br/>C. Create an S3 endpoint policy for each of the company's S3 gateway endpoints that blocks access from any VPC other than the company's trusted VPCs.<br/>D. Create an S3 endpoint policy for each of the company's S3 gateway endpoints that provides access to the Amazon Resource Name (ARN) of the trusted S3 buckets.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample205' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_7'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_12'>Random</a></p><div class='collapse' id='collapseExample205'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Create an S3 endpoint policy for each of the company's S3 gateway endpoints that provides access to the Amazon Resource Name (ARN) of the trusted S3 buckets.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 3%;" aria-valuenow="3" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_7><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 7</p><br/>One of the criteria for a new deployment is that the customer wants to use AWS Storage Gateway. However you are not sure whether you should use gateway&#8211;cached volumes or gateway&#8211;stored volumes or even what the differences are.<br/><br/>Which statement below best describes those differences?<br/><br/>A. Gateway&#8211;cached lets you store your data in Amazon Simple Storage Service (Amazon S3) and retain a copy of frequently accessed data subsets locally. Gateway&#8211;stored enables you to configure your on&#8211;premises gateway to store all your data locally and then asynchronously back up point&#8211;in&#8211;time snapshots of this data to Amazon S3.<br/>B. Gateway&#8211;cached is free whilst gateway&#8211;stored is not.<br/>C. Gateway&#8211;cached is up to 10 times faster than gateway&#8211;stored.<br/>D. Gateway&#8211;stored lets you store your data in Amazon Simple Storage Service (Amazon S3) and retain a copy of frequently accessed data subsets locally. Gateway&#8211;cached enables you to configure your on&#8211;premises gateway to store all your data locally and then asynchronously back up point&#8211;in&#8211;time snapshots of this data to Amazon S3.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample777' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation777' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_8'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_81'>Random</a></p><div class='collapse' id='collapseExample777'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Gateway-cached lets you store your data in Amazon Simple Storage Service (Amazon S3) and retain a copy of frequently accessed data subsets locally. Gateway-stored enables you to configure your on-premises gateway to store all your data locally and then asynchronously back up point-in-time snapshots of this data to Amazon S3.</div></div></div><div class='collapse' id='explanation777'><div class='card card&#45;body'><div>
Volume gateways provide cloud-backed storage volumes that you can mount as Internet Small Computer System Interface (iSCSI) devices from your on-premises application servers. The gateway supports the following volume configurations:

Gateway-cached volumes? You store your data in Amazon Simple Storage Service (Amazon S3) and retain a copy of frequently accessed data subsets locally. Gateway-cached volumes offer a substantial cost savings on primary storage and minimize the need to scale your storage on-premises. You also retain low-latency access to your frequently accessed data. Gateway-stored volumes? If you need low-latency access to your entire data set, you can configure your on-premises gateway to store all your data locally and then asynchronously back up point-in-time snapshots of this data to Amazon S3. This configuration provides durable and inexpensive off-site backups that you can recover to your local data center or Amazon EC2. For example, if you need replacement capacity for disaster recovery, you can recover the backups to Amazon EC2.

References:

AWS Storage Gateway > User Guide > What is AWS Storage Gateway?</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 4%;" aria-valuenow="4" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_8><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 8</p><br/>A company uses an Amazon S3 bucket as its data lake storage platform.<br/><br/>The S3 bucket contains a massive amount of data that is accessed randomly by multiple teams and hundreds of applications.<br/><br/>The company wants to reduce the S3 storage costs and provide immediate availability for frequently accessed objects.<br/><br/>What is the MOST operationally efficient solution that meets these requirements?<br/><br/>A. Create an S3 Lifecycle rule to transition objects to the S3 Intelligent&#8211;Tiering storage class<br/>B. Store objects in Amazon S3 Glacier. Use S3 Select to provide applications with access to the data<br/>C. Use data from S3 storage class analysis to create S3 Lifecycle rules to automatically transition objects to the S3 Standard&#8211;Infrequent Access {S3 Standard&#8211;IA) storage class<br/>D. Transition objects to the S3 Standard&#8211;Infrequent Access (S3 Standard&#8211;IA) storage class. Create an AWS Lambda function to transition objects to the S3 Standard storage class when they are accessed by an application<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample623' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_9'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_125'>Random</a></p><div class='collapse' id='collapseExample623'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Create an S3 Lifecycle rule to transition objects to the S3 Intelligent-Tiering storage class</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 5%;" aria-valuenow="5" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_9><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 9</p><br/>A company uses an Amazon S3 bucket to store static images for its website. The company configured permissions to allow access to Amazon S3 objects by privileged users only.<br/><br/>What should a solutions architect do to protect against data loss? (Choose two.)<br/><br/>A. Enable versioning on the S3 bucket.<br/>B. Enable access logging on the S3 bucket.<br/>C. Enable server&#8211;side encryption on the S3 bucket.<br/>D. Configure an S3 lifecycle rule to transition objects to Amazon S3 Glacier.<br/>E. Use MFA Delete to require multi&#8211;factor authentication to delete an object.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample108' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_10'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_47'>Random</a></p><div class='collapse' id='collapseExample108'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Enable versioning on the S3 bucket.
<br><b>E. </b>Use MFA Delete to require multi-factor authentication to delete an object.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 5%;" aria-valuenow="5" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_10><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 10</p><br/>A company uses Amazon S3 to store its confidential audit documents. The S3 bucket uses bucket policies to restrict access to audit team IAM user credentials according to the principle of least privilege. Company managers are worried about accidental deletion of documents in the S3 bucket and want a more secure solution.<br/><br/>What should a solutions architect do to secure the audit documents?<br/><br/>A. Enable the versioning and MFA Delete features on the S3 bucket<br/>B. Enable multi&#8211;factor authentication (MFA) on the IAM user credentials for each audit team IAM user account.<br/>C. Add an S3 Lifecycle policy to the audit team's IAM user accounts to deny the s3:DeleteObject action during audit dates.<br/>D. Use AWS Key Management Service (AWS KMS> to encrypt the S3 bucket and restrict audit team IAM user accounts from accessing the KMS key.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample503' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_11'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_134'>Random</a></p><div class='collapse' id='collapseExample503'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Enable the versioning and MFA Delete features on the S3 bucket</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 6%;" aria-valuenow="6" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_11><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 11</p><br/>A development team needs to host a website that will be accessed by other teams. The website contents consist of HTML, CSS, client&#8211;side JavaScript, and images.<br/><br/>Which method is the MOST cost&#8211;effective for hosting the website?<br/><br/>A. Containerize the website and host it in AWS Fargate.<br/>B. Create an Amazon S3 bucket and host the website there.<br/>C. Deploy a web server on an Amazon EC2 instance to host the website.<br/>D. Configure an Application Load Balancer with an AWS Lambda target that uses the Express is framework.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample270' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_12'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_79'>Random</a></p><div class='collapse' id='collapseExample270'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Create an Amazon S3 bucket and host the website there.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 7%;" aria-valuenow="7" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_12><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 12</p><br/>A company has an application that scans millions of connected devices for security threats and pushes the scan logs to an Amazon S3 bucket.<br/><br/>A total of 70 GB of data is generated each week, and the company needs to store 3 years of data for historical reporting.<br/><br/>The company must process, aggregate, and enrich the data from Amazon S3 by performing complex analytical queries and joins in the least amount of time.<br/><br/>The aggregated dataset is visualized on an Amazon QuickSight dashboard. What should a solutions architect recommend to meet these requirements?<br/><br/>A. Create and run an ETL job in AWS Glue to process the data from Amazon S3 and load it into Amazon Redshift. Perform the aggregation queries on Amazon Redshift.<br/>B. Use AWS Lambda functions based on S3 PutObject event triggers to copy the incremental changes to Amazon DynamoDB. Perform the aggregation queries on DynamoDB.<br/>C. Use AWS Lambda functions based on S3 PutObject event triggers to copy the incremental changes to Amazon Aurora MySQL. Perform the aggregation queries on Aurora MySQL<br/>D. Use AWS Glue to catalog the data in Amazon S3. Perform the aggregation queries on the cataloged tables by using Amazon Athena.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample524' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_13'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_74'>Random</a></p><div class='collapse' id='collapseExample524'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Create and run an ETL job in AWS Glue to process the data from Amazon S3 and load it into Amazon Redshift. Perform the aggregation queries on Amazon Redshift.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 7%;" aria-valuenow="7" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_13><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 13</p><br/>A company runs a photo processing application mat needs to frequently upload and download pictures from Amazon S3 buckets that are located in the same AWS Region A solutions architect has noticed an increased cost in data transfer lees and needs to implement a solution to reduce these costs<br/><br/>How can the solutions architect meet this requirement?<br/><br/>A. Deploy Amazon API Gateway into a public subnet and adjust the route table to route S3 calls through it<br/>B. Deploy a NAT gateway into a public subnet and attach an endpoint policy that allows access to the S3 buckets<br/>C. Deploy the application into a public subnet and allow it to route through an internet gateway to access the S3 buckets<br/>D. Deploy an S3 VPC gateway endpoint into the VPC and attach an endpoint policy that allows access to the S3 buckets<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample478' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_14'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_57'>Random</a></p><div class='collapse' id='collapseExample478'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Deploy the application into a public subnet and allow it to route through an internet gateway to access the S3 buckets</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 8%;" aria-valuenow="8" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_14><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 14</p><br/>A company runs an application in a branch office within a small data closet with no virtualized compute resources. The application data is stored on an NFS volume. Compliance standards require a daily offsite backup of the NFS volume.<br/><br/>Which solution meet these requirements?<br/><br/>A. Install an AWS Storage Gateway file gateway on premises to replicate the data to Amazon S3.<br/>B. Install an AWS Storage Gateway file gateway hardware appliance on premises to replicate the data to Amazon S3.<br/>C. Install an AWS Storage Gateway volume gateway with stored volumes on premises to replicate the data to Amazon S3.<br/>D. Install an AWS Storage Gateway volume gateway with cached volumes on premises to replicate the data to Amazon S3.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample28' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation28' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_15'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_18'>Random</a></p><div class='collapse' id='collapseExample28'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Install an AWS Storage Gateway file gateway hardware appliance on premises to replicate the data to Amazon S3.</div></div></div><div class='collapse' id='explanation28'><div class='card card&#45;body'><div>
AWS Storage Gateway Hardware Appliance
Hardware Appliance: Storage Gateway is available as a hardware appliance, adding to the existing support for VMware ESXi, Microsoft Hyper-V, and Amazon EC2. This means that you can now make use of Storage Gateway in situations where you do not have a virtualized environment, server-class hardware or IT staff with the specialized skills that are needed to manage them. You can order appliances from Amazon.com for delivery to branch offices, warehouses, and "outpost" offices that lack dedicated IT resources. Setup (as you will see in a minute) is quick and easy, and gives you access to three storage solutions:

File Gateway: A file interface to Amazon S3, accessible via NFS or SMB. The files are stored as S3 objects, allowing you to make use of specialized S3 features such as lifecycle management and cross region replication. You can trigger AWS Lambda functions, run Amazon Athena queries, and use Amazon Macie to discover and classify sensitive data.

Keyword: NFS + Compliance

File gateway provides a virtual on-premises file server, which enables you to store and retrieve files as objects in Amazon S3. It can be used for on-premises applications, and for Amazon EC2- resident applications that need file storage in S3 for object based workloads. Used for flat files only, stored directly on S3. File gateway offers SMB or NFS-based access to data in Amazon S3 with local caching.

WS Storage Gateway – File Gateway

The table below shows the different gateways available and the interfaces and use cases:

Storage Gateway Overview

CORRECT: "Install an AWS Storage Gateway file gateway hardware appliance on premises to replicate the data to Amazon S3" is the correct answer.

INCORRECT: "Install an AWS Storage Gateway file gateway on premises to replicate the data to Amazon S3" is incorrect.

INCORRECT: "Install an AWS Storage Gateway volume gateway with stored volumes on premises to replicate the data to Amazon S3" is incorrect as unsupported NFS. INCORRECT: "Install an AWS Storage Gateway volume gateway with cached volumes on premises to replicate the data to Amazon S3" is incorrect as unsupported NFS.

References:

AWS News Blog > File Interface to AWS Storage Gateway</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 9%;" aria-valuenow="9" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_15><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 15</p><br/>A company wants to host a scalable web application on AWS. The application will be accessed by users from different geographic regions of the world. Application users will be able to download and upload unique data up to gigabytes in size. The development team wants a cost&#8211;effective solution to minimize upload and download latency and maximize performance.<br/><br/>What should a solutions architect do to accomplish this?<br/><br/>A. Use Amazon S3 with Transfer Acceleration to host the application.<br/>B. Use Amazon S3 with CacheControl headers to host the application.<br/>C. Use Amazon EC2 with Auto Scaling and Amazon CloudFront to host the application.<br/>D. Use Amazon EC2 with Auto Scaling and Amazon ElastiCache to host the application.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample259' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation259' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_16'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_16'>Random</a></p><div class='collapse' id='collapseExample259'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Use Amazon S3 with Transfer Acceleration to host the application.</div></div></div><div class='collapse' id='explanation259'><div class='card card&#45;body'><div>
The maximum size of a single file that can be delivered through Amazon CloudFront is 20 GB. This limit applies to all Amazon CloudFront distributions.
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 9%;" aria-valuenow="9" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_16><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 16</p><br/>A company plans to deploy a new application in AWS that reads and writes information to a database.<br/><br/>The company wants to deploy the application in two different AWS Regions with each application writing to a database in their Region.<br/><br/>The databases in the Two Regions needs to keep We data synchronized What should be used to meet these requirements?<br/><br/>A. Use Amazon Athena with Amazon S3 Cross&#8211;Region Replication<br/>B. Use AWS Database Migration Service (AWS DMS] with change data capture between an RDS for MySQL cluster in each Region<br/>C. Use Amazon DynamoDB with global tables<br/>D. Use Amazon RDS for PostgreSQL cluster with a Cross&#8211;Region Read Replica<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample591' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_17'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_66'>Random</a></p><div class='collapse' id='collapseExample591'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Use Amazon Athena with Amazon S3 Cross-Region Replication</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 10%;" aria-valuenow="10" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_17><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 17</p><br/>A company requires that all versions of objects in its Amazon S3 bucket be retained. Current object versions will be frequently accessed during the first 30 days, after which they will be rarely accessed and must be retrievable within 5 minutes. Previous object versions need to be kept forever, will be rarely accessed, and can be retrieved within 1 week. All storage solutions must be highly available and highly durable.<br/><br/>What should a solutions architect recommend to meet these requirements in the MOST cost&#8211;effective manner?<br/><br/>A. Create an S3 lifecycle policy for the bucket that moves current object versions from S3 Standard storage to S3 Glacier after 30 days and moves previous object versions to S3 Glacier after 1 day.<br/>B. Create an S3 lifecycle policy for the bucket that moves current object versions from S3 Standard storage to S3 Glacier after 30 days and moves previous object versions to S3 Glacier Deep Archive after 1 day.<br/>C. Create an S3 lifecycle policy for the bucket that moves current object versions from S3 Standard storage to S3 Standard&#8211;infrequent Access (S3 Standard&#8211;IA) after 30 days and moves previous object versions toS3 Glacier Deep Archive after 1 day.<br/>D. Create an S3 lifecycle policy for the bucket that moves current object versions from S3 Standard storage to S3 One Zone&#8211;Infrequent Access (S3 One Zone&#8211;IA) after 30 days and moves previous object versions to S3 Glacier Deep Archive after 1 day.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample396' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_18'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_110'>Random</a></p><div class='collapse' id='collapseExample396'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Create an S3 lifecycle policy for the bucket that moves current object versions from S3 Standard storage to S3 Glacier after 30 days and moves previous object versions to S3 Glacier after 1 day.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 10%;" aria-valuenow="10" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_18><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 18</p><br/>A development team needs to host a website that will be accessed by other teams. The website contents consist of HTML. CSS, client&#8211;side JavaScript, and images.<br/><br/>Which method is the MOST cost&#8211;effective for hosting the website?<br/><br/>A. Containerize the website and host it in AWS Fargate.<br/>B. Create an Amazon S3 bucket and host the website there<br/>C. Deploy a web server on an Amazon EC2 instance to host the website.<br/>D. Configure an Application Load Balancer with an AWS Lambda target that uses the Express js framework.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample444' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_19'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_27'>Random</a></p><div class='collapse' id='collapseExample444'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Create an Amazon S3 bucket and host the website there</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 11%;" aria-valuenow="11" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_19><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 19</p><br/>A media company stores video content in an Amazon Elastic Block Store (Amazon EBS) volume. A certain video files has become popular and a large number of user across the world are accessing this content.<br/><br/>This has resulted in a cost increase.<br/><br/>Which action will DECREASE cost without compromising user accessibility?<br/><br/>A. Change the EBS volume to provisioned IOPS (PIOPS)<br/>B. Store the video in an Amazon S3 bucket and create an Amazon CloudFront distribution<br/>C. Split the video into multiple, smaller segments so users are routed to the requested video segments only<br/>D. Create an Amazon S3 bucket in each Region and upload the videos so users are routed to the nearest S3 bucket<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample712' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_20'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_61'>Random</a></p><div class='collapse' id='collapseExample712'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Store the video in an Amazon S3 bucket and create and Amazon CloudFront distribution</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 12%;" aria-valuenow="12" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_20><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 20</p><br/>A solutions architect is designing a publicly accessible web application that is on an Amazon CloudFront distribution with an Amazon S3 website endpoint as the origin.<br/><br/>When the solution is deployed, the website returns an Error 403: Access Denied message.<br/><br/>Which steps should the solutions architect take to correct the issue? (Select TWO.)<br/><br/>A. Remove the S3 block public access option from the S3 bucket.<br/>B. Remove the requester pays option from the S3 bucket.<br/>C. Remove the origin access identity (OAI) from the CloudFront distribution.<br/>D. Change the storage class from S3 Standard to S3 One Zone&#8211;Infrequent Access (S3 One Zone&#8211; IA).<br/>E. Disable S3 object versioning<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample685' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_21'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_77'>Random</a></p><div class='collapse' id='collapseExample685'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Remove the S3 block public access option from the S3 bucket.
<br><b>B. </b>Remove the requester pays option from the S3 bucket.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 12%;" aria-valuenow="12" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_21><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 21</p><br/>A company expects its user base to increase five times over one year. Its application is hosted in one region and uses an Amazon RDS for MySQL database, and Application Load Balance Amazon Elastic Container Service (Amazon ECS) to host the website and its microservices.<br/><br/>Which design changes should a solutions architect recommend to support the expected growth? (Select TWO.)<br/><br/>A. Move static files from Amazon ECS to Amazon S3<br/>B. Use an Amazon Route 53 geolocation routing policy.<br/>C. Scale the environment based on real&#8211;time AWS CloudTrail logs.<br/>D. Create a dedicated Elastic Load Balancer for each microservice.<br/>E. Create RDS lead replicas and change the application to use these replicas.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample539' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_22'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_104'>Random</a></p><div class='collapse' id='collapseExample539'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Move static files from Amazon ECS to Amazon S3
<br><b>E. </b>Create RDS lead replicas and change the application to use these replicas.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 13%;" aria-valuenow="13" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_22><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 22</p><br/>You are migrating an internal server on your DC to an EC2 instance with EBS volume. Your server disk usage is around 500GB so you just copied all your data to a 2TB disk to be used with AWS Import/Export.<br/><br/>Where will the data be imported once it arrives at Amazon?<br/><br/>A. to a 2TB EBS volume<br/>B. to an S3 bucket with 2 objects of 1TB<br/>C. to an 500GB EBS volume<br/>D. to an S3 bucket as a 2TB snapshot<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample772' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation772' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_23'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_131'>Random</a></p><div class='collapse' id='collapseExample772'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>to an S3 bucket with 2 objects of 1TB</div></div></div><div class='collapse' id='explanation772'><div class='card card&#45;body'><div>
An import to Amazon EBS will have different results depending on whether the capacity of your storage device is less than or equal to 1 TB or greater than 1 TB. The maximum size of an Amazon EBS snapshot is 1 TB, so if the device image is larger than 1 TB, the image is chunked and stored on Amazon S3. The target location is determined based on the total capacity of the device, not the amount of data on the device.

References:

AWS Snowball</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 14%;" aria-valuenow="14" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_23><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 23</p><br/>A company has several Amazon EC2 instances set up in a private subnet for security reasons. These instances host applications that read and write large amounts of data to and from Amazon S3 regularly.<br/><br/>Currently, subnet routing directs all the traffic destined for the internet through a NAT gateway. The company wants to optimize the overall cost without impacting the ability of the application to communicate with Amazon S3 or the outside internet.<br/><br/>What should a solutions architect do to optimize costs?<br/><br/>A. Create an additional NAT gateway. Update the route table to route to the NAT gateway. Update the network ACL to allow S3 traffic.<br/>B. Create an internet gateway. Update the route table to route traffic to the internet gateway. Update the network ACL to allow S3 traffic.<br/>C. Create a VPC endpoint for Amazon S3. Attach an endpoint policy to the endpoint. Update the route table to direct traffic to the VPC endpoint.<br/>D. Create an AWS Lambda function outside of the VPC to handle S3 requests. Attach an IAM policy to the EC2 instances, allowing them to invoke the Lambda function.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample357' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_24'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_132'>Random</a></p><div class='collapse' id='collapseExample357'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Create a VPC endpoint for Amazon S3. Attach an endpoint policy to the endpoint. Update the route table to direct traffic to the VPC endpoint.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 14%;" aria-valuenow="14" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_24><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 24</p><br/>A user is designing a new service that receives location updates from 3 600 rental cars every hour.<br/><br/>The cars upload their location to an Amazon S3 bucket.<br/><br/>Each location must be checked for distance from the original rental location.<br/><br/>Which services will process the updates and automatically scale?<br/><br/>A. Amazon EC2 and Amazon Elastic Block Store (Amazon EBS)<br/>B. Amazon Kinesis Data Firehose and Amazon S3<br/>C. Amazon Elastic Container Service (Amazon ECS) and Amazon RDS<br/>D. Amazon S3 events and AWS Lambda<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample631' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_25'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_7'>Random</a></p><div class='collapse' id='collapseExample631'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Amazon Kinesis Data Firehose and Amazon S3</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 15%;" aria-valuenow="15" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_25><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 25</p><br/>A company manages a data lake in an Amazon S3 bucket that numerous application share. The S3 bucket contain unique folders with a prefix for each application.<br/><br/>The company wants to restrict each application to its specific folder and have more granular control of the objects in each folder.<br/><br/>Which solution met these requirements with the LEAST amount of effort?<br/><br/>A. Create dedicated S3 access points and access point policies for each application.<br/>B. Create anS3 Batch Operations job to set the ACL permissions for each object in the S3 bucket.<br/>C. Update theS3 S3 bucket policy to grant access to each application based on its specific folder in the S3 bucket.<br/>D. Replicate the objects in the S3 bucket to new S3 buckets for each application. Create replication rules by prefix.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample599' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_26'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_118'>Random</a></p><div class='collapse' id='collapseExample599'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Create anS3 Batch Operations job to set the ACL permissions for each object in the S3 bucket.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 16%;" aria-valuenow="16" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_26><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 26</p><br/>A solutions architect is designing a solution that requires frequent updates to a website that is hosted on Amazon S3 with versioning enabled. For compliance reasons, the older versions of the objects will not be accessed frequently and will need to be deleted after 2 years.<br/><br/>What should the solutions architect recommend to meet these requirements at the LOWEST cost?<br/><br/>A. Use S3 batch operations to replace object tags. Expire the objects based on the modified tags.<br/>B. Configure an S3 Lifecycle policy to transition older versions of objects to S3 Glacier. Expire the objects after 2 years.<br/>C. Enable S3 Event Notifications on the bucket that sends older objects to the Amazon Simple Queue Service (Amazon SQS) queue for further processing.<br/>D. Replicate older object versions to a new bucket. Use an S3 Lifecycle policy to expire the objects in the new bucket after 2 years.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample369' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_27'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_51'>Random</a></p><div class='collapse' id='collapseExample369'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Configure an S3 Lifecycle policy to transition older versions of objects to S3 Glacier. Expire the objects after 2 years.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 16%;" aria-valuenow="16" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_27><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 27</p><br/>A company has an on&#8211;premises application that collects data and stores it to an on&#8211;premises NFS server.<br/><br/>The company recently set up a 10 Gbps AWS Direct Connect connection. The company is running out of storage capacity on&#8211;premises. The company needs to migrate the application data from on&#8211;premises to the AWS Cloud while maintaining low&#8211;latency access to the data from the on&#8211;premises application.<br/><br/>What should a solutions architect do to meet these requirements?<br/><br/>A. Deploy AWS Storage Gateway for the application data, and use the file gateway to store the data in Amazon S3. Connect the on&#8211;premises application servers to the file gateway using NFS.<br/>B. Attach an Amazon Elastic File System (Amazon EFS) file system to the NFS server, and copy the application data to the EFS file system. Then connect the on&#8211;premises application to Amazon EFS.<br/>C. Configure AWS Storage Gateway as a volume gateway. Make the application data available to the on&#8211;premises application from the NFS server and with Amazon Elastic Block Store (Amazon EBS) snapshots.<br/>D. Create an AWS DataSync agent with the NFS server as the source location and an Amazon Elastic File System (Amazon EFS) file system as the destination for application data transfer. Connect the on&#8211;premises application to the EFS file system.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample383' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_28'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_80'>Random</a></p><div class='collapse' id='collapseExample383'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Deploy AWS Storage Gateway for the application data, and use the file gateway to store the data in Amazon S3. Connect the on-premises application servers to the file gateway using NFS.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 17%;" aria-valuenow="17" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_28><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 28</p><br/>A company's security team requests that network traffic be captured in VPC Flow Logs. The logs will be frequently accessed for 90 days and then accessed intermittently.<br/><br/>What should a solutions architect do to meet these requirements when configuring the logs?<br/><br/>A. Use Amazon CloudWatch as the target. Set the CloudWatch log group with an expiration of 90 days.<br/>B. Use Amazon Kinesis as the target. Configure the Kinesis stream to always retain the logs for 90 days.<br/>C. Use AWS CloudTrail as the target. Configure CloudTrail to save to an Amazon S3 bucket, and enable S3 Intelligent&#8211;Tiering.<br/>D. Use Amazon S3 as the target. Enable an S3 Lifecycle policy to transition the logs to S3 StandardInfrequent Access (S3 Standard&#8211;IA) after 90 days.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample416' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_29'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_69'>Random</a></p><div class='collapse' id='collapseExample416'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Use Amazon S3 as the target. Enable an S3 Lifecycle policy to transition the logs to S3 StandardInfrequent Access (S3 Standard-IA) after 90 days.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 18%;" aria-valuenow="18" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_29><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 29</p><br/>A company is building a web application that servers a content management system.<br/><br/>The content management system runs on Amazon EC2 instances behind an Application Load Balancer (ALB).<br/><br/>The EC2 instances run in an Auto Scaling group across Availability Zones.<br/><br/>Users are constantly adding and updating files, blogs, and other website assets in the content management system.<br/><br/>Which solution meets these requirements?<br/><br/>A. Update the EC2 user data in the Auto Scaling group lifecycle policy to copy the website assets from the EC2 instance that was launched most recently. Configure the ALB to make changes to the websites assets only in the newest EC2 instance.<br/>B. Copy the website assets to an Amazon Elastic File System (Amazon EFS) Me system. Configure each EC2 instance to mount the EFS m system locally. Configure the website hosting application to reference the website assets that are stored in the EFS file system.<br/>C. Copy the website assets to an Amazon S3 bucket. Ensure that each EC2 instance downloads the website assets from the S3 bucket to the attached Amazon Basic Block Store (Amazon EBS) volume. Run the S3 sync command once each hour to keep files up to date.<br/>D. Restore an Amazon Elastic Block Store (Amazon EBS) snapshot w.th the website assets. Attach the EBS snapshot as a secondary EBS volume when a new EBS EC2 instance is launched. Configure the website hosting application to reference the website assets that are stored in the secondary EBS volume.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample602' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_30'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_63'>Random</a></p><div class='collapse' id='collapseExample602'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Copy the website assets to an Amazon S3 bucket. Ensure that each EC2 instance downloads the website assets from the S3 bucket to the attached Amazon Basic Block Store (Amazon EBS) volume. Run the S3 sync command once each hour to keep files up to date.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 18%;" aria-valuenow="18" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_30><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 30</p><br/>A company uses a legacy on&#8211;premises analytics application that operates on gigabytes of .csv files and represents months of data. The legacy application cannot handle the growing size of .csv files. New .csv files are added daily from various data sources to a central on&#8211;premises storage location. The company wants to continue to support the legacy application while users learn AWS analytics services. To achieve this, a solutions architect wants to maintain two synchronized copies of all the .csv files on&#8211;premises and in Amazon S3.<br/><br/>Which solution should the solutions architect recommend?<br/><br/>A. Deploy AWS DataSync on&#8211;premises. Configure DataSync to continuously replicate the .csv files between the company's on&#8211;premises storage and the company's S3 bucket.<br/>B. Deploy an on&#8211;premises file gateway. Configure data sources to write the .csv files to the file gateway. Point the legacy analytics application to the file gateway. The file gateway should replicate the .csv files to Amazon S3.<br/>C. Deploy an on&#8211;premises volume gateway. Configure data sources to write the .csv files to the volume gateway. Point the legacy analytics application to the volume gateway. The volume gateway should replicate data to Amazon S3.<br/>D. Deploy AWS DataSync on&#8211;premises. Configure DataSync to continuously replicate the .csv files between on&#8211;premises and Amazon Elastic File System (Amazon EFS). Enable replication from Amazon EFS to the company's S3 bucket.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample274' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_31'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_109'>Random</a></p><div class='collapse' id='collapseExample274'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Deploy an on-premises file gateway. Configure data sources to write the .csv files to the file gateway. Point the legacy analytics application to the file gateway. The file gateway should replicate the .csv files to Amazon S3.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 19%;" aria-valuenow="19" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_31><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 31</p><br/>A recently created startup built a three&#8211;tier web application. The front end has static content. The application layer is based on microservices. User data is stored as JSON documents that need to be accessed with low latency. The company expects regular traffic to be low during the first year, with peaks in traffic when it publicizes new features every month. The startup team needs to minimize operational overhead costs.<br/><br/>What should a solutions architect recommend to accomplish this?<br/><br/>A. Use Amazon S3 static website hosting to store and serve the front end. Use AWS Elastic Beanstalk for the application layer. Use Amazon DynamoDB to store user data.<br/>B. Use Amazon S3 static website hosting to store and serve the front end. Use Amazon Elastic KubernetesService (Amazon EKS) for the application layer. Use Amazon DynamoDB to store user data.<br/>C. Use Amazon S3 static website hosting to store and serve the front end. Use Amazon API Gateway and AWS Lambda functions for the application layer. Use Amazon DynamoDB to store user data.<br/>D. Use Amazon S3 static website hosting to store and serve the front end. Use Amazon API Gateway and AWS Lambda functions for the application layer. Use Amazon RDS with read replicas to store user data.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample337' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_32'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_146'>Random</a></p><div class='collapse' id='collapseExample337'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Use Amazon S3 static website hosting to store and serve the front end. Use Amazon API Gateway and AWS Lambda functions for the application layer. Use Amazon DynamoDB to store user data.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 20%;" aria-valuenow="20" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_32><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 32</p><br/>A company runs an application on a group of Amazon Linux EC2 instances. The application writes log files using standard API calls. For compliance reasons, all log files must be retained indefinitely and will be analyzed by a reporting tool that must access all files concurrently.<br/><br/>Which storage service should a solutions architect use to provide the MOST cost&#8211;effective solution?<br/><br/>A. Amazon EBS<br/>B. Amazon EFS<br/>C. Amazon EC2 instance store<br/>D. Amazon S3<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample37' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation37' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_33'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_141'>Random</a></p><div class='collapse' id='collapseExample37'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Amazon S3</div></div></div><div class='collapse' id='explanation37'><div class='card card&#45;body'><div>
Amazon S3: Requests to Amazon S3 can be authenticated or anonymous. Authenticated access requires credentials that AWS can use to authenticate your requests. When making REST API calls directly from your code, you create a signature using valid credentials and include the signature in your request. Amazon Simple Storage Service (Amazon S3) is an object storage service that offers industry-leading scalability, data availability, security, and performance. This means customers of all sizes and industries can use it to store and protect any amount of data for a range of use cases, such as websites, mobile applications, backup and restore, archive, enterprise applications, IoT devices, and big data analytics. Amazon S3 provides easy-to-use management features so you can organize your data and configure finely-tuned access controls to meet your specific business, organizational, and compliance requirements. Amazon S3 is designed for 99.999999999% (11 9's) of durability, and stores data for millions of applications for companies all around the world.

The application is writing the files using API calls which means it will be compatible with Amazon S3 which uses a REST API. S3 is a massively scalable key-based object store that is well-suited to allowing concurrent access to the files from many instances.

Amazon S3 will also be the most cost-effective choice. A rough calculation using the AWS pricing calculator shows the cost differences between 1TB of storage on EBS, EFS, and S3 Standard.

CORRECT: "Amazon S3" is the correct answer.

INCORRECT: "Amazon EFS" is incorrect as though this does offer concurrent access from many EC2 Linux instances, it is not the most cost-effective solution.

INCORRECT: "Amazon EBS" is incorrect. The Elastic Block Store (EBS) is not a good solution for concurrent access from many EC2 instances and is not the most cost-effective option either. EBS volumes are mounted to a single instance except when using multi-attach which is a new feature and has several constraints.

INCORRECT: "Amazon EC2 instance store" is incorrect as this is an ephemeral storage solution which means the data is lost when powered down.

Therefore, this is not an option for long-term data storage.

References:

Amazon Simple Storage Service > User Guide > Best practices design patterns: optimizing Amazon S3 performance</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 20%;" aria-valuenow="20" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_33><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 33</p><br/>Organizers for a global event want to put daily reports online as static HTML pages. The pages are expected to generate millions of views from users around the work. The files are stored in an Amazon S3 Bucket A solutions architect has been asked to design an efficient and effective solution<br/><br/>Which action should the solutions architect take to accomplish this?<br/><br/>A. Generate presigned URLs for the files<br/>B. Use cross&#8211;Region replication to all Regions<br/>C. Use the geoproximity feature of Amazon Route 53<br/>D. Use Amazon CloudFront with the S3 bucket as its origin<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample455' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_34'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_62'>Random</a></p><div class='collapse' id='collapseExample455'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Use Amazon CloudFront with the S3 bucket as its ongin</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 21%;" aria-valuenow="21" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_34><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 34</p><br/>A company is designing a new application that runs in a VPC on Amazon EC2 instances. The application stores data in Amazon S3 and uses Amazon DynamoDB as its database. For compliance reasons, the company prohibits all traffic between the EC2 instances and other AWS services from passing over the public internet.<br/><br/>What can a solutions architect do to meet this requirement?<br/><br/>A. Configure gateway VPC endpoints to Amazon S3 and DynamoDB.<br/>B. Configure interface VPC endpoints to Amazon S3 and DynamoDB.<br/>C. Configure a gateway VPC endpoint to Amazon S3. Configure an interface VPC endpoint to DynamoDB.<br/>D. Configure a gateway VPC endpoint to DynamoDB. Configure an interface VPC endpoint to Amazon S3.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample415' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_35'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_122'>Random</a></p><div class='collapse' id='collapseExample415'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Configure a gateway VPC endpoint to Amazon S3. Configure an interface VPC endpoint to DynamoDB.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 21%;" aria-valuenow="21" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_35><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 35</p><br/>A company is using Amazon S3 as its local repository for weekly analysis reports. One of the company&#8211;wide requirements is to secure data at rest using encryption. The company chooses Amazon 53 server&#8211;side encryption (SSE)<br/><br/>How can the object be decrypted when a GET request is issued?<br/><br/>A. the user needs a Put request to decrypt the object<br/>B. The user needs to decrypt the object using a private Key<br/>C. Amazon S3 manages encryption and decryption automatically<br/>D. Amazon S3 provides a server&#8211;side key for decrypting the object<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample588' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_36'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_99'>Random</a></p><div class='collapse' id='collapseExample588'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Amazon S3 provides a server-side key for decrypting the object</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 22%;" aria-valuenow="22" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_36><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 36</p><br/>A company is designing a website that uses an Amazon S3 bucket to store static images. The company wants all future requests to have faster response times while reducing both latency and cost.<br/><br/>Which service configuration should a solutions architect recommend?<br/><br/>A. Deploy a NAT server in front of Amazon S3.<br/>B. Deploy Amazon CloudFront in front of Amazon S3.<br/>C. Deploy a Network Load Balancer in front of Amazon S3.<br/>D. Configure Auto Scaling to automatically adjust the capacity of the website.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample232' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_37'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_34'>Random</a></p><div class='collapse' id='collapseExample232'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Deploy Amazon CloudFront in front of Amazon S3.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 23%;" aria-valuenow="23" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_37><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 37</p><br/>A company is hosting its website by using Amazon EC2 instance behind an Elastic Load Balancer across multiple Availability Zones.<br/><br/>The instance run in an EC2 Auto Scaling group.<br/><br/>The website uses Amazon Elastic Block Store (Amazon EBS) volumes to store product manuals for users to download.<br/><br/>The company updates the product content often, so new instance launched by the Auto Scaling group often have old data.<br/><br/>It can take up to 30 minutes for the new instances to receive all the updates.<br/><br/>The updates also requires the EBS volumes to be resized during business hours.<br/><br/>The company wants to ensure that the product manuals are always up to date on all that the architecture adjusts quickly to increased user demand.<br/><br/>A solutions architect needs to meet these requirements without causing the company to update its application code or adjust its website.<br/><br/>What should the solution architect do to accomplish this goal?<br/><br/>A. Store the product manuals in an EBS volume. Mount that volume to the EC2 instances.<br/>B. Store the product manuals in an Amazon S3 bucket. Redirect the downloads to this bucket.<br/>C. Store the product manual in an Amazon Elastic File System (Amazon EFS) volume. Mount that volume to the EC2 instances.<br/>D. Store the product manual in an Amazon S3 Standard&#8211;infrequent Access (S3 Standard&#8211;IA) bucket. Redirect the downloads to this bucket.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample617' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_38'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_86'>Random</a></p><div class='collapse' id='collapseExample617'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Store the product manual in an Amazon S3 Standard-infrequent Access (S3 Standard-IA) bucket. Redirect the downloads to this bucket.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 23%;" aria-valuenow="23" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_38><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 38</p><br/>A company is running a two&#8211;tier eCommerce website using services. The current architect uses a public facing Elastic Load Balancer that sends traffic to Amazon EC2 instances in a private subnet. The static content is hosted on EC2 instances, and the dynamic content is retrieved from a MYSQL database. The application is running in the United States. The company recently started selling to users in Europe and Australia. A solutions architect needs to design solution so their international users have an improved browsing experience.<br/><br/>Which solution is MOST cost&#8211;effective?<br/><br/>A. Host the entire website on Amazon S3.<br/>B. Use Amazon CloudFront and Amazon S3 to host static images.<br/>C. Increase the number of public load balancers and EC2 instances.<br/>D. Deploy the two&#8211;tier website in AWS Regions in Europe and Australia.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample87' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_39'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_108'>Random</a></p><div class='collapse' id='collapseExample87'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Use Amazon CloudFront and Amazon S3 to host static images.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 24%;" aria-valuenow="24" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_39><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 39</p><br/>A company receives data from millions of users totaling about 1 TB each flay. The company provides its user's with usage reports gang back 12 months Al usage data must be stored for at least 5 years to comply with regulatory and auditing requirements<br/><br/>Which storage solution is MOST cost&#8211;effective?<br/><br/>A. Store the data in Amazon S3 Standard. Set a lifecycle &#8211;rule to transition the data to S3 Glacier Deep Archive after 1 year. Set a Recycle rule to delete the data after5 years.<br/>B. Store. The data in Amazon S3 One Zone&#8211;Infrequent Access (S3 One Zone&#8211;IA). Set a lifecycle rule to transition the data to S3 Glacier after 1 year Set the lifecycle rule to delete the data after 5 years.<br/>C. Store the data in Amazon S3 Standard Set a lifecycle rule to transition the data to S3 Standard&#8211;infrequent Access (S3 Standard&#8211;IA) after 1 year Sol a lifecycle rule to delete the data after 5 years.<br/>D. Store the data in Amazon S3 Standard Set a lifecycle &#8211;rule to transition the data to S3 One Zone&#8211;infrequent Access (S3 One Zone&#8211;IA) after 1 year, Set a Lifecycle rule to delete the data after 5 years.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample496' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_40'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_37'>Random</a></p><div class='collapse' id='collapseExample496'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Store the data in Amazon S3 Standard. Set a lifecycle -rule to transition the data to S3 Glacier Deep Archive after 1 year. Set a Recycle rule to delete the data after5 years.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 25%;" aria-valuenow="25" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_40><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 40</p><br/>A social media company allows users to upload images to its website. The website runs on Amazon EC2 instances. During upload requests, the website resizes the images to a standard size and stores the resized images in Amazon S3. Users are experiencing slow upload requests to the website.<br/><br/>The company needs to reduce coupling within the application and improve website performance A solutions architect must design the most operationally efficient process for image uploads.<br/><br/>Which combination of actions should the solutions architect take to meet these requirements? (Select TWO.)<br/><br/>A. Configure the application to upload images to S3 Glacier.<br/>B. Configure the web server to upload the original images to Amazon S3.<br/>C. Configure the application to upload images directly from each user's browser to Amazon S3 through the use of a presigned UR<br/>D. Configure S3 Event Notifications to invoke an AWS Lambda function when an image is uploaded. Use the function to resize the image<br/>E. Create an Amazon EventBridge (Amazon CloudWatch Events) rule that invokes an AWS Lambda function on a schedule to resize uploaded images.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample447' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_41'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_48'>Random</a></p><div class='collapse' id='collapseExample447'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Configure S3 Event Notifications to invoke an AWS Lambda function when an image is uploaded. Use the function to resize the image</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 25%;" aria-valuenow="25" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_41><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 41</p><br/>A company receives inconsistent service from its data center provider because the company is headquartered in an area affected by natural disasters. The company is not ready to fully migrate to the AWS Cloud, but it wants a failure environment on AWS in case the on&#8211;premises data center fails.<br/><br/>The company runs web servers that connect to external vendors. The data available on AWS and on&#8211;premises must be uniform.<br/><br/>Which solution should a solutions architect recommend that has the LEAST amount of downtime?<br/><br/>A. Configure an Amazon Route 53 failover record. Run application servers on Amazon EC2 instances behind an Application Load Balancer in an Auto Scaling group. Set up AWS Storage Gateway with stored volumes to back up data to Amazon S3.<br/>B. Configure an Amazon Route 53 failover record. Execute an AWS CloudFormation template from a script to create Amazon EC2 instances behind an Application Load Balancer. Set up AWS Storage Gateway with stored volumes to back up data to Amazon S3.<br/>C. Configure an Amazon Route 53 failover record. Set up an AWS Direct Connect connection between a VPC and the data center. Run application servers on Amazon EC2 in an Auto Scaling group. Run an AWS Lambda function to execute an AWS CloudFormation template to create an Application Load Balancer.<br/>D. Configure an Amazon Route 53 failover record. Run an AWS Lambda function to execute an AWS CloudFormation template to launch two Amazon EC2 instances. Set up AWS Storage Gateway with stored volumes to back up data to Amazon S3. Set up an AWS Direct Connect connection between a VPC and the data center.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample140' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_42'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_101'>Random</a></p><div class='collapse' id='collapseExample140'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Configure an Amazon Route 53 failover record. Run application servers on Amazon EC2 instances behind an Application Load Balancer in an Auto Scaling group. Set up AWS Storage Gateway with stored volumes to back up data to Amazon S3.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 26%;" aria-valuenow="26" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_42><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 42</p><br/>A company needs to retain application log files for a critical application for 10years. The application team regularly accesses logs from the past month for troubleshooting, but logs older than 1 month are rarely accessed. The application generates more than 10 TB of logs per month.<br/><br/>Which storage option meets these requirements MOST cost&#8211;effectively?<br/><br/>A. Store the logs in Amazon S3. Use AWS Backup to move logs more than 1 month old to S3 Glacier Deep Archive<br/>B. Store the logs in Amazon S3. Use S3 Lifecycle policies to move logs more than 1 month old to S3 Glacier Deep Archive.<br/>C. Store the logs in Amazon CloudWatch Logs. Use AWS Backup to move logs more than 1 month old to S3 Glacier Deep Archive.<br/>D. Store the logs in Amazon CloudWatch Logs. Use Amazon S3 Lifecycle policies to move logs more than 1 month old to S3 Glacier Deep Archive.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample547' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_43'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_148'>Random</a></p><div class='collapse' id='collapseExample547'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Store the logs in Amazon S3. Use S3 Lifecycle policies to move logs more than 1 month old to S3 Glacier Deep Archive.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 27%;" aria-valuenow="27" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_43><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 43</p><br/>A company is moving its legacy workload to the AWS Cloud.<br/><br/>The workload files will be shared, appended, and frequently accessed through Amazon EC2 instances when they are first created.<br/><br/>The files will be accessed occasionally as they age.<br/><br/>What should a solutions architect recommend?<br/><br/>A. Store the data using Amazon EC2 instances with attached Amazon Elastic Block Store (Amazon EBS) data volumes<br/>B. Store the data using AWS Storage Gateway volume gateway and export rarely accessed data to Amazon S3 storage<br/>C. Store the data using Amazon Elastic File System (Amazon EFS) with lifecycle management enabled for rarely accessed data<br/>D. Store the data using Amazon S3 with an S3 lifecycle policy enabled to move data to S3 Standard&#8211; Infrequent Access (S3 Standard&#8211;IA)<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample720' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_44'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_112'>Random</a></p><div class='collapse' id='collapseExample720'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Store the data using Amazon S3 with an S3 lifecycle policy enabled to move data to S3 Standard- Infrequent Access (S3 Standard-IA)</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 27%;" aria-valuenow="27" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_44><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 44</p><br/>A company's security team requests that network traffic be captured in VPC Flow Logs. The logs will be frequently accessed for 90 days and then accessed intermittently.<br/><br/>What should a solutions architect do to meet these requirements when configuring the logs?<br/><br/>A. Use Amazon CloudWatch as the target. Set the CloudWatch log group with an expiration of 90 days.<br/>B. Use Amazon Kinesis as the target Configure the Kinesis stream to always retain the logs for 90 days<br/>C. Use AWS CloudTrail as the target. Configure CloudTrail to save to an Amazon S3 bucket, and enable S3 Intelligent&#8211;Tiering<br/>D. Use Amazon S3 as the target Enable an S3 Lifecycle policy to transition the logs to S3 Standard&#8211;Infrequent Access (S3 Standard&#8211;IA) after 90 days<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample448' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_45'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_13'>Random</a></p><div class='collapse' id='collapseExample448'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Use Amazon S3 as the target Enable an S3 Lifecycle policy to transition the logs to S3 Standard-Infrequent Access (S3 Standard-IA) after 90 days</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 28%;" aria-valuenow="28" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_45><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 45</p><br/>A company hosts a training site on a fleet of Amazon EC2 instances.<br/><br/>The company anticipates that its new course, which consists of dozens of training videos on the site, will be extremely popular when it is released in 1 week.<br/><br/>What should a solutions architect do to minimize the anticipated server load?<br/><br/>A. Store the videos in Amazon ElastiCache for Redis. Update the web servers to serve the videos using the Elastic cache API<br/>B. Store the videos in Amazon Elastic File System (Amazon EFS). Create a user data script for the web servers to mount the EFS volume.<br/>C. Store the videos in an Amazon S3 bucket. Create an Amazon CloudFlight distribution with an origin access identity (OAI) of that S3 bucket. Restrict Amazon S3 access to the OAI.<br/>D. Store the videos in an Amazon S3 bucket. Create an AWS Storage Gateway file gateway to access the S3 bucket. Create a user data script for the web servers to mount the file gateway<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample714' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_46'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_83'>Random</a></p><div class='collapse' id='collapseExample714'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Store the videos in an Amazon S3 bucket. Create an Amazon CloudFlight distribution with an origin access identity (OAI) of that S3 bucket. Restrict Amazon S3 access to the OAI.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 29%;" aria-valuenow="29" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_46><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 46</p><br/>A company wants to optimize the cost of its data storage for data that is accessed quarterly. The company requires high throughput, low latency, and rapid access, when needed.<br/><br/>Which Amazon S3 storage class should a solutions architect recommend?<br/><br/>A. Amazon S3 Glacier (S3 Glacier)<br/>B. Amazon S3 Standard (S3 Standard)<br/>C. Amazon S3 Intelligent&#8211;Tiering (S3 Intelligent&#8211;Tiering)<br/>D. Amazon S3 Standard&#8211;Infrequent Access (S3 Standard&#8211;IA)<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample717' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_47'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_115'>Random</a></p><div class='collapse' id='collapseExample717'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Amazon S3 Standard (S3 Standard)</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 29%;" aria-valuenow="29" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_47><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 47</p><br/>Organizers for a global event want to put daily reports online as static HTML pages. The pages are expected to generate millions of views from users around the world. The files are stored in an Amazon S3 bucket. A solutions architect has been asked to design an efficient and effective solution.<br/><br/>Which action should the solutions architect take to accomplish this?<br/><br/>A. Generate presigned URLs for the files.<br/>B. Use cross&#8211;Region replication to all Regions.<br/>C. Use the geoproximity feature of Amazon Route 53.<br/>D. Use Amazon CloudFront with the S3 bucket as its origin.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample10' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation10' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_48'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_154'>Random</a></p><div class='collapse' id='collapseExample10'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Use Amazon CloudFront with the S3 bucket as its origin.</div></div></div><div class='collapse' id='explanation10'><div class='card card&#45;body'><div>
Using Amazon S3 Origins, MediaPackage Channels, and Custom Origins for Web Distributions

Using Amazon S3 Buckets for Your Origin
When you use Amazon S3 as an origin for your distribution, you place any objects that you want CloudFront to deliver in an Amazon S3 bucket. You can use any method that is supported by Amazon S3 to get your objects into Amazon S3, for example, the Amazon S3 console or API, or a third-party tool. You can create a hierarchy in your bucket to store the objects, just as you would with any other Amazon S3 bucket.

Using an existing Amazon S3 bucket as your CloudFront origin server doesn't change the bucket in any way; you can still use it as you normally would to store and access Amazon S3 objects at the standard Amazon S3 price. You incur regular Amazon S3 charges for storing the objects in the bucket.

Using Amazon S3 Buckets Configured as Website Endpoints for Your Origin
You can set up an Amazon S3 bucket that is configured as a website endpoint as custom origin with CloudFront.

When you configure your CloudFront distribution, for the origin, enter the Amazon S3 static website hosting endpoint for your bucket. This value appears in the Amazon S3 console, on the Properties tab, in the Static website hosting pane. For example: http://bucket-name.s3-website-region.amazonaws.com

For more information about specifying Amazon S3 static website endpoints, see Website endpoints in the Amazon Simple Storage Service Developer Guide.

When you specify the bucket name in this format as your origin, you can use Amazon S3 redirects and Amazon S3 custom error documents. For more information about Amazon S3 features, see the Amazon S3 documentation.

Using an Amazon S3 bucket as your CloudFront origin server doesn't change it in any way. You can still use it as you normally would and you incur regular Amazon S3 charges.

Amazon CloudFront can be used to cache the files in edge locations around the world and this will improve the performance of the webpages.

To serve a static website hosted on Amazon S3, you can deploy a CloudFront distribution using one of these configurations:

Using a REST API endpoint as the origin with access restricted by an origin access identity (OAI) Using a website endpoint as the origin with anonymous (public) access allowed

Using a website endpoint as the origin with access restricted by a Referer header CORRECT: "Use Amazon CloudFront with the S3 bucket as its origin" is the correct answer.

INCORRECT: "Generate presigned URLs for the files" is incorrect as this is used to restrict access which is not a requirement.

INCORRECT: "Use cross-Region replication to all Regions" is incorrect as this does not provide a mechanism for directing users to the closest copy of the static webpages.

INCORRECT: "Use the geoproximity feature of Amazon Route 53" is incorrect as this does not include a solution for having multiple copies of the data in different geographic locations.

References:

How do I use CloudFront to serve a static website hosted on Amazon S3?</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 30%;" aria-valuenow="30" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_48><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 48</p><br/>A company wants to migrate its 1PB on&#8211;premises image repository to AWS.<br/><br/>The images will be used by a serverless web application Images stored in the repository are rarely accessed, but they must be immediately available. Additionally, the images must be encrypted at rest and protected from accidental deletion.<br/><br/>Which solution meets these requirements?<br/><br/>A. Implement client&#8211;side encryption and store the images in an Amazon S3 Glacier vault. Set a vault lock to prevent accidental deletion.<br/>B. Store the images in an Amazon S3 bucket in the S3 Standard&#8211;Infrequent Access (S3 Standard&#8211; IA) storage class. Enable versioning: default encryption, and MFA Delete on the S3 bucket<br/>C. Store the images in an Amazon FSx for Windows File Server file share. Configure the Amazon FSx file share to use an AWS Key Management Service (AWS KMS) customer master key (CMK) to encrypt the images in the file share. Use NTFS permission sets on the images to prevent accidental deletion<br/>D. Store the images in an Amazon Elastic File System (Amazon EFS) file share in the Infrequent Access storage class. Configure the EFS file share to use an AWS Key Management Service (AWS KMS) customer master key (CMK) to encrypt the images in the file share. Use NFS permission set on the images to prevent accidental deletion.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample643' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_49'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_29'>Random</a></p><div class='collapse' id='collapseExample643'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Store the images in an Amazon S3 bucket in the S3 Standard-Infrequent Access (S3 Standard- IA) storage class. Enable versioning: default encryption, and MFA Delete on the S3 bucket</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 30%;" aria-valuenow="30" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_49><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 49</p><br/>A company has copied 1 PB of data from a colocation facility to an Amazon S3 bucket in the us&#8211;east&#8211;1 Region using an AWS Direct Connect link. The company now wants to copy the data to another S3 bucket in the us&#8211;west&#8211;2 Region. The colocation facility does not allow the use of AWS Snowball.<br/><br/>What should a solutions architect recommend to accomplish this?<br/><br/>A. Order a Snowball Edge device to copy the data from one Region to another Region.<br/>B. Transfer contents from the source S3 bucket to a target S3 bucket using the S3 console.<br/>C. Use the aws S3 sync command to copy data from the source bucket to the destination bucket.<br/>D. Add a cross&#8211;Region replication configuration to copy objects across S3 buckets in different Regions.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample221' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_50'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_92'>Random</a></p><div class='collapse' id='collapseExample221'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Use the aws S3 sync command to copy data from the source bucket to the destination bucket.

References:

How can I copy all objects from one Amazon S3 bucket to another bucket?</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 31%;" aria-valuenow="31" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_50><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 50</p><br/>A company has thousands of edge devices that collectively generate 1 TB of status averts each day Each alert s approximately 2 KB in size. A solutions architect needs to implement a solution to ingest and store the alerts for future analysis.<br/><br/>The company wants a highly available solution However the company needs to minimize costs and does not want to manage additional infrastructure Additionally, the company wants to keep 14 days of data available for immediate analysis and archive any data older than 14 days.<br/><br/>What is the MOST operationally efficient solution that meets these requirements?<br/><br/>A. Create an Amazon Kinesis Data Firehose delivery stream to ingest the alerts Configure the Kinesis Data Firehose stream to deliver the alerts to an Amazon S3 bucket Set up an S3 Lifecycle configuration to transition data to Amazon S3 Glacier after 14 days<br/>B. Launch Amazon EC2 instances across two Availability Zones and place them behind an Elastic Load Balancer to ingest the alerts Create a script on the EC2 instances that will store the alerts m an Amazon S3 bucket Set up an S3 Lifecycle configuration to transition data to Amazon S3 Glacier after 14 days<br/>C. Create an Amazon Kinesis Data Firehose delivery stream to ingest the alerts Configure the Kinesis Data Firehose stream to deliver the alerts to an Amazon Elasticsearch Service (Amazon ES) duster Set up the Amazon ES cluster to take manual snapshots every day and delete data from the duster that is older than 14 days<br/>D. Create an Amazon Simple Queue Service (Amazon SQS I standard queue to ingest the alerts and set the message retention period to 14 days Configure consumers to poll the SQS queue check the age of the message and analyze the message data as needed If the message is 14 days old the consumer should copy the message to an Amazon S3 bucket and delete the message from the SQS queue<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample469' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_51'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_145'>Random</a></p><div class='collapse' id='collapseExample469'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Create an Amazon Kinesis Data Firehose delivery stream to ingest the alerts Configure the Kinesis Data Firehose stream to deliver the alerts to an Amazon S3 bucket Set up an S3 Lifecycle configuration to transition data to Amazon S3 Glacier after 14 days</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 32%;" aria-valuenow="32" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_51><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 51</p><br/>A company has a custom application running on an Amazon EC instance that:<br/><br/>Reads a large amount of data from Amazon S3<br/>Performs a multi&#8211;stage analysis<br/>Writes the results to Amazon DynamoDB<br/>The application writes a significant number of large, temporary files during the multi&#8211;stage analysis. The process performance depends on the temporary storage performance.<br/><br/>What would be the fastest storage option for holding the temporary files?<br/><br/>A. Multiple Amazon S3 buckets with Transfer Acceleration for storage.<br/>B. Multiple Amazon EBS drives with Provisioned IOPS and EBS optimization.<br/>C. Multiple Amazon EFS volumes using the Network File System version 4.1 (NFSv4.1) protocol.<br/>D. Multiple instance store volumes with software RAID 0.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample114' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_52'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_1'>Random</a></p><div class='collapse' id='collapseExample114'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Multiple Amazon S3 buckets with Transfer Acceleration for storage.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 32%;" aria-valuenow="32" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_52><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 52</p><br/>A company's website provides users with downloadable historical performance reports. The website needs a solution that will scale to meet the company's website demands globally. The solution should be cost effective, limit the? provisioning of Into and provide the fastest possible response time.<br/><br/>Which combination should a solutions architect recommend to meet these requirements?<br/><br/>A. Amazon CloudFront and Amazon S3<br/>B. AWS Lambda and Amazon Dynamo<br/>C. Application Load Balancer with Amazon EC2 Auto Scaling<br/>D. Amazon Route 53 with internal Application Load Balances<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample731' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_53'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_106'>Random</a></p><div class='collapse' id='collapseExample731'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Amazon CloudFront and Amazon S3</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 33%;" aria-valuenow="33" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_53><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 53</p><br/>A company wants to use high performance computing (HPC) infrastructure on AWS for financial risk modeling. The company's HPC workloads run on Linux. Each HPC workflow runs on hundreds of AmazonEC2 Spot Instances, is short&#8211;lived, and generates thousands of output files that are ultimately stored in persistent storage for analytics and long&#8211;term future use.<br/><br/>The company seeks a cloud storage solution that permits the copying of on&#8211;premises data to long&#8211;term persistent storage to make data available for processing by all EC2 instances. The solution should also be a high performance file system that is integrated with persistent storage to read and write datasets and output files.<br/><br/>Which combination of AWS services meets these requirements?<br/><br/>A. Amazon FSx for Lustre integrated with Amazon S3<br/>B. Amazon FSx for Windows File Server integrated with Amazon S3<br/>C. Amazon S3 Glacier integrated with Amazon Elastic Block Store (Amazon EBS)<br/>D. Amazon S3 bucket with a VPC endpoint integrated with an Amazon Elastic Block Store (Amazon EBS) General Purpose SSD (gp2) volume<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample317' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_54'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_72'>Random</a></p><div class='collapse' id='collapseExample317'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Amazon FSx for Lustre integrated with Amazon S3</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 34%;" aria-valuenow="34" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_54><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 54</p><br/>A company has an Amazon S3 bucket that contains mission&#8211;critical data. The company wants to ensure this data is protected from accidental deletion. The data should still be accessible, and a user should be able to delete the data intentionally.<br/><br/>Which combination of steps should a solutions architect take to accomplish this? (Choose two.)<br/><br/>A. Enable versioning on the S3 bucket.<br/>B. Enable MFA Delete on the S3 bucket.<br/>C. Create a bucket policy on the S3 bucket.<br/>D. Enable default encryption on the S3 bucket.<br/>E. Create a lifecycle policy for the objects in the S3 bucket.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample362' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_55'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_126'>Random</a></p><div class='collapse' id='collapseExample362'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Enable versioning on the S3 bucket.
<br><b>B. </b>Enable MFA Delete on the S3 bucket.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 34%;" aria-valuenow="34" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_55><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 55</p><br/>A company has three AWS accounts Management Development and Production. These accounts use AWS services only in the us&#8211;east&#8211;1 Region All accounts have a VPC with VPC Flow Logs configured to publish data to an Amazon S3 bucket in each separate account For compliance reasons the company needs an ongoing method to aggregate all the VPC flow logs across all accounts into one destination S3 bucket in the Management account.<br/><br/>What should a solutions architect do to meet these requirements with the LEAST operational overhead?<br/><br/>A. Add S3 Same&#8211;Region Replication rules in each S3 bucket that stores VPC flow logs to replicate objects to the destination S3 bucket Configure the destination S3 bucket to allow objects to be received from the S3 buckets in other accounts<br/>B. Set up an 1AM user in the Management account Grant permissions to the 1AM user to access the S3 buckets that contain the VPC flow logs Run the aws s3 sync command in the AWS CLI to copy the objects to the destination S3 bucket<br/>C. Use an S3 inventory report to specify which objects in the S3 buckets to copy Perform an S3 batch operation to copy the objects into the destination S3 bucket in the Management account with a single request.<br/>D. Create an AWS Lambda function in the Management account Grant S3 GET permissions on the source S3 buckets Grant S3 PUT permissions on the destination S3 bucket Configure the function to invoke when objects are loaded in the source S3 buckets<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample462' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_56'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_128'>Random</a></p><div class='collapse' id='collapseExample462'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Add S3 Same-Region Replication rules in each S3 bucket that stores VPC flow logs to replicate objects to the destination S3 bucket Configure the destination S3 bucket to allow objects to be received from the S3 buckets in other accounts</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 35%;" aria-valuenow="35" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_56><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 56</p><br/>A company has a three&#8211;tier image&#8211;sharing application. It uses an Amazon EC2 instance for the front&#8211;end layer, another for the backend tier, and a third for the MySQL database. A solutions architect has been tasked with designing a solution that is highly available, and requires the least amount of changes to the application.<br/><br/>Which solution meets these requirements?<br/><br/>A. Use Amazon S3 to host the front&#8211;end layer and AWS Lambda functions for the backend layer. Move the database to an Amazon DynamoDB table and use Amazon S3 to store and serve users' images.<br/>B. Use load&#8211;balanced Multi&#8211;AZ AWS Elastic Beanstalk environments for the front&#8211;end and backend layers. Move the database to an Amazon RDS instance with multiple read replicas to store and serve users' images.<br/>C. Use Amazon S3 to host the front&#8211;end layer and a fleet of Amazon EC2 instances in an Auto Scaling group for the backend layer. Move the database to a memory optimized instance type to store and serve users' images.<br/>D. Use load&#8211;balanced Multi&#8211;AZ AWS Elastic Beanstalk environments for the front&#8211;end and backend layers. Move the database to an Amazon RDS instance with a Multi&#8211;AZ deployment. Use Amazon S3 to store and serve users' images.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample155' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation155' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_57'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_78'>Random</a></p><div class='collapse' id='collapseExample155'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Use load-balanced Multi-AZ AWS Elastic Beanstalk environments for the front-end and backend layers. Move the database to an Amazon RDS instance with a Multi-AZ deployment. Use Amazon S3 to store and serve users' images.</div></div></div><div class='collapse' id='explanation155'><div class='card card&#45;body'><div>
Keyword: Highly available + Least amount of changes to the application High Availability = Multi-AZ

Least amount of changes to the application = Elastic Beanstalk Automatically handles the deployment, from capacity provisioning, Load Balancing, Auto Scaling to application health monitoring

Option – D will be the right choice and Option – A; Option – B and Option – C out of race due to Cost & inter-operability.

HA with Elastic Beanstalk and RDS

AWS Elastic Beanstalk

AWS Elastic Beanstalk is an easy-to-use service for deploying and scaling web applications and services developed with Java, .NET, PHP, Node.js, Python, Ruby, Go, and Docker on familiar servers such as Apache, Nginx, Passenger, and IIS.

You can simply upload your code and Elastic Beanstalk automatically handles the deployment, from capacity provisioning, load balancing, auto-scaling to application health monitoring. At the same time, you retain full control over the AWS resources powering your application and can access the underlying resources at any time.

There is no additional charge for Elastic Beanstalk – you pay only for the AWS resources needed to store and run your applications.

AWS RDS
Amazon Relational Database Service (Amazon RDS) makes it easy to set up, operate, and scale a relational database in the cloud. It provides cost-efficient and resizable capacity while automating time-consuming administration tasks such as hardware provisioning, database setup, patching and backups. It frees you to focus on your applications so you can give them the fast performance, high availability, security and compatibility they need.

Amazon RDS is available on several database instance types – optimized for memory, performance or I/O – and provides you with six familiar database engines to choose from, including Amazon Aurora, PostgreSQL, MySQL, MariaDB, Oracle Database, and SQL Server. You can use the AWS Database Migration Service to easily migrate or replicate your existing databases to Amazon RDS.

AWS S3
Amazon Simple Storage Service (Amazon S3) is an object storage service that offers industry-leading scalability, data availability, security, and performance. This means customers of all sizes and industries can use it to store and protect any amount of data for a range of use cases, such as websites, mobile applications, backup and restore, archive, enterprise applications, IoT devices, and big data analytics. Amazon S3 provides easy-to-use management features so you can organize your data and configure finely-tuned access controls to meet your specific business, organizational, and compliance requirements. Amazon S3 is designed for 99.999999999% (11 9's) of durability, and stores data for millions of applications for companies all around the world.

References:

AWS Elastic Beanstalk
Amazon Relational Database Service (RDS)
Amazon S3</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 36%;" aria-valuenow="36" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_57><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 57</p><br/>A company needs to store data in Amazon S3 A compliance requirement states that when any changes are made to objects the previous state of the object with any changes must be preserved Additionally files older than 5 years should not be accessed but need to be archived for auditing<br/><br/>What should a solutions architect recommend that is MOST cost&#8211;effective?<br/><br/>A. Enable object&#8211;level versioning and S3 Object Lock in governance mode<br/>B. Enable object&#8211;level versioning and S3 Object Lock in compliance mode<br/>C. Enable object&#8211;level versioning Enable a lifecycle policy to move data older than 5 years to S3 Glacier Deep Archive<br/>D. Enable object&#8211;level versioning Enable a lifecycle policy to move data older than 5 years to S3 Standard&#8211;Infrequent Access (S3 Standard&#8211;IA)<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample499' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_58'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_26'>Random</a></p><div class='collapse' id='collapseExample499'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Enable object-level versioning Enable a lifecycle policy to move data older than 5 years to S3 Glacier Deep Archive</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 36%;" aria-valuenow="36" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_58><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 58</p><br/>A company stores user data in AWS. The data is used continuously with peak usage during business hours. Access patterns vary, with some data not being used for months at a time. A solution architect must choose a cost&#8211;effective solution that maintains the highest level of durability while maintaining high availability.<br/><br/>Which storage solution meets these requirements?<br/><br/>A. Amazon S3 Standard<br/>B. Amazon S3 intelligent&#8211;Tiering<br/>C. Amazon S3 Glacier Deep Archive<br/>D. Amazon S3 One Zone&#8211;infrequent Access (Se One Zone&#8211;IA)<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample670' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_59'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_44'>Random</a></p><div class='collapse' id='collapseExample670'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Amazon S3 intelligent-Tiering</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 37%;" aria-valuenow="37" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_59><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 59</p><br/>The financial application at a company stores monthly reports in an Amazon S3 bucket. The vice president of finance has mandated that all access to these reports be logged and that any modifications to the log files be detected.<br/><br/>Which actions can a solutions architect take to meet these requirements?<br/><br/>A. Use S3 server access logging on the bucket that houses the reports with the read and write data events and log file validation options enabled.<br/>B. Use S3 server access logging on the bucket that houses the reports with the read and write management events and log file validation options enabled<br/>C. Use AWS CloudTrail to create a new trail. Configure the trail to log read and write data events on the S3 bucket that houses the reports Log these events to a new bucket, and enable log file validation<br/>D. Use AWS CloudTrail to create a new trail. Configure the trail to log read and write management events on the S3 bucket that houses the reports. Log these events to a new bucket, and enable log file validation.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample510' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_60'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_102'>Random</a></p><div class='collapse' id='collapseExample510'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Use AWS CloudTrail to create a new trail. Configure the trail to log read and write data events on the S3 bucket that houses the reports Log these events to a new bucket, and enable log file validation

References:

Amazon Simple Storage Service > User Guide > Enabling CloudTrail event logging for S3 buckets and objects</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 38%;" aria-valuenow="38" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_60><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 60</p><br/>A company has an application that generates a large number of files, each approximately 5 MB in size. The files are stored in Amazon S3. Company policy requires the files to be stored for 4 years before they can be deleted. Immediate accessibility is always required as the files contain critical business data that is not easy to reproduce. The files are frequently accessed in the first 30 days of the object creation but are rarely accessed after the first 30 days.<br/><br/>Which storage solution is MOST cost&#8211;effective?<br/><br/>A. Create an S3 bucket lifecycle policy to move files from S3 Standard to S3 Glacier 30 days from object creation. Delete the files 4 years after object creation.<br/>B. Create an S3 bucket lifecycle policy to move files from S3 Standard to S3 One Zone&#8211;Infrequent Access (S3 One Zone&#8211;IA) 30 days from object creation. Delete the files 4 years after object creation.<br/>C. Create an S3 bucket lifecycle policy to move files from S3 Standard to S3 Standard&#8211;Infrequent Access (S3 Standard&#8211;IA) 30 days from object creation. Delete the files 4 years after object creation.<br/>D. Create an S3 bucket lifecycle policy to move files from S3 Standard to S3 Standard&#8211;Infrequent Access (S3 Standard&#8211;IA) 30 days from object creation. Move the files to S3 Glacier 4 years after object creation.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample347' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_61'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_138'>Random</a></p><div class='collapse' id='collapseExample347'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Create an S3 bucket lifecycle policy to move files from S3 Standard to S3 Standard-Infrequent Access (S3 Standard-IA) 30 days from object creation. Delete the files 4 years after object creation.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 38%;" aria-valuenow="38" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_61><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 61</p><br/>A solutions architect is designing a system that will store personally identifiable information (Pll) in an Amazon S3 bucket.<br/><br/>Due to compliance and regulatory requirements, both the master keys and the unencrypted data should never be sent to AWS.<br/><br/>Which Amazon S3 encryption technique should the architect choose?<br/><br/>A. Amazon S3 client&#8211;side encryption with an AWS Key Management Service {AWS KMS) managed customer master key (CMK)<br/>B. Amazon S3 server&#8211;side encryption with AWS KMS managed encryption keys (SSE&#8211;KMS)<br/>C. Amazon S3 client&#8211;side encryption with a client&#8211;side master key<br/>D. Amazon S3 server&#8211;side encryption with customer&#8211;provided encryption keys (SSE&#8211;C)<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample624' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_62'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_32'>Random</a></p><div class='collapse' id='collapseExample624'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Amazon S3 server-side encryption with customer-provided encryption keys (SSE-C)</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 39%;" aria-valuenow="39" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_62><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 62</p><br/>A company has an image processing workload running on Amazon Elastic Container Service (Amazon ECS) in two private subnets. Each private subnet uses a NAT instance for internet access. All images are stored in Amazon S3 buckets. The company is concerned about the data transfer costs between Amazon ECS and Amazon S3.<br/><br/>What should a solutions architect do to reduce costs?<br/><br/>A. Configure a NAT gateway to replace the NAT instances.<br/>B. Configure a gateway endpoint for traffic destined to Amazon S3.<br/>C. Configure an interface endpoint for traffic destined to Amazon S3.<br/>D. Configure Amazon CloudFront for the S3 bucket storing the images.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample240' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation240' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_63'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_84'>Random</a></p><div class='collapse' id='collapseExample240'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Configure an interface endpoint for traffic destined to Amazon S3.</div></div></div><div class='collapse' id='explanation240'><div class='card card&#45;body'><div>
S3 and Dynamo DB does not support interface endpoints. Both S3 and DynamoDB are routed via Gateway endpoint.
Interface Endpoint only supports services that are integrated with PrivateLink.

References:

Amazon Virtual Private Cloud > AWS PrivateLink > VPC endpoints
Amazon Virtual Private Cloud > AWS PrivateLink > AWS services that integrate with AWS PrivateLink</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 40%;" aria-valuenow="40" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_63><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 63</p><br/>A company has multiple AWS accounts with applications deployed in the us&#8211;west&#8211;2 Region Application togs are stored within Amazon S3 buckets in each account. The company wants to build a centralized log analysts solution that uses a single S3 bucket Logs must not leave us&#8211; west&#8211;2T and the company wants to incur minimal operational overhead.<br/><br/>Which solution meets these requirements and is MOST cost&#8211;effective?<br/><br/>A. Create an S3 Lifecycle policy that copies the objects from one of the application S3 buckets to the centralized S3 bucket<br/>B. Use S3 Same&#8211;Region Replication to replicate togs from the S3 buckets to another S3 bucket in us&#8211;west&#8211;2 Use this S3 bucket for log analysis<br/>C. Write a script that uses the PutObject API operation every day to copy the entire contents of the buckets to another S3 bucket in us&#8211;west&#8211;2 Use this S3 bucket for log analysis<br/>D. Write AWS Lambda functions in these accounts that are triggered every time logs ate delivered to the S3 buckets (s3 ObjectCreated. * event) Copy the logs to another S3 bucket in us&#8211;west&#8211;2 Use this S3 bucket for log analysis<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample563' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_64'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_21'>Random</a></p><div class='collapse' id='collapseExample563'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Create an S3 Lifecycle policy that copies the objects from one of the application S3 buckets to the centralized S3 bucket</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 40%;" aria-valuenow="40" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_64><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 64</p><br/>A social media company is building a feature for its website. The feature will give users the ability to upload photos. The company expects significant increases in demand during large events and must ensure that the website can handle the upload traffic from users.<br/><br/>Which solution meets these requirements with the MOST scalability?<br/><br/>A. Upload files from the user's browser to the application servers Transfer the files to an Amazon S3 bucket.<br/>B. Provision an AWS Storage Gateway file gateway. Upload files directly from the user's browser to the file gateway.<br/>C. Generate Amazon S3 presigned URLs in the application. Upload files directly from the user's browser into an S3 bucket<br/>D. Provision an Amazon Elastic File System (Amazon EFS) file system. Upload files directly from the user's browser to the file system.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample443' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_65'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_133'>Random</a></p><div class='collapse' id='collapseExample443'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Generate Amazon S3 presigned URLs in the application. Upload files directly from the user's browser into an S3 bucket</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 41%;" aria-valuenow="41" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_65><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 65</p><br/>A solutions architect is designing the cloud architecture for a new application being deployed to AWS. The application allows users to interactively download and upload files. Files older than 2 years will be accessed less frequently. The solutions architect needs to ensure that the application can scale to any number of files while maintaining high availability and durability.<br/><br/>Which scalable solutions should the solutions architect recommend? (Choose two.)<br/><br/>A. Store the files on Amazon S3 with a lifecycle policy that moves objects older than 2 years to S3 Glacier.<br/>B. Store the files on Amazon S3 with a lifecycle policy that moves objects older than 2 years to S3 Standard&#8211;Infrequent Access (S3 Standard&#8211;IA)<br/>C. Store the files on Amazon Elastic File System (Amazon EFS) with a lifecycle policy that moves objects older than 2 years to EFS Infrequent Access (EFS IA).<br/>D. Store the files in Amazon Elastic Block Store (Amazon EBS) volumes. Schedule snapshots of the volumes. Use the snapshots to archive data older than 2 years.<br/>E. Store the files in RAID&#8211;striped Amazon Elastic Block Store (Amazon EBS) volumes. Schedule snapshots of the volumes. Use the snapshots to archive data older than 2 years.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample104' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_66'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_120'>Random</a></p><div class='collapse' id='collapseExample104'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Store the files on Amazon S3 with a lifecycle policy that moves objects older than 2 years to S3 Glacier.
<br><b>C. </b>Store the files on Amazon Elastic File System (Amazon EFS) with a lifecycle policy that moves objects older than 2 years to EFS Infrequent Access (EFS IA).</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 41%;" aria-valuenow="41" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_66><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 66</p><br/>A company is using an Amazon S3 bucket to store data uploaded by different departments from multiple locations.<br/><br/>During an AWS Well&#8211;Architected review the financial manager notices that 10 TB of S3 Standard storage data has been charged each month.<br/><br/>However, in the AWS Management Console for Amazon S3, using the command to select all files and folders shows a total size of 5 TB.<br/><br/>What are the possible causes for this difference? (Select TWO )<br/><br/>A. Some files are stored with deduplication<br/>B. The S3 bucket has versioning enabled<br/>C. There are incomplete S3 multipart uploads<br/>D. The S3 bucket has AWS Key Management Service (AWS KMS) enabled<br/>E. The S3 bucket has Intelligent&#8211;Tiering enabled<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample652' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_67'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_22'>Random</a></p><div class='collapse' id='collapseExample652'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>The S3 bucket has versioning enabled
<br><b>C. </b>There are incomplete S3 multipart uploads</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 42%;" aria-valuenow="42" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_67><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 67</p><br/>A company hosts an application used to upload files to an Amazon S3 bucket. Once uploaded, the files are processed to extract metadata, which takes less than 5 seconds. The volume and frequency of the uploads varies from a few files each hour to hundreds of concurrent uploads. The company has asked a solutions architect to design a cost&#8211;effective architecture that will meet these requirements.<br/><br/>What should the solutions architect recommend?<br/><br/>A. Configure AWS CloudTrail trails to log S3 API calls. Use AWS AppSync to process the files.<br/>B. Configure an object&#8211;created event notification within the S3 bucket to invoke an AWS Lambda function to process the files.<br/>C. Configure Amazon Kinesis Data Streams to process and send data to Amazon S3. Invoke an AWS Lambda function to process the files.<br/>D. Configure an Amazon Simple Notification Service (Amazon SNS) topic to process the files uploaded to Amazon S3. Invoke an AWS Lambda function to process the files.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample276' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_68'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_52'>Random</a></p><div class='collapse' id='collapseExample276'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Configure an object-created event notification within the S3 bucket to invoke an AWS Lambda function to process the files.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 43%;" aria-valuenow="43" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_68><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 68</p><br/>A solutions architect is using Amazon S3 to design the storage architecture of a new digital media application. The media files must be resilient to the loss of an Availability Zone. Some files are accessed frequently while other files are rarely accessed in an unpredictable pattern. The solutions architect must minimize the costs of storing and retrieving the media files.<br/><br/>Which storage option meets these requirements?<br/><br/>A. S3 Standard<br/>B. S3 Intelligent&#8211;Tiering<br/>C. S3 Standard&#8211;Infrequent Access (S3 Standard&#8211;IA)<br/>D. S3 One Zone&#8211;Infrequent Access (S3 One Zone&#8211;IA)<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample102' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation102' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_69'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_56'>Random</a></p><div class='collapse' id='collapseExample102'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>S3 Intelligent-Tiering</div></div></div><div class='collapse' id='explanation102'><div class='card card&#45;body'><div>
S3 Intelligent-Tiering is a new Amazon S3 storage class designed for customers who want to optimize storage costs automatically when data access patterns change, without performance impact or operational overhead. S3 Intelligent-Tiering is the first cloud object storage class that delivers automatic cost savings by moving data between two access tiers – frequent access and infrequent access – when access patterns change, and is ideal for data with unknown or changing access patterns.

S3 Intelligent-Tiering stores objects in two access tiers: one tier that is optimized for frequent access and another lower-cost tier that is optimized for infrequent access. For a small monthly monitoring and automation fee per object, S3 Intelligent-Tiering monitors access patterns and moves objects that have not been accessed for 30 consecutive days to the infrequent access tier. There are no retrieval fees in S3 Intelligent-Tiering. If an object in the infrequent access tier is accessed later, it is automatically moved back to the frequent access tier. No additional tiering fees apply when objects are moved between access tiers within the S3 Intelligent-Tiering storage class. S3 Intelligent-Tiering is designed for 99.9% availability and 99.999999999% durability, and offers the same low latency and high throughput performance of S3 Standard.
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 43%;" aria-valuenow="43" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_69><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 69</p><br/>A company wants to educe Its Amazon S3 storage costs in its production environment without impacting durability or performance of the stored objects.<br/><br/>What is the FIRST step the company should take to meet these objectives?<br/><br/>A. Enable Amazon Made on the business&#8211;critical S3 buckets to classify the sensitivity of the objects<br/>B. Enable S3 analytics to Identify S3 buckets that are candidates for transitioning to S3 Standard&#8211; Infrequent Access (S3 Standard&#8211;IA)<br/>C. Enable versioning on all business&#8211;critical S3 buckets.<br/>D. Migrate me objects in all S3 buckets to S3 Intelligent&#8211;Tie ring<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample571' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_70'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_70'>Random</a></p><div class='collapse' id='collapseExample571'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Migrate me objects in all S3 buckets to S3 Intelligent-Tie ring</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 44%;" aria-valuenow="44" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_70><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 70</p><br/>An image hosting company uploads its large assets to Amazon S3 Standard buckets.<br/><br/>The company uses multipart upload in parallel by using S3 APIs and overwrites if the same object is uploaded again.<br/><br/>For the first 30 days after upload the objects will be accessed frequently.<br/><br/>The objects will be used less frequently after 30 days but the access patterns for each object will be inconsistent.<br/><br/>The company must optimize its S3 storage costs while maintaining high availability and resiliency of stored assets.<br/><br/>Which combination of actions should a solutions architect recommend to meet these requirements? (Select TWO.)<br/><br/>A. Move assets to S3 Intelligent&#8211;Tiering after 30 days<br/>B. Configure an S3 Lifecycle policy to clean up incomplete multipart uploads<br/>C. Configure an S3 L lifecycle policy to clean up expired object delete markers<br/>D. Move ass ts to S3 Standard&#8211;Infrequent Access (S3 Standard&#8211;iA) after 30 days<br/>E. Move ass ts to S3 One Zone infrequent Access (S3 One Zone&#8211;IA) after 30 days<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample580' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_71'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_46'>Random</a></p><div class='collapse' id='collapseExample580'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Configure an S3 Lifecycle policy to clean up expired object delete markers
<br><b>D. </b>Move ass ts to S3 Standard-Infrequent Access (S3 Standard-iA) after 30 days</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 45%;" aria-valuenow="45" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_71><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 71</p><br/>A company is using Amazon CloudFront with its website.<br/><br/>The company has enabled logging on the CloudFront distribution, and logs are saved in one of the company's Amazon S3 buckets.<br/><br/>The company needs to perform advanced analysis on the logs and build visualizations.<br/><br/>What should a solutions architect do to meet these requirements?<br/><br/>A. Use standard SQL queries in Amazon Athena to analyze CloudFront logs in the S3 bucket. Visualize the results with AWS Glue.<br/>B. Use standard SQL queries in Amazon Athena to analyze the CloudFront logs in the S3 bucket. Visual the results with Amazon QuickSight.<br/>C. Use standard queries in Amazon DynamoDB to analyze the Cloudfront logs in the S3 bucket. Visualize the results with the AWS Glue.<br/>D. Use standard SQL queries in Amazon DynamoDB to analyze the CloudFront logs in the S3 bucket. Visualize the results with Amazon QuickSight.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample608' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_72'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_64'>Random</a></p><div class='collapse' id='collapseExample608'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Use standard SQL queries in Amazon DynamoDB to analyze the CloudFront logs in the S3 bucket. Visualize the results with Amazon QuickSight.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 45%;" aria-valuenow="45" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_72><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 72</p><br/>A medical records company is hosting an application on Amazon EC2 instances. The application processes customer data files that are stored on Amazon S3. The EC2 instances are hosted in public subnets. The EC2 instances access Amazon S3 over the internet, but they do not require any other network access.<br/><br/>A new requirement mandates that the network traffic for file transfers take a private route and not be sent over the internet.<br/><br/>Which change to the network architecture should a solutions architect recommend to meet this requirement?<br/><br/>A. Create a NAT gateway. Configure the route table for the public subnets to send traffic to Amazon S3 through the NAT gateway.<br/>B. Configure the security group for the EC2 instances to restrict outbound traffic so that only traffic to the S3 prefix list is permitted.<br/>C. Move the EC2 instances to private subnets. Create a VPC endpoint for Amazon S3, and link the endpoint to the route table for the private subnets<br/>D. Remove the internet gateway from the VP<br/>E. Set up an AWS Direct Connect connection, and route traffic to Amazon S3 over the Direct Connect connection.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample472' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_73'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_45'>Random</a></p><div class='collapse' id='collapseExample472'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Move the EC2 instances to private subnets. Create a VPC endpoint for Amazon S3, and link the endpoint to the route table for the private subnets</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 46%;" aria-valuenow="46" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_73><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 73</p><br/>A company has a 143 TB MySQL database that it wants to migrate to AWS. The plan is to use Amazon Aurora MySQL as the platform going forward. The company has a 100 Mbps AWS Direct Connect connection to Amazon VPC.<br/><br/>Which solution meets the company's needs and takes the LEAST amount of time?<br/><br/>A. Use a gateway endpoint for Amazon S3. Migrate the data to Amazon S3. Import the data into Aurora.<br/>B. Upgrade the Direct Connect link to 500 Mbps. Copy the data to Amazon S3. Import the data into Aurora.<br/>C. Order an AWS Snowmobile and copy the database backup to it. Have AWS import the data into Amazon S3. Import the backup into Aurora.<br/>D. Order four 50&#8211;TB AWS Snowball devices and copy the database backup onto them. Have AWS import the data into Amazon S3. Import the data into Aurora.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample130' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_74'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_130'>Random</a></p><div class='collapse' id='collapseExample130'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Order four 50-TB AWS Snowball devices and copy the database backup onto them. Have AWS import the data into Amazon S3. Import the data into Aurora.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 47%;" aria-valuenow="47" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_74><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 74</p><br/>A company uses Amazon S3 for storing a variety of files.<br/><br/>A solutions architect needs to design a feature that will allow users to instantly restore any deleted files within 30 days of deletion.<br/><br/>Which is the MOST cost&#8211;efficient solution?<br/><br/>A. Create lifecycle policies that move the objects to Amazon S3 Glacier and delete them after 30 days<br/>B. Enable Cross&#8211;Region Replication Empty the replica bucket every 30 days using an AWS Lambda function<br/>C. Enable versioning and create a lifecycle policy to remove expired versions after 30 days.<br/>D. Enable versioning and MFA Delete Using a Lambda function remove MFA Delete from objects more than 30 days old<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample626' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_75'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_68'>Random</a></p><div class='collapse' id='collapseExample626'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Create lifecycle policies that move the objects to Amazon S3 Glacier and delete them after 30 days</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 47%;" aria-valuenow="47" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_75><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 75</p><br/>A media company stores video content in an Amazon Elastic Block Store (Amazon EBS) volume. A certain video file has become popular and a large number of users across the world are accessing this content.<br/><br/>This has resulted in a cost increase.<br/><br/>Which action will DECREASE cost without compromising user accessibility?<br/><br/>A. Change the EBS volume to Provisioned IOPS (PIOPS).<br/>B. Store the video in an Amazon S3 bucket and create an Amazon CloudFront distribution.<br/>C. Split the video into multiple, smaller segments so users are routed to the requested video segments only.<br/>D. Clear an Amazon S3 bucket in each Region and upload the videos so users are routed to the nearest S3 bucket.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample375' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_76'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_19'>Random</a></p><div class='collapse' id='collapseExample375'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Store the video in an Amazon S3 bucket and create an Amazon CloudFront distribution.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 48%;" aria-valuenow="48" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_76><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 76</p><br/>A company built a new VPC with the intention of the hosting Amazon EC2 based workloads on AWS. A solutions architect specified that an Amazon S3 gateway endpoint be created and attached to this new VPC. Once the first Application server is built, developers report that server time out when accessing data stored in the S3 bucket.<br/><br/>Which scenario could be causing this issue? ( Select TWO)<br/><br/>A. The S3 bucket is in a region other than the VPC<br/>B. The endpoint has a policy that blocks the CIDR of the VPC<br/>C. The route to the S3 endpoint is not configured in the route table<br/>D. The access is routed through an internet gateway rather than the endpoint<br/>E. The S3 bucket has a bucket policy that does not allow access to the CIDR of the VPC<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample711' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_77'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_136'>Random</a></p><div class='collapse' id='collapseExample711'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>The route to the S3 endpoint is not configured in the route table
<br><b>E. </b>The S3 bucket has a bucket policy that does not allow access to the CIDR of the VPC</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 49%;" aria-valuenow="49" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_77><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 77</p><br/>A company is running its application in a single region on Amazon EC2 with Amazon Elastic Block Store (Amazon EBS) and S3 as part of the storage design.<br/><br/>What should be done to reduce data transfer costs?<br/><br/>A. Create a copy of the compute environment in another AWS Region<br/>B. Convert the application to run on Lambda@Edge<br/>C. Create an Amazon CloudFront distribution with Amazon S3 as the origin<br/>D. Replicate Amazon S3 data to buckets in AWS Regions closer to the requester<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample659' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_78'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_137'>Random</a></p><div class='collapse' id='collapseExample659'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Create an Amazon CloudFront distribution with Amazon S3 as the origin</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 49%;" aria-valuenow="49" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_78><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 78</p><br/>An application running on AWS generates audit logs of operational activities Compliance requirements mandate that the application retain the logs for 5 years.<br/><br/>How can these requirements be met?<br/><br/>A. Save the togs in an Amazon S3 bucket and enable MFA Delete on the bucket<br/>B. Save the togs In an Amazon Elastic File System (Amazon EFS) volume and use Network File System version 4 (NFSv4) locking with the volume<br/>C. Save the togs in an Amazon S3 Glacier vault and define a vault lock policy<br/>D. Save the logs in an Amazon Elastic Block Store (Amazon EBS) volume and take monthly snapshots<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample567' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_79'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_41'>Random</a></p><div class='collapse' id='collapseExample567'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Save the togs in an Amazon S3 bucket and enable MFA Delete on the bucket</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 50%;" aria-valuenow="50" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_79><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 79</p><br/>A user is storing a large number of objects on AWS S3. The user wants to implement the search functionality among the objects. How can the user achieve this?<br/><br/>A. Use the indexing feature of S3.<br/>B. Tag the objects with the metadata to search on that.<br/>C. Use the query functionality of S3.<br/>D. Make your own DB system which stores the S3 metadata for the search functionality.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample775' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation775' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_80'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_38'>Random</a></p><div class='collapse' id='collapseExample775'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Make your own DB system which stores the S3 metadata for the search functionality.</div></div></div><div class='collapse' id='explanation775'><div class='card card&#45;body'><div>
In Amazon Web Services, AWS S3 does not provide any query facility. To retrieve a specific object the user needs to know the exact bucket/object key. In this case it is recommended to have an own DB system which manages the S3 metadata and key mapping.

References:

Storage Options in the AWS Cloud </div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 50%;" aria-valuenow="50" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_80><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 80</p><br/>A company currently has 250 TB of backup files stored in Amazon S3 in a vendor's proprietary format.<br/><br/>Using a Linux&#8211;based software application provided by the vendor, the company wants to retrieve files from Amazon S3, transform the files to an industry&#8211;standard format, and re&#8211;upload them to Amazon S3. The company wants to minimize the data transfer charges associated with this conversation.<br/><br/>What should a solutions architect do to accomplish this?<br/><br/>A. Install the conversion software as an Amazon S3 batch operation so the data is transformed without leaving Amazon S3.<br/>B. Install the conversion software onto an on&#8211;premises virtual machine. Perform the transformation and reupload the files to Amazon S3 from the virtual machine.<br/>C. Use AWS Snowball Edge devices to export the data and install the conversion software onto the devices. Perform the data transformation and re&#8211;upload the files to Amazon S3 from the Snowball Edge devices.<br/>D. Launch an Amazon EC2 instance in the same Region as Amazon S3 and install the conversion software onto the instance. Perform the transformation and re&#8211;upload the files to Amazon S3 from the EC2 instance.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample122' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_81'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_140'>Random</a></p><div class='collapse' id='collapseExample122'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Launch an Amazon EC2 instance in the same Region as Amazon S3 and install the conversion software onto the instance. Perform the transformation and re-upload the files to Amazon S3 from the EC2 instance.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 51%;" aria-valuenow="51" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_81><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 81</p><br/>A company uses Amazon S3 as its object storage solution. The company has thousands of S3 buckets it uses to store data. Some of the S3 buckets have data that is accessed less frequently than others. A solutions architect found that lifecycle policies are not consistently implemented or are implemented partially, resulting in data being stored in high&#8211;cost storage.<br/><br/>Which solution will lower costs without compromising the availability of objects?<br/><br/>A. Use S3 ACLs.<br/>B. Use Amazon Elastic Block Store (Amazon EBS) automated snapshots.<br/>C. Use S3 Intelligent&#8211;Tiering storage.<br/>D. Use S3 One Zone&#8211;Infrequent Access (S3 One Zone&#8211;IA).<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample374' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_82'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_144'>Random</a></p><div class='collapse' id='collapseExample374'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Use S3 Intelligent-Tiering storage.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 52%;" aria-valuenow="52" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_82><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 82</p><br/>A company's website provides users with downloadable historical performance reports. The website needs a solution that will scale to meet the company's website demands globally. The solution should be cost effective, limit the provisioning of infrastructure resources, and provide the fastest possible response time.<br/><br/>Which combination should a solutions architect recommend to meet these requirements?<br/><br/>A. Amazon CloudFront and Amazon S3<br/>B. AWS Lambda and Amazon DynamoDB<br/>C. Application Load Balancer with Amazon EC2 Auto Scaling<br/>D. Amazon Route 53 with internal Application Load Balancers<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample88' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_83'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_95'>Random</a></p><div class='collapse' id='collapseExample88'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Amazon CloudFront and Amazon S3</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 52%;" aria-valuenow="52" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_83><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 83</p><br/>A photo&#8211;sharing website running on AWS allows users to generate thumbnail images of photos stored in Amazon S3. An Amazon DynamoDB table maintains the locations of photos, and thumbnails are easily re&#8211;created from the originals if they are accidentally deleted.<br/><br/>How should the thumbnail images be stored to ensure the LOWEST cost?<br/><br/>A. Amazon S3 Standard&#8211;Infrequent Access (S3 Standard&#8211;IA) with cross&#8211;region replication<br/>B. Amazon S3<br/>C. Amazon Glacier<br/>D. Amazon S3 with cross&#8211;region replication<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample788' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_84'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_31'>Random</a></p><div class='collapse' id='collapseExample788'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Amazon S3</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 53%;" aria-valuenow="53" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_84><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 84</p><br/>A company has thousands of edge devices that collectively generate 1 TB of status alerts each day. Each alert is approximately 2 KB in size. A solutions architect needs to implement a solution to ingest and store the alerts for future analysis.<br/><br/>The company wants a highly available solution. However, the company needs to minimize costs and does not want to manage additional infrastructure. Additionally, the company wants to keep 14 days of data available for immediate analysis and archive any data older than 14 days.<br/><br/>What is the MOST operationally efficient solution that meets these requirements?<br/><br/>A. Create an Amazon Kinesis Data Firehose delivery stream to ingest the alerts. Configure the Kinesis Data Firehose stream to deliver the alerts to an Amazon S3 bucket. Set up an S3 Lifecycle configuration to transition data to Amazon S3 Glacier after 14 days.<br/>B. Launch Amazon EC2 instances across two Availability Zones and place them behind an Elastic Load Balancer to ingest the alerts. Create a script on the EC2 instances that will store the alerts in an Amazon S3 bucket. Set up an S3 Lifecycle configuration to transition data to Amazon S3 Glacier after 14 days.<br/>C. Create an Amazon Kinesis Data Firehose delivery stream to ingest the alerts. Configure the Kinesis Data Firehose stream to deliver the alerts to an Amazon Elasticsearch Service (Amazon ES) cluster. Set up the Amazon ES cluster to take manual snapshots every day and delete data from the cluster that is older than 14 days.<br/>D. Create an Amazon Simple Queue Service (Amazon SQS) standard queue to ingest the alerts, and set the message retention period to 14 days. Configure consumers to poll the SQS queue, check the age of the message, and analyze the message data as needed. If the message is 14 days old, the consumer should copy the message to an Amazon S3 bucket and delete the message from the SQS queue.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample307' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_85'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_121'>Random</a></p><div class='collapse' id='collapseExample307'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Create an Amazon Kinesis Data Firehose delivery stream to ingest the alerts. Configure the Kinesis Data Firehose stream to deliver the alerts to an Amazon S3 bucket. Set up an S3 Lifecycle configuration to transition data to Amazon S3 Glacier after 14 days.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 54%;" aria-valuenow="54" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_85><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 85</p><br/>A company is planning to migrate a business&#8211;critical dataset to Amazon S3. The current solution design uses a single S3 bucket in the us&#8211;east&#8211;1 Region with versioning enabled to store the dataset. The company's disaster recovery policy states that all data multiple AWS Regions.<br/><br/>How should a solutions architect design the S3 solution?<br/><br/>A. Create an additional S3 bucket in another Region and configure cross&#8211;Region replication.<br/>B. Create an additional S3 bucket in another Region and configure cross&#8211;origin resource sharing (CORS).<br/>C. Create an additional S3 bucket with versioning in another Region and configure cross&#8211;Region replication.<br/>D. Create an additional S3 bucket with versioning in another Region and configure cross&#8211;origin resource (CORS).<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample13' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation13' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_86'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_152'>Random</a></p><div class='collapse' id='collapseExample13'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Create an additional S3 bucket with versioning in another Region and configure cross-Region replication.</div></div></div><div class='collapse' id='explanation13'><div class='card card&#45;body'><div>
Replication enables automatic, asynchronous copying of objects across Amazon S3 buckets. Buckets that are configured for object replication can be owned by the same AWS account or by different accounts. You can copy objects between different AWS Regions or within the same Region. Both source and destination buckets must have versioning enabled.

CORRECT: "Create an additional S3 bucket with versioning in another Region and configure cross-Region replication" is the correct answer.

INCORRECT: "Create an additional S3 bucket in another Region and configure cross-Region replication" is incorrect as the destination bucket must also have versioning enabled.

INCORRECT: "Create an additional S3 bucket in another Region and configure cross-origin resource sharing (CORS)" is incorrect as CORS is not related to replication.

INCORRECT: "Create an additional S3 bucket with versioning in another Region and configure cross-origin resource sharing (CORS)" is incorrect as CORS is not related to replication.

References:
Amazon Simple Storage Service > User Guide > Replicating objects
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 54%;" aria-valuenow="54" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_86><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 86</p><br/>Much of your company's data does not need to be accessed often, and can take several hours for retrieval time, so it's stored on Amazon Glacier. However someone within your organization has expressed concerns that his data is more sensitive than the other data, and is wondering whether the high level of encryption that he knows is on S3 is also used on the much cheaper Glacier service.<br/><br/>Which of the following statements would be most applicable in regards to this concern?<br/><br/>A. There is no encryption on Amazon Glacier, that's why it is cheaper.<br/>B. Amazon Glacier automatically encrypts the data using AES&#8211;128 a lesser encryption method than Amazon S3 but you can change it to AES&#8211;256 if you are willing to pay more.<br/>C. Amazon Glacier automatically encrypts the data using AES&#8211;256, the same as Amazon S3.<br/>D. Amazon Glacier automatically encrypts the data using AES&#8211;128 a lesser encryption method than Amazon S3.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample741' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation741' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_87'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_103'>Random</a></p><div class='collapse' id='collapseExample741'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Amazon Glacier automatically encrypts the data using AES-256, the same as Amazon S3.</div></div></div><div class='collapse' id='explanation741'><div class='card card&#45;body'><div>
Like Amazon S3, the Amazon Glacier service provides low-cost, secure, and durable storage. But where S3 is designed for rapid retrieval, Glacier is meant to be used as an archival service for data that is not accessed often, and for which retrieval times of several hours are suitable.

Amazon Glacier automatically encrypts the data using AES-256 and stores it durably in an immutable form. Amazon Glacier is designed to provide average annual durability of 99.999999999% for an archive. It stores each archive in multiple facilities and multiple devices. Unlike traditional systems which can require laborious data verification and manual repair, Glacier performs regular, systematic data integrity checks, and is built to be automatically self-healing.

References:

Amazon Web Services: Overview of Security Processes
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 55%;" aria-valuenow="55" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_87><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 87</p><br/>A company is managing health records on&#8211;premises. The company must keep these records indefinitely, disable any modifications to the records once they are stored, and granularly audit access at all levels. The chief technology officer (CTO) is concerned because there are already millions of records not being used by any application, and the current infrastructure is running out of space. The CTO has requested a solutions architect design a solution to move existing data and support future records.<br/><br/>Which services can the solutions architect recommend to meet these requirements?<br/><br/>A. Use AWS DataSync to move existing data to AWS. Use Amazon S3 to store existing and new data. Enable Amazon S3 object lock and enable AWS CloudTrail with data events.<br/>B. Use AWS Storage Gateway to move existing data to AWS. Use Amazon S3 to store existing and new data. Enable Amazon S3 object lock and enable AWS CloudTrail with management events.<br/>C. Use AWS DataSync to move existing data to AWS. Use Amazon S3 to store existing and new data. Enable Amazon S3 object lock and enable AWS CloudTrail with management events.<br/>D. Use AWS Storage Gateway to move existing data to AWS. Use Amazon Elastic Block Store (Amazon EBS) to store existing and new data. Enable Amazon S3 object lock and enable Amazon S3 server access logging.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample45' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation45' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_88'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_129'>Random</a></p><div class='collapse' id='collapseExample45'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Use AWS DataSync to move existing data to AWS. Use Amazon S3 to store existing and new data. Enable Amazon S3 object lock and enable AWS CloudTrail with data events.</div></div></div><div class='collapse' id='explanation45'><div class='card card&#45;body'><div>
Keyword: Move existing data and support future records + Granular audit access at all levels

Use AWS DataSync to migrate existing data to Amazon S3, and then use the File Gateway configuration of AWS Storage Gateway to retain access to the migrated data and for ongoing updates from your on-premises file-based applications.

Need a solution to move existing data and support future records = AWS DataSync should be used for migration.

Need granular audit access at all levels = Data Events should be used in CloudTrail, Management Events is enabled by default.

CORRECT: "Use AWS DataSync to move existing data to AWS. Use Amazon S3 to store existing and new data. Enable Amazon S3 object lock and enable AWS CloudTrail with data events" is the correct answer.

INCORRECT: "Use AWS Storage Gateway to move existing data to AWS. Use Amazon S3 to store existing and new data. Enable Amazon S3 object lock and enable AWS CloudTrail with management events" is incorrect as "current infrastructure is running out of space" INCORRECT: "Use AWS DataSync to move existing data to AWS. Use Amazon S3 to store existing and new data. Enable Amazon S3 object lock and enable AWS CloudTrail with management events." is incorrect as "Management Events is enabled by default" INCORRECT: "Use AWS Storage Gateway to move existing data to AWS. Use Amazon Elastic Block Store (Amazon EBS) to store existing and new data. Enable Amazon S3 object lock and enable Amazon S3 server access logging." is incorrect as "current infrastructure is running out of space"

References:

AWS DataSync
AWS CloudTrail
AWS Storage Gateway</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 56%;" aria-valuenow="56" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_88><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 88</p><br/>A company wants to monitor its AWS costs for financial review. The cloud operations team is designing an architecture in the AWS Organizations master account to query AWS Cost and Usage Reports for all member accounts.<br/><br/>The team must run this query once a month and provide a detailed analysis of the bill.<br/><br/>Which solution is the MOST scalable and cost&#8211;effective way to meet these requirements?<br/><br/>A. Enable Cost and Usage Reports in the master account. Deliver reports to Amazon Kinesis. Use Amazon EMR for analysis.<br/>B. Enable Cost and Usage Reports in the master account. Deliver the reports to Amazon S3. Use Amazon Athena for analysis.<br/>C. Enable Cost and Usage Reports for member accounts. Deliver the reports to Amazon S3. Use Amazon Redshift for analysis.<br/>D. Enable Cost and Usage Reports for member accounts. Deliver the reports to Amazon Kinesis. Use Amazon QuicKSight for analysis.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample650' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_89'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_14'>Random</a></p><div class='collapse' id='collapseExample650'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Enable Cost and Usage Reports in the master account. Deliver the reports to Amazon S3. Use Amazon Athena for analysis.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 56%;" aria-valuenow="56" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_89><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 89</p><br/>A company wants to migrate a high performance computing (HPC) application and data from on&#8211;premises to the AWS Cloud. The company uses tiered storage on&#8211;premises with hot high&#8211;performance parallel storage to support the application during periodic runs of the application, and more economical cold storage to hold the data when the application is not actively running.<br/><br/>Which combination of solutions should a solutions architect recommend to support the storage needs of the application? (Choose two.)<br/><br/>A. Amazon S3 for cold data storage<br/>B. Amazon EFS for cold data storage<br/>C. Amazon S3 for high&#8211;performance parallel storage<br/>D. Amazon FSx for Lustre for high&#8211;performance parallel storage<br/>E. Amazon FSx for Windows for high&#8211;performance parallel storage<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample181' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation181' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_90'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_10'>Random</a></p><div class='collapse' id='collapseExample181'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Amazon S3 for cold data storage
<br><b>D. </b>Amazon FSx for Lustre for high-performance parallel storage</div></div></div><div class='collapse' id='explanation181'><div class='card card&#45;body'><div>
Amazon FSx for Lustre makes it easy and cost effective to launch and run the world's most popular high-performance file system. Use it for workloads where speed matters, such as machine learning, high performance computing (HPC), video processing, and financial modeling.

Amazon FSx for Lustre provides a high-performance file system optimized for fast processing of workloads such as machine learning, high-performance computing (HPC), video processing, financial modeling, and electronic design automation (EDA).

These workloads commonly require data to be presented via a fast and scalable file system interface, and typically have data sets stored on long-term data stores like Amazon S3.

Amazon FSx works natively with Amazon S3, making it easy to access your S3 data to run data processing workloads. Your S3 objects are presented as files in your file system, and you can write your results back to S3. This lets you run data processing workloads on FSx for Lustre and store your long-term data on S3 or on-premises data stores.

Therefore, the best combination for this scenario is to use S3 for cold data and FSx for Lustre for the parallel HPC job.

CORRECT: "Amazon S3 for cold data storage" is the correct answer.

CORRECT: "Amazon FSx for Lustre for high-performance parallel storage" is the correct answer. INCORRECT: "Amazon EFS for cold data storage" is incorrect as FSx works natively with S3 which is also more economical.

INCORRECT: "Amazon S3 for high-performance parallel storage" is incorrect as S3 is not suitable for running high-performance computing jobs.

INCORRECT: "Amazon FSx for Windows for high-performance parallel storage" is incorrect as FSx for Lustre should be used for HPC use cases and use cases that require storing data on S3.

References:

Amazon FSx for Lustre


</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 57%;" aria-valuenow="57" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_90><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 90</p><br/>An application is running on Amazon EC2 instances. Sensitive information required for the application is stored in an Amazon S3 bucket. The bucket needs to be protected from internet access while only allowing services within the VPC access to the bucket.<br/><br/>Which combination of actions should solutions archived take to accomplish this? (Choose two.)<br/><br/>A. Create a VPC endpoint for Amazon S3.<br/>B. Enable server access logging on the bucket.<br/>C. Apply a bucket policy to restrict access to the S3 endpoint.<br/>D. Add an S3 ACL to the bucket that has sensitive information.<br/>E. Restrict users using the IAM policy to use the specific bucket.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample76' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation76' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_91'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_15'>Random</a></p><div class='collapse' id='collapseExample76'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Create a VPC endpoint for Amazon S3.
<br><b>C. </b>Apply a bucket policy to restrict access to the S3 endpoint.</div></div></div><div class='collapse' id='explanation76'><div class='card card&#45;body'><div>
ACL is a property at object level not at bucket level. Also by just adding ACL you cant let the services in VPC allow access to the bucket.
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 58%;" aria-valuenow="58" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_91><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 91</p><br/>A company is implementing a data lake solution on Amazon S3. Its security policy mandates that the data stored in Amazon S3 should be encrypted at rest.<br/><br/>Which options can achieve this? (Select TWO.)<br/><br/>A. Use S3 server&#8211;side encryption with an Amazon EC2 key pair.<br/>B. Use S3 server&#8211;side encryption with customer&#8211;provided keys (SSE&#8211;C).<br/>C. Use S3 bucket policies to restrict access to the data at rest.<br/>D. Use client&#8211;side encryption before ingesting the data to Amazon S3 using encryption keys.<br/>E. Use SSL to encrypt the data while in transit to Amazon S3.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample787' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_92'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_6'>Random</a></p><div class='collapse' id='collapseExample787'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Use S3 server-side encryption with customer-provided keys (SSE-C).
<br><b>D. </b>Use client-side encryption before ingesting the data to Amazon S3 using encryption keys.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 58%;" aria-valuenow="58" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_92><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 92</p><br/>A company hosts more than 300 global websites and applications. The company requires a platform to analyze more than 30 TB of clickstream data each day. What should a solutions architect do to transmit and process the clickstream data?<br/><br/>A. Design an AWS Data Pipeline to archive the data to an Amazon S3 bucket and run an Amazon EMR cluster with the data to generate analytics.<br/>B. Create an Auto Scaling group of Amazon EC2 instances to process the data and send it to an Amazon S3 data lake for Amazon Redshift to use for analysis.<br/>C. Cache the data to Amazon CloudFront. Store the data in an Amazon S3 bucket. When an object is added to the S3 bucket, run an AWS Lambda function to process the data for analysis.<br/>D. Collect the data from Amazon Kinesis Data Streams. Use Amazon Kinesis Data firehose to transmit the data to an Amazon S3 data lake. Load the data in Amazon Redshift for analysis.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample299' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_93'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_123'>Random</a></p><div class='collapse' id='collapseExample299'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Cache the data to Amazon CloudFront. Store the data in an Amazon S3 bucket. When an object is added to the S3 bucket, run an AWS Lambda function to process the data for analysis.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 59%;" aria-valuenow="59" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_93><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 93</p><br/>A company is hosting multiple websites for several lines of business under its registered parent domain.<br/><br/>Users accessing these websites will be routed to appropriate backend Amazon EC2 instances based on the subdomain. The websites host static webpages, images, and server&#8211;side scripts like PHP and JavaScript. Some of the websites experience peak access during the first two hours of business with constant usage throughout the rest of the day. A solutions architect needs to design a solution that will automatically adjust capacity to these traffic patterns while keeping costs low.<br/><br/>Which combination of AWS services or features will meet these requirements? (Choose two.)<br/><br/>A. AWS Batch<br/>B. Network Load Balancer<br/>C. Application Load Balancer<br/>D. Amazon EC2 Auto Scaling<br/>E. Amazon S3 website hosting<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample107' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_94'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_67'>Random</a></p><div class='collapse' id='collapseExample107'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Application Load Balancer
<br><b>D. </b>Amazon EC2 Auto Scaling

References:

Amazon Simple Storage Service > User Guide > Hosting a static website using Amazon S3</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 60%;" aria-valuenow="60" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_94><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 94</p><br/>A company wants to run a static website served through Amazon CloudFront.<br/><br/>What is an advantage of storing the website content in an Amazon S3 bucket instead of an Amazon Elastic Block Store (Amazon EBS) volume?<br/><br/>A. S3 buckets are replicated globally, allowing for large scalability. EBS volumes are replicated only within an AWS Region.<br/>B. S3 is an origin for CloudFront. EBS volumes would need EC2 instances behind an Elastic Load Balancing load balancer to be an origin<br/>C. S3 buckets can be encrypted, allowing for secure storage of the web files. EBS volumes cannot be encrypted.<br/>D. S3 buckets support object&#8211;level read throttling, preventing abuse. EBS volumes do not provide object&#8211;level throttling.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample538' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_95'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_8'>Random</a></p><div class='collapse' id='collapseExample538'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>S3 is an origin for CloudFront. EBS volumes would need EC2 instances behind an Elastic Load Balancing load balancer to be an origin</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 60%;" aria-valuenow="60" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_95><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 95</p><br/>A company has an application mat provides marketing services to stores. The services are based on previous purchases by store customers.<br/><br/>The stores upload transaction data to the company through SFTP, and the data is processed and analyzed to generate new marketing offers.<br/><br/>Some of the files can exceed 200 GB in size.<br/><br/>Recently, the company discovered that some of the stores have uploaded tiles that contain personally identifiable information (PII) mat should not have been included.<br/><br/>The company wants administrators to be alerted if Pll is shared again. The company also wants to automate remediation.<br/><br/>What should a solutions architect do to meet these requirements with the LEAS F development effort?<br/><br/>A. Use an Amazon S3 bucket as a secure transfer point Use Amazon inspector to scan the objects in the bucket If objects contain Pll, trigger an S3 Lifecycle policy to remove the objects that contain Pll.<br/>B. Use an Amazon S3 bucket as a secure transfer point Use Amazon Macie to scan the objects in the bucket If objects contain Pll, use Amazon Simple Notification Service (Amazon SNS) to trigger a notification to the administrators to remove the objects that contain Pll.<br/>C. Implement custom scanning algorithms in an AWS Lambda function. Trigger the function when objects are loaded into the bucket. If objects contain PLL, use Amazon Simple Notification Service (Amazon SNS) to trigger a notification to the administrators to remove the objects that contain PII.<br/>D. Implement custom scanning algorithms in an AWS Lambda function. Trigger the function when objects are loaded into the bucket. If objects contain Pll, use Amazon Simple Email Service (Amazon SES) to Trigger a notification to the administrators and trigger an S3 Lifecycle policy to remove the objects that contain Pll.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample589' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_96'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_35'>Random</a></p><div class='collapse' id='collapseExample589'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Use an Amazon S3 bucket as a secure transfer point Use Amazon inspector to scan the objects in the bucket If objects contain Pll, trigger an S3 Lifecycle policy to remove the objects that contain Pll.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 61%;" aria-valuenow="61" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_96><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 96</p><br/>A company wants to reduce its Amazon S3 storage costs in its production environment without impacting durability or performance of the stored objects.<br/><br/>What is the FIRST step the company should take to meet these objectives?<br/><br/>A. Enable Amazon Macie on the business&#8211;critical S3 buckets to classify the sensitivity of the objects.<br/>B. Enable S3 analytics to identify S3 buckets that are candidates for transitioning to S3 Standard&#8211; Infrequent Access (S3 Standard&#8211;IA).<br/>C. Enable versioning on all business&#8211;critical S3 buckets.<br/>D. Migrate the objects in all S3 buckets to S3 Intelligent&#8211;Tiering.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample366' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_97'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_88'>Random</a></p><div class='collapse' id='collapseExample366'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Migrate the objects in all S3 buckets to S3 Intelligent-Tiering.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 61%;" aria-valuenow="61" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_97><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 97</p><br/>A company runs an application using Amazon ECS. The application creates resized versions of an original image and then makes Amazon S3 API calls to store the resized images in Amazon S3. How can a solutions architect ensure that the application has permission to access Amazon S3?<br/><br/>A. Update the S3 role in AWS IAM to allow read/write access from Amazon ECS, and then relaunch the container.<br/>B. Create an IAM role with S3 permissions, and then specify that role as the taskRoleArn in the task definition.<br/>C. Create a security group that allows access from Amazon ECS to Amazon S3, and update the launch configuration used by the ECS cluster.<br/>D. Create an IAM user with S3 permissions, and then relaunch the Amazon EC2 instances for the ECS cluster while logged in as this account.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample204' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_98'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_49'>Random</a></p><div class='collapse' id='collapseExample204'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Create an IAM role with S3 permissions, and then specify that role as the taskRoleArn in the task definition.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 62%;" aria-valuenow="62" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_98><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 98</p><br/>A data science team requires storage for nightly log processing. The size and number of logs is unknown and will persist for 24 hours only.<br/><br/>What is the MOST cost&#8211;effective solution?<br/><br/>A. Amazon S3 Glacier<br/>B. Amazon S3 Standard<br/>C. Amazon S3 Intelligent&#8211;Tiering<br/>D. Amazon S3 One Zone&#8211;Infrequent Access (S3 One Zone&#8211;IA)<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample30' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation30' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_99'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_28'>Random</a></p><div class='collapse' id='collapseExample30'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Amazon S3 Standard</div></div></div><div class='collapse' id='explanation30'><div class='card card&#45;body'><div>
The S3 Intelligent-Tiering storage class is designed to optimize costs by automatically moving data to the most cost-effective access tier, without performance impact or operational overhead. It works by storing objects in two access tiers: one tier that is optimized for frequent access and another lower-cost tier that is optimized for infrequent access. This is an ideal use case for intelligent-tiering as the access patterns for the log files are not known.

CORRECT: "S3 Intelligent-Tiering" is the correct answer.

INCORRECT: "S3 Standard-Infrequent Access (S3 Standard-IA)" is incorrect as if the data is accessed often retrieval fees could become expensive.

INCORRECT: "S3 One Zone-Infrequent Access (S3 One Zone-IA)" is incorrect as if the data is accessed often retrieval fees could become expensive.

INCORRECT: "S3 Glacier" is incorrect as if the data is accessed often retrieval fees could become expensive. Glacier also requires more work in retrieving the data from the archive and quick access requirements can add further costs.

References:

Unknown or changing access</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 63%;" aria-valuenow="63" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_99><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 99</p><br/>A solutions architect is designing a solution where users will be directed to a backup static error page if the primary website is unavailable. The primary website's DNS records are hosted in Amazon Route 53 where their domain is pointing to an Application Load Balancer (ALB).<br/><br/>Which configuration should the solutions architect use to meet the company's needs while minimizing changes and infrastructure overhead?<br/><br/>A. Point a Route 53 alias record to an Amazon CloudFront distribution with the ALB as one of its origins. Then, create custom error pages for the distribution.<br/>B. Set up a Route 53 active&#8211;passive failover configuration. Direct traffic to a static error page hosted within an Amazon S3 bucket when Route 53 health checks determine that the ALB endpoint is unhealthy.<br/>C. Update the Route 53 record to use a latency&#8211;based routing policy. Add the backup static error page hosted within an Amazon S3 bucket to the record so the traffic is sent to the most responsive endpoints.<br/>D. Set up a Route 53 active&#8211;active configuration with the ALB and an Amazon EC2 instance hosting a static error page as endpoints. Route 53 will only send requests to the instance if the health checks fail for the ALB.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample177' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation177' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_100'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_107'>Random</a></p><div class='collapse' id='collapseExample177'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Set up a Route 53 active-passive failover configuration. Direct traffic to a static error page hosted within an Amazon S3 bucket when Route 53 health checks determine that the ALB endpoint is unhealthy.</div></div></div><div class='collapse' id='explanation177'><div class='card card&#45;body'><div>
Active-passive failover
Use an active-passive failover configuration when you want a primary resource or group of resources to be available the majority of the time and you want a secondary resource or group of resources to be on standby in case all the primary resources become unavailable. When responding to queries, Route 53 includes only the healthy primary resources. If all the primary resources are unhealthy, Route 53 begins to include only the healthy secondary resources in response to DNS queries.

To create an active-passive failover configuration with one primary record and one secondary record, you just create the records and specify Failover for the routing policy. When the primary resource is healthy, Route 53 responds to DNS queries using the primary record. When the primary resource is unhealthy, Route 53 responds to DNS queries using the secondary record.

How Amazon Route 53 averts cascading failures
As the first defense against cascading failures, each request routing algorithm (such as weighted and failover) has a mode of last resort. In this special mode, when all records are considered unhealthy, the Route 53 algorithm reverts to considering all records healthy.

For example, if all instances of an application, on several hosts, are rejecting health check requests, Route 53 DNS servers will choose an answer anyway and return it rather than returning no DNS answer or returning an NXDOMAIN (non-existent domain) response. An application can respond to users but still fail health checks, so this provides some protection against misconfiguration.

Similarly, if an application is overloaded, and one out of three endpoints fails its health checks, so that it's excluded from Route 53 DNS responses, Route 53 distributes responses between the two remaining endpoints. If the remaining endpoints are unable to handle the additional load and they fail, Route 53 reverts to distributing requests to all three endpoints.

Using Amazon CloudFront as the front-end provides the option to specify a custom message instead of the default message. To specify the specific file that you want to return and the errors for which the file should be returned, you update your CloudFront distribution to specify those values.

For example, the following is a customized error message:

The CloudFront distribution can use the ALB as the origin, which will cause the website content to be cached on the CloudFront edge caches.

This solution represents the most operationally efficient choice as no action is required in the event of an issue, other than troubleshooting the root cause.

References:

Amazon CloudFront > Developer Guide > What is Amazon CloudFront?</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 63%;" aria-valuenow="63" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_100><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 100</p><br/>A solutions architect is planning the deployment of a new static website. The solution must minimize costs and provide at least 99% availability. Which solution meets these requirements?<br/><br/>A. Deploy the application to an Amazon S3 bucket in one AWS Region that has versioning disabled.<br/>B. Deploy the application to Amazon EC2 instances that run in two AWS Regions and two Availability Zones.<br/>C. Deploy the application to an Amazon S3 bucket that has versioning and cross&#8211;Region replication enabled.<br/>D. Deploy the application to an Amazon EC2 instance that runs in one AWS Region and one Availability Zone.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample336' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_101'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_96'>Random</a></p><div class='collapse' id='collapseExample336'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Deploy the application to an Amazon S3 bucket in one AWS Region that has versioning disabled.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 64%;" aria-valuenow="64" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_101><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 101</p><br/>A manufacturing company wants to implement predictive maintenance on its machinery equipment. The company will install thousands of IoT sensors that will send data to AWS in real time. A solutions architect is tasked with implementing a solution that will receive events in an ordered manner for each machinery asset and ensure that data is saved for further processing at a later time.<br/><br/>Which solution would be MOST efficient?<br/><br/>A. Use Amazon Kinesis Data Streams for real&#8211;time events with a partition for each equipment asset. Use Amazon Kinesis Data Firehose to save data to Amazon S3.<br/>B. Use Amazon Kinesis Data Streams for real&#8211;time events with a shard for each equipment asset. Use Amazon Kinesis Data Firehose to save data to Amazon EBS.<br/>C. Use an Amazon SQS FIFO queue for real&#8211;time events with one queue for each equipment asset. Trigger an AWS Lambda function for the SQS queue to save data to Amazon EFS.<br/>D. Use an Amazon SQS standard queue for real&#8211;time events with one queue for each equipment asset. Trigger an AWS Lambda function from the SQS queue to save data to Amazon S3.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample146' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation146' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_102'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_30'>Random</a></p><div class='collapse' id='collapseExample146'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Use Amazon Kinesis Data Streams for real-time events with a partition for each equipment asset. Use Amazon Kinesis Data Firehose to save data to Amazon S3.</div></div></div><div class='collapse' id='explanation146'><div class='card card&#45;body'><div>
Amazon SQS Introduces FIFO Queues with Exactly-Once Processing and Lower Prices for Standard Queues

You can now use Amazon Simple Queue Service (SQS) for applications that require messages to be processed in a strict sequence and exactly once using First-in, First-out (FIFO) queues. FIFO queues are designed to ensure that the order in which messages are sent and received is strictly preserved and that each message is processed exactly once.

Amazon SQS is a reliable and highly-scalable managed message queue service for storing messages in transit between application components. FIFO queues complement the existing Amazon SQS standard queues, which offer high throughput, best-effort ordering, and at-least-once delivery. FIFO queues have essentially the same features as standard queues, but provide the added benefits of supporting ordering and exactly-once processing. FIFO queues provide additional features that help prevent unintentional duplicates from being sent by message producers or from being received by message consumers. Additionally, message groups allow multiple separate ordered message streams within the same queue.

Amazon Kinesis Data Streams collect and process data in real time. A Kinesis data stream is a set of shards. Each shard has a sequence of data records. Each data record has a sequence number that is assigned by Kinesis Data Streams. A shard is a uniquely identified sequence of data records in a stream.

A partition key is used to group data by shard within a stream. Kinesis Data Streams segregates the data records belonging to a stream into multiple shards. It uses the partition key that is associated with each data record to determine which shard a given data record belongs to.

For this scenario, the solutions architect can use a partition key for each device. This will ensure the records for that device are grouped by shard and the shard will ensure ordering. Amazon S3 is a valid destination for saving the data records.

CORRECT: "Use Amazon Kinesis Data Streams for real-time events with a partition key for each device. Use Amazon Kinesis Data Firehose to save data to Amazon S3" is the correct answer.

INCORRECT: "Use Amazon Kinesis Data Streams for real-time events with a shard for each device. Use Amazon Kinesis Data Firehose to save data to Amazon EBS" is incorrect as you cannot save data to EBS from Kinesis.

INCORRECT: "Use an Amazon SQS FIFO queue for real-time events with one queue for each device. Trigger an AWS Lambda function for the SQS queue to save data to Amazon EFS" is incorrect as SQS is not the most efficient service for streaming, real time data.

INCORRECT: "Use an Amazon SQS standard queue for real-time events with one queue for each device. Trigger an AWS Lambda function from the SQS queue to save data to Amazon S3" is incorrect as SQS is not the most efficient service for streaming, real time data.

References:

Amazon Kinesis Data Streams > Developer Guide > Amazon Kinesis Data Streams Terminology and Concepts</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 65%;" aria-valuenow="65" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_102><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 102</p><br/>A leasing company generates and emails PDF statements every month for all its customers. Each statement is about 400 KB in size.<br/><br/>Customers can download their statements from the website for up to 30 days from when the statements were generated. At the end of their 3&#8211;year lease, the customers are emailed a ZIP file that contains all the statements.<br/><br/>What is the MOST cost&#8211;effective storage solution for this situation?<br/><br/>A. Store the statements using the Amazon S3 Standard storage class. Create a lifecycle policy to move the statements to Amazon S3 Glacier storage after 1 day.<br/>B. Store the statements using the Amazon S3 Glacier storage class. Create a lifecycle policy to move the statements to Amazon S3 Glacier Deep Archive storage after 30 days.<br/>C. Store the statements using the Amazon S3 Standard storage class. Create a lifecycle policy to move the statements to Amazon S3 One Zone&#8211;Infrequent Access (S3 One Zone&#8211;IA) storage after 30 days.<br/>D. Store the statements using the Amazon S3 Standard&#8211;Infrequent Access (S3 Standard&#8211;IA) storage class. Create a lifecycle policy to move the statements to Amazon S3 Glacier storage after 30 days.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample115' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_103'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_150'>Random</a></p><div class='collapse' id='collapseExample115'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Store the statements using the Amazon S3 Glacier storage class. Create a lifecycle policy to move the statements to Amazon S3 Glacier Deep Archive storage after 30 days.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 65%;" aria-valuenow="65" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_103><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 103</p><br/>A company is building a document storage application on AWS. The application runs on Amazon EC2 instances in multiple Availability Zones. The company requires the document store to be highly available.<br/><br/>The documents need to be returned immediately when requested. The lead engineer has configured the application to use Amazon Elastic Block Store (Amazon EBS) to store the documents, but is willing to consider other options to meet the availability requirement.<br/><br/>What should a solutions architect recommend?<br/><br/>A. Snapshot the EBS volumes regularly and build new volumes using those snapshots in additional Availability Zones.<br/>B. Use Amazon EBS for the EC2 instance root volumes. Configure the application to build the document store on Amazon S3.<br/>C. Use Amazon EBS for the EC2 instance root volumes. Configure the application to build the document store on Amazon S3 Glacier.<br/>D. Use at least three Provisioned IOPS EBS volumes for EC2 instances. Mount the volumes to the EC2 instances in a RAID 5 configuration.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample380' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_104'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_76'>Random</a></p><div class='collapse' id='collapseExample380'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Use Amazon EBS for the EC2 instance root volumes. Configure the application to build the document store on Amazon S3.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 66%;" aria-valuenow="66" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_104><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 104</p><br/>A company has an on&#8211;premises data center that is running out of storage capacity. The company wants to migrate its storage infrastructure to AWS while minimizing bandwidth costs. The solution must allow for immediate retrieval of data at no additional cost.<br/><br/>How can these requirements be met?<br/><br/>A. Deploy Amazon S3 Glacier Vault and enable expedited retrieval. Enable provisioned retrieval capacity for the workload.<br/>B. Deploy AWS Storage Gateway using cached volumes. Use Storage Gateway to store data in Amazon S3 while retaining copies of frequently accessed data subsets locally.<br/>C. Deploy AWS Storage Gateway using stored volumes to store data locally. Use Storage Gateway to asynchronously back up point&#8211;in&#8211;time snapshots of the data to Amazon S3.<br/>D. Deploy AWS Direct Connect to connect with the on&#8211;premises data center. Configure AWS Storage Gateway to store data locally. Use Storage Gateway to asynchronously back up point&#8211;in&#8211;time snapshots of the data to Amazon S3.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample62' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation62' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_105'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_55'>Random</a></p><div class='collapse' id='collapseExample62'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Deploy AWS Storage Gateway using stored volumes to store data locally. Use Storage Gateway to asynchronously back up point-in-time snapshots of the data to Amazon S3.</div></div></div><div class='collapse' id='explanation62'><div class='card card&#45;body'><div>
Volume Gateway provides an iSCSI target, which enables you to create block storage volumes and mount them as iSCSI devices from your on-premises or EC2 application servers. The Volume Gateway runs in either a cached or stored mode:

In the cached mode, your primary data is written to S3, while retaining your frequently accessed data locally in a cache for low-latency access.

In the stored mode, your primary data is stored locally and your entire dataset is available for low-latency access while asynchronously backed up to AWS.
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 67%;" aria-valuenow="67" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_105><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 105</p><br/>A company stores user data in AWS. The data is used continuously with peak usage during business hours.<br/><br/>Access patterns vary, with some data not being used for months at a time.<br/><br/>A solution architect must choose a cost that maintains the highest level of durability while maintaining high availability.<br/><br/>Which storage solution meets these requirements?<br/><br/>A. Amazon S3 Standard<br/>B. Amazon S3 intelligent Tiering<br/>C. Amazon S3 Glacier Deep Archive<br/>D. Amazon S3 One Zone&#8211;Infrequent Access (S3 One Zone&#8211;IA)<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample671' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_106'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_117'>Random</a></p><div class='collapse' id='collapseExample671'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Amazon S3 Standard</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 67%;" aria-valuenow="67" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_106><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 106</p><br/>A healthcare company stores highly sensitive patient records. Compliance requires that multiple copies be stored in different locations. Each record must be stored for 7 years. The company has a service level agreement (SLA) to provide records to government agencies immediately for the first 30 days and then within 4 hours of a request thereafter.<br/><br/>What should a solutions architect recommend?<br/><br/>A. Use Amazon S3 with cross&#8211;Region replication enabled. After 30 days, transition the data to Amazon S3 Glacier using lifecycle policy.<br/>B. Use Amazon S3 with cross&#8211;origin resource sharing (CORS) enabled. After 30 days, transition the data to Amazon S3 Glacier using a lifecycle policy.<br/>C. Use Amazon S3 with cross&#8211;Region replication enabled. After 30 days, transition the data to Amazon S3 Glacier Deep Achieve using a lifecycle policy.<br/>D. Use Amazon S3 with cross&#8211;origin resource sharing (CORS) enabled. After 30 days, transition the data to Amazon S3 Glacier Deep Archive using a lifecycle policy.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample193' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_107'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_90'>Random</a></p><div class='collapse' id='collapseExample193'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Use Amazon S3 with cross-Region replication enabled. After 30 days, transition the data to Amazon S3 Glacier using lifecycle policy.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 68%;" aria-valuenow="68" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_107><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 107</p><br/>A company processes large amounts of data. The output data is stored in Amazon S3 Standard storage in an S3 bucket, where it is analyzed for 1 month. The data must remain immediately accessible after the 1&#8211;month analysis period.<br/><br/>Which storage solution meets these requirements MOST cost&#8211;effectively?<br/><br/>A. Configure an S3 Lifecycle policy to transition the objects to S3 Glacier after 30 days.<br/>B. Configure S3 Intelligent&#8211;Tiering to transition the objects to S3 Glacier after 30 days.<br/>C. Configure an S3 Lifecycle policy to transition the objects to S3 One Zone&#8211;Infrequent Access (S3 One Zone&#8211;IA) after 30 days.<br/>D. Configure an S3 Lifecycle policy to delete the objects after 30 days. Enable versioning on the S3 bucket so that deleted objects can still be immediately restored as needed.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample442' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_108'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_89'>Random</a></p><div class='collapse' id='collapseExample442'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Configure S3 Intelligent-Tiering to transition the objects to S3 Glacier after 30 days.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 69%;" aria-valuenow="69" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_108><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 108</p><br/>A company has application running on Amazon EC2 instances in a VPC. One of the applications needs to call an Amazon S3 API to store and read objects. The company's security policies restrict any internet&#8211;bound traffic from the applications.<br/><br/>Which action will fulfill these requirements and maintain security?<br/><br/>A. Configure an S3 interface endpoint.<br/>B. Configure an S3 gateway endpoint.<br/>C. Create an S3 bucket in a private subnet.<br/>D. Create an S3 bucket in the same Region as the EC2 instance.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample14' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation14' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_109'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_60'>Random</a></p><div class='collapse' id='collapseExample14'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Configure an S3 gateway endpoint.</div></div></div><div class='collapse' id='explanation14'><div class='card card&#45;body'><div>
VPC endpoints: A VPC endpoint enables you to privately connect your VPC to supported AWS services and VPC endpoint services powered by AWS PrivateLink without requiring an internet gateway, NAT device, VPN connection, or AWS Direct Connect connection. Instances in your VPC do not require public IP addresses to communicate with resources in the service. Traffic between your VPC and the other service does not leave the Amazon network.

An interface endpoint is an elastic network interface with a private IP address from the IP address range of your subnet that serves as an entry point for traffic destined to a supported service. Interface endpoints are powered by AWS PrivateLink, a technology that enables you to privately access services by using private IP addresses. AWS PrivateLink restricts all network traffic between your VPC and services to the Amazon network. You do not need an internet gateway, a NAT device, or a virtual private gateway.

References:

Amazon Virtual Private Cloud > AWS PrivateLink > Endpoints for Amazon S3
Amazon Virtual Private Cloud > AWS PrivateLink > Gateway VPC endpoints</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 69%;" aria-valuenow="69" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_109><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 109</p><br/>A company stores call recordings on a monthly basis. Statistically, the recorded data may be referenced randomly within a year but accessed rarely after 1 year. Files that are newer than 1 year old must be queried and retrieved as quickly as possible. A delay in retrieving older files is acceptable. A solutions architect needs to store the recorded data at a minimal cost.<br/><br/>Which solution is MOST cost&#8211;effective?<br/><br/>A. Store individual files in Amazon S3 Glacier and store search metadata in object tags created in S3 Glacier Query S3 Glacier tags and retrieve the files from S3 Glacier.<br/>B. Store individual files in Amazon S3. Use lifecycle policies to move the files to Amazon S3 Glacier after1 year. Query and retrieve the files from Amazon S3 or S3 Glacier.<br/>C. Archive individual files and store search metadata for each archive in Amazon S3. Use lifecycle policies to move the files to Amazon S3 Glacier after 1 year. Query and retrieve the files by searching for metadata from Amazon S3.<br/>D. Archive individual files in Amazon S3. Use lifecycle policies to move the files to Amazon S3 Glacier after 1 year. Store search metadata in Amazon DynamoDB. Query the files from DynamoDB and retrieve them from Amazon S3 or S3 Glacier.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample339' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_110'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_17'>Random</a></p><div class='collapse' id='collapseExample339'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Store individual files in Amazon S3. Use lifecycle policies to move the files to Amazon S3 Glacier after1 year. Query and retrieve the files from Amazon S3 or S3 Glacier.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 70%;" aria-valuenow="70" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_110><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 110</p><br/>A solutions architect is tasked with transferring 750 TB of data from a network&#8211;attached file system located at a branch office Amazon S3 Glacier. The solution must avoid saturating the branch office's low&#8211;bandwidth internet connection.<br/><br/>What is the MOST cost&#8211;effective solution?<br/><br/>A. Create a site&#8211;to&#8211;site VPN tunnel to an Amazon S3 bucket and transfer the files directly. Create a bucket policy to enforce a VPC endpoint.<br/>B. Order 10 AWS Snowball appliances and select an S3 Glacier vault as the destination. Create a bucket policy to enforce a VPC endpoint.<br/>C. Mount the network&#8211;attached file system to Amazon S3 and copy the files directly. Create a lifecycle policy to transition the S3 objects to Amazon S3 Glacier.<br/>D. Order 10 AWS Snowball appliances and select an Amazon S3 bucket as the destination. Create a lifecycle policy to transition the S3 objects to Amazon S3 Glacier.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample33' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation33' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_111'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_33'>Random</a></p><div class='collapse' id='collapseExample33'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Order 10 AWS Snowball appliances and select an Amazon S3 bucket as the destination. Create a lifecycle policy to transition the S3 objects to Amazon S3 Glacier.</div></div></div><div class='collapse' id='explanation33'><div class='card card&#45;body'><div>
Regional Limitations for AWS Snowball
The AWS Snowball service has two device types, the standard Snowball and the Snowball Edge. The following table highlights which of these devices are available in which regions.

The following table highlights which of these devices are available in which regions.

The following table highlights which of these devices are available in which regions.

Limitations on Jobs in AWS Snowball

The following limitations exist for creating jobs in AWS Snowball:

For security purposes, data transfers must be completed within 90 days of the Snowball being prepared.

Currently, AWS Snowball Edge device doesn't support server-side encryption with customer-provided keys (SSE-C). AWS Snowball Edge device does support server-side encryption with Amazon S3–managed encryption keys (SSE-S3) and server-side encryption with AWS Key Management Service – managed keys (SSE-KMS). For more information, see Protecting Data Using Server-Side Encryption in the Amazon Simple Storage Service Developer Guide.

In the US regions, Snowballs come in two sizes: 50 TB and 80 TB. All other regions have the 80 TB Snowballs only. If you're using Snowball to import data, and you need to transfer more data than will fit on a single Snowball, create additional jobs. Each export job can use multiple Snowballs.

The default service limit for the number of Snowballs you can have at one time is 1. If you want to increase your service limit, contact AWS Support.

All objects transferred to the Snowball have their metadata changed. The only metadata that remains the same is filename and filesize. All other metadata is set as in the following example: -rw-rw-r– 1 root root [filesize] Dec 31 1969 [path/filename].

Object lifecycle management
To manage your objects so that they are stored cost effectively throughout their lifecycle, configure their Amazon S3 Lifecycle. An S3 Lifecycle configuration is a set of rules that define actions that Amazon S3 applies to a group of objects. There are two types of actions:

Transition actions – Define when objects transition to another storage class. For example, you might choose to transition objects to the S3 Standard-IA storage class 30 days after you created them, or archive objects to the S3 Glacier storage class one year after creating them.

Expiration actions – Define when objects expire. Amazon S3 deletes expired objects on your behalf. The lifecycle expiration costs depend on when you choose to expire objects.

As the company's internet link is low-bandwidth uploading directly to Amazon S3 (ready for transition to Glacier) would saturate the link. The best alternative is to use AWS Snowball appliances. The Snowball Edge appliance can hold up to 75 TB of data so 10 devices would be required to migrate 750 TB of data.

Snowball moves data into AWS using a hardware device and the data is then copied into an Amazon S3 bucket of your choice. From there, lifecycle policies can transition the S3 objects to Amazon S3 Glacier.

CORRECT: "Order 10 AWS Snowball appliances and select an Amazon S3 bucket as the destination. Create a lifecycle policy to transition the S3 objects to Amazon S3 Glacier" is the correct answer.

INCORRECT: "Order 10 AWS Snowball appliances and select an S3 Glacier vault as the destination. Create a bucket policy to enforce a VPC endpoint" is incorrect as you cannot set a Glacier vault as the destination, it must be an S3 bucket. You also can't enforce a VPC endpoint using a bucket policy.

INCORRECT: "Create an AWS Direct Connect connection and migrate the data straight into Amazon Glacier" is incorrect as this is not the most cost-effective option and takes time to setup. INCORRECT: "Use AWS Global Accelerator to accelerate upload and optimize usage of the available bandwidth" is incorrect as this service is not used for accelerating or optimizing the upload of data from on-premises networks.

References:

AWS Snowball Edge Developer Guide > AWS Snowball Edge Specifications</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 70%;" aria-valuenow="70" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_111><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 111</p><br/>A company has an application running on Amazon EC2 instances in a private subnet. The application needs to store and retrieve data in Amazon S3. To reduce costs, the company wants to configure its AWS resources in a cost&#8211;effective manner.<br/><br/>How should the company accomplish this?<br/><br/>A. Deploy a NAT gateway to access the S3 buckets.<br/>B. Deploy AWS Storage Gateway to access the S3 buckets.<br/>C. Deploy an S3 gateway endpoint to access the S3 buckets.<br/>D. Deploy an S3 interface endpoint to access the S3 buckets.<br/><br/><br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample355' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_112'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_54'>Random</a></p><div class='collapse' id='collapseExample355'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Deploy AWS Storage Gateway to access the S3 buckets.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 71%;" aria-valuenow="71" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_112><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 112</p><br/>A company Is creating a new application that will store a large amount of data.<br/><br/>The data will be analyzed hourly and will be modified by several Amazon EC2 Linux instances that are deployed across multiple Availability Zones.<br/><br/>The needed amount of storage space will continue to grow for the next 6 months<br/><br/>Which storage solution should a solutions architect recommend to meet these requirements?<br/><br/>A. Store the data in Amazon S3 Glacier Update the S3 Glacier vault policy to allow access to the application instances.<br/>B. Store the data in an Amazon Elastic Block Store (Amazon EBS) volume Mount the EBS volume on the application instances.<br/>C. Store the data in an Amazon Elastic File System (Amazon EFS) file system. Mount the file system on the application instances<br/>D. Store the data in an Amazon Elastic Block Store (Amazon ESS) Provisioned IOPS volume shared between the application instances<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample573' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_113'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_25'>Random</a></p><div class='collapse' id='collapseExample573'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Store the data in Amazon S3 Glacier Update the S3 Glacier vault policy to allow access to the application instances.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 72%;" aria-valuenow="72" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_113><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 113</p><br/>A company is building a cloud storage and sharing application for photos.<br/><br/>Users can upload photos from their computers and mobile phones to be stored durably in the cloud.<br/><br/>After photos are uploaded, most are shared and downloaded frequently for the first 40&#8211;90 days. The photos are generally accessed less often after 90 days but some photos maintain a high access rate.<br/><br/>The application initially stores photos n Amazon S3 Standard.<br/><br/>A solutions architect needs to reduce the application's operational costs without sacrificing user experience or data durability.<br/><br/>Which strategy should the solutions architect use to meet these requirements MOST cost&#8211; effectively?<br/><br/>A. Define an S3 Lifecycle rule to transition objects to S3 Intelligent&#8211;Tiering immediately<br/>B. Define an S3 Lifecycle rule to transition objects from S3 Standard to S3 Glacier after 90 days<br/>C. Define an S3 Lifecycle rule to transition objects from S3 Standard to S3 Standard Infrequent Access (S3 Standard&#8211;IA) after 65 days<br/>D. Define an S3 Lifecycle rule to transition objects from S3 Standard to S3 One Zone&#8211;Infrequent Access (S3 One zone&#8211;IA) after 90 days<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample655' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_114'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_23'>Random</a></p><div class='collapse' id='collapseExample655'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Define an S3 Lifecycle rule to transition objects to S3 Intelligent-Tiering immediately</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 72%;" aria-valuenow="72" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_114><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 114</p><br/>A company is automating an order management application. The company's development team has decided to use SFTP to transfer and store the business&#8211;critical information files. The files must be encrypted and must be highly available. The files also must be automatically deleted a month after they are created.<br/><br/>Which solution meets these requirements with the LEAST operational overhead?<br/><br/>A. Configure an Amazon S3 bucket with encryption enabled. Use AWS transfer for SFTP to securely transfer the files to the S3 bucket Apply an AWS Transfer for SFTP file retention policy to delete the files after a month<br/>B. Install an SFTP service on an Amazon EC2 instance Mount an Amazon Elastic File System (Amazon EFS) file share on the EC2 instance. Enable cron to delete the files after a month<br/>C. Configure an Amazon Elastic File System (Amazon EFS) file system with encryption enabled. Use AWS Transfer for SFTP to securely transfer the files to the EFS file system. Apply an EFS lifecycle policy to automatically delete the files after a month.<br/>D. Configure an Amazon S3 bucket with encryption enabled. Use AWS Transfer for SFTP to securely transfer the files to the S3 bucket. Apply S3 Lifecycle rules to automatically delete the files after a month.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample454' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_115'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_153'>Random</a></p><div class='collapse' id='collapseExample454'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Configure an Amazon S3 bucket with encryption enabled. Use AWS Transfer for SFTP to securely transfer the files to the S3 bucket. Apply S3 Lifecycle rules to automatically delete the files after a month.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 73%;" aria-valuenow="73" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_115><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 115</p><br/>A company uses Amazon S3 to store its confidential audit documents. The S3 bucket uses bucket policies to restrict access to audit team IAM user credentials according to the principle of least privilege. Company managers are worried about accidental deletion of documents in the S3 bucket and want a more secure solution.<br/><br/>What should a solutions architect do to secure the audit documents?<br/><br/>A. Enable the versioning and MFA Delete features on the S3 bucket.<br/>B. Enable multi&#8211;factor authentication (MFA) on the IAM user credentials for each audit team IAM user account.<br/>C. Add an S3 Lifecycle policy to the audit team's IAM user accounts to deny the s3:DeleteObject action during audit dates.<br/>D. Use AWS Key Management Service (AWS KMS) to encrypt the S3 bucket and restrict audit team IAM user accounts from accessing the KMS key.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample287' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_116'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_85'>Random</a></p><div class='collapse' id='collapseExample287'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Enable the versioning and MFA Delete features on the S3 bucket.

References:

Amazon Simple Storage Service > User Guide > Security Best Practices for Amazon S3</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 74%;" aria-valuenow="74" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_116><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 116</p><br/>A Solutions Architect must design a web application that will be hosted on AWS, allowing users to purchase access to premium, shared content that is stored in an S3 bucket. Upon payment, content will be available for download for 14 days before the user is denied access.<br/><br/>Which of the following would be the LEAST complicated implementation?<br/><br/>A. Use an Amazon CloudFront distribution with an origin access identity (OAI). Configure the distribution with an Amazon S3 origin to provide access to the file through signed URLs. Design a Lambda function to remove data that is older than 14 days.<br/>B. Use an S3 bucket and provide direct access to the file. Design the application to track purchases in a DynamoDB table. Configure a Lambda function to remove data that is older than 14 days based on a query to Amazon DynamoDB.<br/>C. Use an Amazon CloudFront distribution with an OAI. Configure the distribution with an Amazon S3 origin to provide access to the file through signed URLs. Design the application to set an expiration of 14 days for the URL.<br/>D. Use an Amazon CloudFront distribution with an OAI. Configure the distribution with an Amazon S3 origin to provide access to the file through signed URLs. Design the application to set an expiration of 60 minutes for the URL and recreate the URL as necessary.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample265' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_117'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_98'>Random</a></p><div class='collapse' id='collapseExample265'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Use an Amazon CloudFront distribution with an OAI. Configure the distribution with an Amazon S3 origin to provide access to the file through signed URLs. Design the application to set an expiration of 14 days for the URL.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 74%;" aria-valuenow="74" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_117><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 117</p><br/>A company is planning to deploy an Amazon RDS DB instance running Amazon Aurora. The company has a backup retention policy requirement of 90 days. Which solution should a solutions architect recommend?<br/><br/>A. Set the backup retention period to 90 days when creating the RDS DB instance.<br/>B. Configure RDS to copy automated snapshots to a user&#8211;managed Amazon S3 bucket with a lifecycle policy set to delete after 90 days.<br/>C. Create an AWS Backup plan to perform a daily snapshot of the RDS database with the retention set to 90 days. Create an AWS Backup job to schedule the execution of the backup plan daily.<br/>D. Use a daily scheduled event with Amazon CloudWatch Events to execute a custom AWS Lambda function that makes a copy of the RDS automated snapshot. Purge snapshots older than 90 days.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample121' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_118'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_127'>Random</a></p><div class='collapse' id='collapseExample121'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Configure RDS to copy automated snapshots to a user-managed Amazon S3 bucket with a lifecycle policy set to delete after 90 days.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 75%;" aria-valuenow="75" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_118><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 118</p><br/>A company is looking for a solution that can store video archives in AWS from old news footage. The company needs to minimize costs and will rarely need to restore these files. When the files are needed, they must be available in a maximum of five minutes.<br/><br/>What is the MOST cost&#8211;effective solution?<br/><br/>A. Store the video archives in Amazon S3 Glacier and use Expedited retrievals.<br/>B. Store the video archives in Amazon S3 Glacier and use Standard retrievals.<br/>C. Store the video archives in Amazon S3 Standard&#8211;Infrequent Access (S3 Standard&#8211;IA).<br/>D. Store the video archives in Amazon S3 One Zone&#8211;Infrequent Access (S3 One Zone&#8211;IA).<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample192' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_119'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_100'>Random</a></p><div class='collapse' id='collapseExample192'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Store the video archives in Amazon S3 Glacier and use Expedited retrievals.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 76%;" aria-valuenow="76" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_119><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 119</p><br/>A company hosts historical weather records in Amazon S3. The records are downloaded from the company's website by a way of a URL that resolves to a domain name. Users all over the world access this content through subscriptions. A third&#8211;party provider hosts the company's root domain name, but the company recently migrated some of its services to Amazon Route 53. The company wants to consolidate contracts, reduce latency for users, and reduce costs related to serving the application to subscribers.<br/><br/>Which solution meets these requirements?<br/><br/>A. Create a web distribution on Amazon CloudFront to serve the S3 content for the application. Create a CNAME record in a Route 53 hosted zone that points to the CloudFront distribution, resolving to the application's URL domain name.<br/>B. Create a web distribution on Amazon CloudFront to serve the S3 content for the application. Create an ALIAS record in the Amazon Route 53 hosted zone that points to the CloudFront distribution, resolving to the application's URL domain name.<br/>C. Create an A record in a Route 53 hosted zone for the application. Create a Route 53 traffic policy for the web application, and configure a geolocation rule. Configure health checks to check the health of the endpoint and route DNS queries to other endpoints if an endpoint is unhealthy.<br/>D. Create an A record in a Route 53 hosted zone for the application. Create a Route 53 traffic policy for the web application, and configure a geoproximity rule. Configure health checks to check the health of the endpoint and route DNS queries to other endpoints if an endpoint is unhealthy.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample250' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_120'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_91'>Random</a></p><div class='collapse' id='collapseExample250'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Create a web distribution on Amazon CloudFront to serve the S3 content for the application. Create an ALIAS record in the Amazon Route 53 hosted zone that points to the CloudFront distribution, resolving to the application's URL domain name.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 76%;" aria-valuenow="76" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_120><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 120</p><br/>A media company has an application that tracks user clicks on its websites and performs analytics to provide near&#8211;real&#8211;time recommendations. The application has a Heel of Amazon EC2 instances that receive data from the websites and send the data to an Amazon RDS DB instance. Another fleet of EC2 instances hosts the portion of the application that is continuously checking changes in the database and executing SQL queries to provide recommendations. Management has requested a redesign to decouple the infrastructure. The solution must ensure that data analysts are writing SQL to analyze the data only No data can the lost during the deployment.<br/><br/>What should a solutions architect recommend?<br/><br/>A. Use Amazon Kinesis Data Streams to capture the data from the websites Kinesis Data Firehose to persist the data on Amazon S3, and Amazon Athena to query the data.<br/>B. Use Amazon Kinesis Data Streams to capture the data from the websites. Kinesis Data Analytics to query the data, and Kinesis Data Firehose to persist the data on Amazon S3.<br/>C. Use Amazon Simple Queue Service (Amazon SQS) to capture the data from the websites, keep the fleet of EC2 instances, and change to a bigger instance type in the Auto Scaling group configuration.<br/>D. Use Amazon Simple Notification Service (Amazon SNS) to receive data from the websites and proxy the messages to AWS Lambda functions that execute the queries and persist the data. Change Amazon RDS to Amazon Aurora Serverless to persist the data.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample409' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_121'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_97'>Random</a></p><div class='collapse' id='collapseExample409'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Use Amazon Kinesis Data Streams to capture the data from the websites. Kinesis Data Analytics to query the data, and Kinesis Data Firehose to persist the data on Amazon S3.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 77%;" aria-valuenow="77" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_121><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 121</p><br/>A company's application hosted on Amazon EC2 instances needs to access an Amazon S3 bucket. Due to data sensitivity, traffic cannot traverse the internet.<br/><br/>How should a solutions architect configure access?<br/><br/>A. Create a private hosted zone using Amazon Route 53.<br/>B. Configure a VPC gateway endpoint for Amazon S3 in the VPC.<br/>C. Configure AWS PrivateLink between the EC2 instance and the S3 bucket.<br/>D. Set up a site&#8211;to&#8211;site VPN connection between the VPC and the S3 bucket.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample66' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_122'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_73'>Random</a></p><div class='collapse' id='collapseExample66'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Configure a VPC gateway endpoint for Amazon S3 in the VPC.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 78%;" aria-valuenow="78" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_122><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 122</p><br/>A company uses Amazon S3 to store its confidential audit documents.<br/><br/>The S3 bucket uses bucket policies to restrict access to audit team 1AM user credentials according to the principle of least privilege.<br/><br/>Company managers are worried about accidental deletion of documents in the S3 bucket and want a more secure solution.<br/><br/>What should a solutions architect do to secure the audit documents?<br/><br/>A. Enable the versioning and MFA Delete features on the S3 bucket<br/>B. Enable multi&#8211;factor authentication (MFA) on the 1AM user credentials for each audit team 1AM user account.<br/>C. Add an S3 Lifecycle policy to the audit team's 1AM user accounts to deny the s3:DeleteOb|ect action during audit dates.<br/>D. Use AWS Key Management Service (AWS KMS) to encrypt the S3 bucket and restrict audit team 1AM user accounts from accessing the KMS key.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample679' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_123'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_124'>Random</a></p><div class='collapse' id='collapseExample679'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Enable the versioning and MFA Delete features on the S3 bucket</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 78%;" aria-valuenow="78" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_123><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 123</p><br/>A company hosts a static website on&#8211;premises and wants to migrate the website to AWS. The website should load as quickly as possible for users around the world. The company also wants the most cost&#8211;effective solution.<br/><br/>What should a solutions architect do to accomplish this?<br/><br/>A. Copy the website content to an Amazon S3 bucket. Configure the bucket to serve static webpage content. Replicate the S3 bucket to multiple AWS Regions.<br/>B. Copy the website content to an Amazon S3 bucket. Configure the bucket to serve static webpage content. Configure Amazon CloudFront with the S3 bucket as the origin.<br/>C. Copy the website content to an Amazon EBS&#8211;backed Amazon EC2 instance running Apache HTTP Server. Configure Amazon Route 53 geolocation routing policies to select the closest origin.<br/>D. Copy the website content to multiple Amazon EBS&#8211;backed Amazon EC2 instances running Apache HTTP Server in multiple AWS Regions. Configure Amazon CloudFront geolocation routing policies to select the closest origin.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample150' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation150' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_124'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_53'>Random</a></p><div class='collapse' id='collapseExample150'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Copy the website content to an Amazon S3 bucket. Configure the bucket to serve static webpage content. Configure Amazon CloudFront with the S3 bucket as the origin.</div></div></div><div class='collapse' id='explanation150'><div class='card card&#45;body'><div>
What Is Amazon CloudFront?
Amazon CloudFront is a web service that speeds up distribution of your static and dynamic web content, such as .html, .css, .js, and image files, to your users. CloudFront delivers your content through a worldwide network of data centers called edge locations. When a user requests content that you're serving with CloudFront, the user is routed to the edge location that provides the lowest latency (time delay), so that content is delivered with the best possible performance.

Using Amazon S3 Buckets for Your Origin
When you use Amazon S3 as an origin for your distribution, you place any objects that you want CloudFront to deliver in an Amazon S3 bucket. You can use any method that is supported by Amazon S3 to get your objects into Amazon S3, for example, the Amazon S3 console or API, or a third-party tool. You can create a hierarchy in your bucket to store the objects, just as you would with any other Amazon S3 bucket.

Using an existing Amazon S3 bucket as your CloudFront origin server doesn't change the bucket in any way; you can still use it as you normally would to store and access Amazon S3 objects at the standard Amazon S3 price. You incur regular Amazon S3 charges for storing the objects in the bucket.

The most cost-effective option is to migrate the website to an Amazon S3 bucket and configure that bucket for static website hosting. To enable good performance for global users the solutions architect should then configure a CloudFront distribution with the S3 bucket as the origin. This will cache the static content around the world closer to users.

CORRECT: "Copy the website content to an Amazon S3 bucket. Configure the bucket to serve static webpage content. Configure Amazon CloudFront with the S3 bucket as the origin" is the correct answer.

INCORRECT: "Copy the website content to an Amazon S3 bucket. Configure the bucket to serve static webpage content. Replicate the S3 bucket to multiple AWS Regions" is incorrect as there is no solution here for directing users to the closest region. This could be a more cost-effective (though less elegant) solution if AWS Route 53 latency records are created.

INCORRECT: "Copy the website content to an Amazon EC2 instance. Configure Amazon Route 53 geolocation routing policies to select the closest origin" is incorrect as using Amazon EC2 instances is less cost-effective compared to hosting the website on S3. Also, geolocation routing does not achieve anything with only a single record.

INCORRECT: "Copy the website content to multiple Amazon EC2 instances in multiple AWS Regions. Configure AWS Route 53 geolocation routing policies to select the closest region" is incorrect as using Amazon EC2 instances is less cost-effective compared to hosting the website on S3.

References:

How do I use CloudFront to serve a static website hosted on Amazon S3?</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 79%;" aria-valuenow="79" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_124><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 124</p><br/>A company's website hosted on Amazon EC2 instances processes classified data stored in Amazon S3. Due to security concerns, the company requires a private and secure connection between its EC2 resources and Amazon S3.<br/><br/>Which solution meets these requirements?<br/><br/>A. Set up S3 bucket policies to allow access from a VPC endpoint.<br/>B. Set up an IAM policy to grant read&#8211;write access to the S3 bucket.<br/>C. Set up a NAT gateway to access resources outside the private subnet.<br/>D. Set up an access key ID and a secret access key to access the S3 bucket.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample678' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_125'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_82'>Random</a></p><div class='collapse' id='collapseExample678'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Set up S3 bucket policies to allow access from a VPC endpoint.

References:

Amazon Simple Storage Service > User Guide > Controlling access from VPC endpoints with bucket policies</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 80%;" aria-valuenow="80" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_125><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 125</p><br/>A web application must persist order data to Amazon S3 to support near&#8211;real&#8211;time processing. A solutions architect needs create an architecture that is both scalable and fault tolerant.<br/><br/>Which solutions meet these requirements? (Select TWO)<br/><br/>A. Write the order event to an Amazon DynamoDB table. Use DynamoDB Streams to trigger an AWS Lambda function that parses the payload and writes the data to Amazon<br/>B. Write the order event to an Amazon Simple Queue Service (Amazon SQS) queue. Use the queue to trigger an AWS Lambda function that parses the payload and writes the data to Amazon S3.<br/>C. Write the order event to an Amazon Simple Notification Service (Amazon SNS) topic. Use the SNS topic to trigger an AWS Lambda function that parses the payload and writes the data to Amazon S3.<br/>D. Write the order event to an Amazon Simple Queue Service (Amazon SQS) queue. Use an Amazon EventBridge (Amazon CloudWatch Events) rule to trigger an AWS Lambda function that parses the payload and writes the data to Amazon S3.<br/>E. Write the order event to an Amazon Simple Notification Service (Amazon SNS) topic. Use an Amazon EventBridge (Amazon CloudWatch Events) rule to trigger an AWS Lambda function that parses the payload and writes the data to Amazon S3.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample692' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_126'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_87'>Random</a></p><div class='collapse' id='collapseExample692'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Write the order event to an Amazon DynamoDB table. Use DynamoDB Streams to trigger an AWS Lambda function that parses the payload and writes the data to Amazon
<br><b>B. </b>Write the order event to an Amazon Simple Queue Service (Amazon SQS) queue. Use the queue to trigger an AWS Lambda function that parses the payload and writes the data to Amazon S3.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 80%;" aria-valuenow="80" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_126><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 126</p><br/>A company requires a durable backup storage solution for its on&#8211;premises database servers while ensuring on&#8211;premises applications maintain access to these backups for quick recovery. The company will use AWS storage services as the destination for these backups. A solutions architect is designing a solution with minimal operational overhead.<br/><br/>Which solution should the solutions architect implement?<br/><br/>A. Deploy an AWS Storage Gateway file gateway on&#8211;premises and associate it with an Amazon S3 bucket.<br/>B. Back up the databases to an AWS Storage Gateway volume gateway and access it using the Amazon S3 API.<br/>C. Transfer the database backup files to an Amazon Elastic Block Store (Amazon EBS) volume attached to an Amazon EC2 instance.<br/>D. Back up the database directly to an AWS Snowball device and use lifecycle rules to move the data to Amazon S3 Glacier Deep Archive.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample93' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation93' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_127'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_139'>Random</a></p><div class='collapse' id='collapseExample93'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Deploy an AWS Storage Gateway file gateway on-premises and associate it with an Amazon S3 bucket.</div></div></div><div class='collapse' id='explanation93'><div class='card card&#45;body'><div>
Network Load Balancer overview

A Network Load Balancer functions at the fourth layer of the Open Systems Interconnection (OSI) model. It can handle millions of requests per second. After the load balancer receives a connection request, it selects a target from the target group for the default rule. It attempts to open a TCP connection to the selected target on the port specified in the listener configuration.

When you enable an Availability Zone for the load balancer, Elastic Load Balancing creates a load balancer node in the Availability Zone. By default, each load balancer node distributes traffic across the registered targets in its Availability Zone only. If you enable cross-zone load balancing, each load balancer node distributes traffic across the registered targets in all enabled Availability Zones. For more information, see Availability Zones.

If you enable multiple Availability Zones for your load balancer and ensure that each target group has at least one target in each enabled Availability Zone, this increases the fault tolerance of your applications. For example, if one or more target groups does not have a healthy target in an Availability Zone, we remove the IP address for the corresponding subnet from DNS, but the load balancer nodes in the other Availability Zones are still available to route traffic. If a client doesn't honor the time-to-live (TTL) and sends requests to the IP address after it is removed from DNS, the requests fail.

For TCP traffic, the load balancer selects a target using a flow hash algorithm based on the protocol, source IP address, source port, destination IP address, destination port, and TCP sequence number. The TCP connections from a client have different source ports and sequence numbers, and can be routed to different targets. Each individual TCP connection is routed to a single target for the life of the connection.

For UDP traffic, the load balancer selects a target using a flow hash algorithm based on the protocol, source IP address, source port, destination IP address, and destination port. A UDP flow has the same source and destination, so it is consistently routed to a single target throughout its lifetime. Different UDP flows have different source IP addresses and ports, so they can be routed to different targets.

An Auto Scaling group contains a collection of Amazon EC2 instances that are treated as a logical grouping for the purposes of automatic scaling and management. An Auto Scaling group also enables you to use Amazon EC2 Auto Scaling features such as health check replacements and scaling policies. Both maintaining the number of instances in an Auto Scaling group and automatic scaling are the core functionality of the Amazon EC2 Auto Scaling service.

The size of an Auto Scaling group depends on the number of instances that you set as the desired capacity. You can adjust its size to meet demand, either manually or by using automatic scaling.

An Auto Scaling group starts by launching enough instances to meet its desired capacity. It maintains this number of instances by performing periodic health checks on the instances in the group. The Auto Scaling group continues to maintain a fixed number of instances even if an instance becomes unhealthy. If an instance becomes unhealthy, the group terminates the unhealthy instance and launches another instance to replace it.
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 81%;" aria-valuenow="81" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_127><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 127</p><br/>A company runs a website on Amazon EC2 instances behind an ELB Application Load Balancer. Amazon Route 53 is used for the DNS. The company wants to set up a backup website with a message including a phone number and email address that users can reach if the primary website is down.<br/><br/>How should the company deploy this solution?<br/><br/>A. Use Amazon S3 website hosting for the backup website and Route 53 failover routing policy.<br/>B. Use Amazon S3 website hosting for the backup website and Route 53 latency routing policy.<br/>C. Deploy the application in another AWS Region and use ELB health checks for failover routing.<br/>D. Deploy the application in another AWS Region and use server&#8211;side redirection on the primary website.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample74' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_128'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_2'>Random</a></p><div class='collapse' id='collapseExample74'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Use Amazon S3 website hosting for the backup website and Route 53 failover routing policy.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 81%;" aria-valuenow="81" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_128><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 128</p><br/>A solutions architect must design a solution that uses Amazon CloudFront with an Amazon S3 origin to store a static website. The company's security policy requires that all website traffic be inspected by AWS WAF.<br/><br/>How should the solutions architect comply with these requirements?<br/><br/>A. Configure an S3 bucket policy to accept requests coming from the AWS WAF Amazon Resource Name (ARN) only.<br/>B. Configure Amazon CloudFront to forward all incoming requests to AWS WAF before requesting content from the S3 origin.<br/>C. Configure a security group that allows Amazon CloudFront IP addresses to access Amazon S3 only. Associate AWS WAF to CloudFront.<br/>D. Configure Amazon CloudFront and Amazon S3 to use an origin access identity (OAI) to restrict access to the S3 bucket. Enable AWS WAF on the distribution.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample271' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_129'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_0'>Random</a></p><div class='collapse' id='collapseExample271'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Configure Amazon CloudFront and Amazon S3 to use an origin access identity (OAI) to restrict access to the S3 bucket. Enable AWS WAF on the distribution.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 82%;" aria-valuenow="82" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_129><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 129</p><br/>A company is building a media&#8211;sharing application and decides to use Amazon S3 for storage. When a media file is uploaded the company starts a multi&#8211;step process to create thumbnails, identify objects in the images, transcode videos into standard formats and resolutions and extract and store the metadata to an Amazon DynamoDB table.<br/><br/>The metadata is used for searching and navigation. The amount of traffic is variable The solution must be able to scale to handle spikes in load without unnecessary expenses.<br/><br/>What should a solutions architect recommend to support this workload?<br/><br/>A. Build the processing into the website or mobile app used to upload the content to Amazon S3. Save the required data to the DynamoDB table when the objects are uploaded<br/>B. Trigger AWS Step Functions when an object is stored in the S3 bucket. Have the Step Functions perform the steps needed to process the object and then write the metadata to the DynamoDB table<br/>C. Trigger an AWS Lambda function when an object is stored in the S3 bucket. Have the Lambda function start AWS Batch to perform the steps to process the object. Place the object data in the DynamoDB table when complete<br/>D. Trigger an AWS Lambda function to store an initial entry in the DynamoDB table when an object is uploaded to Amazon S3. Use a program running on an Amazon EC2 instance in an Auto Scaling group to poll the index for unprocess use the program to perform the processing<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample719' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_130'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_40'>Random</a></p><div class='collapse' id='collapseExample719'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Trigger an AWS Lambda function when an object is stored in the S3 bucket. Have the Lambda function start AWS Batch to perform the steps to process the object. Place the object data in the DynamoDB table when complete</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 83%;" aria-valuenow="83" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_130><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 130</p><br/>A company has enabled AWS CloudTrail logs to deliver log files to an Amazon S3 bucket for each of its developer accounts. The company has created a central AWS account for streamlining management and audit reviews. An internal auditor needs to access the CloudTrail logs, yet access needs to be restricted for all developer account users. The solution must be secure and optimized.<br/><br/>How should a solutions architect meet these requirements?<br/><br/>A. Configure an AWS Lambda function in each developer account to copy the log files to the central account. Create an IAM role in the central account for the auditor. Attach an IAM policy providing read only permissions to the bucket.<br/>B. Configure CloudTrail from each developer account to deliver the log files to an S3 bucket in the central account. Create an IAM user in the central account for the auditor. Attach an IAM policy providing full permissions to the bucket.<br/>C. Configure CloudTrail from each developer account to deliver the log files to an S3 bucket in the central account. Create an IAM role in the central account for the auditor. Attach an IAM policy providing read only permissions to the bucket.<br/>D. Configure an AWS Lambda function in the central account to copy the log files from the S3 bucket in each developer account. Create an IAM user in the central account for the auditor. Attach an IAM policy providing full permissions to the bucket.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample71' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_131'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_42'>Random</a></p><div class='collapse' id='collapseExample71'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Configure CloudTrail from each developer account to deliver the log files to an S3 bucket in the central account. Create an IAM role in the central account for the auditor. Attach an IAM policy providing read only permissions to the bucket.

 Go to dashboard</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 83%;" aria-valuenow="83" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_131><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 131</p><br/>A company wants to use Amazon S3 for the secondary copy of its on&#8211;premises dataset. The company would rarely need to access this copy. The storage solution's cost should be minimal.<br/><br/>Which storage solution meets these requirements?<br/><br/>A. S3 Standard<br/>B. S3 Intelligent&#8211;Tiering<br/>C. S3 Standard&#8211;Infrequent Access (S3 Standard&#8211;IA)<br/>D. S3 One Zone&#8211;Infrequent Access (S3 One Zone&#8211;IA)<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample46' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_132'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_43'>Random</a></p><div class='collapse' id='collapseExample46'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>S3 One Zone-Infrequent Access (S3 One Zone-IA)</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 84%;" aria-valuenow="84" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_132><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 132</p><br/>A company sells ringtones created from clips of popular songs. The files containing the ringtones are stored in Amazon S3 Standard and are at least 123 KB m size.<br/><br/>The company has millions of files but downloads are infrequent for ringtones older than 90 days. The company needs to save money on storage while keeping the most accessed files readily available for its users.<br/><br/>Which action should the company take to meet these requirements MOST cost&#8211;effectively?<br/><br/>A. Configure S3 Standard&#8211;infrequent Access (S3 Standard&#8211;IA) storage for the initial storage tier of the objects<br/>B. Move the files to S3 Intelligent&#8211;Tiering and configure it to move objects to a less expensive storage tier after 90 days<br/>C. Configure S3 inventory to manage objects and move them to S3 Standard&#8211;infrequent Access (S3 Standard&#8211;IA) after 90 days<br/>D. Implement an S3 Lifecycle policy that moves the objects from S3 Standard to S3 Standard&#8211; Infrequent Access (S3 Standard&#8211;IA) after 90 days<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample569' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_133'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_143'>Random</a></p><div class='collapse' id='collapseExample569'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Configure S3 Standard-infrequent Access (S3 Standard-IA) storage for the initial storage tier of the objects</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 85%;" aria-valuenow="85" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_133><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 133</p><br/>A company has multiple AWS accounts for various departments. One of the departments wants to share an Amazon S3 bucket with all other departments.<br/><br/>Which solution will require the LEAST amount of effort?<br/><br/>A. Enable cross&#8211;account S3 replication for the bucket.<br/>B. Create a pre&#8211;signed URL for the bucket and share it with other departments.<br/>C. Set the S3 bucket policy to allow cross&#8211;account access to other departments.<br/>D. Create IAM users for each of the departments and configure a read&#8211;only IAM policy.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample112' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation112' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_134'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_119'>Random</a></p><div class='collapse' id='collapseExample112'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Set the S3 bucket policy to allow cross-account access to other departments.</div></div></div><div class='collapse' id='explanation112'><div class='card card&#45;body'><div>
S3 standard is the best choice in this scenario for a short term storage solution. In this case the size and number of logs is unknown and it would be difficult to fully assess the access patterns at this stage. Therefore, using S3 standard is best as it is cost-effective, provides immediate access, and there are no retrieval fees or minimum capacity charge per object.

CORRECT: "Amazon S3 Standard" is the correct answer.

INCORRECT: "Amazon S3 Intelligent-Tiering" is incorrect as there is an additional fee for using this service and for a short-term requirement it may not be beneficial.

INCORRECT: "Amazon S3 One Zone-Infrequent Access (S3 One Zone-IA)" is incorrect as this storage class has a minimum capacity charge per object (128 KB) and a per GB retrieval fee. INCORRECT: "Amazon S3 Glacier Deep Archive" is incorrect as this storage class is used for archiving data. There are retrieval fees and it take hours to retrieve data from an archive.

References:

Amazon S3 Storage Classes</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 85%;" aria-valuenow="85" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_134><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 134</p><br/>A company built a food ordering application that captures user data and stores it for future analysis. The application's static front end is deployed on an Amazon EC2 instance. The front&#8211;end application sends the requests to the backend application running on separate EC2 instance. The backend application then stores the data in Amazon RDS.<br/><br/>What should a solutions architect do to decouple the architecture and make it scalable?<br/><br/>A. Use Amazon S3 to serve the front&#8211;end application, which sends requests to Amazon EC2 to execute the backend application. The backend application will process and store the data in Amazon RDS.<br/>B. Use Amazon S3 to serve the front&#8211;end application and write requests to an Amazon Simple Notification Service (Amazon SNS) topic. Subscribe Amazon EC2 instances to the HTTP/HTTPS endpoint of the topic, and process and store the data in Amazon RDS.<br/>C. Use an EC2 instance to serve the front end and write requests to an Amazon SQS queue. Place the backend instance in an Auto Scaling group, and scale based on the queue depth to process and store the data in Amazon RDS.<br/>D. Use Amazon S3 to serve the static front&#8211;end application and send requests to Amazon API Gateway, which writes the requests to an Amazon SQS queue. Place the backend instances in an Auto Scaling group, and scale based on the queue depth to process and store the data in Amazon RDS.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample43' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation43' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_135'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_135'>Random</a></p><div class='collapse' id='collapseExample43'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Use Amazon S3 to serve the static front-end application and send requests to Amazon API Gateway, which writes the requests to an Amazon SQS queue. Place the backend instances in an Auto Scaling group, and scale based on the queue depth to process and store the data in Amazon RDS.</div></div></div><div class='collapse' id='explanation43'><div class='card card&#45;body'><div>
Keyword: Static + Decouple + Scalable Static=S3

Decouple=SQS Queue Scalable=ASG

Option B will not be there in the race due to Auto-Scaling unavailability. Option A will not be there in the race due to Decouple unavailability.

Option C & D will be in the race and Option D will be correct answers due to all 3 combination matches [Static=S3; Decouple=SQS Queue; Scalable=ASG] & Option C will loose due to Static option unavailability
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 86%;" aria-valuenow="86" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_135><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 135</p><br/>A company stores call recordings on a monthly basis Statistically, the recorded data may be referenced randomly within a year but accessed rarely after 1 year.<br/><br/>Files that are newer than 1 year old must be queried and retrieved as quickly as possible.<br/><br/>A delay in retrieving older files is acceptable A solutions architect needs to store the recorded data at a minimal cost.<br/><br/>Which solution is MOST cost&#8211;effective?<br/><br/>A. Store individual files in Amazon S3 Glacier and store search metadata in object tags created in S3 Glacier. Query S3 Glacier tags and retrieve the files from S3 Glacier<br/>B. Store individual files in Amazon S3 Use lifecycle policies to move the files to Amazon S3 Glacier after 1 year. Query and retrieve the files from Amazon S3 or S3 Glacier.<br/>C. Archive individual files and store search metadata for each archive in Amazon S3. Use lifecycle policies to move the files to Amazon S3 Glacier after 1 year. Query and retrieve the files by searching for metadata from Amazon S3<br/>D. Archive individual files in Amazon S3. Use lifecycle policies to move the files to Amazon S3 Glacier after 1 year. Store search metadata in Amazon DynamoDB Query the files from DynamoDB and retrieve them from Amazon S3 or S3 Glacier<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample715' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_136'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_71'>Random</a></p><div class='collapse' id='collapseExample715'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Store individual files in Amazon S3 Use lifecycle policies to move the files to Amazon S3 Glacier after 1 year. Query and retrieve the files from Amazon S3 or S3 Glacier.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 87%;" aria-valuenow="87" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_136><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 136</p><br/>A company maintains about 300 TB in Amazon S3 Standard storage month after month. The S3 objects are each typically around 50 GB in size and are frequently replaced with multipart uploads by their global application. The number and size of S3 objects remain constant but the company's S3 storage costs are increasing each month.<br/><br/>How should a solutions architect reduce costs in this situation?<br/><br/>A. Switch from multipart uploads to Amazon S3 Transfer Acceleration<br/>B. Enable an S3 Lifecycle policy that deletes incomplete multipart uploads<br/>C. Configure S3 inventory to prevent objects from being archived too quickly<br/>D. Configure Amazon CloudFront to reduce the number of objects stored in Amazon S3<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample440' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_137'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_59'>Random</a></p><div class='collapse' id='collapseExample440'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Enable an S3 Lifecycle policy that deletes incomplete multipart uploads</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 87%;" aria-valuenow="87" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_137><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 137</p><br/>A company stores user data in AWS. The data is used continuously with peak usage during business hours. Access patterns vary, with some data not being used for months at a time. A solutions architect must choose a cost&#8211;effective solution that maintains the highest level of durability while maintaining high availability.<br/><br/>Which storage solution meets these requirements?<br/><br/>A. Amazon S3 Standard<br/>B. Amazon S3 Intelligent&#8211;Tiering<br/>C. Amazon S3 Glacier Deep Archive<br/>D. Amazon S3 One Zone&#8211;Infrequent Access (S3 One Zone&#8211;IA)<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample139' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_138'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_151'>Random</a></p><div class='collapse' id='collapseExample139'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Amazon S3 Intelligent-Tiering</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 88%;" aria-valuenow="88" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_138><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 138</p><br/>A company is running an application on AWS to process weather sensor data that is stored in an Amazon S3 bucket.<br/><br/>Three batch jobs run hourly to process the data in the S3 bucket for different purposes.<br/><br/>The company wants to reduce the overall processing time by running the three applications in parallel using an event&#8211;based approach.<br/><br/>What should a solutions architect do to meet these requirements?<br/><br/>A. Enable S3 Event Notifications for new objects to an Amazon Simple Queue Service (Amazon SQS) FIFO queue. Subscribe all applications to the queue for processing<br/>B. Enable S3 Event Notifications for new objects to an Amazon Simple Queue Service (Amazon SQS) standard queue. Create an additional SQS queue for all applications and subscribe all applications to the initial queue for processing<br/>C. Enable S3 Event Notifications for new objects to separate Amazon Simple Queue Service (Amazon SQS) FIFO queues. Create an additional SQS queue for each application and subscribe each queue to the initial topic for processing<br/>D. Enable S3 Event Notifications for new objects to an Amazon Simple Notification Service (Amazon SNS) topic. Create an Amazon Simple Queue Service (Amazon SQS) queue for each application and subscribe each queue to the topic for processing<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample629' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_139'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_65'>Random</a></p><div class='collapse' id='collapseExample629'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Enable S3 Event Notifications for new objects to separate Amazon Simple Queue Service (Amazon SQS) FIFO queues. Create an additional SQS queue for each application and subscribe each queue to the initial topic for processing</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 89%;" aria-valuenow="89" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_139><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 139</p><br/>A company has thousands of files stored in an Amazon S3 bucket that has a well&#8211;defined access pattern. The files are accessed by an application multiple times a day for the first 30 days. Files are rarely accessed within the next 90 days. After that, the files are never accessed again. During the first 120 days, accessing these files should never take more than a few seconds.<br/><br/>Which lifecycle policy should be used for the S3 objects to minimize costs based on the access pattern?<br/><br/>A. Use Amazon S3 Standard&#8211;Infrequent Access (S3 Standard&#8211;IA) storage for the first 30 days. Then move the files to the GLACIER storage class for the next 90 days. Allow the data to expire after that.<br/>B. Use Amazon S3 Standard storage for the first 30 days. Then move the files to Amazon S3 Standard&#8211; Infrequent Access (S3 Standard&#8211;IA) for the next 90 days. Allow the data to expire after that.<br/>C. Use Amazon S3 Standard storage for first 30 days. Then move the files to the GLACIER storage class for the next 90 days. Allow the data to expire after that.<br/>D. Use Amazon S3 Standard&#8211;Infrequent Access (S3 Standard&#8211;IA) for the first 30 days. After that, move the data to the GLACIER storage class, where is will be deleted automatically.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample792' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation792' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_140'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_50'>Random</a></p><div class='collapse' id='collapseExample792'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Use Amazon S3 Standard storage for the first 30 days. Then move the files to Amazon S3 Standard- Infrequent Access (S3 Standard-IA) for the next 90 days. Allow the data to expire after that.</div></div></div><div class='collapse' id='explanation792'><div class='card card&#45;body'><div>
It is mentioned that they need to access data in few seconds during the 120 days.
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 89%;" aria-valuenow="89" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_140><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 140</p><br/>A company needs to provide its employees with secure access to confidential and sensitive files. The company wants to ensure that the files can be accessed only by authorized users. The files must be downloaded securely to the employees' devices.<br/><br/>The files are stored in an on&#8211;premises Windows file server. However, due to an increase in remote usage, the file server is running out of capacity.<br/><br/>Which solution will meet these requirements?<br/><br/>A. Migrate the file server to an Amazon EC2 instance in a public subnet. Configure the security group to limit inbound traffic to the employees' IP addresses.<br/>B. Migrate the files to an Amazon FSx for Windows File Server file system. Integrate the Amazon FSx file system with the on&#8211;premises Active Directory. Configure AWS Client VPN.<br/>C. Migrate the files to Amazon S3, and create a private VPC endpoint. Create a signed URL to allow download.<br/>D. Migrate the files to Amazon S3, and create a public VPC endpoint. Allow employees to sign on with AWS Single Sign&#8211;On.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample417' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_141'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_58'>Random</a></p><div class='collapse' id='collapseExample417'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Migrate the files to Amazon S3, and create a private VPC endpoint. Create a signed URL to allow download.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 90%;" aria-valuenow="90" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_141><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 141</p><br/>A company has NFS servers in an on&#8211;premises data center that need to periodically back up small amounts of data to Amazon S3.<br/><br/>Which solution meets these requirements and is MOST cost&#8211;effective?<br/><br/>A. Set up AWS Glue to copy the data from the on&#8211;premises servers to Amazon S3.<br/>B. Set up an AWS DataSync agent on the on&#8211;premises servers, and sync the data to Amazon S3.<br/>C. Set up an SFTP sync using AWS Transfer for SFTP to sync data from on&#8211;premises to Amazon S3.<br/>D. Set up an AWS Direct Connect connection between the on&#8211;premises data center and a VPC, and copy the data to Amazon S3.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample391' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_142'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_24'>Random</a></p><div class='collapse' id='collapseExample391'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Set up an SFTP sync using AWS Transfer for SFTP to sync data from on-premises to Amazon S3.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 90%;" aria-valuenow="90" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_142><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 142</p><br/>A company has an application that generates a large number of files, each approximately 5 MB in size. The files are stored in Amazon S3. Company policy requires the files to be stored for 4 years before they can be deleted. Immediate accessibility is always required as the files contain critical business data that is not easy to reproduce. The files are frequently accessed in the first 30 days of the object creation but are rarely accessed after the first 30 days.<br/><br/>Which storage solution is MOST cost effective?<br/><br/>A. Create an S3 bucket lifecycle policy to move files from S3 Standard to S3 Glacier 30 days from object creation. Delete the files 4 years after the object creation.<br/>B. Create an S3 bucket lifecycle policy to move files from S3 Standard to S3 One Zone&#8211;Infrequent Access (S3 One Zone&#8211;IA) 30 days from object creation. Delete the files 4 years after the object creation.<br/>C. Create an S3 bucket lifecycle policy to move files from S3 Standard to S3 Standard&#8211;Infrequent Access (S3 Standard&#8211;IA) 30 days from object creation. Delete the files 4 years after the object creation.<br/>D. Create an S3 bucket lifecycle policy to move files from S3 Standard to S3 Standard&#8211;Infrequent Access (S3 Standard&#8211;IA) 30 days from object creation. Move the file to S3 Glacier 4 years after object creation.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample700' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_143'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_3'>Random</a></p><div class='collapse' id='collapseExample700'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Create an S3 bucket lifecycle policy to move files from S3 Standard to S3 Standard-Infrequent Access (S3 Standard-IA) 30 days from object creation. Delete the files 4 years after the object creation.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 91%;" aria-valuenow="91" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_143><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 143</p><br/>A solutions architect is designing the storage architecture for a new web application used for storing and viewing engineering drawings. All application components will be deployed on the AWS infrastructure.<br/><br/>The application design must support caching to minimize the amount of time that users wait for the engineering drawings to load. The application must be able to store petabytes of data. Which combination of storage and caching should the solutions architect use?<br/><br/>A. Amazon S3 with Amazon CloudFront<br/>B. Amazon S3 Glacier with Amazon ElastiCache<br/>C. Amazon Elastic Block Store (Amazon EBS) volumes with Amazon CloudFront<br/>D. AWS Storage Gateway with Amazon ElastiCache<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample213' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation213' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_144'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_142'>Random</a></p><div class='collapse' id='collapseExample213'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Amazon S3 with Amazon CloudFront</div></div></div><div class='collapse' id='explanation213'><div class='card card&#45;body'><div>
CloudFront for caching and S3 as the origin. Glacier is used for archiving which is not the case for this scenario.
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 92%;" aria-valuenow="92" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_144><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 144</p><br/>A company is building a media sharing application and decides to use Amazon S3 for storage. When a media file is uploaded, the company starts a multi&#8211;step process to create thumbnails, identify objects in the images, transcode videos into standard formats and resolutions, and extract and store the metadata to an Amazon DynamoDB table. The metadata is used for searching and navigation.<br/><br/>The amount of traffic is variable. The solution must be able to scale to handle spikes in load without unnecessary expenses.<br/><br/>What should a solutions architect recommend to support this workload?<br/><br/>A. Build the processing into the website or mobile app used to upload the content to Amazon S3. Save the required data to the DynamoDB table when the objects are uploaded.<br/>B. Trigger AWS Step Functions when an object is stored in the S3 bucket. Have the Step Functions perform the steps needed to process the object and then write the metadata to the DynamoDB table.<br/>C. Trigger an AWS Lambda function when an object is stored in the S3 bucket. Have the Lambda function start AWS Batch to perform the steps to process the object. Place the object data in the DynamoDB table when complete.<br/>D. Trigger an AWS Lambda function to store an initial entry in the DynamoDB table when an object is uploaded to Amazon S3. Use a program running on an Amazon EC2 instance in an Auto Scaling group to poll the index for unprocessed items, and use the program to perform the processing.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample225' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_145'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_75'>Random</a></p><div class='collapse' id='collapseExample225'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Trigger an AWS Lambda function when an object is stored in the S3 bucket. Have the Lambda function start AWS Batch to perform the steps to process the object. Place the object data in the DynamoDB table when complete.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 92%;" aria-valuenow="92" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_145><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 145</p><br/>A company hosts a training site on a fleet of Amazon EC2 instances. The company anticipates that its new course, which consists of dozens of training videos on the site, will be extremely popular when it is released in 1 week.<br/><br/>What should a solutions architect do to minimize the anticipated server load?<br/><br/>A. Store the videos in Amazon ElastiCache for Redis. Update the web servers to serve the videos using the ElastiCache API.<br/>B. Store the videos in Amazon Elastic File System (Amazon EFS). Create a user data script for the web servers to mount the EFS volume.<br/>C. Store the videos in an Amazon S3 bucket. Create an Amazon CloudFront distribution with an origin access identity (OAI) of that S3 bucket. Restrict Amazon S3 access to the OAI.<br/>D. Store the videos in an Amazon S3 bucket. Create an AWS Storage Gateway file gateway to access the S3 bucket. Create a user data script for the web servers to mount the file gateway.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample237' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_146'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_9'>Random</a></p><div class='collapse' id='collapseExample237'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Store the videos in an Amazon S3 bucket. Create an Amazon CloudFront distribution with an origin access identity (OAI) of that S3 bucket. Restrict Amazon S3 access to the OAI.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 93%;" aria-valuenow="93" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_146><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 146</p><br/>A media company is evaluating the possibility of moving its systems to the AWS Cloud. The company needs at least 10 TB of storage with the maximum possible I/O performance for video processing, 300 TB of very durable storage for storing media content, and 900 TB of storage to meet requirements for archival media that is not in use anymore.<br/><br/>Which set of services should a solutions architect recommend to meet these requirements?<br/><br/>A. Amazon EBS for maximum performance, Amazon S3 for durable data storage, and Amazon S3 Glacier for archival storage<br/>B. Amazon EBS for maximum performance, Amazon EFS for durable data storage, and Amazon S3 Glacier for archival storage<br/>C. Amazon EC2 instance store for maximum performance, Amazon EFS for durable data storage, and Amazon S3 for archival storage<br/>D. Amazon EC2 instance store for maximum performance, Amazon S3 for durable data storage, and Amazon S3 Glacier for archival storage<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample75' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_147'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_111'>Random</a></p><div class='collapse' id='collapseExample75'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Amazon EBS for maximum performance, Amazon S3 for durable data storage, and Amazon S3 Glacier for archival storage</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 94%;" aria-valuenow="94" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_147><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 147</p><br/>A solutions architect needs to design a low&#8211;latency solution for a static single&#8211;page application accessed by users utilizing a custom domain name. The solution must be serverless, encrypted in transit, and cost&#8211;effective.<br/><br/>Which combination of AWS services and features should the solutions architect use? (Choose two.)<br/><br/>A. Amazon S3<br/>B. Amazon EC2<br/>C. AWS Fargate<br/>D. Amazon CloudFront<br/>E. Elastic Load Balancer<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample168' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_148'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_116'>Random</a></p><div class='collapse' id='collapseExample168'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Amazon S3
<br><b>D. </b>Amazon CloudFront</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 94%;" aria-valuenow="94" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_148><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 148</p><br/>A solutions architect at an eCommerce company wants to back up application log data to Amazon S3. The solutions architect is unsure how frequently the logs will be accessed or which logs will be accessed the most. The company wants to keep costs as low as possible by using the appropriate S3 storage class.<br/><br/>Which S3 storage class should be implemented to meet these requirements?<br/><br/>A. S3 Glacier<br/>B. S3 Intelligent&#8211;Tiering<br/>C. S3 Standard&#8211;Infrequent Access (S3 Standard&#8211;IA)<br/>D. S3 One Zone&#8211;Infrequent Access (S3 One Zone&#8211;IA)<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample183' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation183' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_149'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_11'>Random</a></p><div class='collapse' id='collapseExample183'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>S3 Intelligent-Tiering</div></div></div><div class='collapse' id='explanation183'><div class='card card&#45;body'><div>
S3 Intelligent-Tiering is a new Amazon S3 storage class designed for customers who want to optimize storage costs automatically when data access patterns change, without performance impact or operational overhead. S3 Intelligent-Tiering is the first cloud object storage class that delivers automatic cost savings by moving data between two access tiers – frequent access and infrequent access – when access patterns change, and is ideal for data with unknown or changing access patterns.

S3 Intelligent-Tiering stores objects in two access tiers: one tier that is optimized for frequent access and another lower-cost tier that is optimized for infrequent access. For a small monthly monitoring and automation fee per object, S3 Intelligent-Tiering monitors access patterns and moves objects that have not been accessed for 30 consecutive days to the infrequent access tier.

There are no retrieval fees in S3 Intelligent-Tiering. If an object in the infrequent access tier is accessed later, it is automatically moved back to the frequent access tier. No additional tiering fees apply when objects are moved between access tiers within the S3 Intelligent-Tiering storage class. S3 Intelligent-Tiering is designed for 99.9% availability and 99.999999999% durability, and offers the same low latency and high throughput performance of S3 Standard.
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 95%;" aria-valuenow="95" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_149><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 149</p><br/>A company has 700 TB of backup data stored in network attached storage (NAS) in its data center This backup data need to be accessible for infrequent regulatory requests and must be retained 7 years. The company has decided to migrate this backup data from its data center to AWS. The migration must be complete within 1 month. The company has 500 Mbps of dedicated bandwidth on its public internet connection available for data transfer.<br/><br/>What should a solutions architect do to migrate and store the data at the LOWEST cost?<br/><br/>A. Order AWS Snowball devices to transfer the data. Use a lifecycle policy to transition the files to Amazon S3 Glacier Deep Archive.<br/>B. Deploy a VPN connection between the data center and Amazon VPC. Use the AWS CLI to copy the data from on&#8211;premises to Amazon S3 Glacier.<br/>C. Provision a 500 Mbps AWS Direct Connect connection and transfer the data to Amazon S3. Use a lifecycle policy to transition the files to Amazon S3 Glacier Deep Archive.<br/>D. Use AWS DataSync to transfer the data and deploy a DataSync agent on&#8211;premises. Use the DataSync task to copy files from the on&#8211;premises NAS storage to Amazon S3 Glacier.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample345' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_150'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_4'>Random</a></p><div class='collapse' id='collapseExample345'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Order AWS Snowball devices to transfer the data. Use a lifecycle policy to transition the files to Amazon S3 Glacier Deep Archive.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 96%;" aria-valuenow="96" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_150><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 150</p><br/>A media company is evaluating the possibility of moving its systems to the AWS Cloud. The company needs at least 10 TB of storage with the maximum possible I/O performance for video processing. 300 TB of very durable storage for storing media content, and 900 TB of storage to meet requirements for archival media that is not in use anymore.<br/><br/>Which set of services should a solutions architect recommend to meet these requirements?<br/><br/>A. Amazon EBS for maximum performance, Amazon S3 for durable data storage, and Amazon S3 Glacier for archival storage<br/>B. Amazon EBS for maximum performance. Amazon EFS for durable data storage, and Amazon S3 Glacier for archival storage<br/>C. Amazon EC2 instance store for maximum performance, Amazon EFS for durable data storage, and Amazon S3 for archival storage<br/>D. Amazon EC2 instance store for maximum performance, Amazon S3 for durable data storage, and Amazon S3 Glacier for archival storage<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample735' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_151'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_105'>Random</a></p><div class='collapse' id='collapseExample735'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Amazon EBS for maximum performance, Amazon S3 for durable data storage, and Amazon S3 Glacier for archival storage</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 96%;" aria-valuenow="96" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_151><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 151</p><br/>A company sells datasets to customers who do research in artificial intelligence and machine learning (AIMU).<br/><br/>The datasets are large formatted files met are stored in an Amazon S3 bucket in the us&#8211;east&#8211;1 Region.<br/><br/>The company hosts a web application that the customers use o purchase access to a given dataset.<br/><br/>The web application Is deployed on mutate Amazon EC2 instances behind an Application Load Balancer.<br/><br/>After a purchase is made customers receive an S3 signed URL that allows access to the files. The customers are distributed across North America and Europe.<br/><br/>The company wants to reduce the cost that is associated with data transfers and wants to maintain or improve performance.<br/><br/>What should a solutions architect do to meet these requirements?<br/><br/>A. Configure S3 Transfer Accelerator on the ex sting S3 bucket. Direct customer requests to the S3 Transfer Acceleration endpoint Continue to use S3 signed URLs to access control<br/>B. Deploy an Amazon CloudFront distribution with the existing S3 bucket as the origin Direct customer requests to the CloudFront URL. Switch to CloudFront signed URLs for access control<br/>C. Set up a second S3 Ducket in the eu&#8211;central&#8211;1 Region with S3 Cross&#8211;Region Replication between lite Duckets. Direct customer requests to the closest Region. Continue to use S3 signed URLs for access control<br/>D. Modify the web application to enable streaming of the datasets to and users. Configure the web application to read the data from the existing S3 bucket implement access control directly in the application<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample597' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_152'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_114'>Random</a></p><div class='collapse' id='collapseExample597'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Configure S3 Transfer Accelerator on the ex sting S3 bucket. Direct customer requests to the S3 Transfer Acceleration endpoint Continue to use S3 signed URLs for access control</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 97%;" aria-valuenow="97" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_152><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 152</p><br/>A solutions architect is designing a solution to access a catalog of images and provide users with the ability to submit requests to customize images. Image customization parameters will be in any request sent to an AWS API Gateway API. The customized image will be generated on demand, and users will receive a link they can click to view or download their customized image. The solution must be highly available for viewing and customizing images.<br/><br/>What is the MOST cost&#8211;effective solution to meet these requirements?<br/><br/>A. Use Amazon EC2 instances to manipulate the original image into the requested customization. Store the original and manipulated images in Amazon S3. Configure an Elastic Load Balancer in front of the EC2 instances.<br/>B. Use AWS Lambda to manipulate the original image to the requested customization. Store the original and manipulated images in Amazon S3. Configure an Amazon CloudFront distribution with the S3 bucket as the origin.<br/>C. Use AWS Lambda to manipulate the original image to the requested customization. Store the original images in Amazon S3 and the manipulated images in Amazon DynamoDB. Configure an Elastic Load Balancer in front of the Amazon EC2 instances.<br/>D. Use Amazon EC2 instances to manipulate the original image into the requested customization. Store the original images in Amazon S3 and the manipulated images in Amazon DynamoDB. Configure an Amazon CloudFront distribution with the S3 bucket as the origin.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample12' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation12' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_153'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_93'>Random</a></p><div class='collapse' id='collapseExample12'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Use AWS Lambda to manipulate the original image to the requested customization. Store the original and manipulated images in Amazon S3. Configure an Amazon CloudFront distribution with the S3 bucket as the origin.</div></div></div><div class='collapse' id='explanation12'><div class='card card&#45;body'><div>
AWS Lambda is a compute service that lets you run code without provisioning or managing servers. AWS Lambda executes your code only when needed and scales automatically, from a few requests per day to thousands per second. You pay only for the compute time you consume – there is no charge when your code is not running. With AWS Lambda, you can run code for virtually any type of application or backend service – all with zero administration. AWS Lambda runs your code on a high-availability compute infrastructure and performs all of the administration of the compute resources, including server and operating system maintenance, capacity provisioning and automatic scaling, code monitoring, and logging.

All you need to do is supply your code in one of the languages that AWS Lambda supports.

Storing your static content with S3 provides a lot of advantages. But to help optimize your application's performance and security while effectively managing cost, we recommend that you also set up Amazon CloudFront to work with your S3 bucket to serve and protect the content. CloudFront is a content delivery network (CDN) service that delivers static and dynamic web content, video streams, and APIs around the world, securely and at scale. By design, delivering data out of CloudFront can be more cost effective than delivering it from S3 directly to your users.

CloudFront serves content through a worldwide network of data centers called Edge Locations. Using edge servers to cache and serve content improves performance by providing content closer to where viewers are located. CloudFront has edge servers in locations all around the world.

All solutions presented are highly available. The key requirement that must be satisfied is that the solution should be cost-effective and you must choose the most cost-effective option.

Therefore, it's best to eliminate services such as Amazon EC2 and ELB as these require ongoing costs even when they're not used. Instead, a fully serverless solution should be used. AWS Lambda, Amazon S3 and CloudFront are the best services to use for these requirements.

CORRECT: "Use AWS Lambda to manipulate the original images to the requested customization. Store the original and manipulated images in Amazon S3. Configure an Amazon CloudFront distribution with the S3 bucket as the origin" is the correct answer.

INCORRECT: "Use Amazon EC2 instances to manipulate the original images into the requested customization. Store the original and manipulated images in Amazon S3. Configure an Elastic Load Balancer in front of the EC2 instances" is incorrect. This is not the most cost-effective option as the ELB and EC2 instances will incur costs even when not used.

INCORRECT: "Use AWS Lambda to manipulate the original images to the requested customization. Store the original images in Amazon S3 and the manipulated images in Amazon DynamoDB. Configure an Elastic Load Balancer in front of the Amazon EC2 instances" is incorrect. This is not the most cost-effective option as the ELB will incur costs even when not used. Also, Amazon DynamoDB will incur RCU/WCUs when running and is not the best choice for storing images.

INCORRECT: "Use Amazon EC2 instances to manipulate the original images into the requested customization. Store the original images in Amazon S3 and the manipulated images in Amazon DynamoDB. Configure an Amazon CloudFront distribution with the S3 bucket as the origin" is incorrect. This is not the most cost-effective option as the EC2 instances will incur costs even when not used.

References:

Serverless on AWS</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 98%;" aria-valuenow="98" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_153><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 153</p><br/>A company collects temperature, humidity, and atmospheric pressure data in cities across multiple continents. The average volume of data collected per site each day is 500 GB. Each site has a high&#8211;speed internet connection. The company's weather forecasting applications are based in a single Region and analyze the data daily.<br/><br/>What is the FASTEST way to aggregate data from all of these global sites?<br/><br/>A. Enable Amazon S3 Transfer Acceleration on the destination bucket. Use multipart uploads to directly upload site data to the destination bucket.<br/>B. Upload site data to an Amazon S3 bucket in the closest AWS Region. Use S3 cross&#8211;Region replication to copy objects to the destination bucket.<br/>C. Schedule AWS Snowball jobs daily to transfer data to the closest AWS Region. Use S3 cross&#8211;Region replication to copy objects to the destination bucket.<br/>D. Upload the data to an Amazon EC2 instance in the closest Region. Store the data in an Amazon EBS volume. Once a day take an EBS snapshot and copy it to the centralized Region. Restore the EBS volume in the centralized Region and run an analysis on the data daily.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample173' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_154'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_5'>Random</a></p><div class='collapse' id='collapseExample173'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Upload site data to an Amazon S3 bucket in the closest AWS Region. Use S3 cross-Region replication to copy objects to the destination bucket.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 98%;" aria-valuenow="98" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_154><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 154</p><br/>A company hosts a static website within an Amazon S3 bucket. A solutions architect needs to ensure that data can be recovered in case of accidental deletion.<br/><br/>Which action will accomplish this?<br/><br/>A. Enable Amazon S3 versioning.<br/>B. Enable Amazon S3 Intelligent&#8211;Tiering.<br/>C. Enable an Amazon S3 lifecycle policy.<br/>D. Enable Amazon S3 cross&#8211;Region replication.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample26' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation26' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_155'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_147'>Random</a></p><div class='collapse' id='collapseExample26'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Enable Amazon S3 versioning.</div></div></div><div class='collapse' id='explanation26'><div class='card card&#45;body'><div>
Data can be recover if versioning enable, also it provide a extra protection like file delete, MFA delete. MFA. Delete only works for CLI or API interaction, not in the AWS Management Console. Also, you cannot make version DELETE actions with MFA using IAM user credentials. You must use your root AWS account.

Object Versioning: Use Amazon S3 Versioning to keep multiple versions of an object in one bucket. For example, you could store my-image.jpg (version 111111) and my-image.jpg (version 222222) in a single bucket. S3 Versioning protects you from the consequences of unintended overwrites and deletions. You can also use it to archive objects so that you have access to previous versions.

You must explicitly enable S3 Versioning on your bucket. By default, S3 Versioning is disabled. Regardless of whether you have enabled Versioning, each object in your bucket has a version ID. If you have not enabled Versioning, Amazon S3 sets the value of the version ID to null. If S3 Versioning is enabled, Amazon S3 assigns a version ID value for the object. This value distinguishes it from other versions of the same key.

Object versioning is a means of keeping multiple variants of an object in the same Amazon S3 bucket. Versioning provides the ability to recover from both unintended user actions and application failures. You can use versioning to preserve, retrieve, and restore every version of every object stored in your Amazon S3 bucket.

CORRECT: "Enable Amazon S3 versioning" is the correct answer.

INCORRECT: "Enable Amazon S3 Intelligent-Tiering" is incorrect. This is a storage class that automatically moves data between frequent access and infrequent access classes based on usage patterns.

INCORRECT: "Enable an Amazon S3 lifecycle policy" is incorrect. An S3 lifecycle policy is a set of rules that define actions that apply to groups of S3 objects such as transitioning objects to another storage class.

INCORRECT: "Enable Amazon S3 cross-Region replication" is incorrect as this is used to copy objects to different regions. CRR relies on versioning which is the feature that is required for protecting against accidental deletion.

References:

Protecting Amazon S3 Against Object Deletion</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 99%;" aria-valuenow="99" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=S3_155><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>S3 Question 155</p><br/>A company needs to provide its employees with secure access to confidential and sensitive files. The company wants to ensure that the tiles can be accessed only by authorized users. The files must be downloaded securely to the employees' devices.<br/><br/>The tiles are stored in an on&#8211;premises Windows file server. However, due to an increase in remote usage, the file server is running out of capacity.<br/><br/>Which solution will meet these requirements?<br/><br/>A. Migrate the file server to an Amazon EC2 instance in a public subnet. Configure the security group to limit inbound traffic to the employees' IP addresses.<br/>B. Migrate the files to an Amazon FSx for Windows File Server file system. Integrate the Amazon FSx file system with the on&#8211;premises Active Directory. Configure AWS Client VP<br/>C. Migrate the tiles to Amazon S3, and create a private VPC endpoint. Create a signed URL to allow download.<br/>D. Migrate the tiles to Amazon S3, and create a public VPC endpoint. Allow employees to sign on with AWS Single Sign&#8211;On.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample449' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_156'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#S3_149'>Random</a></p><div class='collapse' id='collapseExample449'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Migrate the tiles to Amazon S3, and create a public VPC endpoint. Allow employees to sign on with AWS Single Sign-On.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 100%;" aria-valuenow="100" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#S3'>S3</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><a id=EC2><h2>EC2</h2></a> - 90 Questions <br><a href='#EC2'>EC2(90)</a> <a href='#' <i class='bi bi&#45;house'> &nbsp;Home</i><hr> </a><div class='row' id=EC2_1><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EC2 Question 1</p><br/>Cost Explorer is showing charges higher than expected for Amazon Elastic Block Store (Amazon EBS) volumes connected to application servers in a production account.<br/><br/>A significant portion of the changes from Amazon EBS are from volumes that were created as Provisioned IOPS SSD (101) volume types Controlling costs is the highest priority for this application.<br/><br/>Which steps should the user take to analyze and reduce the EBS costs without incurring any application downtime? (Select TWO )<br/><br/>A. Use the Amazon EC2 ModifylnstanceAttribute action to enable EBS optimization on the application server instances<br/>B. Use the Amazon CloudWatch GetMetricData action to evaluate the read write operations and read/write bytes of each volume<br/>C. Use the Amazon EC2 ModifyVolume action to reduce the size of the underutilized 101 volumes<br/>D. Use the Amazon EC2 ModifyVolume action to change the volume type of the underutilized io1 volumes to General Purpose SSD (gp2)<br/>E. Use an Amazon S3 PutBucketPolicy action to migrate existing volume snapshots to Amazon S3 Glacier<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample621' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_2'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_76'>Random</a></p><div class='collapse' id='collapseExample621'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Use the Amazon EC2 ModifylnstanceAttribute action to enable EBS optimization on the application server instances
<br><b>D. </b>Use the Amazon EC2 ModifyVolume action to change the volume type of the underutilized io1 volumes to General Purpose SSD (gp2)</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 1%;" aria-valuenow="1" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EC2'>EC2</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EC2_2><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EC2 Question 2</p><br/>A solutions architect is designing a high performance computing (HPC) workload on Amazon EC2. The EC2 instances need to communicate to each other frequently and require network performance with low latency and high throughput.<br/><br/>Which EC2 configuration meets these requirements?<br/><br/>A. Launch the EC2 instances in a cluster placement group in one Availability Zone.<br/>B. Launch the EC2 instances in a spread placement group in one Availability Zone.<br/>C. Launch the EC2 instances in an Auto Scaling group in two Regions and peer the VPCs.<br/>D. Launch the EC2 instances in an Auto Scaling group spanning multiple Availability Zones.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample144' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation144' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_3'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_89'>Random</a></p><div class='collapse' id='collapseExample144'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Launch the EC2 instances in a cluster placement group in one Availability Zone.</div></div></div><div class='collapse' id='explanation144'><div class='card card&#45;body'><div>
When you launch a new EC2 instance, the EC2 service attempts to place the instance in such a way that all of your instances are spread out across underlying hardware to minimize correlated failures. You can use placement groups to influence the placement of a group of interdependent instances to meet the needs of your workload.

Depending on the type of workload, you can create a placement group using one of the following placement strategies:

Cluster • packs instances close together inside an Availability Zone. This strategy enables workloads to achieve the low-latency network performance necessary for tightly-coupled node-to-node communication that is typical of HPC applications.

Partition • spreads your instances across logical partitions such that groups of instances in one partition do not share the underlying hardware with groups of instances in different partitions. This strategy is typically used by large distributed and replicated workloads, such as Hadoop, Cassandra, and Kafka.

Spread • strictly places a small group of instances across distinct underlying hardware to reduce correlated failures.

For this scenario, a cluster placement group should be used as this is the best option for providing low-latency network performance for a HPC application.

CORRECT: "Launch the EC2 instances in a cluster placement group in one Availability Zone" is the correct answer.

INCORRECT: "Launch the EC2 instances in a spread placement group in one Availability Zone" is incorrect as the spread placement group is used to spread instances across distinct underlying hardware.

INCORRECT: "Launch the EC2 instances in an Auto Scaling group in two Regions. Place a Network Load Balancer in front of the instances" is incorrect as this does not achieve the stated requirement to provide low-latency, high throughput network performance between instances. Also, you cannot use an ELB across Regions.

INCORRECT: "Launch the EC2 instances in an Auto Scaling group spanning multiple Availability Zones" is incorrect as this does not reduce network latency or improve performance.

References:

Amazon Elastic Compute Cloud > User Guide for Linux Instances > Placement groups</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 2%;" aria-valuenow="2" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EC2'>EC2</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EC2_3><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EC2 Question 3</p><br/>A company runs an AWS Lambda function in private subnets in a VPC. The subnets have a default route to the internet through an Amazon EC2 NAT instance. The Lambda function processes input data and saves its output as an object to Amazon S3 intermittently the Lambda function times out while trying to upload the object because of saturated traffic on the NAT instance's network. The company wants to access Amazon S3 without traversing the internet<br/><br/>Which solution will meet these requirements?<br/><br/>A. Replace the fcC2 NAT instance with an AWS managed NAT gateway<br/>B. Increase the size of the EC2 NAT instance in the VPC to a network optimized instance type<br/>C. Provision a gateway endpoint for Amazon S3 in the VPC Update the route tables of the subnets accordingly<br/>D. Provision a transit gateway Place transit gateway attachments in the private subnets where the Lambda function is running<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample475' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_4'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_10'>Random</a></p><div class='collapse' id='collapseExample475'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Increase the size of the EC2 NAT instance in the VPC to a network optimized instance type</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 3%;" aria-valuenow="3" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EC2'>EC2</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EC2_4><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EC2 Question 4</p><br/>A company is building an online multiplayer game. The game communicates by using UDP, and low latency between the client and the backend is important. The backend is hosted on Amazon EC2 instances that can be deployed to multiple AWS Regions to meet demand. The company needs the game to be highly available so that users around the world can access the game at all times.<br/><br/>What should a solutions architect do to meet these requirements?<br/><br/>A. Deploy Amazon CloudFront to support the global traffic. Configure CloudFront with an origin group to allow access to EC2 instances in multiple Regions.<br/>B. Deploy an Application Load Balancer in one Region to distribute traffic to EC2 instances in each Region that hosts the game's backend instances.<br/>C. Deploy Amazon CloudFront to support an origin access identity (OAI). Associate the OAI with EC2 instances in each Region to support global traffic.<br/>D. Deploy a Network Load Balancer in each Region to distribute the traffic. Use AWS Global Accelerator to route traffic to the correct Regional endpoint.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample421' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_5'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_80'>Random</a></p><div class='collapse' id='collapseExample421'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Deploy Amazon CloudFront to support an origin access identity (OAI). Associate the OAI with EC2 instances in each Region to support global traffic.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 4%;" aria-valuenow="4" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EC2'>EC2</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EC2_5><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EC2 Question 5</p><br/>A marketing company is storing CSV files in an Amazon S3 bucket for statistical analysis. An application on an Amazon EC2 instance needs permission to efficiently process the CSV data stored in the S3 bucket.<br/><br/>Which action will MOST securely grant the EC2 instance access to the S3 bucket?<br/><br/>A. Attach a resource&#8211;based policy to the S3 bucket.<br/>B. Create an IAM user for the application with specific permissions to the S3 bucket.<br/>C. Associate an IAM role with least privilege permissions to the EC2 instance profile.<br/>D. Store AWS credentials directly on the EC2 instance for applications on the instance to use for API calls.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample153' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation153' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_6'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_11'>Random</a></p><div class='collapse' id='collapseExample153'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Associate an IAM role with least privilege permissions to the EC2 instance profile.</div></div></div><div class='collapse' id='explanation153'><div class='card card&#45;body'><div>
Keyword: Privilege Permission + IAM Role

AWS Identity and Access Management (IAM) enables you to manage access to AWS services and resources securely. Using IAM, you can create and manage AWS users and groups, and use permissions to allow and deny their access to AWS resources.

IAM is a feature of your AWS account offered at no additional charge. You will be charged only for use of other AWS services by your users.

IAM roles for Amazon EC2
Applications must sign their API requests with AWS credentials. Therefore, if you are an application developer, you need a strategy for managing credentials for your applications that run on EC2 instances. For example, you can securely distribute your AWS credentials to the instances, enabling the applications on those instances to use your credentials to sign requests, while protecting your credentials from other users. However, it's challenging to securely distribute credentials to each instance, especially those that AWS creates on your behalf, such as Spot Instances or instances in Auto Scaling groups. You must also be able to update the credentials on each instance when you rotate your AWS credentials.

We designed IAM roles so that your applications can securely make API requests from your instances, without requiring you to manage the security credentials that the applications use.

Instead of creating and distributing your AWS credentials, you can delegate permission to make API requests using IAM roles as follows:

Create an IAM role.

Define which accounts or AWS services can assume the role.

Define which API actions and resources the application can use after assuming the role. Specify the role when you launch your instance, or attach the role to an existing instance. Have the application retrieve a set of temporary credentials and use them.

For example, you can use IAM roles to grant permissions to applications running on your instances that need to use a bucket in Amazon S3. You can specify permissions for IAM roles by creating a policy in JSON format. These are similar to the policies that you create for IAM users. If you change a role, the change is propagated to all instances.

When creating IAM roles, associate least privilege IAM policies that restrict access to the specific API calls the application requires.

References:

AWS Identity and Access Management (IAM) FAQs
Amazon Elastic Compute Cloud > User Guide for Linux Instances > IAM roles for Amazon EC2

</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 5%;" aria-valuenow="5" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EC2'>EC2</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EC2_6><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EC2 Question 6</p><br/>An environment has an Auto Scaling group across two Availability Zones to as AZ&#8211;a and AZ&#8211;b has four instances, and AZ&#8211;b has three EC2 instances.<br/><br/>The Auto Scaling group uses a default termination policies. None of the instances are protected from a scale&#8211;in event.<br/><br/>How will Auto Scaling processed if there is a scale&#8211;in event?<br/><br/>A. Auto Scaling selects an instance to terminate randomly.<br/>B. Auto Scaling terminates the instance with the oldest launch configuration of all instances.<br/>C. Auto Scaling selects the Availability Zone with four EC2 instances, and then continues to evaluate.<br/>D. Auto Scaling terminates the instance with the closed next billing hour of all instances.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample587' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_7'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_9'>Random</a></p><div class='collapse' id='collapseExample587'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Auto Scaling selects the Availability Zone with four EC2 instances, and then continues to evaluate.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 6%;" aria-valuenow="6" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EC2'>EC2</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EC2_7><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EC2 Question 7</p><br/>A company receives inconsistent service from its data center provider because the company is headquartered in an area affected by natural disasters. The company is not ready to fully migrate to the AWS Cloud, but it wants a failure environment on AWS in case the on&#8211;premises data center fails.<br/><br/>The company runs web servers that connect to external vendors. The data available on AWS and on&#8211;premises must be uniform.<br/><br/>Which solution should a solutions architect recommend that has the LEAST amount of downtime?<br/><br/>A. Configure an Amazon Route 53 failover record. Run application servers on Amazon EC2 instances behind an Application Load Balancer in an Auto Scaling group. Set up AWS Storage Gateway with stored volumes to back up data to Amazon S3.<br/>B. Configure an Amazon Route 53 failover record. Execute an AWS CloudFormation template from a script to create Amazon EC2 instances behind an Application Load Balancer. Set up AWS Storage Gateway with stored volumes to back up data to Amazon S3.<br/>C. Configure an Amazon Route 53 failover record. Set up an AWS Direct Connect connection between a VPC and the data center. Run application servers on Amazon EC2 in an Auto Scaling group. Run an AWS Lambda function to execute an AWS CloudFormation template to create an Application Load Balancer.<br/>D. Configure an Amazon Route 53 failover record. Run an AWS Lambda function to execute an AWS CloudFormation template to launch two Amazon EC2 instances. Set up AWS Storage Gateway with stored volumes to back up data to Amazon S3. Set up an AWS Direct Connect connection between a VPC and the data center.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample140' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_8'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_62'>Random</a></p><div class='collapse' id='collapseExample140'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Configure an Amazon Route 53 failover record. Run application servers on Amazon EC2 instances behind an Application Load Balancer in an Auto Scaling group. Set up AWS Storage Gateway with stored volumes to back up data to Amazon S3.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 7%;" aria-valuenow="7" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EC2'>EC2</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EC2_8><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EC2 Question 8</p><br/>A company recently migrated a message processing system to AWS. The system receives messages into an ActiveMQ queue running on an Amazon EC2 instance. Messages are processed by a consumer application running on Amazon EC2. The consumer application processes the messages and writes results to a MySQL database running on Amazon EC2. The company wants this application to be highly available with low operational complexity<br/><br/>Which architecture offers the HIGHEST availability?<br/><br/>A. Add a second ActiveMQ server to another Availability Zone Add an additional consumer EC2 instance in another Availability Zone Replicate the MySQL database to another Availability Zone.<br/>B. Use Amazon MQ with active/standby brokers configured across two Availability Zones Add an additional consumer EC2 instance in another Availability Zone. Replicate the MySQL database to another Availability Zone<br/>C. Use Amazon MQ with active/standby brokers configured across two Availability Zones. Add an additional consumer EC2 instance in another Availability Zone. Use Amazon RDS for MySQL with Multi&#8211;AZ enabled<br/>D. Use Amazon MQ with active/standby brokers configured across two Availability Zones Add an Auto Scaling group for the consumer EC2 instances across two Availability Zones Use Amazon RDS for MySQL with Multi&#8211;AZ enabled.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample493' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_9'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_77'>Random</a></p><div class='collapse' id='collapseExample493'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Use Amazon MQ with active/standby brokers configured across two Availability Zones Add an Auto Scaling group for the consumer EC2 instances across two Availability Zones Use Amazon RDS for MySQL with Multi-AZ enabled.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 8%;" aria-valuenow="8" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EC2'>EC2</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EC2_9><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EC2 Question 9</p><br/>The following IAM policy is attached to an IAM group.<br/>What are the effective IAM permissions of this policy for group members?<br/>This is the only policy applied to the group.<br/><br/>What are the effective IAM permissions of this policy for group members?<br/><br/>A. Group members are permitted any Amazon EC2 action within the us&#8211;east&#8211;1 Region. Statements after the Allow permission are not applied.<br/>B. Group members are denied any Amazon EC2 permissions in the us&#8211;east&#8211;1 Region unless they are logged in with multi&#8211;factor authentication (MFA).<br/>C. Group members are allowed the ec2 Stoplnstances and ec2. TerminateInstances permissions for all Regions when logged in with multi&#8211;factor authentication (MFA) Group members are permitted any other Amazon EC2 action.<br/>D. Group members are allowed the ec2 Stoplnstances and ec2. Terminate instances permissions for the us&#8211;east&#8211;1 Region only when logged in with multi&#8211;factor authentication (MFA) Group members are permitted any other Amazon EC2 action within the us&#8211;east&#8211;1 Region.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample474' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_10'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_79'>Random</a></p><div class='collapse' id='collapseExample474'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Group members are allowed the ec2 Stoplnstances and ec2. Terminate instances permissions for the us-east-1 Region only when logged in with multi-factor authentication (MFA) Group members are permitted any other Amazon EC2 action within the us-east-1 Region.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 10%;" aria-valuenow="10" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EC2'>EC2</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EC2_10><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EC2 Question 10</p><br/>A user wants to list the IAM role that is attached to their Amazon EC2 instance. The user has login access to the EC2 instance but does not have IAM permissions.<br/><br/>What should a solutions architect do to retrieve this information?<br/><br/>A. Run the following EC2 command: curl http://169.254.169.254/latest/meta&#8211;data/iam/info<br/>B. Run the following EC2 command: curl http://169.254.169.254/latest/user&#8211;data/iam/info<br/>C. Run the following EC2 command: http://169.254.169.254/latest/dynamic/instance&#8211;identity/<br/>D. Run the following AWS CLI command: aws iam get&#8211;instance&#8211;profile &#8211;&#8211;instance&#8211;profile&#8211;name ExampleInstanceProfile<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample289' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_11'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_75'>Random</a></p><div class='collapse' id='collapseExample289'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Run the following EC2 command: curl http://169.254.169.254/latest/meta-data/iam/info

References:

Amazon Elastic Compute Cloud > User Guide for Linux Instances > IAM roles for Amazon EC2</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 11%;" aria-valuenow="11" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EC2'>EC2</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EC2_11><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EC2 Question 11</p><br/>A company is building a web application that serves a content management system. The content management system runs on Amazon EC2 instances behind an Application Load Balancer (ALB). The EC2 instances run in an Auto Scaling group across multiple Availability Zones Users are constantly adding and updating files blogs and other website assets in the content management system.<br/><br/>A solutions architect must implement a solution in which all the EC2 instances share up&#8211;to&#8211;date website content with the least possible lag time.<br/><br/>Which solution meets these requirements?<br/><br/>A. Update the EC2 user data in the Auto Scaling group lifecycle policy to copy the website assets from the EC2 instance that was launched most recently Configure the ALB to make changes to the website assets only m the newest EC2 instance<br/>B. Copy the website assets to an Amazon Elastic File System (Amazon EFS) file system Configure each EC2 instance to mount the EPS file system locally Configure the website hosting application to reference the website assets that are stored in the EFS file system<br/>C. Copy the website assets to an Amazon S3 bucket Ensure that each EC2 instance downloads the website assets from the S3 bucket to the attached Amazon Elastic Block Store (Amazon EBS) volume Run the S3 sync command once each hour to keep files up to date<br/>D. Restore an Amazon Elastic Block Store (Amazon EBS) snapshot with the website assets Attach the EBS snapshot as a secondary EBS volume when a new EC2 instance is launched Configure the website hosting application to reference the website assets that are stored in the secondary EBS volume<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample463' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_12'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_43'>Random</a></p><div class='collapse' id='collapseExample463'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Update the EC2 user data in the Auto Scaling group lifecycle policy to copy the website assets from the EC2 instance that was launched most recently Configure the ALB to make changes to the website assets only m the newest EC2 instance</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 12%;" aria-valuenow="12" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EC2'>EC2</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EC2_12><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EC2 Question 12</p><br/>A company wants to improve the availability and performance of its hybrid application. The application consists of a stateful TCP&#8211;based workload hosted on Amazon EC2 instances in different AWS Regions and a stateless UOP&#8211;based workload hosted on&#8211;premises.<br/><br/>Which combination of actions should a solutions architect take to improve availability and performance? (Choose two.)<br/><br/>A. Create an accelerator using AWS Global Accelerator. Add the load balancers as endpoints.<br/>B. Create an Amazon CloudFront distribution with an origin that uses Amazon Route 53 latency&#8211;based routing to route requests to the load balancers.<br/>C. Configure two Application Load Balancers in each Region. The first will route to the EC2 endpoints and the second will route to the on&#8211;premises endpoints.<br/>D. Configure a Network Load Balancer in each Region to address the EC2 endpoints. Configure a Network Load Balancer in each Region that routes to the on&#8211;premises endpoints.<br/>E. Configure a Network Load Balancer in each Region to address the EC2 endpoints. Configure an Application Load Balancer in each Region that routes to the on&#8211;premises endpoints.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample294' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_13'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_3'>Random</a></p><div class='collapse' id='collapseExample294'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Create an accelerator using AWS Global Accelerator. Add the load balancers as endpoints.
<br><b>D. </b>Configure a Network Load Balancer in each Region to address the EC2 endpoints. Configure a Network Load Balancer in each Region that routes to the on-premises endpoints.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 13%;" aria-valuenow="13" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EC2'>EC2</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EC2_13><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EC2 Question 13</p><br/>A company is deploying an application that processes large quantities of data in parallel. The company plans to use Amazon EC2 instances for the workload.<br/><br/>The network architecture must be configurable to provide the lowest possible latency between nodes.<br/><br/>Which combination of network solutions will meet these requirements? (Select TWO)<br/><br/>A. Distribute the EC2 instances across multiple Availability Zones<br/>B. Attach an Elastic Fabric Adapter (EFA) to each EC2 instance<br/>C. Place the EC2 instances in a single Availability Zone<br/>D. Use Amazon Elastic Block Store (Amazon EBS) optimized instance types<br/>E. Run the EC2 instances in a cluster placement group<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample632' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_14'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_88'>Random</a></p><div class='collapse' id='collapseExample632'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Place the EC2 instances in a single Availability Zone
<br><b>E. </b>Run the EC2 instances in a cluster placement group</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 14%;" aria-valuenow="14" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EC2'>EC2</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EC2_14><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EC2 Question 14</p><br/>A company has two applications it wants to migrate to AWS. Both applications process a large set of files by accessing the same files at the same time. Both applications need to read the files with low latency.<br/><br/>Which architecture should a solutions architect recommend for this situation?<br/><br/>A. Configure two AWS Lambda functions to run the applications. Create an Amazon EC2 instance with an instance store volume to store the data.<br/>B. Configure two AWS Lambda functions to run the applications. Create an Amazon EC2 instance with an Amazon Elastic Block Store (Amazon EBS) volume to store the data.<br/>C. Configure one memory optimized Amazon EC2 instance to run both applications simultaneously. Create an Amazon Elastic Block Store (Amazon EBS) volume with Provisioned IOPS to store the data.<br/>D. Configure two Amazon EC2 instances to run both applications. Configure Amazon Elastic File System (Amazon EFS) with General Purpose performance mode and Bursting Throughput mode to store the data.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample67' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_15'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_81'>Random</a></p><div class='collapse' id='collapseExample67'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Configure two Amazon EC2 instances to run both applications. Configure Amazon Elastic File System (Amazon EFS) with General Purpose performance mode and Bursting Throughput mode to store the data.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 15%;" aria-valuenow="15" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EC2'>EC2</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EC2_15><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EC2 Question 15</p><br/>A company's application is running on Amazon EC2 instances in a single Region. In the event of a disaster, a solutions architect needs to ensure that the resources can also be deployed to a second Region.<br/><br/>Which combination of actions should the solutions architect take to accomplish this? (Choose two.)<br/><br/>A. Detach a volume on an EC2 instance and copy it to Amazon S3.<br/>B. Launch a new EC2 instance from an Amazon Machine Image (AMI) in a new Region.<br/>C. Launch a new EC2 instance in a new Region and copy a volume from Amazon S3 to the new instance.<br/>D. Copy an Amazon Machine Image (AMI) of an EC2 instance and specify a different Region for the destination.<br/>E. Copy an Amazon Elastic Block Store (Amazon EBS) volume from Amazon S3 and launch an EC2 instance in the destination Region using that EBS volume.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample145' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation145' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_16'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_0'>Random</a></p><div class='collapse' id='collapseExample145'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Launch a new EC2 instance from an Amazon Machine Image (AMI) in a new Region.
<br><b>D. </b>Copy an Amazon Machine Image (AMI) of an EC2 instance and specify a different Region for the destination.</div></div></div><div class='collapse' id='explanation145'><div class='card card&#45;body'><div>
Cross Region EC2 AMI Copy
We know that you want to build applications that span AWS Regions and we're working to provide you with the services and features needed to do so. We started out by launching the EBS Snapshot Copy feature late last year. This feature gave you the ability to copy a snapshot from Region to Region with just a couple of clicks. In addition, last month we made a significant reduction (26% to 83%) in the cost of transferring data between AWS Regions, making it less expensive to operate in more than one AWS region.

Today we are introducing a new feature: Amazon Machine Image (AMI) Copy. AMI Copy enables you to easily copy your Amazon Machine Images between AWS Regions. AMI Copy helps enable several key scenarios including:

Simple and Consistent Multi-Region Deployment – You can copy an AMI from one region to another, enabling you to easily launch consistent instances based on the same AMI into different regions.

Scalability – You can more easily design and build world-scale applications that meet the needs of your users, regardless of their location.

Performance – You can increase performance by distributing your application and locating critical components of your application in closer proximity to your users. You can also take advantage of region specific features such as instance types or other AWS services.

Even Higher Availability – You can design and deploy applications across AWS regions, to increase availability. Once the new AMI is in an Available state the copy is complete.

Once the new AMI is in an Available state the copy is complete.
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 16%;" aria-valuenow="16" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EC2'>EC2</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EC2_16><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EC2 Question 16</p><br/>A company hosts its multi&#8211;tier public web application in the AWS Cloud. The web application runs on Amazon EC2 instances and its database runs on Amazon RDS. The company is anticipating a large increase in sales during an upcoming holiday weekend. A solutions architect needs to build a solution to analyze the performance of the web application with a granularity of no more than 2 minutes.<br/><br/>What should the solutions architect do to meet this requirement?<br/><br/>A. Send Amazon CloudWatch logs to Amazon Redshift. Use Amazon QuickSight to perform further analysis.<br/>B. Enable detailed monitoring on all EC2 instances. Use Amazon CloudWatch metrics to perform further analysis.<br/>C. Create an AWS Lambda function to fetch EC2 logs from Amazon CloudWatch Logs. Use Amazon CloudWatch metrics to perform further analysis.<br/>D. Send EC2 logs to Amazon S3. Use Amazon Redshift to fetch logs from the S3 bucket to process raw data for further analysis with Amazon QuickSight.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample370' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_17'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_72'>Random</a></p><div class='collapse' id='collapseExample370'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Enable detailed monitoring on all EC2 instances. Use Amazon CloudWatch metrics to perform further analysis.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 17%;" aria-valuenow="17" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EC2'>EC2</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EC2_17><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EC2 Question 17</p><br/>A company manages its own Amazon EC2 instances that run MySQL databases. The company is manually managing replication and scaling as demand increases or decreases. The company needs a new solution that simplifies the process of adding or removing compute capacity to or from its database tier as needed.<br/><br/>The solution also must offer improved performance, scaling, and durability with minimal effort from operations.<br/><br/>Which solution meets these requirements?<br/><br/>A. Migrate the databases to Amazon Aurora Serverless for Aurora MySQL.<br/>B. Migrate the databases to Amazon Aurora Serverless for Aurora PostgreSQL.<br/>C. Combine the databases into one larger MySQL database. Run the larger database on larger EC2 instances.<br/>D. Create an EC2 Auto Scaling group for the database tier. Migrate the existing databases to the new environment.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample308' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_18'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_56'>Random</a></p><div class='collapse' id='collapseExample308'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Create an EC2 Auto Scaling group for the database tier. Migrate the existing databases to the new environment.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 18%;" aria-valuenow="18" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EC2'>EC2</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EC2_18><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EC2 Question 18</p><br/>In Amazon AWS, which of the following statements is true of key pairs?<br/><br/>A. Key pairs are used only for Amazon SDKs.<br/>B. Key pairs are used only for Amazon EC2 and Amazon CloudFront.<br/>C. Key pairs are used only for Elastic Load Balancing and AWS IAM.<br/>D. Key pairs are used for all Amazon services.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample762' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation762' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_19'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_61'>Random</a></p><div class='collapse' id='collapseExample762'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Key pairs are used only for Amazon EC2 and Amazon CloudFront.</div></div></div><div class='collapse' id='explanation762'><div class='card card&#45;body'><div>
Key pairs consist of a public and private key, where you use the private key to create a digital signature, and then AWS uses the corresponding public key to validate the signature. Key pairs are used only for Amazon EC2 and Amazon CloudFront.

References:

AWS General Reference > Reference guide > Understanding and getting your AWS credentials</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 20%;" aria-valuenow="20" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EC2'>EC2</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EC2_19><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EC2 Question 19</p><br/>A company designed a stateless two&#8211;tier application that uses Amazon EC2 in a single Availability Zone and an Amazon RDS Multi&#8211;AZ DB instance. New company management wants to ensure the application is highly available.<br/><br/>What should a solutions architect do to meet this requirement?<br/><br/>A. Configure the application to use Multi&#8211;AZ EC2 Auto Scaling and create an Application Load Balancer.<br/>B. Configure the application to take snapshots of the EC2 instances and send them to a different AWS Region.<br/>C. Configure the application to use Amazon Route 53 latency&#8211;based routing to feed requests to the application.<br/>D. Configure Amazon Route 53 rules to handle incoming requests and create a Multi&#8211;AZ Application Load Balancer.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample438' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_20'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_37'>Random</a></p><div class='collapse' id='collapseExample438'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Configure the application to use Multi-AZ EC2 Auto Scaling and create an Application Load Balancer.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 21%;" aria-valuenow="21" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EC2'>EC2</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EC2_20><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EC2 Question 20</p><br/>A solutions architect is using an AWS Cloud Formation template to deploy a three&#8211;tier web application. The web application consists of a web tier and an application tier that stores and retrieves user data in Amazon DynamoDB tables. The web and application tiers are hosted on Amazon EC2 instances, and the database tier is not publicly accessible. The application EC2 instances need to access the DynamoDB tables without exposing API credentials in the template.<br/><br/>What should the solutions architect do to meet these requirements?<br/><br/>A. Create an IAM role to read the DynamoOB tables. Associate the role with the application instances by reference an instance profile<br/>B. Create an IAM role that has the required permissions to read and write from the DynamoOB tables. Add the role to the EC2 instance profile and associate the instance profile with the apphcanon instances<br/>C. Use the parameter section in the AWS CkHidFormaton template to have the user input access and secret keys from an already&#8211;created IAM user mat has the required permissions to read and write from the DynamoOB tables<br/>D. Create an IAM user m the AWS CioudFormation template that has the required permissions to read and write from the DynamoOB tables. Use the GetAti function to retrieve the access and secret keys and pass them to the application instances through the user data<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample525' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_21'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_33'>Random</a></p><div class='collapse' id='collapseExample525'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Create an IAM role that has the required permissions to read and write from the DynamoOB tables. Add the role to the EC2 instance profile and associate the instance profile with the apphcanon instances</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 22%;" aria-valuenow="22" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EC2'>EC2</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EC2_21><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EC2 Question 21</p><br/>A company's application runs on Amazon EC2 instances behind an Application Load Balancer (ALB). The instances run in an Amazon EC2 Auto Scaling group across multiple Availability Zones. On the first day of every month at midnight, the application becomes much slower when the month&#8211;end financial calculation batch executes. This causes the CPU utilization of the EC2 instances to immediately peak to 100%, which disrupts the application.<br/><br/>What should a solutions architect recommend to ensure the application is able to handle the workload and avoid downtime?<br/><br/>A. Configure an Amazon CloudFront distribution in front of the ALB.<br/>B. Configure an EC2 Auto Scaling simple scaling policy based on CPU utilization.<br/>C. Configure an EC2 Auto Scaling scheduled scaling policy based on the monthly schedule.<br/>D. Configure Amazon ElastiGache to remove some of the workload from the EC2 instances.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample413' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_22'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_4'>Random</a></p><div class='collapse' id='collapseExample413'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Configure an EC2 Auto Scaling scheduled scaling policy based on the monthly schedule.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 23%;" aria-valuenow="23" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EC2'>EC2</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EC2_22><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EC2 Question 22</p><br/>A solutions architect is designing a multi&#8211;region disaster recovery solution for an application that will provide public API access. The application will use Amazon EC2 instances with a user data script to load application code and an Amazon RDS for MySQL database. The Recovery Time Objective (RTO) is 3 hours and the Recovery Point Objective (RPO) is 24 hours.<br/><br/>Which architecture would meet these requirements at the LOWEST cost?<br/><br/>A. Use an Application Load Balancer for Region failover. Deploy new EC2 instances with the user data script. Deploy separate RDS instances in each Region.<br/>B. Use Amazon Route 53 for Region failover. Deploy new EC2 instances with the user data script. Create a read replica of the RDS instance in a backup Region.<br/>C. Use Amazon API Gateway for the public APIs and Region failover. Deploy new EC2 instances with the user data script. Create a MySQL read replica of the RDS instance in a backup Region.<br/>D. Use Amazon Route 53 for Region failover. Deploy new EC2 instances with the user data script for APIs, and create a snapshot of the RDS instance daily for a backup. Replicate the snapshot to a backup Region.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample279' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_23'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_65'>Random</a></p><div class='collapse' id='collapseExample279'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Use Amazon Route 53 for Region failover. Deploy new EC2 instances with the user data script for APIs, and create a snapshot of the RDS instance daily for a backup. Replicate the snapshot to a backup Region.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 24%;" aria-valuenow="24" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EC2'>EC2</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EC2_23><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EC2 Question 23</p><br/>A mobile gaming company runs application servers on Amazon EC2 instances. The servers receive updates from players every 15 minutes. The mobile game creates a JSON object of the progress made in the game since the last update, and sends the JSON object to an Application Load Balancer. As the mobile game is played, game updates are being lost. The company wants to create a durable way to get the updates in older.<br/><br/>What should a solutions architect recommend to decouple the system?<br/><br/>A. Use Amazon Kinesis Data Streams to capture the data and store the JSON object in Amazon S3.<br/>B. Use Amazon Kinesis Data Firehose to capture the data and store the JSON object in Amazon S3.<br/>C. Use Amazon Simple Queue Service (Amazon SQS) FIFO queues to capture the data and EC2 instances to process the messages in the queue.<br/>D. Use Amazon Simple Notification Service (Amazon SNS) to capture the data and EC2 instances to process the messages sent to the Application Load Balancer.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample404' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_24'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_36'>Random</a></p><div class='collapse' id='collapseExample404'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Use Amazon Simple Queue Service (Amazon SQS) FIFO queues to capture the data and EC2 instances to process the messages in the queue.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 25%;" aria-valuenow="25" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EC2'>EC2</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EC2_24><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EC2 Question 24</p><br/>A company is hosting multiple websites for several lines of business under its registered parent domain.<br/><br/>Users accessing these websites will be routed to appropriate backend Amazon EC2 instances based on the subdomain. The websites host static webpages, images, and server&#8211;side scripts like PHP and JavaScript. Some of the websites experience peak access during the first two hours of business with constant usage throughout the rest of the day. A solutions architect needs to design a solution that will automatically adjust capacity to these traffic patterns while keeping costs low.<br/><br/>Which combination of AWS services or features will meet these requirements? (Choose two.)<br/><br/>A. AWS Batch<br/>B. Network Load Balancer<br/>C. Application Load Balancer<br/>D. Amazon EC2 Auto Scaling<br/>E. Amazon S3 website hosting<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample107' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_25'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_59'>Random</a></p><div class='collapse' id='collapseExample107'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Application Load Balancer
<br><b>D. </b>Amazon EC2 Auto Scaling

References:

Amazon Simple Storage Service > User Guide > Hosting a static website using Amazon S3</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 26%;" aria-valuenow="26" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EC2'>EC2</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EC2_25><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EC2 Question 25</p><br/>A solutions architect is designing a shared storage solution for a web application that is deployed across multiple Availability Zones.<br/><br/>The web application runs on Amazon EC2 instances in an Auto Scaling group.<br/><br/>The company anticipates making frequent changes to the content, so the solution must have strong consistency.<br/><br/>Which solution meets these requirements?<br/><br/>A. Create an Amazon S3 bucket to store the web content Use Amazon CloudFront to deliver the content.<br/>B. Create an Amazon Elastic File System (Amazon EFS) file system and mount it on the individual EC2 instances.<br/>C. Create a shared Amazon Elastic Block Store (Amazon EBS) volume and mount it on the individual EC2 instances.<br/>D. Use AWS DataSync to perform continuous synchronization of data between EC2 hosts in the Auto Scaling group.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample654' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_26'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_83'>Random</a></p><div class='collapse' id='collapseExample654'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Create an Amazon Elastic File System (Amazon EFS) file system and mount it on the individual EC2 instances.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 27%;" aria-valuenow="27" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EC2'>EC2</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EC2_26><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EC2 Question 26</p><br/>A company is running an application on Amazon EC2 instances hosted in a private subnet of a VPC.<br/><br/>The EC2 instances are configured in an Auto Scaling group behind an Elastic Load Balancer (ELB).<br/><br/>The EC2 instances use a NAT gateway for outbound internet access.<br/><br/>However the EC2 instances are not able to connect to the public internet to download software updates.<br/><br/>What are the possible root causes of this issue? (Select TWO )<br/><br/>A. The ELB is not configured with a proper health check<br/>B. The route tables in the VPC are configured incorrectly<br/>C. The EC2 instances are not associated with an Elastic IP address<br/>D. The security group attached to the NAT gateway is configured incorrectly<br/>E. The outbound rules on the security group attached to the EC2 Instances are configured incorrectly.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample658' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_27'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_68'>Random</a></p><div class='collapse' id='collapseExample658'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>The route tables in the VPC are configured incorrectly
<br><b>E. </b>The outbound rules on the security group attached to the EC2 Instances are configured incorrectly.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 28%;" aria-valuenow="28" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EC2'>EC2</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EC2_27><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EC2 Question 27</p><br/>A solution architect at a company is designing the architecture for a two&#8211;tiered web application. The web application is composed of an internet facing application load balancer that forwards traffic to an auto scaling group of Amazon EC2 instances. The EC2 instances must be able to access a database that runs on Amazon RDS.<br/><br/>The company has requested a defense&#8211;in&#8211;depth approach to the network layout. The company does not want to rely solely on security groups or network ACLs. Only the minimum resources that are necessary should be routable from the internet.<br/><br/>Which network design should the solutions architect recommend to meet these requirements?<br/><br/>A. Place the ALB, EC2 instances and RDS database in private subnets.<br/>B. Place the ALB in public subnets. Place the EC2 instances and RDS database in private subnets<br/>C. Place the ALB and EC2 instances in public subnets. Place the RDS database in private subnets<br/>D. Place the ALB outside the VP<br/>E. Place the EC2 instances and RDS database in private subnets.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample468' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_28'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_53'>Random</a></p><div class='collapse' id='collapseExample468'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Place the ALB in public subnets. Place the EC2 instances and RDS database in private subnets</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 30%;" aria-valuenow="30" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EC2'>EC2</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EC2_28><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EC2 Question 28</p><br/>A company observes an increase in Amazon EC2 costs in its most recent bill.<br/><br/>The billing team notices unwanted vertical scaling of instance types for a couple of EC2 instances.<br/><br/>A solutions architect needs to create a graph comparing the last 2 months of EC2 costs and perform an in&#8211;depth analysis to identify the root cause of the vertical scaling.<br/><br/>How should the solutions architect generate the information with the LEAST operational overhead?<br/><br/>A. Use AWS Budgets to create a budget report and compare costs based on instance types.<br/>B. Use Cost Explorer's granular filtering feature to perform an in&#8211;depth analysis of EC2 costs based on instance types.<br/>C. Use graphs from the AWS Billing and Cost Management dashboard to compare EC2 costs based on instance types for the least 2 months.<br/>D. Use AWS Cost and Usage Report to create a report and send it to an Amazon S3 bucket. Use Amazon QuickSight Amazon S3 as a source to generate an interactive graph based on instance types.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample614' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_29'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_78'>Random</a></p><div class='collapse' id='collapseExample614'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Use graphs from the AWS Billing and Cost Management dashboard to compare EC2 costs based on instance types for the least 2 months.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 31%;" aria-valuenow="31" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EC2'>EC2</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EC2_29><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EC2 Question 29</p><br/>A company runs its two&#8211;tier eCommerce website on AWS. The web tier consists of a load balancer that sends traffic to Amazon EC2 instances. The database tier uses an Amazon RDS DB instance. The EC2 instances and the RDS DB instance should not be exposed to the public internet. The EC2 instances require internet access to complete payment processing of orders through a third&#8211;party web service. The application must be highly available.<br/><br/>Which combination of configuration options will meet these requirements? (Choose two.)<br/><br/>A. Use an Auto Scaling group to launch the EC2 instances in private subnets. Deploy an RDS Multi&#8211;AZ DB instance in private subnets.<br/>B. Configure a VPC with two private subnets and two NAT gateways across two Availability Zones. Deploy an Application Load Balancer in the private subnets.<br/>C. Use an Auto Scaling group to launch the EC2 instances in public subnets across two Availability Zones. Deploy an RDS Multi&#8211;AZ DB instance in private subnets.<br/>D. Configure a VPC with one public subnet, one private subnet, and two NAT gateways across two Availability Zones. Deploy an Application Load Balancer in the public subnet.<br/>E. Configure a VPC with two public subnets, two private subnets, and two NAT gateways across two Availability Zones. Deploy an Application Load Balancer in the public subnets.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample422' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_30'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_44'>Random</a></p><div class='collapse' id='collapseExample422'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Use an Auto Scaling group to launch the EC2 instances in private subnets. Deploy an RDS Multi-AZ DB instance in private subnets.
<br><b>B. </b>Configure a VPC with two private subnets and two NAT gateways across two Availability Zones. Deploy an Application Load Balancer in the private subnets.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 32%;" aria-valuenow="32" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EC2'>EC2</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EC2_30><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EC2 Question 30</p><br/>A company captures clickstream data from multiple websites and analyzes it using batch processing. The data is loaded nightly into Amazon Redshift and is consumed by business analysts. The company wants to move towards near&#8211;real&#8211;time data processing for timely insights. The solution should process the streaming data with minimal effort and operational overhead.<br/><br/>Which combination of AWS services are MOST cost&#8211;effective for this solution? (Choose two.)<br/><br/>A. Amazon EC2<br/>B. AWS Lambda<br/>C. Amazon Kinesis Data Streams<br/>D. Amazon Kinesis Data Firehose<br/>E. Amazon Kinesis Data Analytics<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample4' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation4' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_31'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_15'>Random</a></p><div class='collapse' id='collapseExample4'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Amazon EC2
<br><b>D. </b>Amazon Kinesis Data Firehose</div></div></div><div class='collapse' id='explanation4'><div class='card card&#45;body'><div>
Kinesis Data Streams and Kinesis Client Library (KCL) – Data from the data source can be continuously captured and streamed in near real-time using Kinesis Data Streams. With the Kinesis Client Library (KCL), you can build your own application that can preprocess the streaming data as they arrive and emit the data for generating incremental views and downstream analysis. Kinesis Data Analytics – This service provides the easiest way to process the data that is streaming through Kinesis Data Stream or Kinesis Data Firehose using SQL. This enables customers to gain actionable insight in near real-time from the incremental stream before storing it in Amazon S3.

Lambda architecture building blocks on AWS

References:

Evolve from batch to real-time analytics</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 33%;" aria-valuenow="33" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EC2'>EC2</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EC2_31><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EC2 Question 31</p><br/>A company is running a three&#8211;tier web application to process credit card payments. The front&#8211;end user interface consists of static webpages. The application tier can have long&#8211;running processes. The database tier uses MySQL.<br/><br/>The application is currently running on a single, general&#8211;purpose large Amazon EC2 instance. A solutions architect needs to decouple the services to make the web application highly available.<br/><br/>Which solution would provide the HIGHEST availability?<br/><br/>A. Move static assets to Amazon CloudFront. Leave the application in EC2 in an Auto Scaling group. Move the database to Amazon RDS to deploy Multi&#8211;AZ.<br/>B. Move static assets and the application into a medium EC2 instance. Leave the database on the large instance. Place both instances in an Auto Scaling group.<br/>C. Move static assets to Amazon S3, Move the application to AWS Lambda with the concurrency limit set. Move the database to Amazon DynamoDB with on&#8211;demand enabled.<br/>D. Move static assets to Amazon S3. Move the application to Amazon Elastic Container Service (Amazon ECS) containers with Auto Scaling enabled. Move the database to Amazon RDS to deploy Multi&#8211;AZ.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample103' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_32'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_29'>Random</a></p><div class='collapse' id='collapseExample103'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Move static assets and the application into a medium EC2 instance. Leave the database on the large instance. Place both instances in an Auto Scaling group.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 34%;" aria-valuenow="34" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EC2'>EC2</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EC2_32><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EC2 Question 32</p><br/>A company has hired a solutions architect to design a reliable architecture for its application.<br/><br/>The application consists of one Amazon RDS DB instance and two manually provisioned Amazon EC2 instances that run web servers.<br/><br/>The EC2 instances are located in a single Availability Zone.<br/><br/>An employee recently deleted the DB instance and the application was unavailable for 24 hours as a result.<br/><br/>The company is concerned with the overall reliability of its environment.<br/><br/>What should the solutions architect do to maximize reliability of the application's infrastructure?<br/><br/>A. Delete one EC2 instance and enable termination protection on the other EC2 instance. Update the DB instance to be Muto&#8211;AZ and enable deletion protection<br/>B. Update the DB instance to be Multiple&#8211;AZ and enable deletion protection. Place the EC2 instances behind an Application Load Balancer and run them in an EC2 Auto Seating group across multiple Availability Zones<br/>C. Create an additional DB instance along with an Amazon API Gateway and an AWS Lambda function. Configure the application to invoke the Lambda function through API Gateway. Have the Lambda function write the data to the two DB instances<br/>D. Place the EC2 instances in an EC2 Auto Scaling group that has multiple subnets located in multiple Availability Zones. Use Spot Instances instead of On&#8211;Demand instances. Set up Amazon CloudWatch alarms to monitor the health of the instances. Update the DB instance to be Multi&#8211;AZ and enable deletion protection<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample528' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_33'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_13'>Random</a></p><div class='collapse' id='collapseExample528'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Update the DB instance to be Multiple-AZ and enable deletion protection. Place the EC2 instances behind an Application Load Balancer and run them in an EC2 Auto Seating group across multiple Availability Zones</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 35%;" aria-valuenow="35" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EC2'>EC2</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EC2_33><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EC2 Question 33</p><br/>An Amazon EC2 administrator created the following policy associated with an IAM group containing several users:<br/><br/>An Amazon EC2 administrator created the following policy associated with an IAM group containing several users.<br/><br/>What is the effect of this policy?<br/><br/>A. Users can terminate an EC2 instance in any AWS Region except us&#8211;east&#8211;1.<br/>B. Users can terminate an EC2 instance with the IP address 10.100.100.1 in the us&#8211;east&#8211;1 Region.<br/>C. Users can terminate an EC2 instance in the us&#8211;east&#8211;1 Region when the user's source IP is 10.100.100.254.<br/>D. Users cannot terminate an EC2 instance in the us&#8211;east&#8211;1 Region when the user's source IP is 10.100.100.254.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample41' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation41' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_34'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_84'>Random</a></p><div class='collapse' id='collapseExample41'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Users can terminate an EC2 instance in the us-east-1 Region when the user's source IP is 10.100.100.254.</div></div></div><div class='collapse' id='explanation41'><div class='card card&#45;body'><div>
What the policy means:
1. Allow termination of any instance if user's source IP address is 100.100.254.
2. Deny termination of instances that are not in the us-east-1 Combining this two, you get:
"Allow instance termination in the us-east-1 region if the user's source IP address is 10.100.100.254. Deny termination operation on other regions."


</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 36%;" aria-valuenow="36" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EC2'>EC2</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EC2_34><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EC2 Question 34</p><br/>A company recently deployed a new auditing system to centralize information about operating system versions, patching, and installed software for Amazon EC2 instances. A solutions architect must ensure all instances provisioned through EC2 Auto Scaling groups successfully send reports to the auditing system as soon as they are launched and terminated.<br/><br/>Which solution achieves these goals MOST efficiently?<br/><br/>A. Use a scheduled AWS Lambda function and execute a script remotely on all EC2 instances to send data to the audit system.<br/>B. Use EC2 Auto Scaling lifecycle hooks to execute a custom script to send data to the audit system when instances are launched and terminated.<br/>C. Use an EC2 Auto Scaling launch configuration to execute a custom script through user data to send data to the audit system when instances are launched and terminated.<br/>D. Execute a custom script on the instance operating system to send data to the audit system. Configure the script to be executed by the EC2 Auto Scaling group when the instance starts and is terminated.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample50' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_35'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_85'>Random</a></p><div class='collapse' id='collapseExample50'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Use EC2 Auto Scaling lifecycle hooks to execute a custom script to send data to the audit system when instances are launched and terminated.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 37%;" aria-valuenow="37" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EC2'>EC2</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EC2_35><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EC2 Question 35</p><br/>A company runs multiple Amazon EC2 Linux instances in a VPC with applications that use a hierarchical directory structure. The applications need to rapidly and concurrently read and write to shared storage.<br/><br/>How can this be achieved?<br/><br/>A. Create an Amazon EFS file system and mount it from each EC2 instance.<br/>B. Create an Amazon S3 bucket and permit access from all the EC2 instances in the VPC.<br/>C. Create a file system on an Amazon EBS Provisioned IOPS SSD (io1) volume. Attach the volume to all the EC2 instances.<br/>D. Create file systems on Amazon EBS volumes attached to each EC2 instance. Synchronize the Amazon EBS volumes across the different EC2 instances.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample195' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_36'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_50'>Random</a></p><div class='collapse' id='collapseExample195'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Create an Amazon EFS file system and mount it from each EC2 instance.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 38%;" aria-valuenow="38" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EC2'>EC2</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EC2_36><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EC2 Question 36</p><br/>A company is building an application that consists of several microservices. The company has decided to use container technologies to deploy its software on AWS. The company needs a solution that minimizes the amount of ongoing effort for maintenance and scaling. The company cannot manage additional infrastructure.<br/><br/>Which combination of actions should a solutions architect take to meet these requirements? (Choose two.)<br/><br/>A. Deploy an Amazon Elastic Container Service (Amazon ECS) cluster.<br/>B. Deploy the Kubernetes control plane on Amazon EC2 instances that span multiple Availability Zones.<br/>C. Deploy an Amazon Elastic Container Service (Amazon ECS) service with an Amazon EC2 launch type. Specify a desired task number level of greater than or equal to 2.<br/>D. Deploy an Amazon Elastic Container Service (Amazon ECS) service with a Fargate launch type. Specify a desired task number level of greater than or equal to 2.<br/>E. Deploy Kubernetes worker nodes on Amazon EC2 instances that span multiple Availability Zones. Create a deployment that specifies two or more replicas for each microservice.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample419' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_37'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_71'>Random</a></p><div class='collapse' id='collapseExample419'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Deploy an Amazon Elastic Container Service (Amazon ECS) cluster.
<br><b>B. </b>Deploy the Kubernetes control plane on Amazon EC2 instances that span multiple Availability Zones.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 40%;" aria-valuenow="40" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EC2'>EC2</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EC2_37><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EC2 Question 37</p><br/>A solution architect needs to design a highly available application consisting of web, application, and database tiers. HTTPS content delivery should be as close to the edge as possible, with the least delivery time.<br/><br/>Which solution meets these requirements and is MOST secure?<br/><br/>A. Configure a public Application Load Balancer (ALB) with multiple redundant Amazon EC2 instances in public subnets. Configure Amazon CloudFront to deliver HTTPS content using the public ALB as the origin.<br/>B. Amazon EC2 instances in private subnets Configure. Configure a public Application Load Balancer with multiple redundant Amazon CloudFront to deliver HTTPS content using the EC2 instances as the origin.<br/>C. Configure a public Application Load Balancer (ALB) with multiple redundant Amazon EC2 instances in private subnets. Configure Amazon CloudFront to deliver HTTPS content using the public ALB as the origin.<br/>D. Configure a public Application Load Balancer with multiple redundant Amazon EC2 instances in public subnets. Configure Amazon CloudFront to deliver HTTPS content using the EC2 instances as the origin.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample314' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_38'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_57'>Random</a></p><div class='collapse' id='collapseExample314'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Amazon EC2 instances in private subnets Configure. Configure a public Application Load Balancer with multiple redundant Amazon CloudFront to deliver HTTPS content using the EC2 instances as the origin.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 41%;" aria-valuenow="41" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EC2'>EC2</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EC2_38><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EC2 Question 38</p><br/>A company operates a website on Amazon EC2 Linux instances. Some of the instances are failing.<br/><br/>Troubleshooting points to insufficient swap space on the failed instances. The operations team lead needs a solution to monitor this.<br/><br/>What should a solutions architect recommend?<br/><br/>A. Configure an Amazon CloudWatch SwapUsage metric dimension. Monitor the SwapUsage dimension in the EC2 metrics in CloudWatch.<br/>B. Use EC2 metadata to collect information, then publish it to Amazon CloudWatch custom metrics. Monitor SwapUsage metrics in CloudWatch.<br/>C. Install an Amazon CloudWatch agent on the instances. Run an appropriate script on a set schedule. Monitor SwapUtilization metrics in CloudWatch.<br/>D. Enable detailed monitoring in the EC2 console. Create an Amazon CloudWatch SwapUtilization custom metric. Monitor SwapUtilization metrics in CloudWatch.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample211' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_39'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_35'>Random</a></p><div class='collapse' id='collapseExample211'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Install an Amazon CloudWatch agent on the instances. Run an appropriate script on a set schedule. Monitor SwapUtilization metrics in CloudWatch.

References:

Amazon Elastic Compute Cloud > User Guide for Linux Instances > Monitor memory and disk metrics for Amazon EC2 Linux instances</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 42%;" aria-valuenow="42" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EC2'>EC2</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EC2_39><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EC2 Question 39</p><br/>In Amazon EC2 Container Service, are other container types supported?<br/><br/>A. Yes, EC2 Container Service supports any container service you need.<br/>B. Yes, EC2 Container Service also supports Microsoft container service.<br/>C. No, Docker is the only container platform supported by EC2 Container Service presently.<br/>D. Yes, EC2 Container Service supports Microsoft container service and Openstack.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample737' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation737' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_40'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_69'>Random</a></p><div class='collapse' id='collapseExample737'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>No, Docker is the only container platform supported by EC2 Container Service presently.</div></div></div><div class='collapse' id='explanation737'><div class='card card&#45;body'><div>
In Amazon EC2 Container Service, Docker is the only container platform supported by EC2 Container Service presently.

References:

Amazon Elastic Container Service FAQs</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 43%;" aria-valuenow="43" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EC2'>EC2</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EC2_40><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EC2 Question 40</p><br/>A start&#8211;up company has a web application based in the us&#8211;east&#8211;1 Region with multiple Amazon EC2 instances running behind an Application Load Balancer across multiple Availability Zones As the company's user base grows in the us&#8211;west&#8211;1 Region, it needs 3 solution with low latency and high availability.<br/><br/>What should a solutions architect do to accomplish this?<br/><br/>A. Provision EC2 instances in us&#8211;west&#8211;1. Switch my Application Load Balancer to a Network Load Balancer to achieve cross&#8211;Region load balancing.<br/>B. Provision EC2 instances and an Application Load Balancer in us&#8211;west&#8211;1 Make the load balancer distribute the traffic based on the location of the request<br/>C. Provision EC2 instances and configure an Application Load Balancer in us&#8211;west&#8211;1. Create an accelerator in AWS Global Accelerator that uses an endpoint group that includes the load balancer endpoints in both Regions.<br/>D. Provision EC2 Instances and configure an Application Load Balancer in us&#8211;west&#8211;1 Configure Amazon Route 53 with a weighted routing policy. Create alias records in Route 53 that point to the Application Load Balancer<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample489' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation489' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_41'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_39'>Random</a></p><div class='collapse' id='collapseExample489'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Provision EC2 instances and configure an Application Load Balancer in us-west-1. Create an accelerator in AWS Global Accelerator that uses an endpoint group that includes the load balancer endpoints in both Regions.</div></div></div><div class='collapse' id='explanation489'><div class='card card&#45;body'><div>
ELB provides load balancing within one Region, AWS Global Accelerator provides traffic management across multiple Regions […] AWS Global Accelerator complements ELB by extending these capabilities beyond a single AWS Region, allowing you to provision a global interface for your applications in any number of Regions. If you have workloads that cater to a global client base, we recommend that you use AWS Global Accelerator. If you have workloads hosted in a single AWS Region and used by clients in and around the same Region, you can use an Application Load Balancer or Network Load Balancer to manage your resources.

References:
AWS Global Accelerator FAQs
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 44%;" aria-valuenow="44" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EC2'>EC2</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EC2_41><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EC2 Question 41</p><br/>A company recently migrated a message processing system to AWS. The system receives messages into an ActiveMQ queue running on an Amazon EC2 instance. Messages are processed by a consumer application running on Amazon EC2. The consumer application processes the messages and writes results to a MySQL database running on Amazon EC2. The company wants this application to be highly available with low operational complexity<br/><br/>Which architecture offers the HIGHEST availability?<br/><br/>A. Add a second ActiveMQ server to another Availability Zone Add an additional consumer EC2 instance in another Availability Zone Replicate the MySQL database to another Availability Zone.<br/>B. Use Amazon MQ with active/standby brokers configured across two Availability Zones Add an additional consumer EC2 instance in another Availability Zone. Replicate the MySQL database to another Availability Zone<br/>C. Use Amazon MQ with active/standby brokers configured across two Availability Zones. Add an additional consumer EC2 instance in another Availability Zone. Use Amazon RDS for MySQL with Multi&#8211;AZ enabled<br/>D. Use Amazon MQ with active/standby brokers configured across two Availability Zones Add an Auto Scaling group for the consumer EC2 instances across two Availability Zones Use Amazon RDS for MySQL with Multi&#8211;AZ enabled.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample500' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_42'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_54'>Random</a></p><div class='collapse' id='collapseExample500'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Use Amazon MQ with active/standby brokers configured across two Availability Zones Add an Auto Scaling group for the consumer EC2 instances across two Availability Zones Use Amazon RDS for MySQL with Multi-AZ enabled.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 45%;" aria-valuenow="45" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EC2'>EC2</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EC2_42><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EC2 Question 42</p><br/>A company is launching an eCommerce website on AWS. This website is built with a three&#8211;tier architecture that includes a MySQL database in a Multi&#8211;AZ deployment of Amazon Aurora MySQL. The website application must be highly available and will initially be launched in an AWS Region with three Availability Zones The application produces a metric that describes the load the application experiences.<br/><br/>Which solution meets these requirements?<br/><br/>A. Configure an Application Load Balancer (ALB) with Amazon EC2 Auto Scaling behind the ALB with scheduled scaling<br/>B. Configure an Application Load Balancer (ALB) and Amazon EC2 Auto Scaling behind the ALB with a simple scaling policy.<br/>C. Configure a Network Load Balancer (NLB) and launch a Spot Fleet with Amazon EC2 Auto Scaling behind the NLB.<br/>D. Configure an Application Load Balancer (ALB) and Amazon EC2 Auto Scaling behind the ALB with a target tracking scaling policy.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample323' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_43'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_63'>Random</a></p><div class='collapse' id='collapseExample323'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Configure an Application Load Balancer (ALB) and Amazon EC2 Auto Scaling behind the ALB with a simple scaling policy.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 46%;" aria-valuenow="46" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EC2'>EC2</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EC2_43><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EC2 Question 43</p><br/>A solutions architect has created two IAM policies: Policy1 and Policy2. Both policies are attached to an IAM group.<br/><br/>A solutions architect has created two IAM policies: Policy1 and Policy2. Both policies are attached to an IAM group.<br/><br/>A cloud engineer is added as an IAM user to the IAM group. Which action will the cloud engineer be able to perform?<br/><br/>A. Deleting IAM users<br/>B. Deleting directories<br/>C. Deleting Amazon EC2 instances<br/>D. Deleting logs from Amazon CloudWatch Logs<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample58' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_44'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_52'>Random</a></p><div class='collapse' id='collapseExample58'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Deleting Amazon EC2 instances</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 47%;" aria-valuenow="47" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EC2'>EC2</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EC2_44><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EC2 Question 44</p><br/>A company is running an application on Amazon EC2 instances. Traffic to the workload increases substantially during business hours and decreases afterward. The CPU utilization of an EC2 instance is a strong indicator of end&#8211;user demand on the application.<br/><br/>The company has configured an Auto Scaling group to have a minimum group size of 2 EC2 instances and a maximum group size of 10 EC2 instances.<br/><br/>The company is concerned that the current scaling policy that is associated with the Auto Scaling group might not be correct. The company must avoid over&#8211;provisioning EC2 instances and incurring unnecessary costs.<br/><br/>What should a solutions architect recommend to meet these requirements?<br/><br/>A. Configure Amazon EC2 Auto Scaling to use a scheduled scaling plan and launch an additional 8 EC2 instances during business hours.<br/>B. Configure AWS Auto Scaling to use a scaling plan that enables predictive scaling. Configure predictive scaling with a scaling mode of forecast and scale, and to enforce the maximum capacity setting during scaling.<br/>C. Configure a step scaling policy to add 4 EC2 instances at 50% CPU utilization and add another 4 EC2 instances at 90% CPU utilization. Configure scale&#8211;in policies to perform the reverse and remove EC2 instances based on the two values.<br/>D. Configure AWS Auto Scaling to have a desired capacity of 5 EC2 instances, and disable any existing scaling policies. Monitor the CPU utilization metric for 1 week. Then create dynamic scaling policies that are based on the observed values.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample435' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_45'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_48'>Random</a></p><div class='collapse' id='collapseExample435'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Configure AWS Auto Scaling to have a desired capacity of 5 EC2 instances, and disable any existing scaling policies. Monitor the CPU utilization metric for 1 week. Then create dynamic scaling policies that are based on the observed values.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 48%;" aria-valuenow="48" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EC2'>EC2</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EC2_45><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EC2 Question 45</p><br/>A company Is designing an internet&#8211;facing web application. The application runs on Amazon EC2 for Linux&#8211;based instances that store sensitive user data in Amazon RDS MySQL Multi&#8211;AZ DB instances.<br/><br/>The EC2 instances are in public subnets, and the RDS DB instances are in private subnets. The security team has mandated that the DB instances be secured against web&#8211;based attacks.<br/><br/>What should a solutions architect recommend?<br/><br/>A. Ensure the EC2 instances are part of an Auto Scaling group and are behind an Application Load Balancer. Configure the EC2 instance iptables rules to drop suspicious web traffic. Create a security group for the DB instances. Configure the RDS security group to only allow port 3306 inbound from the individual EC2 instances.<br/>B. Ensure the EC2 instances are part of an Auto Scaling group and are behind an Application Load Balancer. Move DB instances to the same subnets that EC2 instances are located in. Create a security group for the DB instances. Configure the RDS security group to only allow port 3306 inbound from the individual EC2 instances.<br/>C. Ensure the EC2 instances are part of an Auto Scaling group and are behind an Application Load Balancer. Use AWS WAF to monitor inbound web traffic for threats. Create a security group for the web application servers and a security group for the DB instances. Configure the RDS security group to only allow port 3306 inbound from the web application server security group.<br/>D. Ensure the EC2 instances are part of an Auto Scaling group and are behind an Application Load Balancer. Use AWS WAF to monitor inbound web traffic for threats. Configure the Auto Scaling group to automatically create new DB instances under heavy traffic. Create a security group for the RDS DB instances. Configure the RDS security group to only allow port 3306 inbound.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample680' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_46'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_66'>Random</a></p><div class='collapse' id='collapseExample680'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Ensure the EC2 instances are part of an Auto Scaling group and are behind an Application Load Balancer. Use AWS WAF to monitor inbound web traffic for threats. Configure the Auto Scaling group to automatically create new DB instances under heavy traffic. Create a security group for the RDS DB instances. Configure the RDS security group to only allow port 3306 inbound.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 50%;" aria-valuenow="50" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EC2'>EC2</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EC2_46><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EC2 Question 46</p><br/>A company wants to move a multi&#8211;tiered application from on&#8211;premises to the AWS Cloud to improve the application's performance. The application consists of application tiers that communicate with each other by way of RESTful services.<br/><br/>Transactions are dropped when one tier becomes overloaded. A solutions architect must design a solution that resolves these issues and modernizes the application.<br/><br/>Which solution meets these requirements and is the MOST operationally efficient?<br/><br/>A. Use Amazon API Gateway and direct transactions to the AWS Lambda functions as the application layer. Use Amazon Simple Queue Service (Amazon SQS) as the communication layer between application services.<br/>B. Use Amazon CloudWatch metrics to analyze the application performance history to determine the server's peak utilization during the performance failures. Increase the size of the application server's Amazon EC2 instances to meet the peak requirements.<br/>C. Use Amazon Simple Notification Service (Amazon SNS) to handle the messaging between application servers running on Amazon EC2 in an Auto Scaling group. Use Amazon CloudWatch to monitor the SNS queue length and scale up and down as required.<br/>D. Use Amazon Simple Queue Service (Amazon SQS) to handle the messaging between application servers running on Amazon EC2 in an Auto Scaling group. Use Amazon CloudWatch to monitor the SQS queue length and scale up when communication failures are detected.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample255' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_47'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_30'>Random</a></p><div class='collapse' id='collapseExample255'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Use Amazon Simple Queue Service (Amazon SQS) to handle the messaging between application servers running on Amazon EC2 in an Auto Scaling group. Use Amazon CloudWatch to monitor the SQS queue length and scale up when communication failures are detected.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 51%;" aria-valuenow="51" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EC2'>EC2</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EC2_47><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EC2 Question 47</p><br/>A company hosts its multi&#8211;tier public web application in the AWS Cloud. The web application runs on Amazon EC2 instances and its database runs on Amazon RDS. The company is anticipating a large increase in sales during an upcoming holiday weekend A solutions architect needs to build a solution to analyze the performance of the web application with a granularity of no more than 2 minutes.<br/><br/>What should the solutions architect do to meet this requirement?<br/><br/>A. Send Amazon CloudWatch logs to Amazon Redshift Use Amazon QuickSight to perform further analysis<br/>B. Enable detailed monitoring on all EC2 instances Use Amazon CloudWatch metrics to perform further analysis<br/>C. Create an AWS Lambda function to fetch EC2 logs from Amazon CloudWatch Logs Use Amazon CloudWatch metrics to perform further analysis<br/>D. Send EC2 logs to Amazon S3 Use Amazon Redshift to fetch logs from the S3 bucket to process raw data for further analysis with Amazon QuickSight.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample487' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_48'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_21'>Random</a></p><div class='collapse' id='collapseExample487'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Enable detailed monitoring on all EC2 instances Use Amazon CloudWatch metrics to perform further analysis</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 52%;" aria-valuenow="52" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EC2'>EC2</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EC2_48><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EC2 Question 48</p><br/>A company's application runs on Amazon EC2 instances behind an Application Load Balancer (ALB). The instances run in an Amazon EC2 Auto Scaling group across multiple Availability Zones. On the first day of every month at midnight, the application becomes much slower when the month&#8211;end financial calculation batch executes. This causes the CPU utilization of the EC2 instances to immediately peak to 100%, which disrupts the application.<br/><br/>What should a solutions architect recommend to ensure the application is able to handle the workload and avoid downtime?<br/><br/>A. Configure an Amazon CloudFront distribution in front of the ALB.<br/>B. Configure an EC2 Auto Scaling simple scaling policy based on CPU utilization.<br/>C. Configure an EC2 Auto Scaling scheduled scaling policy based on the monthly schedule.<br/>D. Configure Amazon ElastiCache to remove some of the workload from the EC2 instances.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample5' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation5' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_49'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_28'>Random</a></p><div class='collapse' id='collapseExample5'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Configure an EC2 Auto Scaling scheduled scaling policy based on the monthly schedule.</div></div></div><div class='collapse' id='explanation5'><div class='card card&#45;body'><div>
Scheduled Scaling for Amazon EC2 Auto Scaling
Scheduled scaling allows you to set your own scaling schedule. For example, let's say that every week the traffic to your web application starts to increase on Wednesday, remains high on Thursday, and starts to decrease on Friday. You can plan your scaling actions based on the predictable traffic patterns of your web application. Scaling actions are performed automatically as a function of time and date.

Scheduled scaling allows you to set your own scaling schedule. In this case the scaling action can be scheduled to occur just prior to the time that the reports will be run each month. Scaling actions are performed automatically as a function of time and date. This will ensure that there are enough EC2 instances to serve the demand and prevent the application from slowing down.

CORRECT: "Configure an EC2 Auto Scaling scheduled scaling policy based on the monthly schedule" is the correct answer.

INCORRECT: "Configure an Amazon CloudFront distribution in front of the ALB" is incorrect as this would be more suitable for providing access to global users by caching content.

INCORRECT: "Configure an EC2 Auto Scaling simple scaling policy based on CPU utilization" is incorrect as this would not prevent the slow-down from occurring as there would be a delay between when the CPU hits 100% and the metric being reported and additional instances being launched.

INCORRECT: "Configure Amazon ElastiCache to remove some of the workload from the EC2 instances" is incorrect as ElastiCache is a database cache, it cannot replace the compute functions of an EC2 instance.

References:

Amazon EC2 Auto Scaling > User Guide > Scheduled scaling for Amazon EC2 Auto Scaling</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 53%;" aria-valuenow="53" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EC2'>EC2</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EC2_49><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EC2 Question 49</p><br/>A company is launching a new application deployed on an Amazon Elastic Container Service (Amazon ECS) cluster and is using the Fargate launch type for ECS tasks. The company is monitoring CPU and memory usage because it is expecting high traffic to the application upon its launch. However, the company wants to reduce costs when utilization decreases.<br/><br/>What should a solutions architect recommend?<br/><br/>A. Use Amazon EC2 Auto Scaling to scale at certain periods based on previous traffic patterns.<br/>B. Use an AWS Lambda function to scale Amazon ECS based on metric breaches that trigger an Amazon CloudWatch alarm.<br/>C. Use Amazon EC2 Auto Scaling with simple scaling policies to scale when ECS metric breaches trigger an Amazon CloudWatch alarm.<br/>D. Use AWS Application Auto Scaling with target tracking policies to scale when ECS metric breaches trigger an Amazon CloudWatch alarm.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample288' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_50'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_87'>Random</a></p><div class='collapse' id='collapseExample288'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Use Amazon EC2 Auto Scaling to scale at certain periods based on previous traffic patterns.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 54%;" aria-valuenow="54" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EC2'>EC2</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EC2_50><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EC2 Question 50</p><br/>A solutions architect is creating an application that will handle batch processing of large amounts of data.<br/><br/>The input data will be held in Amazon S3 and the output data will be stored in a different S3 bucket. For processing, the application will transfer the data over the network between multiple Amazon EC2 instances.<br/><br/>What should the solutions architect do to reduce the overall data transfer costs?<br/><br/>A. Place all the EC2 instances in an Auto Scaling group.<br/>B. Place all the EC2 instances in the same AWS Region.<br/>C. Place all the EC2 instances in the same Availability Zone.<br/>D. Place all the EC2 instances in private subnets in multiple Availability Zones.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample126' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation126' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_51'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_31'>Random</a></p><div class='collapse' id='collapseExample126'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Place all the EC2 instances in the same Availability Zone.</div></div></div><div class='collapse' id='explanation126'><div class='card card&#45;body'><div>
The transfer is between EC2 instances and not just between S3 and EC2.

Also, be aware of inter-Availability Zones data transfer charges between Amazon EC2 instances, even within the same region. If possible, the instances in a development or test environment that need to communicate with each other should be co-located within the same Availability Zone to avoid data transfer charges. (This doesn't apply to production workloads which will most likely need to span multiple Availability Zones for high availability.)

References:

AWS Management & Governance Blog > Using AWS Cost Explorer to analyze data transfer costs
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 55%;" aria-valuenow="55" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EC2'>EC2</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EC2_51><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EC2 Question 51</p><br/>A company runs a high performance computing (HPC) workload on AWS. The workload required low latency network performance and high network throughput with tightly coupled node&#8211;to&#8211;node communication. The Amazon EC2 instances are properly sized for compute and storage capacity, and are launched using default options.<br/><br/>What should a solutions architect propose to improve the performance of the workload?<br/><br/>A. Choose a cluster placement group while launching Amazon EC2 instances.<br/>B. Choose dedicated instance tenancy while launching Amazon EC2 instances.<br/>C. Choose an Elastic Inference accelerator while launching Amazon EC2 instances.<br/>D. Choose the required capacity reservation while launching Amazon EC2 instances.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample143' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_52'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_16'>Random</a></p><div class='collapse' id='collapseExample143'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Choose a cluster placement group while launching Amazon EC2 instances.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 56%;" aria-valuenow="56" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EC2'>EC2</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EC2_52><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EC2 Question 52</p><br/>A medical records company is hosting an application on Amazon EC2 instances. The application processes customer data files that are stored on Amazon S3. The EC2 instances are hosted in public subnets. The EC2 instances access Amazon S3 over the internet, but they do not require any other network access.<br/><br/>A new requirement mandates that the network traffic for file transfers take a private route and not be sent over the internet.<br/><br/>Which change to the network architecture should a solutions architect recommend to meet this requirement?<br/><br/>A. Create a NAT gateway. Configure the route table for the public subnets to send traffic to Amazon S3 through the NAT gateway.<br/>B. Configure the security group for the EC2 instances to restrict outbound traffic so that only traffic to the S3 prefix list is permitted.<br/>C. Move the EC2 instances to private subnets. Create a VPC endpoint for Amazon S3, and link the endpoint to the route table for the private subnets<br/>D. Remove the internet gateway from the VP<br/>E. Set up an AWS Direct Connect connection, and route traffic to Amazon S3 over the Direct Connect connection.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample472' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_53'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_8'>Random</a></p><div class='collapse' id='collapseExample472'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Move the EC2 instances to private subnets. Create a VPC endpoint for Amazon S3, and link the endpoint to the route table for the private subnets</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 57%;" aria-valuenow="57" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EC2'>EC2</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EC2_53><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EC2 Question 53</p><br/>A company is building an application on Amazon EC2 instances that generates temporary transactional data. The application requires access to data storage that can provide configurable and consistent IOPS.<br/><br/>What should a solutions architect recommend?<br/><br/>A. Provision an EC2 instance with a Throughput Optimized HDD (st1) root volume and a Cold HDD (sc1) data volume.<br/>B. Provision an EC2 instance with a Throughput Optimized HDD (st1) volume that will serve as the root and data volume.<br/>C. Provision an EC2 instance with a General Purpose SSD (gp2) root volume and Provisioned IOPS SSD (io1) data volume.<br/>D. Provision an EC2 instance with a General Purpose SSD (gp2) root volume. Configure the application to store its data in an Amazon S3 bucket.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample253' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_54'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_73'>Random</a></p><div class='collapse' id='collapseExample253'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Provision an EC2 instance with a General Purpose SSD (gp2) root volume and Provisioned IOPS SSD (io1) data volume.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 58%;" aria-valuenow="58" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EC2'>EC2</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EC2_54><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EC2 Question 54</p><br/>A company is deploying a production portal application on AWS. The database tier has structured data.<br/><br/>The company requires a solution that is easily manageable and highly available.<br/><br/>How can these requirements be met?<br/><br/>A. Deploy the database on multiple Amazon EC2 instances backed by Amazon Elastic Block Store (Amazon EBS) across multiple Availability Zones.<br/>B. Use Amazon RDS with a multiple Availability Zone option<br/>C. Use Amazon RDS with a single Availability Zone option and schedule periodic database snapshots.<br/>D. Use Amazon DynamoDB<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample572' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_55'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_47'>Random</a></p><div class='collapse' id='collapseExample572'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Deploy the database on multiple Amazon EC2 instances backed by Amazon Elastic Block Store (Amazon EBS) across multiple Availability Zones.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 60%;" aria-valuenow="60" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EC2'>EC2</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EC2_55><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EC2 Question 55</p><br/>A monolithic application was recently migrated to AWS and is now running on a single Amazon EC2 instance. Due to application limitations, it is not possible to use automatic scaling to scale out the application. The chief technology officer (CTO) wants an automated solution to restore the EC2 instance in the unlikely event the underlying hardware fails.<br/><br/>What would allow for automatic recovery of the EC2 instance as quickly as possible?<br/><br/>A. Configure an Amazon CloudWatch alarm that triggers the recovery of the EC2 instance if it becomes impaired.<br/>B. Configure an Amazon CloudWatch alarm to trigger an SNS message that alerts the CTO when the EC2 instance is impaired.<br/>C. Configure AWS CloudTrail to monitor the health of the EC2 instance, and if it becomes impaired, trigger instance recovery.<br/>D. Configure an Amazon EventBridge event to trigger an AWS Lambda function once an hour that checks the health of the EC2 instance and triggers instance recovery if the EC2 instance is unhealthy.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample170' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_56'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_46'>Random</a></p><div class='collapse' id='collapseExample170'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Configure an Amazon CloudWatch alarm that triggers the recovery of the EC2 instance if it becomes impaired.

References:

Amazon Elastic Compute Cloud > User Guide for Linux Instances > Recover your instance</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 61%;" aria-valuenow="61" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EC2'>EC2</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EC2_56><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EC2 Question 56</p><br/>An eCommerce company is creating an application that requires a connection to a third&#8211;party payment service to process payments. The payment service needs to explicitly allow the public IP address of the server that is making the payment request. However, the company's security policies do not allow any server to be exposed directly to the public internet.<br/><br/>Which solution will meet these requirements?<br/><br/>A. Provision an Elastic IP address. Host the application servers on Amazon EC2 instances in a private subnet. Assign the public IP address to the application servers.<br/>B. Create a NAT gateway in a public subnet. Host the application servers on Amazon EC2 instances in a private subnet. Route payment requests through the NAT gateway.<br/>C. Deploy an Application Load Balancer (ALB). Host the application servers on Amazon EC2 instances in a private subnet. Route the payment requests through the ALB.<br/>D. Set up an AWS Client VPN connection to the payment service. Host the application servers on Amazon EC2 instances in a private subnet. Route the payment requests through the VPN.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample428' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_57'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_5'>Random</a></p><div class='collapse' id='collapseExample428'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Create a NAT gateway in a public subnet. Host the application servers on Amazon EC2 instances in a private subnet. Route payment requests through the NAT gateway.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 62%;" aria-valuenow="62" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EC2'>EC2</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EC2_57><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EC2 Question 57</p><br/>A company wants to run a static website served through Amazon CloudFront.<br/><br/>What is an advantage of storing the website content in an Amazon S3 bucket instead of an Amazon Elastic Block Store (Amazon EBS) volume?<br/><br/>A. S3 buckets are replicated globally, allowing for large scalability. EBS volumes are replicated only within an AWS Region.<br/>B. S3 is an origin for CloudFront. EBS volumes would need EC2 instances behind an Elastic Load Balancing load balancer to be an origin<br/>C. S3 buckets can be encrypted, allowing for secure storage of the web files. EBS volumes cannot be encrypted.<br/>D. S3 buckets support object&#8211;level read throttling, preventing abuse. EBS volumes do not provide object&#8211;level throttling.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample538' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_58'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_74'>Random</a></p><div class='collapse' id='collapseExample538'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>S3 is an origin for CloudFront. EBS volumes would need EC2 instances behind an Elastic Load Balancing load balancer to be an origin</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 63%;" aria-valuenow="63" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EC2'>EC2</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EC2_58><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EC2 Question 58</p><br/>A company hosts its website on AWS. To address the highly variable demand, the company has implemented Amazon EC2 Auto Scaling.<br/><br/>Management is concerned that the company is over&#8211;provisioning its infrastructure, especially at the front end of the three&#8211;tier application. A solutions architect needs to ensure costs are optimized without impacting performance.<br/><br/>What should the solutions architect do to accomplish this?<br/><br/>A. Use Auto Scaling with Reserved Instances.<br/>B. Use Auto Scaling with a scheduled scaling policy.<br/>C. Use Auto Scaling with the suspend&#8211;resume feature.<br/>D. Use Auto Scaling with a target tracking scaling policy.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample110' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_59'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_86'>Random</a></p><div class='collapse' id='collapseExample110'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Use Auto Scaling with a target tracking scaling policy.

References:

Amazon EC2 Auto Scaling > User Guid > Target tracking scaling policies for Amazon EC2 Auto Scaling</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 64%;" aria-valuenow="64" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EC2'>EC2</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EC2_59><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EC2 Question 59</p><br/>A company is building a document storage application on AWS. The application runs on Amazon EC2 instances in multiple Availability Zones. The company requires the document store to be highly available.<br/><br/>The documents need to be returned immediately when requested. The lead engineer has configured the application to use Amazon Elastic Block Store (Amazon EBS) to store the documents, but is willing to consider other options to meet the availability requirement.<br/><br/>What should a solutions architect recommend?<br/><br/>A. Snapshot the EBS volumes regularly and build new volumes using those snapshots in additional Availability Zones.<br/>B. Use Amazon EBS for the EC2 instance root volumes. Configure the application to build the document store on Amazon S3.<br/>C. Use Amazon EBS for the EC2 instance root volumes. Configure the application to build the document store on Amazon S3 Glacier.<br/>D. Use at least three Provisioned IOPS EBS volumes for EC2 instances. Mount the volumes to the EC2 instances in a RAID 5 configuration.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample380' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_60'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_26'>Random</a></p><div class='collapse' id='collapseExample380'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Use Amazon EBS for the EC2 instance root volumes. Configure the application to build the document store on Amazon S3.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 65%;" aria-valuenow="65" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EC2'>EC2</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EC2_60><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EC2 Question 60</p><br/>A three&#8211;tier web application processes orders from customers. The web tier consists of Amazon EC2 instances behind an Application Load Balancer, a middle tier of three EC2 instances decoupled from the web tier using Amazon SQS. and an Amazon DynamoDB backend. At peak times, customers who submit orders using the site have to wait much longer than normal to receive confirmations due to lengthy processing times. A solutions architect needs to reduce these processing times.<br/><br/>Which action will be MOST effective in accomplishing this?<br/><br/>A. Replace the SQS queue with Amazon Kinesis Data Firehose.<br/>B. Use Amazon ElastiCache for Redis in front of the DynamoDB backend tier.<br/>C. Add an Amazon CloudFront distribution to cache the responses for the web tier.<br/>D. Use Amazon EC2 Auto Scaling to scale out the middle tier instances based on the SOS queue depth.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample497' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_61'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_82'>Random</a></p><div class='collapse' id='collapseExample497'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Use Amazon EC2 Auto Scaling to scale out the middle tier instances based on the SOS queue depth.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 66%;" aria-valuenow="66" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EC2'>EC2</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EC2_61><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EC2 Question 61</p><br/>A gaming company has multiple Amazon EC2 instances in a single Availability Zone for its multiplayer game that communicates with users on Layer 4. The chief technology officer (CTO) wants to make the architecture highly available and cost&#8211;effective.<br/>What should a solutions architect do to meet these requirements? (Choose two.)?<br/><br/>A. Increase the number of EC2 instances.<br/>B. Decrease the number of EC2 instances.<br/>C. Configure a Network Load Balancer in front of the EC2 instances.<br/>D. Configure an Application Load Balancer in front of the EC2 instances.<br/>E. Configure an Auto Scaling group to add or remove instances in multiple Availability Zones automatically.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample19' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation19' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_62'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_42'>Random</a></p><div class='collapse' id='collapseExample19'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Configure a Network Load Balancer in front of the EC2 instances.
<br><b>E. </b>Configure an Auto Scaling group to add or remove instances in multiple Availability Zones automatically.</div></div></div><div class='collapse' id='explanation19'><div class='card card&#45;body'><div>
Network Load Balancer overview: A Network Load Balancer functions at the fourth layer of the Open Systems Interconnection (OSI) model. It can handle millions of requests per second. After the load balancer receives a connection request, it selects a target from the target group for the default rule. It attempts to open a TCP connection to the selected target on the port specified in the listener configuration.

When you enable an Availability Zone for the load balancer, Elastic Load Balancing creates a load balancer node in the Availability Zone. By default, each load balancer node distributes traffic across the registered targets in its Availability Zone only. If you enable cross-zone load balancing, each load balancer node distributes traffic across the registered targets in all enabled Availability Zones. For more information, see Availability Zones.

If you enable multiple Availability Zones for your load balancer and ensure that each target group has at least one target in each enabled Availability Zone, this increases the fault tolerance of your applications. For example, if one or more target groups does not have a healthy target in an Availability Zone, we remove the IP address for the corresponding subnet from DNS, but the load balancer nodes in the other Availability Zones are still available to route traffic. If a client doesn't honor the time-to-live (TTL) and sends requests to the IP address after it is removed from DNS, the requests fail.

For TCP traffic, the load balancer selects a target using a flow hash algorithm based on the protocol, source IP address, source port, destination IP address, destination port, and TCP sequence number. The TCP connections from a client have different source ports and sequence numbers, and can be routed to different targets. Each individual TCP connection is routed to a single target for the life of the connection.

For UDP traffic, the load balancer selects a target using a flow hash algorithm based on the protocol, source IP address, source port, destination IP address, and destination port. A UDP flow has the same source and destination, so it is consistently routed to a single target throughout its lifetime. Different UDP flows have different source IP addresses and ports, so they can be routed to different targets.

An Auto Scaling group contains a collection of Amazon EC2 instances that are treated as a logical grouping for the purposes of automatic scaling and management. An Auto Scaling group also enables you to use Amazon EC2 Auto Scaling features such as health check replacements and scaling policies. Both maintaining the number of instances in an Auto Scaling group and automatic scaling are the core functionality of the Amazon EC2 Auto Scaling service.

The size of an Auto Scaling group depends on the number of instances that you set as the desired capacity. You can adjust its size to meet demand, either manually or by using automatic scaling.

An Auto Scaling group starts by launching enough instances to meet its desired capacity. It maintains this number of instances by performing periodic health checks on the instances in the group. The Auto Scaling group continues to maintain a fixed number of instances even if an instance becomes unhealthy. If an instance becomes unhealthy, the group terminates the unhealthy instance and launches another instance to replace it.

The solutions architect must enable high availability for the architecture and ensure it is cost- effective. To enable high availability an Amazon EC2 Auto Scaling group should be created to add and remove instances across multiple availability zones.

In order to distribute the traffic to the instances the architecture should use a Network Load Balancer which operates at Layer 4. This architecture will also be cost-effective as the Auto Scaling group will ensure the right number of instances are running based on demand.

CORRECT: "Configure a Network Load Balancer in front of the EC2 instances" is a correct answer.

CORRECT: "Configure an Auto Scaling group to add or remove instances in multiple Availability Zones automatically" is also a correct answer.

INCORRECT: "Increase the number of instances and use smaller EC2 instance types" is incorrect as this is not the most cost-effective option. Auto Scaling should be used to maintain the right number of active instances.

INCORRECT: "Configure an Auto Scaling group to add or remove instances in the Availability Zone automatically" is incorrect as this is not highly available as it's a single AZ.

INCORRECT: "Configure an Application Load Balancer in front of the EC2 instances" is incorrect as an ALB operates at Layer 7 rather than Layer 4.

References:

Amazon EC2 Auto Scaling > User Guide > Elastic Load Balancing and Amazon EC2 Auto Scaling
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 67%;" aria-valuenow="67" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EC2'>EC2</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EC2_62><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EC2 Question 62</p><br/>A solutions architect is moving the static content from a public website hosted on Amazon EC2 instances to an Amazon S3 bucket. An Amazon CloudFront distribution will be used to deliver the static assets. The security group used by the EC2 instances restricts access to a limited set of IP ranges. Access to the static content should be similarly restricted.<br/><br/>Which combination of steps will meet these requirements? (Choose two.)<br/><br/>A. Create an origin access identity (OAI) and associate it with the distribution. Change the permissions in the bucket policy so that only the OAI can read the objects.<br/>B. Create an AWS WAF web ACL that includes the same IP restrictions that exist in the EC2 security group. Associate this new web ACL with the CloudFront distribution.<br/>C. Create a new security group that includes the same IP restrictions that exist in the current EC2 security group. Associate this new security group with the CloudFront distribution.<br/>D. Create a new security group that includes the same IP restrictions that exist in the current EC2 security group. Associate this new security group with the S3 bucket hosting the static content.<br/>E. Create a new IAM role and associate the role with the distribution. Change the permissions either on the S3 bucket or on the files within the S3 bucket so that only the newly created IAM role has read and download permissions.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample162' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_63'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_17'>Random</a></p><div class='collapse' id='collapseExample162'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Create an origin access identity (OAI) and associate it with the distribution. Change the permissions in the bucket policy so that only the OAI can read the objects.
<br><b>B. </b>Create an AWS WAF web ACL that includes the same IP restrictions that exist in the EC2 security group. Associate this new web ACL with the CloudFront distribution.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 68%;" aria-valuenow="68" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EC2'>EC2</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EC2_63><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EC2 Question 63</p><br/>A company requires operating system permission on a relational database server.<br/><br/>What should a solutions architect suggest as a configuration for a highly available database architecture?<br/><br/>A. Multiple Amazon EC2 instances in a database replication configuration that uses two Availability Zones<br/>B. A standalone Amazon FC2 instance with a selected database installed<br/>C. Amazon RDS m a Multi&#8211;AZ configuration with Provisioned IOPS<br/>D. Multiple Amazon EC2 instances in a replication configuration that uses a placement group<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample577' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_64'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_6'>Random</a></p><div class='collapse' id='collapseExample577'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Multiple Amazon EC2 instances in a database replication configuration that uses two Availability Zones</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 70%;" aria-valuenow="70" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EC2'>EC2</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EC2_64><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EC2 Question 64</p><br/>A company has a web application hosted over 10 Amazon CC2 instances with traffic directed by Amazon Route 53.<br/><br/>The company occasionally experiences a timeout error when attempting to browse the application.<br/><br/>The networking team finds that some DNS queries return IP addresses of unhealthy instances, resulting in the timeout error.<br/><br/>What should a solutions architect implement to overcome these timeout errors?<br/><br/>A. Create a Route 53 simple touting policy record lot each EC2 instance Associate a hearth check with each record<br/>B. Create a Route 53 failover routing policy record for each EC2 instance Associate a health check with each record<br/>C. Create an Amazon CloudFront distribution with EC2 instances as its origin Associate a health check with the EC2 instances<br/>D. Create an Application Load Balancer (ALB) with a health check in front of the EC2 instances Route to the ALB from Route 53<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample596' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_65'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_23'>Random</a></p><div class='collapse' id='collapseExample596'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Create a Route 53 simple touting policy record lot each EC2 instance Associate a hearth check with each record</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 71%;" aria-valuenow="71" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EC2'>EC2</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EC2_65><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EC2 Question 65</p><br/>A user wants to list the IAM role that is attached to their Amazon EC2 instance. The user has login access to the EC2 instance but does not have IAM permissions.<br/><br/>What should a solutions architect do to retrieve this information?<br/><br/>A. Run the following EC2 command curl http://169.254.169.254/latest/meta&#8211;data/iam/info<br/>B. Run the following EC2 command curl http://169.254.169.254/latest&#8211;/user&#8211;data/iam/info<br/>C. Run the following EC2 command http://169.254.169.254/latest/dynamic/instance&#8211;idencity/<br/>D. Run the following AWS CLI command aws iam get&#8211;instance&#8211;prof lie &#8212;instance&#8211;profile&#8211;name ExamplelnstanceProfile<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample667' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_66'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_60'>Random</a></p><div class='collapse' id='collapseExample667'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Run the following EC2 command curl http://169.254.169.254/latest-/user-data/iam/info</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 72%;" aria-valuenow="72" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EC2'>EC2</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EC2_66><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EC2 Question 66</p><br/>A company is performing an AWS Well&#8211;Architected Framework review of an existing workload deployed on AWS. The review identified a public&#8211;facing website running on the same Amazon EC2 instance as a Microsoft Active Directory domain controller that was installed recently to support other AWS services. A solutions architect needs to recommend a new design that would improve the security of the architecture and minimize the administrative demand on IT staff.<br/><br/>What should the solutions architect recommend?<br/><br/>A. Use AWS Directory Service to create a managed Active Directory. Uninstall Active Directory on the current EC2 instance.<br/>B. Create another EC2 instance in the same subnet and reinstall Active Directory on it. Uninstall Active Directory.<br/>C. Use AWS Directory Service to create an Active Directory connector. Proxy Active Directory requests to the Active domain controller running on the current EC2 instance.<br/>D. Enable AWS Single Sign&#8211;On (AWS SSO) with Security Assertion Markup Language (SAML) 2.0 federation with the current Active Directory controller. Modify the EC2 instance's security group to deny public access to Active Directory.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample25' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation25' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_67'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_19'>Random</a></p><div class='collapse' id='collapseExample25'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Use AWS Directory Service to create a managed Active Directory. Uninstall Active Directory on the current EC2 instance.</div></div></div><div class='collapse' id='explanation25'><div class='card card&#45;body'><div>
AWS Managed Microsoft AD: AWS Directory Service lets you run Microsoft Active Directory (AD) as a managed service. AWS Directory Service for Microsoft Active Directory, also referred to as AWS Managed Microsoft AD, is powered by Windows Server 2012 R2. When you select and launch this directory type, it is created as a highly available pair of domain controllers connected to your virtual private cloud (VPC). The domain controllers run in different Availability Zones in a region of your choice. Host monitoring and recovery, data replication, snapshots, and software updates are automatically configured and managed for you.

Migrate AD to AWS Managed AD and keep the webserver alone. Reduce risk = remove AD from that EC2. Minimize admin = remove AD from any EC2

-> use AWS Directory Service

Active Directory connector is only for ON-PREM AD. The one they have exists in the cloud already.
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 73%;" aria-valuenow="73" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EC2'>EC2</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EC2_67><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EC2 Question 67</p><br/>A company is planning to build a new web application on AWS. The company expects predictable traffic most of the year and very high traffic on occasion. The web application needs to be highly available and fault tolerant with minimal latency.<br/><br/>What should a solutions architect recommend to meet these requirements?<br/><br/>A. Use an Amazon Route 53 routing policy to distribute requests to two AWS Regions, each with one Amazon EC2 instance.<br/>B. Use Amazon EC2 instances in an Auto Scaling group with an Application Load Balancer across multiple Availability Zones.<br/>C. Use Amazon EC2 instances in a cluster placement group with an Application Load Balancer across multiple Availability Zones.<br/>D. Use Amazon EC2 instances in a cluster placement group and include the cluster placement group within a new Auto Scaling group.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample100' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_68'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_14'>Random</a></p><div class='collapse' id='collapseExample100'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Use Amazon EC2 instances in an Auto Scaling group with an Application Load Balancer across multiple Availability Zones.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 74%;" aria-valuenow="74" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EC2'>EC2</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EC2_68><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EC2 Question 68</p><br/>A company relies on an application that needs at least 4 Amazon EC2 instances during regular traffic and must scale up to 12 EC2 instances during peak loads. The application is critical to the business and must be highly available.<br/><br/>Which solution will meet these requirements?<br/><br/>A. Deploy the EC2 instances in an Auto Scaling group. Set the minimum to 4 and the maximum to 12, with 2 in Availability Zone A and 2 in Availability Zone B.<br/>B. Deploy the EC2 instances in an Auto Scaling group. Set the minimum to 4 and the maximum to 12, with all 4 in Availability Zone A.<br/>C. Deploy the EC2 instances in an Auto Scaling group. Set the minimum to 8 and the maximum to 12, with 4 in Availability Zone A and 4 in Availability Zone B.<br/>D. Deploy the EC2 instances in an Auto Scaling group. Set the minimum to 8 and the maximum to 12, with all 8 in Availability Zone A.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample165' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_69'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_18'>Random</a></p><div class='collapse' id='collapseExample165'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Deploy the EC2 instances in an Auto Scaling group. Set the minimum to 8 and the maximum to 12, with 4 in Availability Zone A and 4 in Availability Zone B.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 75%;" aria-valuenow="75" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EC2'>EC2</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EC2_69><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EC2 Question 69</p><br/>A solutions architect must design a solution for a persistent database that is being migrated from on&#8211;premises to AWS. The database requires 64,000 IOPS according to the database administrator. If possible, the database administrator wants to use a single Amazon Elastic Block Store (Amazon EBS) volume to host the database instance.<br/><br/>Which solution effectively meets the database administrator's criteria?<br/><br/>A. Use an instance from the I3 I/O optimized family and leverage local ephemeral storage to achieve the IOPS requirement.<br/>B. Create an Nitro&#8211;based Amazon EC2 instance with an Amazon EBS Provisioned IOPS SSD (io1) volume attached. Configure the volume to have 64,000 IOPS.<br/>C. Create and map an Amazon Elastic File System (Amazon EFS) volume to the database instance and use the volume to achieve the required IOPS for the database.<br/>D. Provision two volumes and assign 32,000 IOPS to each. Create a logical volume at the operating system level that aggregates both volumes to achieve the IOPS requirements.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample166' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_70'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_27'>Random</a></p><div class='collapse' id='collapseExample166'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Create an Nitro-based Amazon EC2 instance with an Amazon EBS Provisioned IOPS SSD (io1) volume attached. Configure the volume to have 64,000 IOPS.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 76%;" aria-valuenow="76" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EC2'>EC2</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EC2_70><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EC2 Question 70</p><br/>A start&#8211;up company has a web application based in the us&#8211;east&#8211;1 Region with multiple Amazon EC2 instances running behind an Application Load Balancer across multiple Availability Zones. As the company's user base grows in the us&#8211;west&#8211;1 Region, it needs a solution with low latency and high availability.<br/><br/>What should a solutions architect do to accomplish this?<br/><br/>A. Provision EC2 instances in us&#8211;west&#8211;1. Switch the Application Load Balancer to a Network Load Balancer to achieve cross&#8211;Region load balancing.<br/>B. Provision EC2 instances and an Application Load Balancer in us&#8211;west&#8211;1. Make the load balancer distribute the traffic based on the location of the request.<br/>C. Provision EC2 instances and configure an Application Load Balancer in us&#8211;west&#8211;1. Create an accelerator in AWS Global Accelerator that uses an endpoint group that includes the load balancer endpoints in both Regions.<br/>D. Provision EC2 instances and configure an Application Load Balancer in us&#8211;west&#8211;1. Configure Amazon Route 53 with a weighted routing policy. Create alias records in Route 53 that point to the Application Load Balancer.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample11' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation11' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_71'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_67'>Random</a></p><div class='collapse' id='collapseExample11'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Provision EC2 instances and configure an Application Load Balancer in us-west-1. Create an accelerator in AWS Global Accelerator that uses an endpoint group that includes the load balancer endpoints in both Regions.</div></div></div><div class='collapse' id='explanation11'><div class='card card&#45;body'><div>
Register endpoints for endpoint groups: You register one or more regional resources, such as Application Load Balancers, Network Load Balancers, EC2 Instances, or Elastic IP addresses, in each endpoint group. Then you can set weights to choose how much traffic is routed to each endpoint.

Endpoints in AWS Global Accelerator: Endpoints in AWS Global Accelerator can be Network Load Balancers, Application Load Balancers, Amazon EC2 instances, or Elastic IP addresses. A static IP address serves as a single point of contact for clients, and Global Accelerator then distributes incoming traffic across healthy endpoints. Global Accelerator directs traffic to endpoints by using the port (or port range) that you specify for the listener that the endpoint group for the endpoint belongs to.

Each endpoint group can have multiple endpoints. You can add each endpoint to multiple endpoint groups, but the endpoint groups must be associated with different listeners.

Global Accelerator continually monitors the health of all endpoints that are included in an endpoint group. It routes traffic only to the active endpoints that are healthy. If Global Accelerator doesn't have any healthy endpoints to route traffic to, it routes traffic to all endpoints.

ELB provides load balancing within one Region, AWS Global Accelerator provides traffic management across multiple Regions […] AWS Global Accelerator complements ELB by extending these capabilities beyond a single AWS Region, allowing you to provision a global interface for your applications in any number of Regions. If you have workloads that cater to a global client base, we recommend that you use AWS Global Accelerator. If you have workloads hosted in a single AWS Region and used by clients in and around the same Region, you can use an Application Load Balancer or Network Load Balancer to manage your resources.

References:

AWS Global Accelerator FAQs
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 77%;" aria-valuenow="77" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EC2'>EC2</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EC2_71><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EC2 Question 71</p><br/>A company has an application hosted on Amazon EC2 instances in two VPCs across different AWS Regions. To communicate with each other, the instances use the internet for connectivity. The security team wants to ensure that no communication between the instances happens over the internet.<br/><br/>What should a solutions architect do to accomplish this?<br/><br/>A. Create a NAT gateway and update the route table of the EC2 instances' subnet.<br/>B. Create a VPC endpoint and update the route table of the EC2 instances' subnet.<br/>C. Create a VPN connection and update the route table of the EC2 instances' subnet.<br/>D. Create a VPC peering connection and update the route table of the EC2 instances' subnet.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample407' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_72'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_20'>Random</a></p><div class='collapse' id='collapseExample407'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Create a VPC peering connection and update the route table of the EC2 instances' subnet.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 78%;" aria-valuenow="78" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EC2'>EC2</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EC2_72><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EC2 Question 72</p><br/>A company has an application that uses overnight digital images of products on store shelves to analyze inventory data. The application runs on Amazon EC2 instances behind an Application Load Balancer (ALB) and obtains the images from an Amazon S3 bucket for its metadata to be processed by worker nodes for analysis. A solutions architect needs to ensure that every image is processed by the worker nodes.<br/><br/>What should the solutions architect do to meet this requirement in the MOST cost&#8211;efficient way?<br/><br/>A. Send the image metadata from the application directly to a second ALB for the worker nodes that use an Auto Scaling group of EC2 Spot Instances as the target group.<br/>B. Process the image metadata by sending it directly to EC2 Reserved Instances in an Auto Scaling group. With a dynamic scaling policy, use an Amazon CloudWatch metric for average CPU utilization of the Auto Scaling group as soon as the front&#8211;end application obtains the images.<br/>C. Write messages to Amazon Simple Queue Service (Amazon SQS) when the front&#8211;end application obtains an image. Process the images with EC2 On&#8211;Demand instances in an Auto Scaling group with instance scale&#8211;in protection and a fixed number of instances with periodic health checks.<br/>D. Write messages to Amazon Simple Queue Service (Amazon SQS) when the application obtains an image. Process the images with EC2 Spot Instances in an Auto Scaling group with instance scale&#8211;in protection and a dynamic scaling policy using a custom Amazon CloudWatch metric for the current number of messages in the queue.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample310' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_73'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_70'>Random</a></p><div class='collapse' id='collapseExample310'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Process the image metadata by sending it directly to EC2 Reserved Instances in an Auto Scaling group. With a dynamic scaling policy, use an Amazon CloudWatch metric for average CPU utilization of the Auto Scaling group as soon as the front-end application obtains the images.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 80%;" aria-valuenow="80" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EC2'>EC2</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EC2_73><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EC2 Question 73</p><br/>A solution architect is designing a shared storage solution for an Auto Scaling web application. The company anticipates making frequent changes to the content, so the solution must have strong consistency.<br/><br/>Which solution requires the LEAST amount of effort?<br/><br/>A. Create an Amazon S3 bucket to store the web content and use Amazon Cloudfront to deliver the content<br/>B. Create an Amazon Elastic File system (Amazon EFS) file system and mount it on the individual Amazon EC2 instance<br/>C. Create a shared Amazon Elastic Block Store (Amazon EBS) volume and mount it on the individual Amazon EC2 instance<br/>D. Use AWS Datasync to perform continuous synchronization of data between Amazon EC2 hosts in the Auto scaling group.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample710' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_74'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_2'>Random</a></p><div class='collapse' id='collapseExample710'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Create an Amazon Elastic File system ( Amazon EFS ) file system and mount it on the individual Amazon EC2 instance</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 81%;" aria-valuenow="81" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EC2'>EC2</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EC2_74><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EC2 Question 74</p><br/>An application running on an Amazon EC2 instance needs to access an Amazon DynamoDB table. Both the EC2 instance and the DynamoDB table are in the same AWS account. A solutions architect must configure the necessary permissions.<br/><br/>Which solution will allow least privilege access to the DynamoDB table from the EC2 instance?<br/><br/>A. Create an IAM role with the appropriate policy to allow access to the DynamoDB table. Create an instance profile to assign this IAM role to the EC2 instance.<br/>B. Create an IAM role with the appropriate policy to allow access to the DynamoDB table. Add the EC2 instance to the trust relationship policy document to allow it to assume the role.<br/>C. Create an IAM user with the appropriate policy to allow access to the DynamoDB table. Store the credentials in an Amazon S3 bucket and read them from within the application code directly.<br/>D. Create an IAM user with the appropriate policy to allow access to the DynamoDB table. Ensure that the application stores the IAM credentials securely on local storage and uses them to make the DynamoDB calls.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample136' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_75'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_7'>Random</a></p><div class='collapse' id='collapseExample136'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Create an IAM role with the appropriate policy to allow access to the DynamoDB table. Create an instance profile to assign this IAM role to the EC2 instance.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 82%;" aria-valuenow="82" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EC2'>EC2</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EC2_75><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EC2 Question 75</p><br/>A company has a highly dynamic batch processing job that uses many Amazon EC2 instances to complete it. The job is stateless in nature, can be started and stopped at any given time with no negative impact, and typically takes upwards of 60 minutes total to complete. The company has asked a solutions architect to design a scalable and cost&#8211;effective solution that meets the requirements of the job.<br/><br/>What should the solutions architect recommend?<br/><br/>A. Implement EC2 Spot Instances.<br/>B. Purchase EC2 Reserved Instances.<br/>C. Implement EC2 On&#8211;Demand Instances.<br/>D. Implement the processing on AWS Lambda.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample230' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_76'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_25'>Random</a></p><div class='collapse' id='collapseExample230'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Implement EC2 Spot Instances.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 83%;" aria-valuenow="83" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EC2'>EC2</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EC2_76><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EC2 Question 76</p><br/>The following IAM policy is attached to an IAM group. This is the only policy applied to the group.<br/>The following IAM policy is attached to an IAM group. This is the only policy applied to the group.<br/>What are the effective IAM permissions of this policy for group members?<br/><br/>A. Group members are permitted any Amazon EC2 action within the us&#8211;east&#8211;1 Region. Statements after. The Allow permission are not applied<br/>B. Group member are denied any Amazon EC2 permissions in the us&#8211;east&#8211;1 Region unless they are tagged in with multi&#8211;factor authentication (MFA).<br/>C. Group members are allowed the ec2:StopInstances and ec2:Terminatelnstances permissions for all Regions when logged in with multi&#8211;factor authentication (MFA). Group members authorized any other Amazon EC2 action.<br/>D. Group members are allowed the ec2:Stoplnstances and ec2:Terminatelnstances permissions for the us&#8211;east&#8211;1 Region only when logged in with multi&#8211;factor authentication (MFA). Groups are permitted any other Amazon EC2 action within the us&#8211;east&#8211;1 Region<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample491' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_77'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_45'>Random</a></p><div class='collapse' id='collapseExample491'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Group members are allowed the ec2:Stoplnstances and ec2:Terminatelnstances permissions for the us-east-1 Region only when logged in with multi-factor authentication (MFA). Groups are permitted any other Amazon EC2 action within the us-east-1 Region</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 84%;" aria-valuenow="84" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EC2'>EC2</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EC2_77><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EC2 Question 77</p><br/>A company is designing an internet&#8211;facing web application. The application runs on Amazon EC2 for Linux&#8211;based instances that store sensitive user data in Amazon RDS MySQL Multi&#8211;AZ DB instances. The EC2 instances are in public subnets, and the RDS DB instances are in private subnets. The security team has mandated that the DB instances be secured against web&#8211;based attacks.<br/><br/>What should a solutions architect recommend?<br/><br/>A. Ensure the EC2 instances are part of an Auto Scaling group and are behind an Application Load Balancer. Configure the EC2 instance iptables rules to drop suspicious web traffic. Create a security group for the DB instances. Configure the RDS security group to only allow port 3306 inbound from the individual EC2 instances.<br/>B. Ensure the EC2 instances are part of an Auto Scaling group and are behind an Application Load Balancer. Move DB instances to the same subnets that EC2 instances are located in. Create a security group for the DB instances. Configure the RDS security group to only allow port 3306 inbound from the individual EC2 instances.<br/>C. Ensure the EC2 instances are part of an Auto Scaling group and are behind an Application Load Balancer. Use AWS WAF to monitor inbound web traffic for threats. Create a security group for the web application servers and a security group for the DB instances. Configure the RDS security group to only allow port 3306 inbound from the web application server security group.<br/>D. Ensure the EC2 instances are part of an Auto Scaling group and are behind an Application Load Balancer. Use AWS WAF to monitor inbound web traffic for threats. Configure the Auto Scaling group to automatically create new DB instances under heavy traffic. Create a security group for the RDS DB instances. Configure the RDS security group to only allow port 3306 inbound.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample385' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_78'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_22'>Random</a></p><div class='collapse' id='collapseExample385'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Ensure the EC2 instances are part of an Auto Scaling group and are behind an Application Load Balancer. Use AWS WAF to monitor inbound web traffic for threats. Create a security group for the web application servers and a security group for the DB instances. Configure the RDS security group to only allow port 3306 inbound from the web application server security group.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 85%;" aria-valuenow="85" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EC2'>EC2</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EC2_78><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EC2 Question 78</p><br/>A company is building its web application using containers on AWS. The company requires three instances of the web application to run at all times. The application must be able to scale to meet increases in demand. Management is extremely sensitive to cost but agrees that the application should be highly available.<br/><br/>What should a solutions architect recommend?<br/><br/>A. Create an Amazon Elastic Container Service (Amazon ECS) cluster using the Fargate launch type. Create a task definition for the web application. Create an ECS service with a desired count of three tasks.<br/>B. Create an Amazon Elastic Container Service (Amazon ECS) cluster using the Amazon EC2 launch type with three container instances in one Availability Zone. Create a task definition for the web application. Place one task for each container instance.<br/>C. Create an Amazon Elastic Container Service (Amazon ECS) cluster using the Fargate launch type with one container instance in three different Availability Zones. Create a task definition for the web application. Create an ECS service with a desired count of three tasks.<br/>D. Create an Amazon Elastic Container Service (Amazon ECS) cluster using the Amazon EC2 launch type with one container instance in two different Availability Zones. Create a task definition for the web application. Place two tasks on one container instance and one task on the remaining container instance.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample322' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_79'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_1'>Random</a></p><div class='collapse' id='collapseExample322'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Create an Amazon Elastic Container Service (Amazon ECS) cluster using the Amazon EC2 launch type with one container instance in two different Availability Zones. Create a task definition for the web application. Place two tasks on one container instance and one task on the remaining container instance.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 86%;" aria-valuenow="86" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EC2'>EC2</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EC2_79><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EC2 Question 79</p><br/>A company is building a web application that servers a content management system.<br/><br/>The content management system runs on Amazon EC2 instances behind an Application Load Balancer (ALB).<br/><br/>The EC2 instances run in an Auto Scaling group across Availability Zones.<br/><br/>Users are constantly adding and updating files, blogs, and other website assets in the content management system.<br/><br/>Which solution meets these requirements?<br/><br/>A. Update the EC2 user data in the Auto Scaling group lifecycle policy to copy the website assets from the EC2 instance that was launched most recently. Configure the ALB to make changes to the websites assets only in the newest EC2 instance.<br/>B. Copy the website assets to an Amazon Elastic File System (Amazon EFS) Me system. Configure each EC2 instance to mount the EFS m system locally. Configure the website hosting application to reference the website assets that are stored in the EFS file system.<br/>C. Copy the website assets to an Amazon S3 bucket. Ensure that each EC2 instance downloads the website assets from the S3 bucket to the attached Amazon Basic Block Store (Amazon EBS) volume. Run the S3 sync command once each hour to keep files up to date.<br/>D. Restore an Amazon Elastic Block Store (Amazon EBS) snapshot w.th the website assets. Attach the EBS snapshot as a secondary EBS volume when a new EBS EC2 instance is launched. Configure the website hosting application to reference the website assets that are stored in the secondary EBS volume.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample602' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_80'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_32'>Random</a></p><div class='collapse' id='collapseExample602'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Copy the website assets to an Amazon S3 bucket. Ensure that each EC2 instance downloads the website assets from the S3 bucket to the attached Amazon Basic Block Store (Amazon EBS) volume. Run the S3 sync command once each hour to keep files up to date.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 87%;" aria-valuenow="87" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EC2'>EC2</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EC2_80><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EC2 Question 80</p><br/>A three&#8211;tier web application processes orders from customers. The web tier consists of Amazon EC2 instances behind an Application Load Balancer, a middle tier of three EC2 instances decoupled from the web tier using Amazon SQS, and an Amazon DynamoDB backend. At peak times, customers who submit orders using the site have to wait much longer than normal to receive confirmations due to lengthy processing times. A solutions architect needs to reduce these processing times.<br/><br/>Which action will be MOST effective in accomplishing this?<br/><br/>A. Replace the SQS queue with Amazon Kinesis Data Firehose.<br/>B. Use Amazon ElastiCache for Redis in front of the DynamoDB backend tier.<br/>C. Add an Amazon CloudFront distribution to cache the responses for the web tier.<br/>D. Use Amazon EC2 Auto Scaling to scale out the middle tier instances based on the SQS queue depth.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample79' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_81'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_40'>Random</a></p><div class='collapse' id='collapseExample79'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Use Amazon EC2 Auto Scaling to scale out the middle tier instances based on the SQS queue depth.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 88%;" aria-valuenow="88" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EC2'>EC2</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EC2_81><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EC2 Question 81</p><br/>A company wants to improve the availability and performance of its stateless UDP&#8211;based workload. The workload is deployed on Amazon EC2 instances in multiple AWS Regions.<br/><br/>What should a solutions architect recommend to accomplish this?<br/><br/>A. Place the EC2 instances behind Network Load Balancers (NLBs) in each Region. Create an accelerator using AWS Global Accelerator. Use the NLBs as endpoints for the accelerator.<br/>B. Place the EC2 instances behind Application Load Balancers (ALBs) in each Region. Create an accelerator using AWS Global Accelerator. Use the ALBs as endpoints for the accelerator.<br/>C. Place the EC2 instances behind Network Load Balancers (NLBs) in each Region. Create an Amazon CloudFront distribution with an origin that uses Amazon Route 53 latency&#8211;based routing to route requests to the NLBs.<br/>D. Place the EC2 instances behind Application Load Balancers (ALBs) in each Region. Create an Amazon CloudFront distribution with an origin that uses Amazon Route 53 latency&#8211;based routing to route requests to the ALBs.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample387' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_82'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_64'>Random</a></p><div class='collapse' id='collapseExample387'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Place the EC2 instances behind Application Load Balancers (ALBs) in each Region. Create an Amazon CloudFront distribution with an origin that uses Amazon Route 53 latency-based routing to route requests to the ALBs.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 90%;" aria-valuenow="90" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EC2'>EC2</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EC2_82><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EC2 Question 82</p><br/>A company relies on an application that needs at least 4 Amazon EC2 instances during regular traffic and must scale up to 12 EC2 instances during peak loads.<br/><br/>The application is critical to the business and must be highly available.<br/><br/>Which solution will meet these requirements?<br/><br/>A. Deploy the EC2 instances in an Auto Scaling group. Set the minimum to 4 and the maximum to M, with 2 in Availability Zone A and 2 in Availability Zone B<br/>B. Deploy the EC2 instances in an Auto Scaling group. Set the minimum to 4 and the maximum to 12, with all 4 in Availability Zone A<br/>C. Deploy the EC2 instances in an Auto Scaling group. Set the minimum to 8 and the maximum to 12, with 4 in Availability Zone A and 4 in Availability Zone B<br/>D. Deploy the EC2 instances in an Auto Scaling group. Set the minimum to 8 and the maximum to 12 with all 8 in Availability Zone A<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample721' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation721' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_83'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_51'>Random</a></p><div class='collapse' id='collapseExample721'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Deploy the EC2 instances in an Auto Scaling group. Set the minimum to 8 and the maximum to 12, with 4 in Availability Zone A and 4 in Availability Zone B</div></div></div><div class='collapse' id='explanation721'><div class='card card&#45;body'><div>
It requires HA and if one AZ is down then at least 4 instances will be active in another AZ which is key for this question.
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 91%;" aria-valuenow="91" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EC2'>EC2</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EC2_83><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EC2 Question 83</p><br/>A company has a two&#8211;tier application architecture that runs in public and private subnets. Amazon EC2 instances running the web application are in the public subnet and a database runs on the private subnet.<br/><br/>The web application instances and the database are running in a single Availability Zone (AZ).<br/><br/>Which combination of steps should a solutions architect take to provide high availability for this architecture? (Choose two.)<br/><br/>A. Create new public and private subnets in the same AZ for high availability.<br/>B. Create an Amazon EC2 Auto Scaling group and Application Load Balancer spanning multiple AZs.<br/>C. Add the existing web application instances to an Auto Scaling group behind an Application Load Balancer.<br/>D. Create new public and private subnets in a new AZ. Create a database using Amazon EC2 in one AZ.<br/>E. Create new public and private subnets in the same VPC, each in a new AZ. Migrate the database to an Amazon RDS multi&#8211;AZ deployment.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample152' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation152' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_84'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_34'>Random</a></p><div class='collapse' id='collapseExample152'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Create an Amazon EC2 Auto Scaling group and Application Load Balancer spanning multiple AZs.
<br><b>E. </b>Create new public and private subnets in the same VPC, each in a new AZ. Migrate the database to an Amazon RDS multi-AZ deployment.</div></div></div><div class='collapse' id='explanation152'><div class='card card&#45;body'><div>

You would the EC2 instances to have high availability by placing them in multiple AZs.
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 92%;" aria-valuenow="92" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EC2'>EC2</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EC2_84><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EC2 Question 84</p><br/>A development team stores its Amazon RDS MySQL DB instance user name and password credentials in a configuration file. The configuration file is stored as plaintext on the root device volume of the team's Amazon EC2 instance. When the team's application needs to reach the database, it reads the file and loads the credentials into the code. The team has modified the permissions of the configuration file so that only the application can read its content. A solution architect must design a more secure solution.<br/><br/>What should the solutions architect do to meet this requirement?<br/><br/>A. Store the configuration file in Amazon S3. Grant the application access to read the configuration file.<br/>B. Create an IAM role with permission to access the database. Attach this IAM role to the EC2 instance.<br/>C. Enable SSL connections on the database instance. Alter the database user to require SSL when logging in.<br/>D. Move the configuration file to an EC2 instance store, and create an Amazon Machine Image (AMI) of the instance. Launch new instances from this AMI.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample316' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_85'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_12'>Random</a></p><div class='collapse' id='collapseExample316'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Move the configuration file to an EC2 instance store, and create an Amazon Machine Image (AMI) of the instance. Launch new instances from this AMI.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 93%;" aria-valuenow="93" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EC2'>EC2</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EC2_85><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EC2 Question 85</p><br/>What is a placement group in Amazon EC2?<br/><br/>A. It is a group of EC2 instances within a single Availability Zone.<br/>B. It the edge location of your web content.<br/>C. It is the AWS region where you run the EC2 instance of your web content.<br/>D. It is a group used to span multiple Availability Zones.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample773' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation773' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_86'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_38'>Random</a></p><div class='collapse' id='collapseExample773'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>It is a group of EC2 instances within a single Availability Zone.</div></div></div><div class='collapse' id='explanation773'><div class='card card&#45;body'><div>
A placement group is a logical grouping of instances within a single Availability Zone.

References:

Amazon Elastic Compute Cloud > User Guide for Linux Instances > Placement groups</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 94%;" aria-valuenow="94" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EC2'>EC2</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EC2_86><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EC2 Question 86</p><br/>A company wants to use a custom distributed application that calculates various profit and loss scenarios. To achieve this goal, the company needs to provide a network connection between its Amazon EC2 instances. The connection must minimize latency and must maximize throughput<br/><br/>Which solution will meet these requirements?<br/><br/>A. Provision the application to use EC2 Dedicated Hosts of the same instance type.<br/>B. Configure a placement group for EC2 instances that have the same instance type.<br/>C. Use multiple AWS elastic network interfaces and link aggregation.<br/>D. Configure AWS PrivateLink for the EC2 instances.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample437' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_87'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_24'>Random</a></p><div class='collapse' id='collapseExample437'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Configure a placement group for EC2 instances that have the same instance type.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 95%;" aria-valuenow="95" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EC2'>EC2</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EC2_87><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EC2 Question 87</p><br/>A company stores project information in a shared spreadsheet. The company wants to create a web application to replace the spreadsheet. The company has chosen Amazon DynamoDB to store the spreadsheet's data and is designing the web application to display the project information that is obtained from DynamoDB.<br/><br/>A solutions architect must design the web application's backend by using managed services that require minimal operational maintenance.<br/><br/>Which architectures meet these requirements? (Select TWO.)<br/><br/>A. An Amazon API Gateway REST API accesses the project information that is in DynamoD<br/>B. An Elastic Load Balancer forwards requests to a target group with DynamoDB set up as the target.<br/>C. An Amazon API Gateway REST API invokes an AWS Lambda function. The Lambda function accesses DynamoD<br/>D. An Amazon Route 53 hosted zone routes requests to an AWS Lambda endpoint to invoke a Lambda function that accesses DynamoD<br/>E. An Elastic Load Balancer forwards requests to a target group of Amazon EC2 instances. The EC2 instances run an application that accesses DynamoD<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample467' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_88'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_58'>Random</a></p><div class='collapse' id='collapseExample467'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>An Amazon API Gateway REST API accesses the project information that is in DynamoD
<br><b>E. </b>An Elastic Load Balancer forwards requests to a target group of Amazon EC2 instances. The EC2 instances run an application that accesses DynamoD</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 96%;" aria-valuenow="96" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EC2'>EC2</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EC2_88><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EC2 Question 88</p><br/>A solutions architect is designing an architecture to run a third&#8211;party database server. The database software is memory intensive and has a CPU&#8211;based licensing model where the cost increases with the number of vCPU cores within the operating system. The solutions architect must select an Amazon EC2 instance with sufficient memory to run the database software, but the selected instance has a large number of vCPUs. The solutions architect must ensure that the vCPUs will not be underutilized and must minimize costs.<br/><br/>Which solution meets these requirements?<br/><br/>A. Select and launch a smaller EC2 instance with an appropriate number of vCPUs.<br/>B. Configure the CPU cores and threads on the selected EC2 instance during instance launch.<br/>C. Create a new EC2 instance and ensure multithreading is enabled when configuring the instance details.<br/>D. Create a new Capacity Reservation and select the appropriate instance type. Launch the instance into this new Capacity Reservation.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample297' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_89'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_41'>Random</a></p><div class='collapse' id='collapseExample297'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Select and launch a smaller EC2 instance with an appropriate number of vCPUs.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 97%;" aria-valuenow="97" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EC2'>EC2</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EC2_89><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EC2 Question 89</p><br/>A company operates a website on Amazon EC2 Linux instances Some of the instances are failing. Troubleshooting points to insufficient swap space on the failed instances. The operations team lead needs a solution to monitor this<br/><br/>What should a solutions architect recommend?<br/><br/>A. Configure an Amazon CloudWatch SwapUsage metric dimension Monitor the SwapUsage dimension in the EC2 metrics in CloudWatch.<br/>B. Use EC2 metadata to collect information, then publish it to Amazon CloudWatch custom metrics Monitor SwapUsage metrics in CloudWatch<br/>C. Install an Amazon CloudWatch agent on the instances. Run an appropriate script on a set schedule. Monitor SwapUtilization metrics in CloudWatch<br/>D. Enable detailed monitoring in the EC2 console Create an Amazon CloudWatch SwapUtilization custom metric Monitor SwapUtilization metrics in CloudWatch<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample481' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_90'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_49'>Random</a></p><div class='collapse' id='collapseExample481'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Configure an Amazon CloudWatch SwapUsage metric dimension Monitor the SwapUsage dimension in the EC2 metrics in CloudWatch.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 98%;" aria-valuenow="98" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EC2'>EC2</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EC2_90><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EC2 Question 90</p><br/>A company currently has 250 TB of backup files stored in Amazon S3 in a vendor's proprietary format.<br/><br/>Using a Linux&#8211;based software application provided by the vendor, the company wants to retrieve files from Amazon S3, transform the files to an industry&#8211;standard format, and re&#8211;upload them to Amazon S3. The company wants to minimize the data transfer charges associated with this conversation.<br/><br/>What should a solutions architect do to accomplish this?<br/><br/>A. Install the conversion software as an Amazon S3 batch operation so the data is transformed without leaving Amazon S3.<br/>B. Install the conversion software onto an on&#8211;premises virtual machine. Perform the transformation and reupload the files to Amazon S3 from the virtual machine.<br/>C. Use AWS Snowball Edge devices to export the data and install the conversion software onto the devices. Perform the data transformation and re&#8211;upload the files to Amazon S3 from the Snowball Edge devices.<br/>D. Launch an Amazon EC2 instance in the same Region as Amazon S3 and install the conversion software onto the instance. Perform the transformation and re&#8211;upload the files to Amazon S3 from the EC2 instance.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample122' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_91'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EC2_55'>Random</a></p><div class='collapse' id='collapseExample122'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Launch an Amazon EC2 instance in the same Region as Amazon S3 and install the conversion software onto the instance. Perform the transformation and re-upload the files to Amazon S3 from the EC2 instance.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 100%;" aria-valuenow="100" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EC2'>EC2</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><a id=CloudFront><h2>CloudFront</h2></a> - 52 Questions <br><a href='#CloudFront'>CloudFront(52)</a> <a href='#' <i class='bi bi&#45;house'> &nbsp;Home</i><hr> </a><div class='row' id=CloudFront_1><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>CloudFront Question 1</p><br/>A solution architect is performing a security review of a recently migrated workload. The workload is a web application that consists of Amazon EC2 instances in an Auto Scaling group behind an Application Load balancer. The solution architect must improve the security posture and minimize the impact of a DDoS attack on resources.<br/><br/>Which solution is MOST effective?<br/><br/>A. Configure an AWS WAF ACL with rate&#8211;based rules Create an Amazon CloudFront distribution that points to the Application Load Balancer. Enable the EAF ACL on the CloudFront distribution<br/>B. Create a custom AWS Lambda function that adds identified attacks into a common vulnerability pool to capture a potential DDoS attack. use the identified information to modify a network ACL to block access.<br/>C. Enable VPC Flow Logs and store them in Amazon S3. Create a custom AWS Lambda functions that parse the logs looking for a DDoS attack. Modify a network ACL to block identified source IP addresses.<br/>D. Enable Amazon GuardDuty and, configure findings written 10 Amazon GloudWatch Create an event with Cloud Watch Events for DDoS alerts that triggers Amazon Simple Notification Service (Amazon SNS) Have Amazon SNS invoke a custom AWS Lambda function that parses the logs looking for a DDoS attack Modify a network ACL to block identified source IP addresses<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample729' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_2'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_49'>Random</a></p><div class='collapse' id='collapseExample729'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Configure an AWS WAF ACL with rate-based rules Create an Amazon CloudFront distribution that points to the Application Load Balancer. Enable the EAF ACL on the CloudFront distribution</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 1%;" aria-valuenow="1" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#CloudFront'>CloudFront</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=CloudFront_2><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>CloudFront Question 2</p><br/>A company is planning to migrate a TCP&#8211;based application into the company's VPC. The application is publicly accessible on a nonstandard TCP port through a hardware appliance in the company's data center. This public endpoint can process up to 3 million requests per second with low latency. The company requires the same level of performance for the new public endpoint in AWS.<br/><br/>What should a solutions architect recommend to meet this requirement?<br/><br/>A. Deploy a Network Load Balancer (NLB). Configure the NLB to be publicly accessible over the TCP port that the application requires.<br/>B. Deploy an Application Load Balancer (ALB). Configure the ALB to be publicly accessible over the TCP port that the application requires.<br/>C. Deploy an Amazon CloudFront distribution that listens on the TCP port that the application requires. Use an Application Load Balancer as the origin.<br/>D. Deploy an Amazon API Gateway API that is configured with the TCP port that the application requires. Configure AWS Lambda functions with provisioned concurrency to process the requests.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample427' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_3'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_11'>Random</a></p><div class='collapse' id='collapseExample427'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Deploy an Amazon CloudFront distribution that listens on the TCP port that the application requires. Use an Application Load Balancer as the origin.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 3%;" aria-valuenow="3" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#CloudFront'>CloudFront</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=CloudFront_3><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>CloudFront Question 3</p><br/>A solutions architect is optimizing a website for an upcoming musical event. Videos of the performances will be streamed in real time and then will be available on demand. The event is expected to attract a global online audience.<br/><br/>Which service will improve the performance of both the real&#8211;time and on&#8211;demand streaming?<br/><br/>A. Amazon CloudFront<br/>B. AWS Global Accelerator<br/>C. Amazon Route S3<br/>D. Amazon S3 Transfer Acceleration<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample42' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_4'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_19'>Random</a></p><div class='collapse' id='collapseExample42'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Amazon CloudFront</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 5%;" aria-valuenow="5" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#CloudFront'>CloudFront</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=CloudFront_4><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>CloudFront Question 4</p><br/>A company hosts a static website on&#8211;premises and wants to migrate the website to AWS. The website should load as quickly as possible for users around the world. The company also wants the most cost&#8211;effective solution.<br/><br/>What should a solutions architect do to accomplish this?<br/><br/>A. Copy the website content to an Amazon S3 bucket. Configure the bucket to serve static webpage content. Replicate the S3 bucket to multiple AWS Regions.<br/>B. Copy the website content to an Amazon S3 bucket. Configure the bucket to serve static webpage content. Configure Amazon CloudFront with the S3 bucket as the origin.<br/>C. Copy the website content to an Amazon EBS&#8211;backed Amazon EC2 instance running Apache HTTP Server. Configure Amazon Route 53 geolocation routing policies to select the closest origin.<br/>D. Copy the website content to multiple Amazon EBS&#8211;backed Amazon EC2 instances running Apache HTTP Server in multiple AWS Regions. Configure Amazon CloudFront geolocation routing policies to select the closest origin.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample150' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation150' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_5'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_14'>Random</a></p><div class='collapse' id='collapseExample150'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Copy the website content to an Amazon S3 bucket. Configure the bucket to serve static webpage content. Configure Amazon CloudFront with the S3 bucket as the origin.</div></div></div><div class='collapse' id='explanation150'><div class='card card&#45;body'><div>
What Is Amazon CloudFront?
Amazon CloudFront is a web service that speeds up distribution of your static and dynamic web content, such as .html, .css, .js, and image files, to your users. CloudFront delivers your content through a worldwide network of data centers called edge locations. When a user requests content that you're serving with CloudFront, the user is routed to the edge location that provides the lowest latency (time delay), so that content is delivered with the best possible performance.

Using Amazon S3 Buckets for Your Origin
When you use Amazon S3 as an origin for your distribution, you place any objects that you want CloudFront to deliver in an Amazon S3 bucket. You can use any method that is supported by Amazon S3 to get your objects into Amazon S3, for example, the Amazon S3 console or API, or a third-party tool. You can create a hierarchy in your bucket to store the objects, just as you would with any other Amazon S3 bucket.

Using an existing Amazon S3 bucket as your CloudFront origin server doesn't change the bucket in any way; you can still use it as you normally would to store and access Amazon S3 objects at the standard Amazon S3 price. You incur regular Amazon S3 charges for storing the objects in the bucket.

The most cost-effective option is to migrate the website to an Amazon S3 bucket and configure that bucket for static website hosting. To enable good performance for global users the solutions architect should then configure a CloudFront distribution with the S3 bucket as the origin. This will cache the static content around the world closer to users.

CORRECT: "Copy the website content to an Amazon S3 bucket. Configure the bucket to serve static webpage content. Configure Amazon CloudFront with the S3 bucket as the origin" is the correct answer.

INCORRECT: "Copy the website content to an Amazon S3 bucket. Configure the bucket to serve static webpage content. Replicate the S3 bucket to multiple AWS Regions" is incorrect as there is no solution here for directing users to the closest region. This could be a more cost-effective (though less elegant) solution if AWS Route 53 latency records are created.

INCORRECT: "Copy the website content to an Amazon EC2 instance. Configure Amazon Route 53 geolocation routing policies to select the closest origin" is incorrect as using Amazon EC2 instances is less cost-effective compared to hosting the website on S3. Also, geolocation routing does not achieve anything with only a single record.

INCORRECT: "Copy the website content to multiple Amazon EC2 instances in multiple AWS Regions. Configure AWS Route 53 geolocation routing policies to select the closest region" is incorrect as using Amazon EC2 instances is less cost-effective compared to hosting the website on S3.

References:

How do I use CloudFront to serve a static website hosted on Amazon S3?</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 7%;" aria-valuenow="7" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#CloudFront'>CloudFront</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=CloudFront_5><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>CloudFront Question 5</p><br/>A solutions architect is moving the static content from a public website hosted on Amazon EC2 instances to an Amazon S3 bucket. An Amazon CloudFront distribution will be used to deliver the static assets. The security group used by the EC2 instances restricts access to a limited set of IP ranges. Access to the static content should be similarly restricted.<br/><br/>Which combination of steps will meet these requirements? (Choose two.)<br/><br/>A. Create an origin access identity (OAI) and associate it with the distribution. Change the permissions in the bucket policy so that only the OAI can read the objects.<br/>B. Create an AWS WAF web ACL that includes the same IP restrictions that exist in the EC2 security group. Associate this new web ACL with the CloudFront distribution.<br/>C. Create a new security group that includes the same IP restrictions that exist in the current EC2 security group. Associate this new security group with the CloudFront distribution.<br/>D. Create a new security group that includes the same IP restrictions that exist in the current EC2 security group. Associate this new security group with the S3 bucket hosting the static content.<br/>E. Create a new IAM role and associate the role with the distribution. Change the permissions either on the S3 bucket or on the files within the S3 bucket so that only the newly created IAM role has read and download permissions.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample162' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_6'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_24'>Random</a></p><div class='collapse' id='collapseExample162'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Create an origin access identity (OAI) and associate it with the distribution. Change the permissions in the bucket policy so that only the OAI can read the objects.
<br><b>B. </b>Create an AWS WAF web ACL that includes the same IP restrictions that exist in the EC2 security group. Associate this new web ACL with the CloudFront distribution.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 9%;" aria-valuenow="9" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#CloudFront'>CloudFront</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=CloudFront_6><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>CloudFront Question 6</p><br/>Organizers for a global event want to put daily reports online as static HTML pages. The pages are expected to generate millions of views from users around the world. The files are stored in an Amazon S3 bucket. A solutions architect has been asked to design an efficient and effective solution.<br/><br/>Which action should the solutions architect take to accomplish this?<br/><br/>A. Generate presigned URLs for the files.<br/>B. Use cross&#8211;Region replication to all Regions.<br/>C. Use the geoproximity feature of Amazon Route 53.<br/>D. Use Amazon CloudFront with the S3 bucket as its origin.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample10' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation10' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_7'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_50'>Random</a></p><div class='collapse' id='collapseExample10'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Use Amazon CloudFront with the S3 bucket as its origin.</div></div></div><div class='collapse' id='explanation10'><div class='card card&#45;body'><div>
Using Amazon S3 Origins, MediaPackage Channels, and Custom Origins for Web Distributions

Using Amazon S3 Buckets for Your Origin
When you use Amazon S3 as an origin for your distribution, you place any objects that you want CloudFront to deliver in an Amazon S3 bucket. You can use any method that is supported by Amazon S3 to get your objects into Amazon S3, for example, the Amazon S3 console or API, or a third-party tool. You can create a hierarchy in your bucket to store the objects, just as you would with any other Amazon S3 bucket.

Using an existing Amazon S3 bucket as your CloudFront origin server doesn't change the bucket in any way; you can still use it as you normally would to store and access Amazon S3 objects at the standard Amazon S3 price. You incur regular Amazon S3 charges for storing the objects in the bucket.

Using Amazon S3 Buckets Configured as Website Endpoints for Your Origin
You can set up an Amazon S3 bucket that is configured as a website endpoint as custom origin with CloudFront.

When you configure your CloudFront distribution, for the origin, enter the Amazon S3 static website hosting endpoint for your bucket. This value appears in the Amazon S3 console, on the Properties tab, in the Static website hosting pane. For example: http://bucket-name.s3-website-region.amazonaws.com

For more information about specifying Amazon S3 static website endpoints, see Website endpoints in the Amazon Simple Storage Service Developer Guide.

When you specify the bucket name in this format as your origin, you can use Amazon S3 redirects and Amazon S3 custom error documents. For more information about Amazon S3 features, see the Amazon S3 documentation.

Using an Amazon S3 bucket as your CloudFront origin server doesn't change it in any way. You can still use it as you normally would and you incur regular Amazon S3 charges.

Amazon CloudFront can be used to cache the files in edge locations around the world and this will improve the performance of the webpages.

To serve a static website hosted on Amazon S3, you can deploy a CloudFront distribution using one of these configurations:

Using a REST API endpoint as the origin with access restricted by an origin access identity (OAI) Using a website endpoint as the origin with anonymous (public) access allowed

Using a website endpoint as the origin with access restricted by a Referer header CORRECT: "Use Amazon CloudFront with the S3 bucket as its origin" is the correct answer.

INCORRECT: "Generate presigned URLs for the files" is incorrect as this is used to restrict access which is not a requirement.

INCORRECT: "Use cross-Region replication to all Regions" is incorrect as this does not provide a mechanism for directing users to the closest copy of the static webpages.

INCORRECT: "Use the geoproximity feature of Amazon Route 53" is incorrect as this does not include a solution for having multiple copies of the data in different geographic locations.

References:

How do I use CloudFront to serve a static website hosted on Amazon S3?</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 11%;" aria-valuenow="11" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#CloudFront'>CloudFront</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=CloudFront_7><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>CloudFront Question 7</p><br/>A company is building an online multiplayer game. The game communicates by using UDP, and low latency between the client and the backend is important. The backend is hosted on Amazon EC2 instances that can be deployed to multiple AWS Regions to meet demand. The company needs the game to be highly available so that users around the world can access the game at all times.<br/><br/>What should a solutions architect do to meet these requirements?<br/><br/>A. Deploy Amazon CloudFront to support the global traffic. Configure CloudFront with an origin group to allow access to EC2 instances in multiple Regions.<br/>B. Deploy an Application Load Balancer in one Region to distribute traffic to EC2 instances in each Region that hosts the game's backend instances.<br/>C. Deploy Amazon CloudFront to support an origin access identity (OAI). Associate the OAI with EC2 instances in each Region to support global traffic.<br/>D. Deploy a Network Load Balancer in each Region to distribute the traffic. Use AWS Global Accelerator to route traffic to the correct Regional endpoint.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample421' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_8'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_43'>Random</a></p><div class='collapse' id='collapseExample421'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Deploy Amazon CloudFront to support an origin access identity (OAI). Associate the OAI with EC2 instances in each Region to support global traffic.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 13%;" aria-valuenow="13" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#CloudFront'>CloudFront</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=CloudFront_8><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>CloudFront Question 8</p><br/>A company serves content to its subscribers across the world using an application running on AWS. The application has several Amazon EC2 instances in a private subnet behind an Application Load Balancer (ALB). Due to a recent change in copyright restrictions, the chief information officer (CIO) wants to block access for certain countries.<br/><br/>Which action will meet these requirements?<br/><br/>A. Modify the ALB security group to deny incoming traffic from blocked countries.<br/>B. Modify the security group for EC2 instances to deny incoming traffic from blocked countries.<br/>C. Use Amazon CloudFront to serve the application and deny access to blocked countries.<br/>D. Use ALB listener rules to return access denied responses to incoming traffic from blocked countries.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample180' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation180' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_9'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_12'>Random</a></p><div class='collapse' id='collapseExample180'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Use Amazon CloudFront to serve the application and deny access to blocked countries.</div></div></div><div class='collapse' id='explanation180'><div class='card card&#45;body'><div>
"block access for certain countries." You can use geo restriction, also known as geo blocking, to prevent users in specific geographic locations from accessing content that you're distributing through a CloudFront web distribution.

When a user requests your content, CloudFront typically serves the requested content regardless of where the user is located. If you need to prevent users in specific countries from accessing your content, you can use the CloudFront geo restriction feature to do one of the following:

Allow your users to access your content only if they're in one of the countries on a whitelist of approved countries.

Prevent your users from accessing your content if they're in one of the countries on a blacklist of banned countries.

For example, if a request comes from a country where, for copyright reasons, you are not authorized to distribute your content, you can use CloudFront geo restriction to block the request. This is the easiest and most effective way to implement a geographic restriction for the delivery of content.

CORRECT: "Use Amazon CloudFront to serve the application and deny access to blocked countries" is the correct answer.

INCORRECT: "Use a Network ACL to block the IP address ranges associated with the specific countries" is incorrect as this would be extremely difficult to manage.

INCORRECT: "Modify the ALB security group to deny incoming traffic from blocked countries" is incorrect as security groups cannot block traffic by country.

INCORRECT: "Modify the security group for EC2 instances to deny incoming traffic from blocked countries" is incorrect as security groups cannot block traffic by country.

References:

Amazon CloudFront > Developer Guide > Restricting the geographic distribution of your content</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 15%;" aria-valuenow="15" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#CloudFront'>CloudFront</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=CloudFront_9><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>CloudFront Question 9</p><br/>A solution architect needs to design a highly available application consisting of web, application, and database tiers. HTTPS content delivery should be as close to the edge as possible, with the least delivery time.<br/><br/>Which solution meets these requirements and is MOST secure?<br/><br/>A. Configure a public Application Load Balancer (ALB) with multiple redundant Amazon EC2 instances in public subnets. Configure Amazon CloudFront to deliver HTTPS content using the public ALB as the origin.<br/>B. Amazon EC2 instances in private subnets Configure. Configure a public Application Load Balancer with multiple redundant Amazon CloudFront to deliver HTTPS content using the EC2 instances as the origin.<br/>C. Configure a public Application Load Balancer (ALB) with multiple redundant Amazon EC2 instances in private subnets. Configure Amazon CloudFront to deliver HTTPS content using the public ALB as the origin.<br/>D. Configure a public Application Load Balancer with multiple redundant Amazon EC2 instances in public subnets. Configure Amazon CloudFront to deliver HTTPS content using the EC2 instances as the origin.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample314' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_10'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_31'>Random</a></p><div class='collapse' id='collapseExample314'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Amazon EC2 instances in private subnets Configure. Configure a public Application Load Balancer with multiple redundant Amazon CloudFront to deliver HTTPS content using the EC2 instances as the origin.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 17%;" aria-valuenow="17" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#CloudFront'>CloudFront</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=CloudFront_10><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>CloudFront Question 10</p><br/>A solutions architect is optimizing a website for an upcoming musical event Videos of the performances will be streamed in real&#8211;time and then will be available on demand. The event is expected to attract a global online audience<br/><br/>Which service will improve the performance of both real&#8211;time and on&#8211;demand streaming?<br/><br/>A. Amazon CloudFront<br/>B. AWS Global Accelerator<br/>C. Amazon Route 53<br/>D. Amazon S3 Transfer Acceleration<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample458' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation458' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_11'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_28'>Random</a></p><div class='collapse' id='collapseExample458'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Amazon CloudFront</div></div></div><div class='collapse' id='explanation458'><div class='card card&#45;body'><div>
Amazon CloudFront can be used to stream video to users across the globe using a wide variety of protocols that are layered on top of HTTP. This can include both on-demand video as well as real-time streaming video.

CORRECT: "Amazon CloudFront" is the correct answer.

INCORRECT: "AWS Global Accelerator" is incorrect as this would be an expensive way of getting the content closer to users compared to using CloudFront. As this is a use case for CloudFront and there are so many edge locations it is the better option.

INCORRECT: "Amazon Route 53" is incorrect as you still need a solution for getting the content closer to users.

INCORRECT: "Amazon S3 Transfer Acceleration" is incorrect as this is used to accelerate uploads of data to Amazon S3 buckets.

References:

Amazon CloudFront media streaming tutorials
Amazon CloudFront > Developer Guide > Video on Demand and Live Streaming Video with CloudFront</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 19%;" aria-valuenow="19" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#CloudFront'>CloudFront</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=CloudFront_11><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>CloudFront Question 11</p><br/>A company hosts historical weather records in Amazon S3. The records are downloaded from the company's website by a way of a URL that resolves to a domain name. Users all over the world access this content through subscriptions. A third&#8211;party provider hosts the company's root domain name, but the company recently migrated some of its services to Amazon Route 53. The company wants to consolidate contracts, reduce latency for users, and reduce costs related to serving the application to subscribers.<br/><br/>Which solution meets these requirements?<br/><br/>A. Create a web distribution on Amazon CloudFront to serve the S3 content for the application. Create a CNAME record in a Route 53 hosted zone that points to the CloudFront distribution, resolving to the application's URL domain name.<br/>B. Create a web distribution on Amazon CloudFront to serve the S3 content for the application. Create an ALIAS record in the Amazon Route 53 hosted zone that points to the CloudFront distribution, resolving to the application's URL domain name.<br/>C. Create an A record in a Route 53 hosted zone for the application. Create a Route 53 traffic policy for the web application, and configure a geolocation rule. Configure health checks to check the health of the endpoint and route DNS queries to other endpoints if an endpoint is unhealthy.<br/>D. Create an A record in a Route 53 hosted zone for the application. Create a Route 53 traffic policy for the web application, and configure a geoproximity rule. Configure health checks to check the health of the endpoint and route DNS queries to other endpoints if an endpoint is unhealthy.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample250' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_12'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_46'>Random</a></p><div class='collapse' id='collapseExample250'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Create a web distribution on Amazon CloudFront to serve the S3 content for the application. Create an ALIAS record in the Amazon Route 53 hosted zone that points to the CloudFront distribution, resolving to the application's URL domain name.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 21%;" aria-valuenow="21" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#CloudFront'>CloudFront</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=CloudFront_12><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>CloudFront Question 12</p><br/>A Solutions Architect must design a web application that will be hosted on AWS, allowing users to purchase access to premium, shared content that is stored in an S3 bucket. Upon payment, content will be available for download for 14 days before the user is denied access.<br/><br/>Which of the following would be the LEAST complicated implementation?<br/><br/>A. Use an Amazon CloudFront distribution with an origin access identity (OAI). Configure the distribution with an Amazon S3 origin to provide access to the file through signed URLs. Design a Lambda function to remove data that is older than 14 days.<br/>B. Use an S3 bucket and provide direct access to the file. Design the application to track purchases in a DynamoDB table. Configure a Lambda function to remove data that is older than 14 days based on a query to Amazon DynamoDB.<br/>C. Use an Amazon CloudFront distribution with an OAI. Configure the distribution with an Amazon S3 origin to provide access to the file through signed URLs. Design the application to set an expiration of 14 days for the URL.<br/>D. Use an Amazon CloudFront distribution with an OAI. Configure the distribution with an Amazon S3 origin to provide access to the file through signed URLs. Design the application to set an expiration of 60 minutes for the URL and recreate the URL as necessary.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample265' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_13'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_17'>Random</a></p><div class='collapse' id='collapseExample265'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Use an Amazon CloudFront distribution with an OAI. Configure the distribution with an Amazon S3 origin to provide access to the file through signed URLs. Design the application to set an expiration of 14 days for the URL.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 23%;" aria-valuenow="23" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#CloudFront'>CloudFront</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=CloudFront_13><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>CloudFront Question 13</p><br/>A company's dynamic website is hosted using on&#8211;premises servers in the United States. The company is launching its product in Europe, and it wants to optimize site loading times for new European users. The site's backend must remain in the United States. The product is being launched in a few days, and an immediate solution is needed.<br/><br/>What should the solutions architect recommend?<br/><br/>A. Launch an Amazon EC2 instance in us&#8211;east&#8211;1 and migrate the site to it.<br/>B. Move the website to Amazon S3. Use cross&#8211;Region replication between Regions.<br/>C. Use Amazon CloudFront with a custom origin pointing to the on&#8211;premises servers.<br/>D. Use an Amazon Route 53 geo&#8211;proximity routing policy pointing to on&#8211;premises servers.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample106' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_14'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_41'>Random</a></p><div class='collapse' id='collapseExample106'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Use Amazon CloudFront with a custom origin pointing to the on-premises servers.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 25%;" aria-valuenow="25" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#CloudFront'>CloudFront</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=CloudFront_14><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>CloudFront Question 14</p><br/>A solutions architect is designing a solution to access a catalog of images and provide users with the ability to submit requests to customize images. Image customization parameters will be in any request sent to an AWS API Gateway API. The customized image will be generated on demand, and users will receive a link they can click to view or download their customized image. The solution must be highly available for viewing and customizing images.<br/><br/>What is the MOST cost&#8211;effective solution to meet these requirements?<br/><br/>A. Use Amazon EC2 instances to manipulate the original image into the requested customization. Store the original and manipulated images in Amazon S3. Configure an Elastic Load Balancer in front of the EC2 instances.<br/>B. Use AWS Lambda to manipulate the original image to the requested customization. Store the original and manipulated images in Amazon S3. Configure an Amazon CloudFront distribution with the S3 bucket as the origin.<br/>C. Use AWS Lambda to manipulate the original image to the requested customization. Store the original images in Amazon S3 and the manipulated images in Amazon DynamoDB. Configure an Elastic Load Balancer in front of the Amazon EC2 instances.<br/>D. Use Amazon EC2 instances to manipulate the original image into the requested customization. Store the original images in Amazon S3 and the manipulated images in Amazon DynamoDB. Configure an Amazon CloudFront distribution with the S3 bucket as the origin.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample12' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation12' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_15'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_23'>Random</a></p><div class='collapse' id='collapseExample12'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Use AWS Lambda to manipulate the original image to the requested customization. Store the original and manipulated images in Amazon S3. Configure an Amazon CloudFront distribution with the S3 bucket as the origin.</div></div></div><div class='collapse' id='explanation12'><div class='card card&#45;body'><div>
AWS Lambda is a compute service that lets you run code without provisioning or managing servers. AWS Lambda executes your code only when needed and scales automatically, from a few requests per day to thousands per second. You pay only for the compute time you consume – there is no charge when your code is not running. With AWS Lambda, you can run code for virtually any type of application or backend service – all with zero administration. AWS Lambda runs your code on a high-availability compute infrastructure and performs all of the administration of the compute resources, including server and operating system maintenance, capacity provisioning and automatic scaling, code monitoring, and logging.

All you need to do is supply your code in one of the languages that AWS Lambda supports.

Storing your static content with S3 provides a lot of advantages. But to help optimize your application's performance and security while effectively managing cost, we recommend that you also set up Amazon CloudFront to work with your S3 bucket to serve and protect the content. CloudFront is a content delivery network (CDN) service that delivers static and dynamic web content, video streams, and APIs around the world, securely and at scale. By design, delivering data out of CloudFront can be more cost effective than delivering it from S3 directly to your users.

CloudFront serves content through a worldwide network of data centers called Edge Locations. Using edge servers to cache and serve content improves performance by providing content closer to where viewers are located. CloudFront has edge servers in locations all around the world.

All solutions presented are highly available. The key requirement that must be satisfied is that the solution should be cost-effective and you must choose the most cost-effective option.

Therefore, it's best to eliminate services such as Amazon EC2 and ELB as these require ongoing costs even when they're not used. Instead, a fully serverless solution should be used. AWS Lambda, Amazon S3 and CloudFront are the best services to use for these requirements.

CORRECT: "Use AWS Lambda to manipulate the original images to the requested customization. Store the original and manipulated images in Amazon S3. Configure an Amazon CloudFront distribution with the S3 bucket as the origin" is the correct answer.

INCORRECT: "Use Amazon EC2 instances to manipulate the original images into the requested customization. Store the original and manipulated images in Amazon S3. Configure an Elastic Load Balancer in front of the EC2 instances" is incorrect. This is not the most cost-effective option as the ELB and EC2 instances will incur costs even when not used.

INCORRECT: "Use AWS Lambda to manipulate the original images to the requested customization. Store the original images in Amazon S3 and the manipulated images in Amazon DynamoDB. Configure an Elastic Load Balancer in front of the Amazon EC2 instances" is incorrect. This is not the most cost-effective option as the ELB will incur costs even when not used. Also, Amazon DynamoDB will incur RCU/WCUs when running and is not the best choice for storing images.

INCORRECT: "Use Amazon EC2 instances to manipulate the original images into the requested customization. Store the original images in Amazon S3 and the manipulated images in Amazon DynamoDB. Configure an Amazon CloudFront distribution with the S3 bucket as the origin" is incorrect. This is not the most cost-effective option as the EC2 instances will incur costs even when not used.

References:

Serverless on AWS</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 26%;" aria-valuenow="26" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#CloudFront'>CloudFront</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=CloudFront_15><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>CloudFront Question 15</p><br/>A company runs an online media site, hosted on&#8211;premises. An employee posted a product review that contained videos and pictures. The review went viral and the company needs to handle the resulting spike in website traffic.<br/><br/>What action would provide an immediate solution?<br/><br/>A. Redesign the website to use Amazon API Gateway, and use AWS Lambda to deliver content<br/>B. Add server instances using Amazon EC2 and use Amazon Route 53 with a failover routing policy<br/>C. Serve the images and videos using an Amazon CloudFront distribution created using the news site as the origin<br/>D. Use Amazon ElasbCache for Redis for caching and reducing the load requests from the origin<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample544' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_16'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_4'>Random</a></p><div class='collapse' id='collapseExample544'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Serve the images and videos using an Amazon CloudFront distribution created using the news site as the origin</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 28%;" aria-valuenow="28" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#CloudFront'>CloudFront</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=CloudFront_16><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>CloudFront Question 16</p><br/>A company is hosting its static website in an Amazon S3 bucket, which is the origin for Amazon CloudFront.<br/><br/>The company has users in the United States, Canada, and Europe and wants to reduce costs.<br/><br/>What should a solutions architect recommend?<br/><br/>A. Adjust the CloudFront caching time to live (TTL) from the default to a longer timeframe.<br/>B. Implement CloudFront events with Lambda@Edge to run the website's data processing.<br/>C. Modify the CloudFront price class to include only the locations of the countries that are served.<br/>D. Implement a CloudFront Secure Sockets Layer (SSL) certificate to push security closer to the locations of the countries that are served.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample231' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_17'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_5'>Random</a></p><div class='collapse' id='collapseExample231'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Modify the CloudFront price class to include only the locations of the countries that are served.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 30%;" aria-valuenow="30" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#CloudFront'>CloudFront</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=CloudFront_17><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>CloudFront Question 17</p><br/>A solutions architect is designing the storage architecture for a new web application used for storing and viewing engineering drawings. All application components will be deployed on the AWS infrastructure.<br/><br/>The application design must support caching to minimize the amount of time that users wait for the engineering drawings to load. The application must be able to store petabytes of data. Which combination of storage and caching should the solutions architect use?<br/><br/>A. Amazon S3 with Amazon CloudFront<br/>B. Amazon S3 Glacier with Amazon ElastiCache<br/>C. Amazon Elastic Block Store (Amazon EBS) volumes with Amazon CloudFront<br/>D. AWS Storage Gateway with Amazon ElastiCache<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample213' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation213' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_18'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_2'>Random</a></p><div class='collapse' id='collapseExample213'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Amazon S3 with Amazon CloudFront</div></div></div><div class='collapse' id='explanation213'><div class='card card&#45;body'><div>
CloudFront for caching and S3 as the origin. Glacier is used for archiving which is not the case for this scenario.
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 32%;" aria-valuenow="32" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#CloudFront'>CloudFront</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=CloudFront_18><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>CloudFront Question 18</p><br/>A company's dynamic website is hosted using on&#8211;premises servers in the United States. The company is launching its product in Europe and it wants to optimize site loading times for new European users. The site's backend must remain in the United States.<br/><br/>The product is being launched in a few days, and an immediate solution is needed<br/><br/>What should the solutions architect recommend?<br/><br/>A. Launch an Amazon EC2 instance in us&#8211;east&#8211;1 and migrate the site to it<br/>B. Move the website to Amazon S3 Use cross&#8211;Region replication between Regions.<br/>C. Use Amazon CloudFront with a custom origin pointing to the on&#8211;premises servers<br/>D. Use an Amazon Route 53 geoproximity routing policy pointing to on&#8211;premises servers<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample509' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_19'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_16'>Random</a></p><div class='collapse' id='collapseExample509'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Use Amazon CloudFront with a custom origin pointing to the on-premises servers</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 34%;" aria-valuenow="34" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#CloudFront'>CloudFront</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=CloudFront_19><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>CloudFront Question 19</p><br/>A company hosts a training site on a fleet of Amazon EC2 instances. The company anticipates that its new course, which consists of dozens of training videos on the site, will be extremely popular when it is released in 1 week.<br/><br/>What should a solutions architect do to minimize the anticipated server load?<br/><br/>A. Store the videos in Amazon ElastiCache for Redis. Update the web servers to serve the videos using the ElastiCache API.<br/>B. Store the videos in Amazon Elastic File System (Amazon EFS). Create a user data script for the web servers to mount the EFS volume.<br/>C. Store the videos in an Amazon S3 bucket. Create an Amazon CloudFront distribution with an origin access identity (OAI) of that S3 bucket. Restrict Amazon S3 access to the OAI.<br/>D. Store the videos in an Amazon S3 bucket. Create an AWS Storage Gateway file gateway to access the S3 bucket. Create a user data script for the web servers to mount the file gateway.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample237' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_20'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_42'>Random</a></p><div class='collapse' id='collapseExample237'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Store the videos in an Amazon S3 bucket. Create an Amazon CloudFront distribution with an origin access identity (OAI) of that S3 bucket. Restrict Amazon S3 access to the OAI.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 36%;" aria-valuenow="36" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#CloudFront'>CloudFront</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=CloudFront_20><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>CloudFront Question 20</p><br/>A company's website provides users with downloadable historical performance reports. The website needs a solution that will scale to meet the company's website demands globally. The solution should be cost effective, limit the? provisioning of Into and provide the fastest possible response time.<br/><br/>Which combination should a solutions architect recommend to meet these requirements?<br/><br/>A. Amazon CloudFront and Amazon S3<br/>B. AWS Lambda and Amazon Dynamo<br/>C. Application Load Balancer with Amazon EC2 Auto Scaling<br/>D. Amazon Route 53 with internal Application Load Balances<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample731' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_21'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_20'>Random</a></p><div class='collapse' id='collapseExample731'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Amazon CloudFront and Amazon S3</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 38%;" aria-valuenow="38" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#CloudFront'>CloudFront</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=CloudFront_21><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>CloudFront Question 21</p><br/>A company is designing a website that uses an Amazon S3 bucket to store static images. The company wants all future requests to have faster response times while reducing both latency and cost.<br/><br/>Which service configuration should a solutions architect recommend?<br/><br/>A. Deploy a NAT server in front of Amazon S3.<br/>B. Deploy Amazon CloudFront in front of Amazon S3.<br/>C. Deploy a Network Load Balancer in front of Amazon S3.<br/>D. Configure Auto Scaling to automatically adjust the capacity of the website.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample232' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_22'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_51'>Random</a></p><div class='collapse' id='collapseExample232'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Deploy Amazon CloudFront in front of Amazon S3.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 40%;" aria-valuenow="40" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#CloudFront'>CloudFront</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=CloudFront_22><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>CloudFront Question 22</p><br/>A company runs a multi&#8211;tier web application that hosts news content. The application runs on Amazon EC2 instances behind an Application Load Balancer. The instances run in an EC2 Auto Scaling group across multiple Availability Zones and use an Amazon Aurora database. A solutions architect needs to make the application more resilient to periodic increases in request rates.<br/><br/>Which architecture should the solutions architect implement? (Choose two.)<br/><br/>A. Add AWS Shield.<br/>B. Add Aurora Replica.<br/>C. Add AWS Direct Connect.<br/>D. Add AWS Global Accelerator.<br/>E. Add an Amazon CloudFront distribution in front of the Application Load Balancer.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample6' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation6' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_23'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_33'>Random</a></p><div class='collapse' id='collapseExample6'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Add Aurora Replica.
<br><b>E. </b>Add an Amazon CloudFront distribution in front of the Application Load Balancer.</div></div></div><div class='collapse' id='explanation6'><div class='card card&#45;body'><div>
AWS Global Accelerator: Acceleration for latency-sensitive applications. Many applications, especially in areas such as gaming, media, mobile apps, and financials, require very low latency for a great user experience. To improve the user experience, Global Accelerator directs user traffic to the application endpoint that is nearest to the client, which reduces internet latency and jitter.
Global Accelerator routes traffic to the closest edge location by using Anycast, and then routes it to the closest regional endpoint over the AWS global network. Global Accelerator quickly reacts to changes in network performance to improve your users' application performance.

Amazon CloudFront: Amazon CloudFront is a fast content delivery network (CDN) service that securely delivers data, videos, applications, and APIs to customers globally with low latency, high transfer speeds, all within a developer-friendly environment.

The architecture is already highly resilient but the may be subject to performance degradation if there are sudden increases in request rates. To resolve this situation Amazon Aurora Read Replicas can be used to serve read traffic which offloads requests from the main database. On the frontend an Amazon CloudFront distribution can be placed in front of the ALB and this will cache content for better performance and also offloads requests from the backend.

CORRECT: "Add Amazon Aurora Replicas" is the correct answer.

CORRECT: "Add an Amazon CloudFront distribution in front of the ALB" is the correct answer.

INCORRECT: "Add and Amazon WAF in front of the ALB" is incorrect. A web application firewall protects applications from malicious attacks. It does not improve performance.

INCORRECT: "Add an Amazon Transit Gateway to the Availability Zones" is incorrect as this is used to connect on-premises networks to VPCs.

INCORRECT: "Add an Amazon Global Accelerator endpoint" is incorrect as this service is used for directing users to different instances of the application in different regions based on latency.

References:

Amazon Aurora > User Guide for Aurora > Replication with Amazon Aurora
Amazon CloudFront > Developer Guide > What is Amazon CloudFront?</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 42%;" aria-valuenow="42" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#CloudFront'>CloudFront</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=CloudFront_23><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>CloudFront Question 23</p><br/>A company runs a static website through its on&#8211;premises data center. The company has multiple servers that handle all of its traffic, but on busy days, services are interrupted and the website becomes unavailable.<br/><br/>The company wants to expand its presence globally and plans to triple its website traffic.<br/><br/>What should a solutions architect recommend to meet these requirements?<br/><br/>A. Migrate the website content to Amazon S3 and host the website on Amazon CloudFront.<br/>B. Migrate the website content to Amazon EC2 instances with public Elastic IP addresses in multiple AWS Regions.<br/>C. Migrate the website content to Amazon EC2 instances and vertically scale as the load increases.<br/>D. Use Amazon Route 53 to distribute the loads across multiple Amazon CloudFront distributions for each AWS Region that exists globally.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample229' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_24'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_36'>Random</a></p><div class='collapse' id='collapseExample229'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Use Amazon Route 53 to distribute the loads across multiple Amazon CloudFront distributions for each AWS Region that exists globally.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 44%;" aria-valuenow="44" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#CloudFront'>CloudFront</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=CloudFront_24><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>CloudFront Question 24</p><br/>A solutions architect is creating a new Amazon CloudFront distribution for an application. Some of the information submitted by users is sensitive. The application uses HTTPS but needs another layer of security. The sensitive information should be protected throughout the entire application stack, and access to the information should be restricted to certain applications.<br/><br/>Which action should the solutions architect take?<br/><br/>A. Configure a CloudFront signed URL<br/>B. Configure a CloudFront signed cookie.<br/>C. Configure a CloudFront field&#8211;level encryption profile.<br/>D. Configure a CloudFront and set the Origin Protocol Policy setting to HTTPS. Only for the Viewer Protocol Pokey.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample324' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_25'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_3'>Random</a></p><div class='collapse' id='collapseExample324'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Configure a CloudFront signed URL</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 46%;" aria-valuenow="46" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#CloudFront'>CloudFront</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=CloudFront_25><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>CloudFront Question 25</p><br/>A company is hosting its static website in an Amazon S3 bucket, which is the origin for Amazon CloudFront. The company has users in the United States, Canada, and Europe and wants to reduce.<br/><br/>What should a solutions architect recommend?<br/><br/>A. Adjust the CloudFront caching time to live (TTL) from the default to a longer timeframe<br/>B. Implement CloudFront events with Lambda@edge to run the website's data processing<br/>C. Modify the CloudFront price class to include only the locations of the countries that are served<br/>D. Implement a CloudFront Secure Socket Layer (SSL) certificate to push security closer to the locations of the countries that are served<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample713' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_26'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_34'>Random</a></p><div class='collapse' id='collapseExample713'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Modify the CloudFront price class to include only the locations of the countries that are served</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 48%;" aria-valuenow="48" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#CloudFront'>CloudFront</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=CloudFront_26><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>CloudFront Question 26</p><br/>A company hosts its product information webpages on AWS. The existing solution uses multiple Amazon C2 instances behind an Application Load Balancer in an Auto Scaling group. The website also uses a custom DNS name and communicates with HTTPS only using a dedicated SSL certificate. The company is planning a new product launch and wants to be sure that users from around the world have the best possible experience on the new website.<br/><br/>What should a solutions architect do to meet these requirements?<br/><br/>A. Redesign the application to use Amazon CloudFront.<br/>B. Redesign the application to use AWS Elastic Beanstalk.<br/>C. Redesign the application to use a Network Load Balancer.<br/>D. Redesign the application to use Amazon S3 static website hosting.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample188' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation188' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_27'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_39'>Random</a></p><div class='collapse' id='collapseExample188'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Redesign the application to use Amazon CloudFront.</div></div></div><div class='collapse' id='explanation188'><div class='card card&#45;body'><div>
What Is Amazon CloudFront?
Amazon CloudFront is a web service that speeds up distribution of your static and dynamic web content, such as .html, .css, .js, and image files, to your users. CloudFront delivers your content through a worldwide network of data centers called edge locations. When a user requests content that you're serving with CloudFront, the user is routed to the edge location that provides the lowest latency (time delay), so that content is delivered with the best possible performance.

If the content is already in the edge location with the lowest latency, CloudFront delivers it immediately.

If the content is not in that edge location, CloudFront retrieves it from an origin that you've defined – such as an Amazon S3 bucket, a MediaPackage channel, or an HTTP server (for example, a web server) that you have identified as the source for the definitive version of your content.

As an example, suppose that you're serving an image from a traditional web server, not from CloudFront. For example, you might serve an image, sunsetphoto.png, using the URL http://example.com/sunsetphoto.png.

Your users can easily navigate to this URL and see the image. But they probably don't know that their request was routed from one network to another – through the complex collection of interconnected networks that comprise the internet – until the image was found.

CloudFront speeds up the distribution of your content by routing each user request through the AWS backbone network to the edge location that can best serve your content. Typically, this is a CloudFront edge server that provides the fastest delivery to the viewer. Using the AWS network dramatically reduces the number of networks that your users' requests must pass through, which improves performance. Users get lower latency – the time it takes to load the first byte of the file – and higher data transfer rates.

You also get increased reliability and availability because copies of your files (also known as objects) are now held (or cached) in multiple edge locations around the world.
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 50%;" aria-valuenow="50" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#CloudFront'>CloudFront</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=CloudFront_27><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>CloudFront Question 27</p><br/>A company is using Amazon Route 53 latency&#8211;based routing to route requests to its UDP&#8211;based application for users around the world. The application is hosted on redundant servers in the company's on&#8211;premises data centers in the United States, Asia, and Europe. The company's compliance requirements state that the application must be hosted on&#8211;premises. The company wants to improve the performance and availability of the application.<br/><br/>What should a solutions architect do to meet these requirements?<br/><br/>A. Configure three Network Load Balancers (NLBs) in the three AWS Regions to address the on&#8211;premises endpoints. Create an accelerator by using AWS Global Accelerator, and register the NLBs as its endpoints. Provide access to the application by using a CNAME that points to the accelerator DNS.<br/>B. Configure three Application Load Balancers (ALBs) in the three AWS Regions to address the on&#8211;premises endpoints. Create an accelerator by using AWS Global Accelerator, and register the ALBs as its endpoints. Provide access to the application by using a CNAME that points to the accelerator DNS.<br/>C. Configure three Network Load Balancers (NLBs) in the three AWS Regions to address the on&#8211;premises endpoints. In Route 53, create a latency&#8211;based record that points to the three NLBs, and use it as an origin for an Amazon CloudFront distribution. Provide access to the application by using a CNAME that points to the CloudFront DNS.<br/>D. Configure three Application Load Balancers (ALBs) in the three AWS Regions to address the on&#8211;premises endpoints. In Route 53, create a latency&#8211;based record that points to the three ALBs, and use it as an origin for an Amazon CloudFront distribution. Provide access to the application by using a CNAME that points to the CloudFront DNS.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample309' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_28'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_37'>Random</a></p><div class='collapse' id='collapseExample309'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Configure three Network Load Balancers (NLBs) in the three AWS Regions to address the on-premises endpoints. In Route 53, create a latency-based record that points to the three NLBs, and use it as an origin for an Amazon CloudFront distribution. Provide access to the application by using a CNAME that points to the CloudFront DNS.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 51%;" aria-valuenow="51" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#CloudFront'>CloudFront</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=CloudFront_28><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>CloudFront Question 28</p><br/>A Solutions Architect must design a web application that will be hosted on AWS, allowing users to purchase access to premium, shared content that is stored in an S3 bucket. Upon payment, content will be available for download for 14 days before the user is denied access.<br/><br/>Which of the following would be the LEAST complicated implementation?<br/><br/>A. Use an Amazon CloudFront distribution with an origin access identity (OAI). Configure the distribution with an Amazon S3 origin to provide access to the file through signed URLs. Design a Lambda function to remove data that is older than 14 days.<br/>B. Use an S3 bucket and provide direct access to the file. Design the application to track purchases in a DynamoDB table. Configure a Lambda function to remove data that is older than 14 days based on a query to Amazon DynamoDB.<br/>C. Use an Amazon CloudFront distribution with an OAI. Configure the distribution with an Amazon S3 origin to provide access to the file through signed URLs. Design the application to set an expiration of 14 days for the URL.<br/>D. Use an Amazon CloudFront distribution with an OAI. Configure the distribution with an Amazon S3 origin to provide access to the file through signed URLs. Design the application to set an expiration of 60 minutes for the URL and recreate the URL as necessary.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample160' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_29'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_30'>Random</a></p><div class='collapse' id='collapseExample160'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Use an Amazon CloudFront distribution with an OAI. Configure the distribution with an Amazon S3 origin to provide access to the file through signed URLs. Design the application to set an expiration of 14 days for the URL.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 53%;" aria-valuenow="53" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#CloudFront'>CloudFront</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=CloudFront_29><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>CloudFront Question 29</p><br/>A company is developing a serverless web application that gives users the ability to interact with real&#8211;time analytics from online games. The data from the games must be streamed in real time. The company needs a durable, low&#8211;latency database option for user data. The company does not know how many users will use the application Any design considerations must provide response times of single&#8211;digit milliseconds as the application scales.<br/><br/>Which combination of AWS services will meet these requirements? (Select TWO.)<br/><br/>A. Amazon CloudFront<br/>B. Amazon DynamoDB<br/>C. Amazon Kinesis<br/>D. Amazon RDS<br/>E. AWS Global Accelerator<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample471' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_30'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_1'>Random</a></p><div class='collapse' id='collapseExample471'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Amazon CloudFront
<br><b>B. </b>Amazon DynamoDB</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 55%;" aria-valuenow="55" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#CloudFront'>CloudFront</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=CloudFront_30><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>CloudFront Question 30</p><br/>Organizers for a global event want to put daily reports online as static HTML pages. The pages are expected to generate millions of views from users around the work. The files are stored in an Amazon S3 Bucket A solutions architect has been asked to design an efficient and effective solution<br/><br/>Which action should the solutions architect take to accomplish this?<br/><br/>A. Generate presigned URLs for the files<br/>B. Use cross&#8211;Region replication to all Regions<br/>C. Use the geoproximity feature of Amazon Route 53<br/>D. Use Amazon CloudFront with the S3 bucket as its origin<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample455' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_31'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_38'>Random</a></p><div class='collapse' id='collapseExample455'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Use Amazon CloudFront with the S3 bucket as its ongin</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 57%;" aria-valuenow="57" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#CloudFront'>CloudFront</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=CloudFront_31><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>CloudFront Question 31</p><br/>A company is using Amazon CloudFront with its website.<br/><br/>The company has enabled logging on the CloudFront distribution, and logs are saved in one of the company's Amazon S3 buckets.<br/><br/>The company needs to perform advanced analysis on the logs and build visualizations.<br/><br/>What should a solutions architect do to meet these requirements?<br/><br/>A. Use standard SQL queries in Amazon Athena to analyze CloudFront logs in the S3 bucket. Visualize the results with AWS Glue.<br/>B. Use standard SQL queries in Amazon Athena to analyze the CloudFront logs in the S3 bucket. Visual the results with Amazon QuickSight.<br/>C. Use standard queries in Amazon DynamoDB to analyze the Cloudfront logs in the S3 bucket. Visualize the results with the AWS Glue.<br/>D. Use standard SQL queries in Amazon DynamoDB to analyze the CloudFront logs in the S3 bucket. Visualize the results with Amazon QuickSight.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample608' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_32'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_26'>Random</a></p><div class='collapse' id='collapseExample608'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Use standard SQL queries in Amazon DynamoDB to analyze the CloudFront logs in the S3 bucket. Visualize the results with Amazon QuickSight.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 59%;" aria-valuenow="59" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#CloudFront'>CloudFront</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=CloudFront_32><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>CloudFront Question 32</p><br/>A company serves a multilingual website from a fleet of Amazon EC2 instances behind an Application Load Balancer (ALB). This architecture is currently running in the us&#8211;west&#8211;1 Region but is exhibiting high request latency for users located in other parts of the world.<br/><br/>The website needs to serve requests quickly and efficiently regardless of a user's location. However, the company does not want to recreate the existing architecture across multiple Regions.<br/><br/>How should a solutions architect accomplish this?<br/><br/>A. Replace the existing architecture with a website served from an Amazon S3 bucket. Configure an Amazon CloudFront distribution with the S3 bucket as the origin.<br/>B. Configure an Amazon CloudFront distribution with the ALB as the origin. Set the cache behavior settings to only cache based on the Accept&#8211;Language request header.<br/>C. Set up Amazon API Gateway with the ALB as an integration. Configure API Gateway to use an HTTP integration type. Set up an API Gateway stage to enable the API cache.<br/>D. Launch an EC2 instance in each additional Region and configure NGINX to act as a cache server for that Region. Put all the instances plus the ALB behind an Amazon Route 53 record set with a geolocation routing policy.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample256' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_33'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_45'>Random</a></p><div class='collapse' id='collapseExample256'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Configure an Amazon CloudFront distribution with the ALB as the origin. Set the cache behavior settings to only cache based on the Accept-Language request header.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 61%;" aria-valuenow="61" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#CloudFront'>CloudFront</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=CloudFront_33><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>CloudFront Question 33</p><br/>A company's website runs on Amazon EC2 instances behind an Application Load Balancer (ALB). The website has a mix of dynamic and static content. Users around the globe are reporting that the website is slow.<br/><br/>Which set of actions will improve website performance for users worldwide?<br/><br/>A. Create an Amazon CloudFront distribution and configure the ALB as an origin. Then update the Amazon Route 53 record to point to the CloudFront distribution.<br/>B. Create a latency&#8211;based Amazon Route 53 record for the ALB. Then launch new EC2 instances with larger instance sizes and register the instances with the ALB.<br/>C. Launch new EC2 instances hosting the same web application in different Regions closer to the users. Then register instances with the same ALB using cross&#8211;region VPC peering.<br/>D. Host the website in an Amazon S3 bucket in the Regions closest to the users and delete the ALB and EC2 instances. Then update an Amazon Route 53 record to point to the S3 buckets.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample261' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation261' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_34'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_35'>Random</a></p><div class='collapse' id='collapseExample261'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Create an Amazon CloudFront distribution and configure the ALB as an origin. Then update the Amazon Route 53 record to point to the CloudFront distribution.</div></div></div><div class='collapse' id='explanation261'><div class='card card&#45;body'><div>
What Is Amazon CloudFront?

Amazon CloudFront is a web service that speeds up distribution of your static and dynamic web content, such as .html, .css, .js, and image files, to your users. CloudFront delivers your content through a worldwide network of data centers called edge locations. When a user requests content that you're serving with CloudFront, the user is routed to the edge location that provides the lowest latency (time delay), so that content is delivered with the best possible performance.

Routing Traffic to an Amazon CloudFront web distribution by using your domain name.

If you want to speed up delivery of your web content, you can use Amazon CloudFront, the AWS content delivery network (CDN). CloudFront can deliver your entire website – including dynamic, static, streaming, and interactive content – by using a global network of edge locations. Requests for your content are automatically routed to the edge location that gives your users the lowest latency.

To use CloudFront to distribute your content, you create a web distribution and specify settings such as the Amazon S3 bucket or HTTP server that you want CloudFront to get your content from, whether you want only selected users to have access to your content, and whether you want to require users to use HTTPS.

When you create a web distribution, CloudFront assigns a domain name to the distribution, such asd111111abcdef8.cloudfront.net. You can use this domain name in the URLs for your content, for example:

http://d111111abcdef8.cloudfront.net/logo.jpg

Alternatively, you might prefer to use your own domain name in URLs, for example:

http://example.com/logo.jpg

If you want to use your own domain name, use Amazon Route 53 to create an alias record that points to your CloudFront distribution. An alias record is a Route 53 extension to DNS. It's similar to a CNAME record, but you can create an alias record both for the root domain, such as example.com, and for subdomains, such aswww.example.com. (You can create CNAME records only for subdomains.) When Route 53 receives a DNS query that matches the name and type of an alias record, Route 53 responds with the domain name that is associated with your distribution.

Amazon CloudFront is a content delivery network (CDN) that improves website performance by caching content at edge locations around the world. It can serve both dynamic and static content.

This is the best solution for improving the performance of the website.

CORRECT: "Create an Amazon CloudFront distribution and configure the ALB as an origin. Then update the Amazon Route 53 record to point to the CloudFront distribution" is the correct answer. INCORRECT: "Create a latency-based Amazon Route 53 record for the ALB. Then launch new EC2 instances with larger instance sizes and register the instances with the ALB" is incorrect.

Latency routing routes based on the latency between the client and AWS. There is no mention in the answer about creating the new instances in another region therefore the only advantage is in using larger instance sizes. For a dynamic site this adds complexity in keeping the instances in sync.

INCORRECT: "Launch new EC2 instances hosting the same web application in different Regions closer to the users. Use an AWS Transit Gateway to connect customers to the closest region" is incorrect as Transit Gateway is a service for connecting on-premises networks and VPCs to a single gateway.

INCORRECT: "Migrate the website to an Amazon S3 bucket in the Regions closest to the users. Then create an Amazon Route 53 geolocation record to point to the S3 buckets" is incorrect as with S3 you can only host static websites, not dynamic websites.

References:

Amazon CloudFront Dynamic Content Delivery

</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 63%;" aria-valuenow="63" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#CloudFront'>CloudFront</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=CloudFront_34><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>CloudFront Question 34</p><br/>A company hosts more than 300 global websites and applications. The company requires a platform to analyze more than 30 TB of clickstream data each day. What should a solutions architect do to transmit and process the clickstream data?<br/><br/>A. Design an AWS Data Pipeline to archive the data to an Amazon S3 bucket and run an Amazon EMR cluster with the data to generate analytics.<br/>B. Create an Auto Scaling group of Amazon EC2 instances to process the data and send it to an Amazon S3 data lake for Amazon Redshift to use for analysis.<br/>C. Cache the data to Amazon CloudFront. Store the data in an Amazon S3 bucket. When an object is added to the S3 bucket, run an AWS Lambda function to process the data for analysis.<br/>D. Collect the data from Amazon Kinesis Data Streams. Use Amazon Kinesis Data firehose to transmit the data to an Amazon S3 data lake. Load the data in Amazon Redshift for analysis.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample299' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_35'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_6'>Random</a></p><div class='collapse' id='collapseExample299'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Cache the data to Amazon CloudFront. Store the data in an Amazon S3 bucket. When an object is added to the S3 bucket, run an AWS Lambda function to process the data for analysis.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 65%;" aria-valuenow="65" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#CloudFront'>CloudFront</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=CloudFront_35><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>CloudFront Question 35</p><br/>An edge location refers to which Amazon Web Service?<br/><br/>A. An edge location is referred to the network configured within a Zone or Region<br/>B. An edge location is an AWS Region<br/>C. An edge location is the location of the data center used for Amazon CloudFront.<br/>D. An edge location is a Zone within an AWS Region<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample769' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation769' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_36'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_7'>Random</a></p><div class='collapse' id='collapseExample769'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>An edge location is the location of the data center used for Amazon CloudFront.</div></div></div><div class='collapse' id='explanation769'><div class='card card&#45;body'><div>
Amazon CloudFront is a content distribution network. A content delivery network or content distribution network (CDN) is a large distributed system of servers deployed in multiple data centers across the world. The location of the data center used for CDN is called edge location. Amazon CloudFront can cache static content at each edge location. This means that your popular static content (e.g., your site's logo, navigational images, cascading style sheets, JavaScript code, etc.) will be available at a nearby edge location for the browsers to download with low latency and improved performance for viewers. Caching popular static content with Amazon CloudFront also helps you offload requests for such files from your origin server – CloudFront serves the cached copy when available and only makes a request to your origin server if the edge location receiving the browser's request does not have a copy of the file.

References:

Amazon CloudFront</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 67%;" aria-valuenow="67" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#CloudFront'>CloudFront</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=CloudFront_36><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>CloudFront Question 36</p><br/>A company recently launched its website to serve content to its global user base. The company wants to store and accelerate the delivery of static content to its users by leveraging Amazon CloudFront with an Amazon EC2 instance attached as its origin.<br/><br/>How should a solutions architect optimize high availability for the application?<br/><br/>A. Use Lambda@Edge for CloudFront.<br/>B. Use Amazon S3 Transfer Acceleration for CloudFront.<br/>C. Configure another EC2 instance in a different Availability Zone as part of the origin group.<br/>D. Configure another EC2 instance as part of the origin server cluster in the same Availability Zone.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample163' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_37'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_40'>Random</a></p><div class='collapse' id='collapseExample163'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Use Lambda@Edge for CloudFront.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 69%;" aria-valuenow="69" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#CloudFront'>CloudFront</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=CloudFront_37><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>CloudFront Question 37</p><br/>A solutions architect must design a solution that uses Amazon CloudFront with an Amazon S3 origin to store a static website. The company's security policy requires that all website traffic be inspected by AWS WAF.<br/><br/>How should the solutions architect comply with these requirements?<br/><br/>A. Configure an S3 bucket policy to accept requests coming from the AWS WAF Amazon Resource Name (ARN) only.<br/>B. Configure Amazon CloudFront to forward all incoming requests to AWS WAF before requesting content from the S3 origin.<br/>C. Configure a security group that allows Amazon CloudFront IP addresses to access Amazon S3 only. Associate AWS WAF to CloudFront.<br/>D. Configure Amazon CloudFront and Amazon S3 to use an origin access identity (OAI) to restrict access to the S3 bucket. Enable AWS WAF on the distribution.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample271' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_38'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_29'>Random</a></p><div class='collapse' id='collapseExample271'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Configure Amazon CloudFront and Amazon S3 to use an origin access identity (OAI) to restrict access to the S3 bucket. Enable AWS WAF on the distribution.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 71%;" aria-valuenow="71" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#CloudFront'>CloudFront</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=CloudFront_38><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>CloudFront Question 38</p><br/>A media company stores video content in an Amazon Elastic Block Store (Amazon EBS) volume. A certain video files has become popular and a large number of user across the world are accessing this content.<br/><br/>This has resulted in a cost increase.<br/><br/>Which action will DECREASE cost without compromising user accessibility?<br/><br/>A. Change the EBS volume to provisioned IOPS (PIOPS)<br/>B. Store the video in an Amazon S3 bucket and create an Amazon CloudFront distribution<br/>C. Split the video into multiple, smaller segments so users are routed to the requested video segments only<br/>D. Create an Amazon S3 bucket in each Region and upload the videos so users are routed to the nearest S3 bucket<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample712' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_39'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_13'>Random</a></p><div class='collapse' id='collapseExample712'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Store the video in an Amazon S3 bucket and create and Amazon CloudFront distribution</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 73%;" aria-valuenow="73" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#CloudFront'>CloudFront</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=CloudFront_39><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>CloudFront Question 39</p><br/>53 latency&#8211;based routing to route requests to its UDP&#8211;based application tor users around the world the application is hosted on redundant servers in the company's on&#8211;premises data centers in the United States Asia, and Europe The company's compliance requirements state that the application must be hosted on&#8211;premises. The company wants to improve the performance and availability of the application.<br/><br/>What should a solutions architect do to meet these requirements?<br/><br/>A. Configure throe Network Load Balancers (NLBs) in the three AWS Regions to address the on&#8211;premises endpoints. Create an accelerator by using AWS Global Accelerator, and register the NLBs as its endpoints. Provide access to the application by using a CNAML that points to the accelerator DNS.<br/>B. Configure three Application Load Balancers (ALGs) in the three AWS Regions to wireless the on&#8211;premises endpoints. Create an accelerator by using AWS Global Accelerator, and register the ALBs as its endpoints. Provide access to the application by using a CNAK1L that points to the accelerator UNS<br/>C. Configure three Network Load Balancers (NLOs) in the three AWS Regions to address the on&#8211;premises endpoints in Route 53. Create latency&#8211;based record that points to the three NLBs. and use it as an origin for an Amazon CloudFront distribution. Provide access to the application by using a CNAML that points to the CloudFront DNS.<br/>D. Configure three Application Load Balancers (ALBs) in the three AWS Regions to address the on&#8211;premises endpoint. in Route 53.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample535' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_40'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_47'>Random</a></p><div class='collapse' id='collapseExample535'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Configure three Network Load Balancers (NLOs) in the three AWS Regions to address the on-premises endpoints in Route 53. Create latency-based record that points to the three NLBs. and use it as an origin for an Amazon CloudFront distribution. Provide access to the application by using a CNAML that points to the CloudFront DNS.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 75%;" aria-valuenow="75" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#CloudFront'>CloudFront</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=CloudFront_40><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>CloudFront Question 40</p><br/>A company hosts its website on Amazon S3. The website serves petabytes of outbound traffic monthly, which accounts for most of the company's AWS costs. What should a solutions architect do to reduce costs?<br/><br/>A. Configure Amazon CloudFront with the existing website as the origin.<br/>B. Move the website to Amazon EC2 with Amazon EBS volumes for storage.<br/>C. Use AWS Global Accelerator and specify the existing website as the endpoint.<br/>D. Rearchitect the website to run on a combination of Amazon API Gateway and AWS Lambda.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample201' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation201' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_41'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_22'>Random</a></p><div class='collapse' id='collapseExample201'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Configure Amazon CloudFront with the existing website as the origin.</div></div></div><div class='collapse' id='explanation201'><div class='card card&#45;body'><div>
A textbook case for CloudFront. The data transfer cost in CloudFront is lower than in S3. With heavy read operations of static content, it's more economical to add CloudFront in front of your S3 bucket.
https://pupuweb.com/aws-saa-c02-actual-exam-question-answer-dumps-2/10/3
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 76%;" aria-valuenow="76" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#CloudFront'>CloudFront</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=CloudFront_41><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>CloudFront Question 41</p><br/>A media company stores video content in an Amazon Elastic Block Store (Amazon EBS) volume. A certain video file has become popular and a large number of users across the world are accessing this content.<br/><br/>This has resulted in a cost increase.<br/><br/>Which action will DECREASE cost without compromising user accessibility?<br/><br/>A. Change the EBS volume to Provisioned IOPS (PIOPS).<br/>B. Store the video in an Amazon S3 bucket and create an Amazon CloudFront distribution.<br/>C. Split the video into multiple, smaller segments so users are routed to the requested video segments only.<br/>D. Clear an Amazon S3 bucket in each Region and upload the videos so users are routed to the nearest S3 bucket.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample375' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_42'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_10'>Random</a></p><div class='collapse' id='collapseExample375'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Store the video in an Amazon S3 bucket and create an Amazon CloudFront distribution.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 78%;" aria-valuenow="78" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#CloudFront'>CloudFront</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=CloudFront_42><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>CloudFront Question 42</p><br/>A company is running its application in a single region on Amazon EC2 with Amazon Elastic Block Store (Amazon EBS) and S3 as part of the storage design.<br/><br/>What should be done to reduce data transfer costs?<br/><br/>A. Create a copy of the compute environment in another AWS Region<br/>B. Convert the application to run on Lambda@Edge<br/>C. Create an Amazon CloudFront distribution with Amazon S3 as the origin<br/>D. Replicate Amazon S3 data to buckets in AWS Regions closer to the requester<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample659' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_43'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_25'>Random</a></p><div class='collapse' id='collapseExample659'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Create an Amazon CloudFront distribution with Amazon S3 as the origin</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 80%;" aria-valuenow="80" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#CloudFront'>CloudFront</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=CloudFront_43><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>CloudFront Question 43</p><br/>A solutions architect is creating a new Amazon CloudFront distribution for an application Some of the information submitted by users is sensitive. The application uses HTTPS but needs another layer of security. The sensitive information should be protected throughout the entire application stack, and access to the information should be restricted to certain applications.<br/><br/>Which action should the solutions architect take?<br/><br/>A. Configure a CloudFront signed URL<br/>B. Configure a CloudFront signed cookie.<br/>C. Configure a CloudFront field&#8211;level encryption profile.<br/>D. Configure CloudFront and set the Origin Protocol Policy setting to HTTPS Only for the Viewer Protocol Pokey<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample484' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_44'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_48'>Random</a></p><div class='collapse' id='collapseExample484'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Configure a CloudFront signed URL</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 82%;" aria-valuenow="82" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#CloudFront'>CloudFront</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=CloudFront_44><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>CloudFront Question 44</p><br/>A company is running a two&#8211;tier eCommerce website using services. The current architect uses a public facing Elastic Load Balancer that sends traffic to Amazon EC2 instances in a private subnet. The static content is hosted on EC2 instances, and the dynamic content is retrieved from a MYSQL database. The application is running in the United States. The company recently started selling to users in Europe and Australia. A solutions architect needs to design solution so their international users have an improved browsing experience.<br/><br/>Which solution is MOST cost&#8211;effective?<br/><br/>A. Host the entire website on Amazon S3.<br/>B. Use Amazon CloudFront and Amazon S3 to host static images.<br/>C. Increase the number of public load balancers and EC2 instances.<br/>D. Deploy the two&#8211;tier website in AWS Regions in Europe and Australia.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample87' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_45'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_9'>Random</a></p><div class='collapse' id='collapseExample87'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Use Amazon CloudFront and Amazon S3 to host static images.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 84%;" aria-valuenow="84" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#CloudFront'>CloudFront</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=CloudFront_45><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>CloudFront Question 45</p><br/>A company is hosting an election reporting website on AWS for users around the world. The website uses Amazon EC2 instances for the web and application tiers in an Auto Scaling group with Application Load Balancers. The database tier uses an Amazon RDS for MySQL database. The website is updated with election results once an hour and has historically observed hundreds of users accessing the reports.<br/><br/>The company is expecting a significant increase in demand because of upcoming elections in different countries. A solutions architect must improve the website's ability to handle additional demand while minimizing the need for additional EC2 instances.<br/><br/>Which solution will meet these requirements?<br/><br/>A. Launch an Amazon ElastiCache cluster to cache common database queries.<br/>B. Launch an Amazon CloudFront web distribution to cache commonly requested website content.<br/>C. Enable disk&#8211;based caching on the EC2 instances to cache commonly requested website content.<br/>D. Deploy a reverse proxy into the design using an EC2 instance with caching enabled for commonly requested website content.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample129' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_46'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_32'>Random</a></p><div class='collapse' id='collapseExample129'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Launch an Amazon CloudFront web distribution to cache commonly requested website content.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 86%;" aria-valuenow="86" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#CloudFront'>CloudFront</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=CloudFront_46><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>CloudFront Question 46</p><br/>A company wants to improve the availability and performance of its stateless UDP&#8211;based workload. The workload is deployed on Amazon EC2 instances in multiple AWS Regions.<br/><br/>What should a solutions architect recommend to accomplish this?<br/><br/>A. Place the EC2 instances behind Network Load Balancers (NLBs) in each Region. Create an accelerator using AWS Global Accelerator. Use the NLBs as endpoints for the accelerator.<br/>B. Place the EC2 instances behind Application Load Balancers (ALBs) in each Region. Create an accelerator using AWS Global Accelerator. Use the ALBs as endpoints for the accelerator.<br/>C. Place the EC2 instances behind Network Load Balancers (NLBs) in each Region. Create an Amazon CloudFront distribution with an origin that uses Amazon Route 53 latency&#8211;based routing to route requests to the NLBs.<br/>D. Place the EC2 instances behind Application Load Balancers (ALBs) in each Region. Create an Amazon CloudFront distribution with an origin that uses Amazon Route 53 latency&#8211;based routing to route requests to the ALBs.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample387' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_47'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_21'>Random</a></p><div class='collapse' id='collapseExample387'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Place the EC2 instances behind Application Load Balancers (ALBs) in each Region. Create an Amazon CloudFront distribution with an origin that uses Amazon Route 53 latency-based routing to route requests to the ALBs.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 88%;" aria-valuenow="88" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#CloudFront'>CloudFront</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=CloudFront_47><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>CloudFront Question 47</p><br/>A company's website provides users with downloadable historical performance reports. The website needs a solution that will scale to meet the company's website demands globally. The solution should be cost effective, limit the provisioning of infrastructure resources, and provide the fastest possible response time.<br/><br/>Which combination should a solutions architect recommend to meet these requirements?<br/><br/>A. Amazon CloudFront and Amazon S3<br/>B. AWS Lambda and Amazon DynamoDB<br/>C. Application Load Balancer with Amazon EC2 Auto Scaling<br/>D. Amazon Route 53 with internal Application Load Balancers<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample88' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_48'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_8'>Random</a></p><div class='collapse' id='collapseExample88'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Amazon CloudFront and Amazon S3</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 90%;" aria-valuenow="90" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#CloudFront'>CloudFront</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=CloudFront_48><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>CloudFront Question 48</p><br/>In Amazon AWS, which of the following statements is true of key pairs?<br/><br/>A. Key pairs are used only for Amazon SDKs.<br/>B. Key pairs are used only for Amazon EC2 and Amazon CloudFront.<br/>C. Key pairs are used only for Elastic Load Balancing and AWS IAM.<br/>D. Key pairs are used for all Amazon services.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample762' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation762' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_49'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_44'>Random</a></p><div class='collapse' id='collapseExample762'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Key pairs are used only for Amazon EC2 and Amazon CloudFront.</div></div></div><div class='collapse' id='explanation762'><div class='card card&#45;body'><div>
Key pairs consist of a public and private key, where you use the private key to create a digital signature, and then AWS uses the corresponding public key to validate the signature. Key pairs are used only for Amazon EC2 and Amazon CloudFront.

References:

AWS General Reference > Reference guide > Understanding and getting your AWS credentials</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 92%;" aria-valuenow="92" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#CloudFront'>CloudFront</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=CloudFront_49><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>CloudFront Question 49</p><br/>A company hosts its static website content from an Amazon S3 bucket in the us&#8211;east&#8211;1 Region. Content is made available through an Amazon CloudFront origin pointing to that bucket. Cross&#8211;Region replication is set to create a second copy of the bucket in the ap&#8211;southeast&#8211;1 Region. Management wants a solution that provides greater availability for the website.<br/><br/>Which combination of actions should a solutions architect take to increase availability? (Choose two.)<br/><br/>A. Add both buckets to the CloudFront origin.<br/>B. Configure failover routing in Amazon Route 53.<br/>C. Create a record in Amazon Route 53 pointing to the replica bucket.<br/>D. Create an additional CloudFront origin pointing to the ap&#8211;southeast&#8211;1 bucket.<br/>E. Set up a CloudFront origin group with the us&#8211;east&#8211;1 bucket as the primary and the ap&#8211;southeast&#8211;1 bucket as the secondary.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample236' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_50'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_0'>Random</a></p><div class='collapse' id='collapseExample236'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Configure failover routing in Amazon Route 53.
<br><b>E. </b>Set up a CloudFront origin group with the us-east-1 bucket as the primary and the ap-southeast-1 bucket as the secondary.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 94%;" aria-valuenow="94" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#CloudFront'>CloudFront</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=CloudFront_50><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>CloudFront Question 50</p><br/>A company wants to run a static website served through Amazon CloudFront.<br/><br/>What is an advantage of storing the website content in an Amazon S3 bucket instead of an Amazon Elastic Block Store (Amazon EBS) volume?<br/><br/>A. S3 buckets are replicated globally, allowing for large scalability. EBS volumes are replicated only within an AWS Region.<br/>B. S3 is an origin for CloudFront. EBS volumes would need EC2 instances behind an Elastic Load Balancing load balancer to be an origin<br/>C. S3 buckets can be encrypted, allowing for secure storage of the web files. EBS volumes cannot be encrypted.<br/>D. S3 buckets support object&#8211;level read throttling, preventing abuse. EBS volumes do not provide object&#8211;level throttling.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample538' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_51'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_15'>Random</a></p><div class='collapse' id='collapseExample538'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>S3 is an origin for CloudFront. EBS volumes would need EC2 instances behind an Elastic Load Balancing load balancer to be an origin</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 96%;" aria-valuenow="96" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#CloudFront'>CloudFront</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=CloudFront_51><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>CloudFront Question 51</p><br/>A solution architect is creating a new Amazon CloudFront distribution for an application Some of Ine information submitted by users is sensitive. The application uses HTTPS but needs another layer" of security. The sensitive information should be protected throughout the entire application stack end access to the information should be restricted to certain applications<br/><br/>Which action should the solutions architect take?<br/><br/>A. Configure a CloudFront signed URL<br/>B. Configure a CloudFront signed cookie.<br/>C. Configure a CloudFront field&#8211;level encryption profile<br/>D. Configure CloudFront and set the Origin Protocol Policy setting to HTTPS Only for the Viewer Protocol Policy<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample476' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_52'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_27'>Random</a></p><div class='collapse' id='collapseExample476'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Configure a CloudFront field-level encryption profile</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 98%;" aria-valuenow="98" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#CloudFront'>CloudFront</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=CloudFront_52><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>CloudFront Question 52</p><br/>A solutions architect needs to design a low&#8211;latency solution for a static single&#8211;page application accessed by users utilizing a custom domain name. The solution must be serverless, encrypted in transit, and cost&#8211;effective.<br/><br/>Which combination of AWS services and features should the solutions architect use? (Choose two.)<br/><br/>A. Amazon S3<br/>B. Amazon EC2<br/>C. AWS Fargate<br/>D. Amazon CloudFront<br/>E. Elastic Load Balancer<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample168' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_53'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#CloudFront_18'>Random</a></p><div class='collapse' id='collapseExample168'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Amazon S3
<br><b>D. </b>Amazon CloudFront</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 100%;" aria-valuenow="100" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#CloudFront'>CloudFront</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><a id=VPC><h2>VPC</h2></a> - 43 Questions <br><a href='#VPC'>VPC(43)</a> <a href='#' <i class='bi bi&#45;house'> &nbsp;Home</i><hr> </a><div class='row' id=VPC_1><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>VPC Question 1</p><br/>A company wants to use an AWS Region as a disaster recovery location for its on&#8211;premises infrastructure. The company has 10 TB of existing data, and the on&#8211;premise data center has a 1 Gbps internet connection. A solutions architect must find a solution so the company can have its existing data on AWS in 72 hours without transmitting it using an unencrypted channel.<br/><br/>Which solution should the solutions architect select?<br/><br/>A. Send the initial 10 TB of data to AWS using FTP.<br/>B. Send the initial 10 TB of data to AWS using AWS Snowball.<br/>C. Establish a VPN connection between Amazon VPC and the company's data center.<br/>D. Establish an AWS Direct Connect connection between Amazon VPC and the company's data center.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample733' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation733' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#VPC_2'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#VPC_5'>Random</a></p><div class='collapse' id='collapseExample733'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Establish a VPN connection between Amazon VPC and the company's data center.</div></div></div><div class='collapse' id='explanation733'><div class='card card&#45;body'><div>
Keyword: AWS Region as DR for On-premises DC (Existing Data=10TB) + 1G Internet Connection

Condition: 10TB on AWS in 72 Hours + Without Unencrypted Channel Without Unencrypted Channel = VPN

FTP = Unencrypted Channel

Options – A – Out of race, since this is unencrypted channel & not matching the condition Options – B – Out of race due to the timebound target & order /delivering AWS Snowball device will take time

Options – C – Win the race, using the existing 1G Internet Link we can transfer this 10TB data within 24Hrs using encrypted Channel

Options – D – Out of race due to the timebound target & order /delivering AWS Direct Connect will take time

References:

AWS Snowball > User Guide > Shipping an AWS Snowball device
AWS Direct Connect
Amazon VPC</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 2%;" aria-valuenow="2" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#VPC'>VPC</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=VPC_2><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>VPC Question 2</p><br/>An application is running on Amazon EC2 instances. Sensitive information required for the application is stored in an Amazon S3 bucket. The bucket needs to be protected from internet access while only allowing services within the VPC access to the bucket.<br/><br/>Which combination of actions should solutions archived take to accomplish this? (Choose two.)<br/><br/>A. Create a VPC endpoint for Amazon S3.<br/>B. Enable server access logging on the bucket.<br/>C. Apply a bucket policy to restrict access to the S3 endpoint.<br/>D. Add an S3 ACL to the bucket that has sensitive information.<br/>E. Restrict users using the IAM policy to use the specific bucket.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample76' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation76' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#VPC_3'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#VPC_31'>Random</a></p><div class='collapse' id='collapseExample76'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Create a VPC endpoint for Amazon S3.
<br><b>C. </b>Apply a bucket policy to restrict access to the S3 endpoint.</div></div></div><div class='collapse' id='explanation76'><div class='card card&#45;body'><div>
ACL is a property at object level not at bucket level. Also by just adding ACL you cant let the services in VPC allow access to the bucket.
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 4%;" aria-valuenow="4" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#VPC'>VPC</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=VPC_3><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>VPC Question 3</p><br/>A business application is hosted on Amazon EC2 and uses Amazon S3 for encrypted object storage. The chief information security officer has directed that no application traffic between the two services should traverse the public internet.<br/><br/>Which capability should the solutions architect use to meet the compliance requirements?<br/><br/>A. AWS Key Management Service (AWS KMS)<br/>B. VPC endpoint<br/>C. Private subnet<br/>D. Virtual private gateway<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample247' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#VPC_4'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#VPC_0'>Random</a></p><div class='collapse' id='collapseExample247'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>AWS Key Management Service (AWS KMS)

References:

Amazon VPC FAQs</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 6%;" aria-valuenow="6" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#VPC'>VPC</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=VPC_4><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>VPC Question 4</p><br/>A company has three VPCs named Development, Testing, and Production in the us&#8211;east&#8211;1 Region. The three VPCs need to be connected to an on&#8211;premises data center and are designed to be separate to maintain security and prevent any resource sharing. A solutions architect needs to find a scalable and secure solution.<br/><br/>What should the solutions architect recommend?<br/><br/>A. Create an AWS Direct Connect connection and a VPN connection for each VPC to connect back to the data center.<br/>B. Create VPC peers from all the VPCs to the Production VPC. Use an AWS Direct Connect connection from the Production VPC back to the data center.<br/>C. Connect VPN connections from all the VPCs to a VPN in the Production VPC. Use a VPN connection from the Production VPC back to the data center.<br/>D. Create a new VPC called Network. Within the Network VPC, create an AWS Transit Gateway with an AWS Direct Connect connection back to the data center. Attach all the other VPCs to the Network VPC.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample218' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#VPC_5'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#VPC_38'>Random</a></p><div class='collapse' id='collapseExample218'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Create VPC peers from all the VPCs to the Production VP<br><b>C. </b>Use an AWS Direct Connect connection from the Production VPC back to the data center.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 9%;" aria-valuenow="9" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#VPC'>VPC</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=VPC_5><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>VPC Question 5</p><br/>A company wants to use an AWS Region as a disaster recovery location for its on&#8211;premises infrastructure.<br/><br/>The company has 10 TB of existing data, and the on&#8211;premise data center has a 1 Gbps internet connection.<br/><br/>A solutions architect must find a solution so the company can have its existing data on AWS in 72 hours without transmitting it using an unencrypted channel.<br/><br/>Which solution should the solutions architect select?<br/><br/>A. Send the initial 10 TB of data to AWS using FTP.<br/>B. Send the initial 10 TB of data to AWS using AWS Snowball.<br/>C. Establish a VPN connection between Amazon VPC and the company's data center.<br/>D. Establish an AWS Direct Connect connection between Amazon VPC and the company's data center.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample208' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#VPC_6'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#VPC_23'>Random</a></p><div class='collapse' id='collapseExample208'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Establish a VPN connection between Amazon VPC and the company's data center.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 11%;" aria-valuenow="11" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#VPC'>VPC</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=VPC_6><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>VPC Question 6</p><br/>An application runs on Amazon EC2 instances in private subnets. The application needs to access an Amazon DynamoDB table. What is the MOST secure way to access the table while ensuring that the traffic does not leave the AWS network?<br/><br/>A. Use a VPC endpoint for DynamoDB.<br/>B. Use a NAT gateway in a public subnet.<br/>C. Use a NAT instance in a private subnet.<br/>D. Use the internet gateway attached to the VPC.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample48' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation48' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#VPC_7'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#VPC_15'>Random</a></p><div class='collapse' id='collapseExample48'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Use a VPC endpoint for DynamoDB.</div></div></div><div class='collapse' id='explanation48'><div class='card card&#45;body'><div>
An Interface endpoint uses AWS PrivateLink and is an elastic network interface (ENI) with a private IP address that serves as an entry point for traffic destined to a supported service.

Using PrivateLink you can connect your VPC to supported AWS services, services hosted by other AWS accounts (VPC endpoint services), and supported AWS Marketplace partner services.

AWS PrivateLink access over Inter-Region VPC Peering:

Applications in an AWS VPC can securely access AWS PrivateLink endpoints across AWS Regions using Inter-Region VPC Peering.

AWS PrivateLink allows you to privately access services hosted on AWS in a highly available and scalable manner, without using public IPs, and without requiring the traffic to traverse the Internet.

Customers can privately connect to a service even if the service endpoint resides in a different AWS Region.

Traffic using Inter-Region VPC Peering stays on the global AWS backbone and never traverses the public Internet.

A gateway endpoint is a gateway that is a target for a specified route in your route table, used for traffic destined to a supported AWS service.

An interface VPC endpoint (interface endpoint) enables you to connect to services powered by AWS PrivateLink.

References:
Amazon DynamoDB > Developer Guide > What Is Amazon DynamoDB?
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 13%;" aria-valuenow="13" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#VPC'>VPC</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=VPC_7><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>VPC Question 7</p><br/>A company wants to improve the availability of an existing firewall.<br/><br/>To meet the compliance requirements of the applications hosted in the VPC.<br/><br/>The company's security team is using a proprietary firewall running on Amazon EC2 instances. All internet traffic flows through the primary firewall.<br/><br/>When the primary firewall goes down, the team manually changes the VPC route table so that it uses a secondary firewall running in a different Availability Zone.<br/><br/>Which strategies should a solutions architect use to improve the availability of the firewall? (Select TWO.)<br/><br/>A. Create an EC2 gateway endpoint In the VPC where the firewall is hosted.<br/>B. Create an EC2 interface endpoint in the VPC where the firewall is hosted.<br/>C. Enable enhanced networking on the EC2 instance running the proprietary firewall<br/>D. Deploy a scheduled AWS Lambda function in the VPC to monitor the primary firewall and change the route table to use the secondary firewall in case of failure.<br/>E. Monitor the firewall instance health in Amazon EventBridge (Amazon CloudWatch Events). Trigger an event rule to restart the primary firewall upon a detected failure.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample570' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#VPC_8'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#VPC_36'>Random</a></p><div class='collapse' id='collapseExample570'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Deploy a scheduled AWS Lambda function in the VPC to monitor the primary firewall and change the route table to use the secondary firewall in case of failure.
<br><b>E. </b>Monitor the firewall instance health in Amazon EventBridge (Amazon CloudWatch Events). Trigger an event rule to restart the primary firewall upon a detected failure.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 16%;" aria-valuenow="16" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#VPC'>VPC</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=VPC_8><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>VPC Question 8</p><br/>A solutions architect is designing a VPC with public and private subnets. The VPC and subnets use IPv4 CIDR blocks. There is one public subnet and one private subnet in each of three Availability Zones (AZs) for high availability. An internet gateway is used to provide internet access for the public subnets. The private subnets require access to the internet to allow Amazon EC2 instances to download software updates.<br/><br/>What should the solutions architect do to enable internet access for the private subnets?<br/><br/>A. Create three NAT gateways, one for each public subnet in each AZ. Create a private route table for each AZ that forwards non&#8211;VPC traffic to the NAT gateway in its AZ.<br/>B. Create three NAT instances, one for each private subnet in each AZ. Create a private route table for each AZ that forwards non&#8211;VPC traffic to the NAT instance in its AZ.<br/>C. Create a second internet gateway on one of the private subnets. Update the route table for the private subnets that forward non&#8211;VPC traffic to the private internet gateway.<br/>D. Create an egress&#8211;only internet gateway on one of the public subnets. Update the route table for the private subnets that forward non&#8211;VPC traffic to the egress&#8211;only internet gateway.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample216' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#VPC_9'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#VPC_6'>Random</a></p><div class='collapse' id='collapseExample216'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Create three NAT instances, one for each private subnet in each AZ. Create a private route table for each AZ that forwards non-VPC traffic to the NAT instance in its AZ.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 18%;" aria-valuenow="18" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#VPC'>VPC</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=VPC_9><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>VPC Question 9</p><br/>A company fails an AWS security reviews conducted by the third party.<br/><br/>The review finds out that some of the company method to access the Amazon EMR through the public internet.<br/><br/>Which combination of steps should the company take to MOST improve its security? (Select TWO.)<br/><br/>A. Set up a VPC peering connect to the Amazon EMR API.<br/>B. Set up VPC endpoints to connect to the Amazon EMR API.<br/>C. Set up a NAT gateway to connect to the Amazon EMR API.<br/>D. Set up 1AM roles to be used to connect to the Amazon FMR API.<br/>E. Set up each developer with AWS Secrets Manager to store access keys.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample604' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#VPC_10'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#VPC_37'>Random</a></p><div class='collapse' id='collapseExample604'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Set up a VPC peering connect to the Amazon EMR API.
<br><b>D. </b>Set up 1AM roles to be used to connect to the Amazon FMR API.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 20%;" aria-valuenow="20" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#VPC'>VPC</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=VPC_10><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>VPC Question 10</p><br/>A company needs to provide its employees with secure access to confidential and sensitive files. The company wants to ensure that the tiles can be accessed only by authorized users. The files must be downloaded securely to the employees' devices.<br/><br/>The tiles are stored in an on&#8211;premises Windows file server. However, due to an increase in remote usage, the file server is running out of capacity.<br/><br/>Which solution will meet these requirements?<br/><br/>A. Migrate the file server to an Amazon EC2 instance in a public subnet. Configure the security group to limit inbound traffic to the employees' IP addresses.<br/>B. Migrate the files to an Amazon FSx for Windows File Server file system. Integrate the Amazon FSx file system with the on&#8211;premises Active Directory. Configure AWS Client VP<br/>C. Migrate the tiles to Amazon S3, and create a private VPC endpoint. Create a signed URL to allow download.<br/>D. Migrate the tiles to Amazon S3, and create a public VPC endpoint. Allow employees to sign on with AWS Single Sign&#8211;On.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample449' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#VPC_11'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#VPC_8'>Random</a></p><div class='collapse' id='collapseExample449'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Migrate the tiles to Amazon S3, and create a public VPC endpoint. Allow employees to sign on with AWS Single Sign-On.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 23%;" aria-valuenow="23" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#VPC'>VPC</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=VPC_11><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>VPC Question 11</p><br/>A company has an application hosted on Amazon EC2 instances in two VPCs across different AWS Regions. To communicate with each other, the instances use the internet for connectivity. The security team wants to ensure that no communication between the instances happens over the internet.<br/><br/>What should a solutions architect do to accomplish this?<br/><br/>A. Create a NAT gateway and update the route table of the EC2 instances' subnet.<br/>B. Create a VPC endpoint and update the route table of the EC2 instances' subnet.<br/>C. Create a VPN connection and update the route table of the EC2 instances' subnet.<br/>D. Create a VPC peering connection and update the route table of the EC2 instances' subnet.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample407' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#VPC_12'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#VPC_35'>Random</a></p><div class='collapse' id='collapseExample407'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Create a VPC peering connection and update the route table of the EC2 instances' subnet.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 25%;" aria-valuenow="25" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#VPC'>VPC</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=VPC_12><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>VPC Question 12</p><br/>A company needs to provide its employees with secure access to confidential and sensitive files. The company wants to ensure that the files can be accessed only by authorized users. The files must be downloaded securely to the employees' devices.<br/><br/>The files are stored in an on&#8211;premises Windows file server. However, due to an increase in remote usage, the file server is running out of capacity.<br/><br/>Which solution will meet these requirements?<br/><br/>A. Migrate the file server to an Amazon EC2 instance in a public subnet. Configure the security group to limit inbound traffic to the employees' IP addresses.<br/>B. Migrate the files to an Amazon FSx for Windows File Server file system. Integrate the Amazon FSx file system with the on&#8211;premises Active Directory. Configure AWS Client VPN.<br/>C. Migrate the files to Amazon S3, and create a private VPC endpoint. Create a signed URL to allow download.<br/>D. Migrate the files to Amazon S3, and create a public VPC endpoint. Allow employees to sign on with AWS Single Sign&#8211;On.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample417' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#VPC_13'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#VPC_11'>Random</a></p><div class='collapse' id='collapseExample417'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Migrate the files to Amazon S3, and create a private VPC endpoint. Create a signed URL to allow download.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 27%;" aria-valuenow="27" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#VPC'>VPC</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=VPC_13><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>VPC Question 13</p><br/>A company that recently started using AWS establishes a Site&#8211;to&#8211;Site VPN between its on&#8211;premises datacenter and AWS. The company's security mandate states that traffic originating from on&#8211;premises should stay within the company's private IP space when communicating with an Amazon Elastic Container Service (Amazon ECS) cluster that is hosting a sample web application.<br/><br/>Which solution meets this requirement?<br/><br/>A. Configure a gateway endpoint for Amazon ECS. Modify the route table to include an entry pointing to the ECS cluster.<br/>B. Create a Network Load Balancer and AWS PrivateLink endpoint for Amazon ECS in the same VPC that is hosting the ECS cluster.<br/>C. Create a Network Load Balancer in one VPC and an AWS PrivateLink endpoint for Amazon ECS in another VPC. Connect the two VPCs by using VPC peering.<br/>D. Configure an Amazon Route 53 record with Amazon ECS as the target. Apply a server certificate to Route 53 from AWS Certificate Manager (ACM) for SSL offloading.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample394' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#VPC_14'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#VPC_18'>Random</a></p><div class='collapse' id='collapseExample394'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Create a Network Load Balancer in one VPC and an AWS PrivateLink endpoint for Amazon ECS in another VP<b>C. </b>Connect the two VPCs by using VPC peering.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 30%;" aria-valuenow="30" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#VPC'>VPC</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=VPC_14><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>VPC Question 14</p><br/>A company needs to connect its on&#8211;premises data center network to a new VPC. The data center network has a 100 Mbps symmetrical Internet connection. An application that is running on&#8211;premises will transfer multiple gigabytes of data each day. The application will use an Amazon Kinesis Data Firehose delivery stream for processing.<br/><br/>What should a solutions architect recommend for maximum performance?<br/><br/>A. Create a VPC peering connection between the on&#8211;premises network and the VPC Configure routing for the on&#8211;premises network to use the VPC peering connection.<br/>B. Procure an AWS Snowball Edge Storage Optimized device. After several days' worth of data has accumulated, copy the data to the device and ship the device to AWS for expedited transfer to Kinesis Data Firehose Repeat as needed<br/>C. Create an AWS Site&#8211;to&#8211;Site VPN connection between the on&#8211;premises network and the VPC Configure BGP routing between the customer gateway and the virtual private gateway. Use the VPN connection to send the data from on&#8211;premises to Kinesis Data Firehose.<br/>D. Use AWS PrivateLink to create an interface VPC endpoint for Kinesis Data Firehose in the VP<br/>E. Set up a 1 Gbps AWS Direct Connect connection between the on&#8211;premises network and AWS Use the PrivateLink endpoint to send the data from on&#8211;premises to Kinesis Data Firehose.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample480' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#VPC_15'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#VPC_22'>Random</a></p><div class='collapse' id='collapseExample480'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Use AWS PrivateLink to create an interface VPC endpoint for Kinesis Data Firehose in the VP</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 32%;" aria-valuenow="32" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#VPC'>VPC</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=VPC_15><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>VPC Question 15</p><br/>A company is using a VPC peering strategy to connect its VPCs in a single Region to allow for cross communication.<br/><br/>A recent increase in account creations and VPCs has made it difficult to maintain the VPC peering strategy, and the company expects to grow to hundreds of VPCs. There are also new requests to create site&#8211;to&#8211;site VPNs with some of the VPCs. A solutions architect has been tasked with creating a centrally managed networking setup for multiple accounts, VPCs, and VPNs.<br/><br/>Which networking solution meets these requirements?<br/><br/>A. Configure shared VPCs and VPNs and share to each other.<br/>B. Configure a hub&#8211;and&#8211;spoke VPC and route all traffic through VPC peering.<br/>C. Configure an AWS Direct Connect connection between all VPCs and VPNs.<br/>D. Configure a transit gateway with AWS Transit Gateway and connect all VPCs and VPNs.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample95' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#VPC_16'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#VPC_29'>Random</a></p><div class='collapse' id='collapseExample95'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Configure a transit gateway with AWS Transit Gateway and connect all VPCs and VPNs.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 34%;" aria-valuenow="34" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#VPC'>VPC</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=VPC_16><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>VPC Question 16</p><br/>A company is planning to migrate a mission&#8211;critical three&#8211;tor web application from on&#8211;premises to the AWS Cloud.<br/><br/>The backend database is shared with other on&#8211;premises systems and will remain in the on&#8211;premises data center.<br/><br/>The application tier requires quick and predictable response times between the presentation tier and the database Encryption is required for data in transit between client web browsers and the VPC.<br/><br/>And between the on&#8211;premises data center and the VPC.<br/><br/>Which solution meets these requirements?<br/><br/>A. Use VPN tunnels over an AWS Direct Connect connection for the data transfers between the VPC and the on&#8211;premises data center<br/>B. Use SSL/TLS for the web traffic encryption. Use VPN tunnels for the data transfer between the VPC and the on&#8211;premises data center<br/>C. Use SSL/TLS for the web traffic encryption. Use an AWS Direct Connect connection for the data transfers between the VPC and the on&#8211;premises data center<br/>D. Use SSL/TLS for the web traffic encryption. Use VPN tunnels over an AWS Direct Connect connection for the data transfer between the VPC and the on&#8211;premises data center.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample635' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#VPC_17'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#VPC_42'>Random</a></p><div class='collapse' id='collapseExample635'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Use SSL/TLS for the web traffic encryption. Use VPN tunnels over an AWS Direct Connect connection for the data transfer between the VPC and the on-premises data center.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 37%;" aria-valuenow="37" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#VPC'>VPC</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=VPC_17><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>VPC Question 17</p><br/>A company runs an application in the AWS Cloud and uses Amazon DynamoDB as the database. The company deploys Amazon EC2 instances to a private network to process data from the database.<br/><br/>The company uses two NAT instances to provide connectivity to DynamoDB. The company wants to retire the NAT instances.<br/><br/>A solutions architect must implement a solution that provides connectivity to DynamoDB and that does not require ongoing management.<br/><br/>What is the MOST cost&#8211;effective solution that meets these requirements?<br/><br/>A. Create a gateway VPC endpoint to provide connectivity to DynamoDB<br/>B. Configure a managed NAT gateway to provide connectivity to DynamoDB<br/>C. Establish an AWS Direct Connect connection between the private network and DynamoDB<br/>D. Deploy an AWS PrivateLink endpoint service between the private network and DynamoDB<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample660' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#VPC_18'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#VPC_32'>Random</a></p><div class='collapse' id='collapseExample660'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Create a gateway VPC endpoint to provide connectivity to DynamoDB</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 39%;" aria-valuenow="39" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#VPC'>VPC</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=VPC_18><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>VPC Question 18</p><br/>An application runs on Amazon EC2 instances in private subnets. The application needs to access an Amazon DynamoDB table.<br/><br/>What is me MOST secure way to access the table while ensuring that the traffic does not leave the AWS network?<br/><br/>A. Use a VPC endpoint for DynamoDB<br/>B. Use a NAT gateway in a public subnet<br/>C. Use a NAT instance in a private subnet<br/>D. Use the internet gateway attached to the VPC<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample446' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#VPC_19'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#VPC_14'>Random</a></p><div class='collapse' id='collapseExample446'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Use a VPC endpoint for DynamoDB</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 41%;" aria-valuenow="41" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#VPC'>VPC</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=VPC_19><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>VPC Question 19</p><br/>A company has two VPCs that are located in the us&#8211;west&#8211;2 Region within the same AWS account. The company needs to allow network traffic between these VPCs. Approximately 500 GB of data transfer will occur between the VPCs each month.<br/><br/>What is the MOST cost&#8211;effective solution to connect these VPCs?<br/><br/>A. Implement AWS Transit Gateway to connect the VPCs Update the route tables of each VPC to use the transit gateway for inter&#8211;VPC communication<br/>B. Implement an AWS Site&#8211;to&#8211;Site VPN tunnel between the VPCs. Update the route tables of each VPC to use the VPN tunnel for inter&#8211;VPC communication<br/>C. Set up a VPC peering connection between the VPCs. Update the route tables of each VPC to use the VPC peering connection for inter&#8211;VPC communication.<br/>D. Set up a 1 GB AWS Direct Connect connection between the VPCs. Update the route tables of each VPC to use the Direct Connect connection for inter&#8211;VPC communication.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample461' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#VPC_20'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#VPC_17'>Random</a></p><div class='collapse' id='collapseExample461'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Set up a VPC peering connection between the VPCs. Update the route tables of each VPC to use the VPC peering connection for inter-VPC communication.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 44%;" aria-valuenow="44" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#VPC'>VPC</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=VPC_20><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>VPC Question 20</p><br/>A company runs an AWS Lambda function in private subnets in a VPC. The subnets have a default route to the internet through an Amazon EC2 NAT instance. The Lambda function processes input data and saves its output as an object to Amazon S3 intermittently the Lambda function times out while trying to upload the object because of saturated traffic on the NAT instance's network. The company wants to access Amazon S3 without traversing the internet<br/><br/>Which solution will meet these requirements?<br/><br/>A. Replace the fcC2 NAT instance with an AWS managed NAT gateway<br/>B. Increase the size of the EC2 NAT instance in the VPC to a network optimized instance type<br/>C. Provision a gateway endpoint for Amazon S3 in the VPC Update the route tables of the subnets accordingly<br/>D. Provision a transit gateway Place transit gateway attachments in the private subnets where the Lambda function is running<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample475' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#VPC_21'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#VPC_21'>Random</a></p><div class='collapse' id='collapseExample475'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Increase the size of the EC2 NAT instance in the VPC to a network optimized instance type</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 46%;" aria-valuenow="46" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#VPC'>VPC</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=VPC_21><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>VPC Question 21</p><br/>A company built a new VPC with the intention of the hosting Amazon EC2 based workloads on AWS. A solutions architect specified that an Amazon S3 gateway endpoint be created and attached to this new VPC. Once the first Application server is built, developers report that server time out when accessing data stored in the S3 bucket.<br/><br/>Which scenario could be causing this issue? ( Select TWO)<br/><br/>A. The S3 bucket is in a region other than the VPC<br/>B. The endpoint has a policy that blocks the CIDR of the VPC<br/>C. The route to the S3 endpoint is not configured in the route table<br/>D. The access is routed through an internet gateway rather than the endpoint<br/>E. The S3 bucket has a bucket policy that does not allow access to the CIDR of the VPC<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample711' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#VPC_22'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#VPC_13'>Random</a></p><div class='collapse' id='collapseExample711'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>The route to the S3 endpoint is not configured in the route table
<br><b>E. </b>The S3 bucket has a bucket policy that does not allow access to the CIDR of the VPC</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 48%;" aria-valuenow="48" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#VPC'>VPC</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=VPC_22><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>VPC Question 22</p><br/>A company's web application is running on Amazon EC2 instances behind an Application Load Balancer.<br/><br/>The company recently changed its policy, which now requires the application to be accessed from one specific country only.<br/><br/>Which configuration will meet this requirement?<br/><br/>A. Configure the security group for the EC2 instances.<br/>B. Configure the security group on the Application Load Balancer.<br/>C. Configure AWS WAF on the Application Load Balancer in a VPC.<br/>D. Configure the network ACL for the subnet that contains the EC2 instances.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample57' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#VPC_23'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#VPC_24'>Random</a></p><div class='collapse' id='collapseExample57'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Configure AWS WAF on the Application Load Balancer in a VPC.

References:

AWS Security Blog > How to use AWS WAF to filter incoming traffic from embargoed countries</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 51%;" aria-valuenow="51" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#VPC'>VPC</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=VPC_23><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>VPC Question 23</p><br/>A software vendor is deploying a new software&#8211;as&#8211;a&#8211;service (SaaS) solution that will be utilized by many AWS users. The service is hosted in a VPC behind a Network Load Balancer. The software vendor wants to provide access to this service to users with the least amount of administrative overhead and without exposing the service to the public internet.<br/><br/>What should a solutions architect do to accomplish this goal?<br/><br/>A. Create a peering VPC connection from each user's VPC to the software vendor's VPC.<br/>B. Deploy a transit VPC in the software vendor's AWS account. Create a VPN connection with each user account.<br/>C. Connect the service in the VPC with an AWS Private Link endpoint. Have users subscribe to the endpoint.<br/>D. Deploy a transit VPC in the software vendor's AWS account. Create an AWS Direct Connect connection with each user account.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample257' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#VPC_24'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#VPC_27'>Random</a></p><div class='collapse' id='collapseExample257'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Connect the service in the VPC with an AWS Private Link endpoint. Have users subscribe to the endpoint.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 53%;" aria-valuenow="53" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#VPC'>VPC</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=VPC_24><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>VPC Question 24</p><br/>A company has several Amazon EC2 instances set up in a private subnet for security reasons. These instances host applications that read and write large amounts of data to and from Amazon S3 regularly.<br/><br/>Currently, subnet routing directs all the traffic destined for the internet through a NAT gateway. The company wants to optimize the overall cost without impacting the ability of the application to communicate with Amazon S3 or the outside internet.<br/><br/>What should a solutions architect do to optimize costs?<br/><br/>A. Create an additional NAT gateway. Update the route table to route to the NAT gateway. Update the network ACL to allow S3 traffic.<br/>B. Create an internet gateway. Update the route table to route traffic to the internet gateway. Update the network ACL to allow S3 traffic.<br/>C. Create a VPC endpoint for Amazon S3. Attach an endpoint policy to the endpoint. Update the route table to direct traffic to the VPC endpoint.<br/>D. Create an AWS Lambda function outside of the VPC to handle S3 requests. Attach an IAM policy to the EC2 instances, allowing them to invoke the Lambda function.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample357' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#VPC_25'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#VPC_3'>Random</a></p><div class='collapse' id='collapseExample357'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Create a VPC endpoint for Amazon S3. Attach an endpoint policy to the endpoint. Update the route table to direct traffic to the VPC endpoint.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 55%;" aria-valuenow="55" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#VPC'>VPC</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=VPC_25><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>VPC Question 25</p><br/>A company wants to use an AWS Region as a disaster recovery location for its on&#8211;premises infrastructure. The company has 10 TB of existing data, and the on&#8211;premise data center has a 1 Gbps internet connection. A solutions architect must find a solution so the company can have its existing data on AWS in 72 hours without transmitting it using an unencrypted channel.<br/><br/>Which solution should the solutions architect select?<br/><br/>A. Send the initial 10 TB of data to AWS using FTP.<br/>B. Send the initial 10 TB of data to AWS using AWS Snowball.<br/>C. Establish a VPN connection between Amazon VPC and the company's data center.<br/>D. Establish an AWS Direct Connect connection between Amazon VPC and the company's data center<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample732' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation732' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#VPC_26'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#VPC_1'>Random</a></p><div class='collapse' id='collapseExample732'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Establish a VPN connection between Amazon VPC and the company's data center.</div></div></div><div class='collapse' id='explanation732'><div class='card card&#45;body'><div>
Keyword: AWS Region as DR for On-premises DC (Existing Data=10TB) + 1G Internet Connection
Condition: 10TB on AWS in 72 Hours + Without Unencrypted Channel Without Unencrypted Channel = VPN
FTP = Unencrypted Channel
Options – A – Out of race, since this is unencrypted channel & not matching the condition Options – B – Out of race due to the timebound target & order /delivering AWS Snowball device will take time
Options – C – Win the race, using the existing 1G Internet Link we can transfer this 10TB data within 24Hrs using encrypted Channel
Options – D – Out of race due to the timebound target & order /delivering AWS Direct Connect will take time
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 58%;" aria-valuenow="58" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#VPC'>VPC</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=VPC_26><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>VPC Question 26</p><br/>A company's website hosted on Amazon EC2 instances processes classified data stored in Amazon S3. Due to security concerns, the company requires a private and secure connection between its EC2 resources and Amazon S3.<br/><br/>Which solution meets these requirements?<br/><br/>A. Set up S3 bucket policies to allow access from a VPC endpoint.<br/>B. Set up an IAM policy to grant read&#8211;write access to the S3 bucket.<br/>C. Set up a NAT gateway to access resources outside the private subnet.<br/>D. Set up an access key ID and a secret access key to access the S3 bucket.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample678' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#VPC_27'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#VPC_7'>Random</a></p><div class='collapse' id='collapseExample678'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Set up S3 bucket policies to allow access from a VPC endpoint.

References:

Amazon Simple Storage Service > User Guide > Controlling access from VPC endpoints with bucket policies</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 60%;" aria-valuenow="60" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#VPC'>VPC</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=VPC_27><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>VPC Question 27</p><br/>A company is designing a new application that runs in a VPC on Amazon EC2 instances. The application stores data in Amazon S3 and uses Amazon DynamoDB as its database. For compliance reasons, the company prohibits all traffic between the EC2 instances and other AWS services from passing over the public internet.<br/><br/>What can a solutions architect do to meet this requirement?<br/><br/>A. Configure gateway VPC endpoints to Amazon S3 and DynamoDB.<br/>B. Configure interface VPC endpoints to Amazon S3 and DynamoDB.<br/>C. Configure a gateway VPC endpoint to Amazon S3. Configure an interface VPC endpoint to DynamoDB.<br/>D. Configure a gateway VPC endpoint to DynamoDB. Configure an interface VPC endpoint to Amazon S3.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample415' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#VPC_28'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#VPC_33'>Random</a></p><div class='collapse' id='collapseExample415'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Configure a gateway VPC endpoint to Amazon S3. Configure an interface VPC endpoint to DynamoDB.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 62%;" aria-valuenow="62" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#VPC'>VPC</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=VPC_28><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>VPC Question 28</p><br/>A company has deployed an API in a VPC behind an internet&#8211;facing Application Load Balancer (ALB). An application that consumes the API as a client is deployed in a second account in private subnets behind a NAT gateway. When requests to the client application increase, the NAT gateway costs are higher than expected. A solutions architect has configured the ALB to be internal.<br/><br/>Which combination of architectural changes will reduce the NAT gateway costs? (Choose two.)<br/><br/>A. Configure a VPC peering connection between the two VPCs. Access the API using the private address.<br/>B. Configure an AWS Direct Connect connection between the two VPCs. Access the API using the private address.<br/>C. Configure a ClassicLink connection for the API into the client VPC. Access the API using the ClassicLink address.<br/>D. Configure a PrivateLink connection for the API into the client VPC. Access the API using the PrivateLink address.<br/>E. Configure an AWS Resource Access Manager connection between the two accounts. Access the API using the private address.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample151' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation151' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#VPC_29'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#VPC_20'>Random</a></p><div class='collapse' id='collapseExample151'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Configure a VPC peering connection between the two VPCs. Access the API using the private address.
<br><b>D. </b>Configure a PrivateLink connection for the API into the client VP<br><b>C. </b>Access the API using the PrivateLink address.</div></div></div><div class='collapse' id='explanation151'><div class='card card&#45;body'><div>
PrivateLink makes it easy to connect services across different accounts and VPCs to significantly simplify the network architecture. There is no API listed in shareable resources for RAM.

References:

AWS Resource Access Manager > User Guide > Shareable AWS resources
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 65%;" aria-valuenow="65" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#VPC'>VPC</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=VPC_29><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>VPC Question 29</p><br/>A company's application hosted on Amazon EC2 instances needs to access an Amazon S3 bucket. Due to data sensitivity, traffic cannot traverse the internet.<br/><br/>How should a solutions architect configure access?<br/><br/>A. Create a private hosted zone using Amazon Route 53.<br/>B. Configure a VPC gateway endpoint for Amazon S3 in the VPC.<br/>C. Configure AWS PrivateLink between the EC2 instance and the S3 bucket.<br/>D. Set up a site&#8211;to&#8211;site VPN connection between the VPC and the S3 bucket.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample66' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#VPC_30'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#VPC_28'>Random</a></p><div class='collapse' id='collapseExample66'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Configure a VPC gateway endpoint for Amazon S3 in the VPC.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 67%;" aria-valuenow="67" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#VPC'>VPC</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=VPC_30><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>VPC Question 30</p><br/>An application running on an Amazon EC2 instance in VPC&#8211;A needs to access files in another EC2 instance in VPC&#8211;B. Both are in separate. AWS accounts. The network administrator needs to design a solution to enable secure access to EC2 instance in VPC&#8211;B from VPC&#8211;A. The connectivity should not have a single point of failure or bandwidth concerns.<br/><br/>Which solution will meet these requirements?<br/><br/>A. Set up a VPC peering connection between VPC&#8211;A and VPC&#8211;B.<br/>B. Set up VPC gateway endpoints for the EC2 instance running in VPC&#8211;B.<br/>C. Attach a virtual private gateway to VPC&#8211;B and enable routing from VPC&#8211;A.<br/>D. Create a private virtual interface (VIF) for the EC2 instance running in VPC&#8211;B and add appropriate routes from VPC&#8211;B.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample65' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation65' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#VPC_31'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#VPC_39'>Random</a></p><div class='collapse' id='collapseExample65'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Set up a VPC peering connection between VPC-A and VPC-B.</div></div></div><div class='collapse' id='explanation65'><div class='card card&#45;body'><div>
A VPC peering connection is a networking connection between two VPCs that enables you to route traffic between them using private IPv4 addresses or IPv6 addresses. Instances in either VPC can communicate with each other as if they are within the same network. You can create a VPC peering connection between your own VPCs, or with a VPC in another AWS account.

The traffic remains in the private IP space. All inter-region traffic is encrypted with no single point of failure, or bandwidth bottleneck.

References:
Amazon Virtual Private Cloud > VPC Peering > What is VPC peering?
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 69%;" aria-valuenow="69" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#VPC'>VPC</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=VPC_31><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>VPC Question 31</p><br/>A company has two VPCs named Management and Production. The Management VPC uses VPNs through a customer gateway to connect to a single device in the data center The Production VPC uses a virtual private gateway with two attached AWS Direct Connect connections. The Management and Production VPCs both use a single VPC peering connection to allow communication between the applications.<br/><br/>What should a solutions architect do to mitigate any single point of failure in this architecture?<br/><br/>A. Add a second virtual private gateway and attach it to the Management VPC.<br/>B. Add a second VPC peering connection between the Management VPC and the Production VPC.<br/>C. Add a set of VPNs between the Management and Production VPCs.<br/>D. Add a second set of VPNs to the Management VPC from a second customer gateway device.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample514' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#VPC_32'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#VPC_41'>Random</a></p><div class='collapse' id='collapseExample514'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Add a second virtual private gateway and attach it to the Management VPC.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 72%;" aria-valuenow="72" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#VPC'>VPC</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=VPC_32><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>VPC Question 32</p><br/>A company needs to connect several VPCs in the us&#8211;east Region that span hundreds of AWS accounts.<br/><br/>The company's networking team as its own AWS account to manage the cloud network.<br/><br/>What is the MOST operationally efficient solution to connect the VPCs?<br/><br/>A. Set up VPC peering connections between each VPC. Update each associated subnet's route table.<br/>B. Configure a NAT gateway and an internal gateway in each VPC in connected each VPC through the internal.<br/>C. Create an AWS Transit Gateway in the networking team's AWS account. Configure static routes from each VPC.<br/>D. Deploy VPN gateway in each VPC. Configure create a transit VPC in the networking team's AWS account to connect to each VPC.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample601' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#VPC_33'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#VPC_30'>Random</a></p><div class='collapse' id='collapseExample601'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Create an AWS Transit Gateway in the networking team's AWS account. Configure static routes from each VPC.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 74%;" aria-valuenow="74" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#VPC'>VPC</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=VPC_33><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>VPC Question 33</p><br/>After setting up a Virtual Private Cloud (VPC) network, a more experienced cloud engineer suggests that to achieve low network latency and high network throughput you should look into setting up a placement group. You know nothing about this, but begin to do some research about it and are especially curious about its limitations.<br/><br/>Which of the below statements is wrong in describing the limitations of a placement group?<br/><br/>A. Although launching multiple instance types into a placement group is possible, this reduces the likelihood that the required capacity will be available for your launch to succeed.<br/>B. A placement group can span multiple Availability Zones.<br/>C. You can't move an existing instance into a placement group.<br/>D. A placement group can span peered VPCs<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample774' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation774' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#VPC_34'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#VPC_4'>Random</a></p><div class='collapse' id='collapseExample774'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>A placement group can span peered VPCs</div></div></div><div class='collapse' id='explanation774'><div class='card card&#45;body'><div>
A placement group is a logical grouping of instances within a single Availability Zone. Using placement groups enables applications to participate in a low-latency, 10 Gbps network.

Placement groups are recommended for applications that benefit from low network latency, high network throughput, or both. To provide the lowest latency, and the highest packet-per-second network performance for your placement group, choose an instance type that supports enhanced networking.

Placement groups have the following limitations: The name you specify for a placement group a name must be unique within your AWS account. A placement group can't span multiple Availability Zones. Although launching multiple instance types into a placement group is possible, this reduces the likelihood that the required capacity will be available for your launch to succeed. We recommend using the same instance type for all instances in a placement group. You can't merge placement groups. Instead, you must terminate the instances in one placement group, and then relaunch those instances into the other placement group. A placement group can span peered VPCs; however, you will not get full-bisection bandwidth between instances in peered VPCs. For more information about VPC peering connections, see VPC Peering in the Amazon VPC User Guide. You can't move an existing instance into a placement group. You can create an AMI from your existing instance, and then launch a new instance from the AMI into a placement group.

References:

Amazon Elastic Compute Cloud > User Guide for Linux Instances > Placement groups</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 76%;" aria-valuenow="76" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#VPC'>VPC</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=VPC_34><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>VPC Question 34</p><br/>A medical records company is hosting an application on Amazon EC2 instances. The application processes customer data files that are stored on Amazon S3. The EC2 instances are hosted in public subnets. The EC2 instances access Amazon S3 over the internet, but they do not require any other network access.<br/><br/>A new requirement mandates that the network traffic for file transfers take a private route and not be sent over the internet.<br/><br/>Which change to the network architecture should a solutions architect recommend to meet this requirement?<br/><br/>A. Create a NAT gateway. Configure the route table for the public subnets to send traffic to Amazon S3 through the NAT gateway.<br/>B. Configure the security group for the EC2 instances to restrict outbound traffic so that only traffic to the S3 prefix list is permitted.<br/>C. Move the EC2 instances to private subnets. Create a VPC endpoint for Amazon S3, and link the endpoint to the route table for the private subnets<br/>D. Remove the internet gateway from the VP<br/>E. Set up an AWS Direct Connect connection, and route traffic to Amazon S3 over the Direct Connect connection.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample472' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#VPC_35'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#VPC_34'>Random</a></p><div class='collapse' id='collapseExample472'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Move the EC2 instances to private subnets. Create a VPC endpoint for Amazon S3, and link the endpoint to the route table for the private subnets</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 79%;" aria-valuenow="79" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#VPC'>VPC</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=VPC_35><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>VPC Question 35</p><br/>A company is using a VPC peering strategy to connect its VPCs in a single Region to allow for cross&#8211; communication. A recent increase in account creations and VPCs has made it difficult to maintain the VPC peering strategy, and the company expects to grow to hundreds of VPCs.<br/><br/>There are also new requests to create site&#8211;to&#8211;site VPNs with some of the VPCs. A solutions architect has been tasked with creating a centrally networking setup for multiple accounts, VPNS, and VPNs.<br/><br/>Which networking solution meets these requirements?<br/><br/>A. Configure shared VPCs and VPNs and share with each other<br/>B. Configure a hub&#8211;and&#8211;spoke and route all traffic through VPC peering.<br/>C. Configure an AWS Direct Connect between all VPCs and VPNs.<br/>D. Configure a transit gateway with AWS Transit Gateway and connected all VPCs and VPNs.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample727' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#VPC_36'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#VPC_25'>Random</a></p><div class='collapse' id='collapseExample727'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Configure a transit gateway with AWS Transit Gateway and connected all VPCs and VPNs.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 81%;" aria-valuenow="81" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#VPC'>VPC</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=VPC_36><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>VPC Question 36</p><br/>A company runs its two&#8211;tier eCommerce website on AWS. The web tier consists of a load balancer that sends traffic to Amazon EC2 instances. The database tier uses an Amazon RDS DB instance. The EC2 instances and the RDS DB instance should not be exposed to the public internet. The EC2 instances require internet access to complete payment processing of orders through a third&#8211;party web service. The application must be highly available.<br/><br/>Which combination of configuration options will meet these requirements? (Choose two.)<br/><br/>A. Use an Auto Scaling group to launch the EC2 instances in private subnets. Deploy an RDS Multi&#8211;AZ DB instance in private subnets.<br/>B. Configure a VPC with two private subnets and two NAT gateways across two Availability Zones. Deploy an Application Load Balancer in the private subnets.<br/>C. Use an Auto Scaling group to launch the EC2 instances in public subnets across two Availability Zones. Deploy an RDS Multi&#8211;AZ DB instance in private subnets.<br/>D. Configure a VPC with one public subnet, one private subnet, and two NAT gateways across two Availability Zones. Deploy an Application Load Balancer in the public subnet.<br/>E. Configure a VPC with two public subnets, two private subnets, and two NAT gateways across two Availability Zones. Deploy an Application Load Balancer in the public subnets.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample422' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#VPC_37'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#VPC_16'>Random</a></p><div class='collapse' id='collapseExample422'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Use an Auto Scaling group to launch the EC2 instances in private subnets. Deploy an RDS Multi-AZ DB instance in private subnets.
<br><b>B. </b>Configure a VPC with two private subnets and two NAT gateways across two Availability Zones. Deploy an Application Load Balancer in the private subnets.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 83%;" aria-valuenow="83" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#VPC'>VPC</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=VPC_37><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>VPC Question 37</p><br/>A company has an application that runs on Amazon EC2 instances within a private subnet in a VPC. The instances access data in an Amazon S3 bucket in the same AWS Region. The VPC contains a NAT gateway in a public subnet to access the S3 bucket. The company wants to reduce costs by replacing the NAT gateway without compromising security or redundancy.<br/><br/>Which solution meets these requirements?<br/><br/>A. Replace the NAT gateway with a NAT instance.<br/>B. Replace the NAT gateway with an internet gateway.<br/>C. Replace the NAT gateway with a gateway VPC endpoint.<br/>D. Replace the NAT gateway with an AWS Direct Connect connection.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample405' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#VPC_38'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#VPC_40'>Random</a></p><div class='collapse' id='collapseExample405'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Replace the NAT gateway with a gateway VPC endpoint.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 86%;" aria-valuenow="86" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#VPC'>VPC</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=VPC_38><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>VPC Question 38</p><br/>A company has a two&#8211;tier application architecture that runs in public and private subnets. Amazon EC2 instances running the web application are in the public subnet and a database runs on the private subnet.<br/><br/>The web application instances and the database are running in a single Availability Zone (AZ).<br/><br/>Which combination of steps should a solutions architect take to provide high availability for this architecture? (Choose two.)<br/><br/>A. Create new public and private subnets in the same AZ for high availability.<br/>B. Create an Amazon EC2 Auto Scaling group and Application Load Balancer spanning multiple AZs.<br/>C. Add the existing web application instances to an Auto Scaling group behind an Application Load Balancer.<br/>D. Create new public and private subnets in a new AZ. Create a database using Amazon EC2 in one AZ.<br/>E. Create new public and private subnets in the same VPC, each in a new AZ. Migrate the database to an Amazon RDS multi&#8211;AZ deployment.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample152' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation152' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#VPC_39'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#VPC_2'>Random</a></p><div class='collapse' id='collapseExample152'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Create an Amazon EC2 Auto Scaling group and Application Load Balancer spanning multiple AZs.
<br><b>E. </b>Create new public and private subnets in the same VPC, each in a new AZ. Migrate the database to an Amazon RDS multi-AZ deployment.</div></div></div><div class='collapse' id='explanation152'><div class='card card&#45;body'><div>

You would the EC2 instances to have high availability by placing them in multiple AZs.
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 88%;" aria-valuenow="88" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#VPC'>VPC</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=VPC_39><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>VPC Question 39</p><br/>A company has an AWS Direct Connect connection from its corporate data center to its VPC in the us&#8211;east&#8211;1 Region.<br/><br/>The company recently acquired a corporation that has several VPCs and a Direct Connect connection between its on&#8211;premises data center and the eu&#8211;west&#8211;2 Region.<br/><br/>The CIDR blocks for the VPCs of the company and the corporation do not overlap. The company requires connectivity between two Regions and the data centers.<br/><br/>The company needs a solution that is scalable while reducing operational overhead. What should a solutions architect do to meet these requirements?<br/><br/>A. Set up inter&#8211;Region VPC peering between the VPC m us&#8211;east&#8211;1 and the VPCs in eu&#8211;west&#8211;2<br/>B. Create private virtual interfaces from the Direct Connect connection in us&#8211;east&#8211;1 to the VPCs in eu&#8211;west&#8211;2<br/>C. Establish VPN appliances in a fully meshed VPN network hosted by Amazon EC2 Use AWS VPN CloudHub to send and receive data between the data centers and each VPC<br/>D. Connect the existing Direct Connect connection to a Direct Connect gateway Route traffic from the virtual private gateways of the VPCs in each Region to the Direct Connect gateway<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample519' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#VPC_40'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#VPC_9'>Random</a></p><div class='collapse' id='collapseExample519'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Connect the existing Direct Connect connection to a Direct Connect gateway Route traffic from the virtual private gateways of the VPCs in each Region to the Direct Connect gateway</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 90%;" aria-valuenow="90" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#VPC'>VPC</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=VPC_40><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>VPC Question 40</p><br/>A company is running an application on Amazon EC2 instances hosted in a private subnet of a VPC.<br/><br/>The EC2 instances are configured in an Auto Scaling group behind an Elastic Load Balancer (ELB).<br/><br/>The EC2 instances use a NAT gateway for outbound internet access.<br/><br/>However the EC2 instances are not able to connect to the public internet to download software updates.<br/><br/>What are the possible root causes of this issue? (Select TWO )<br/><br/>A. The ELB is not configured with a proper health check<br/>B. The route tables in the VPC are configured incorrectly<br/>C. The EC2 instances are not associated with an Elastic IP address<br/>D. The security group attached to the NAT gateway is configured incorrectly<br/>E. The outbound rules on the security group attached to the EC2 Instances are configured incorrectly.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample658' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#VPC_41'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#VPC_12'>Random</a></p><div class='collapse' id='collapseExample658'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>The route tables in the VPC are configured incorrectly
<br><b>E. </b>The outbound rules on the security group attached to the EC2 Instances are configured incorrectly.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 93%;" aria-valuenow="93" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#VPC'>VPC</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=VPC_41><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>VPC Question 41</p><br/>A company fails an AWS security review conducted by a third party.<br/><br/>The review finds that some of the company's methods to access the Amazon EMR API are not secure.<br/><br/>Developers are using AWS Cloud9, and access keys are connecting to the Amazon EMR API through the public internet.<br/><br/>Which combination of steps should the company take to MOST improve its security? (Select TWO)<br/><br/>A. Set up a VPC peering connection to the Amazon EMR API<br/>B. Set up VPC endpoints to connect to the Amazon EMR API<br/>C. Set up a NAT gateway to connect to the Amazon EMR API.<br/>D. Set up IAM roles to be used to connect to the Amazon EMR API<br/>E. Set up each developer with AWS Secrets Manager to store access keys<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample532' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#VPC_42'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#VPC_19'>Random</a></p><div class='collapse' id='collapseExample532'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Set up VPC endpoints to connect to the Amazon EMR API
<br><b>D. </b>Set up IAM roles to be used to connect to the Amazon EMR API</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 95%;" aria-valuenow="95" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#VPC'>VPC</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=VPC_42><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>VPC Question 42</p><br/>A company wants to create an application that will transmit protected health information (PHI) to thousands of service consumers in different AWS accounts.<br/><br/>The application servers will sit in private VPC subnets The routing for the application must be fault tolerant.<br/><br/>What should be done to meet these requirements?<br/><br/>A. Create a VPC endpoint service and grant permissions to specific service consumers to create a connection<br/>B. Create a virtual private gateway connection between each pair of service provider VPCs and service consumer VPCs<br/>C. Create an internal Application Load Balancer in the service provider VPC and put application servers behind it.<br/>D. Create a proxy server in the service provider VPC to route requests from service consumers to the application servers.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample622' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#VPC_43'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#VPC_26'>Random</a></p><div class='collapse' id='collapseExample622'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Create a VPC endpoint service and grant permissions to specific service consumers to create a connection</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 97%;" aria-valuenow="97" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#VPC'>VPC</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=VPC_43><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>VPC Question 43</p><br/>A company has three AWS accounts Management Development and Production. These accounts use AWS services only in the us&#8211;east&#8211;1 Region All accounts have a VPC with VPC Flow Logs configured to publish data to an Amazon S3 bucket in each separate account For compliance reasons the company needs an ongoing method to aggregate all the VPC flow logs across all accounts into one destination S3 bucket in the Management account.<br/><br/>What should a solutions architect do to meet these requirements with the LEAST operational overhead?<br/><br/>A. Add S3 Same&#8211;Region Replication rules in each S3 bucket that stores VPC flow logs to replicate objects to the destination S3 bucket Configure the destination S3 bucket to allow objects to be received from the S3 buckets in other accounts<br/>B. Set up an 1AM user in the Management account Grant permissions to the 1AM user to access the S3 buckets that contain the VPC flow logs Run the aws s3 sync command in the AWS CLI to copy the objects to the destination S3 bucket<br/>C. Use an S3 inventory report to specify which objects in the S3 buckets to copy Perform an S3 batch operation to copy the objects into the destination S3 bucket in the Management account with a single request.<br/>D. Create an AWS Lambda function in the Management account Grant S3 GET permissions on the source S3 buckets Grant S3 PUT permissions on the destination S3 bucket Configure the function to invoke when objects are loaded in the source S3 buckets<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample462' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#VPC_44'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#VPC_10'>Random</a></p><div class='collapse' id='collapseExample462'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Add S3 Same-Region Replication rules in each S3 bucket that stores VPC flow logs to replicate objects to the destination S3 bucket Configure the destination S3 bucket to allow objects to be received from the S3 buckets in other accounts</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 100%;" aria-valuenow="100" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#VPC'>VPC</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><a id=SQS><h2>SQS</h2></a> - 36 Questions <br><a href='#SQS'>SQS(36)</a> <a href='#' <i class='bi bi&#45;house'> &nbsp;Home</i><hr> </a><div class='row' id=SQS_1><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>SQS Question 1</p><br/>A company receives data from different sources and implements multiple applications to consume this data.<br/><br/>There are many short&#8211;running jobs that run only on the weekend. The data arrives in batches rather than throughout the entire weekend.<br/><br/>The company needs an environment on AWS to ingest and process this data while maintaining the order of the transactions.<br/><br/>Which combination of AWS services meets these requirements in the MOST cost&#8211;effective manner?<br/><br/>A. Amazon Kinesis Data Streams with AWS Lambda<br/>B. Amazon Kinesis Data Streams with Amazon EC2 Auto Scaling<br/>C. Amazon Simple Queue Service (Amazon SQS) with AWS Lambda<br/>D. Amazon Simple Queue Service (Amazon SQS) with Amazon EC2 Auto Scaling<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample522' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#SQS_2'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#SQS_17'>Random</a></p><div class='collapse' id='collapseExample522'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Amazon Simple Queue Service (Amazon SQS) with AWS Lambda</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 2%;" aria-valuenow="2" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#SQS'>SQS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=SQS_2><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>SQS Question 2</p><br/>A company wants to build an online marketplace application on AWS as a set of loosely coupled microservices. For this application, when a customer submits a new order, two microservices should handle the event simultaneously. The Email microservice will send a confirmation email, and the order processing microservice will start the order delivery process. If a customer cancels an order, the OrderCancelation and Email microservices should handle the event simultaneously.<br/><br/>A solutions architect wants to use Amazon Simple Queue Service (Amazon SQS) and Amazon Simple<br/><br/>Notification Service (Amazon SNS) to design the messaging between the microservices.<br/><br/>How should the solutions architect design the solution?<br/><br/>A. Create a single SQS queue and publish order events to it. The Email OrderProcessing and Order Cancellation microservices can then consume messages of the queue.<br/>B. Create three SNS topics for each microservice. Publish order events to the three topics. Subscribe each of the Email OrderProcessing and Order Cancellation microservices to its own topic.<br/>C. Create an SNS topic and publish order events to it. Create three SQS queues for the Email OrderProcessing and Order Cancellation microservices. Subscribe all SQS queues to the SNS topic with message filtering.<br/>D. Create two SQS queues and publish order events to both queues simultaneously. One queue is for the Email and OrderProcessing microservices. The second queue is for the Email and Order Cancellation microservices.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample300' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#SQS_3'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#SQS_25'>Random</a></p><div class='collapse' id='collapseExample300'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Create two SQS queues and publish order events to both queues simultaneously. One queue is for the Email and OrderProcessing microservices. The second queue is for the Email and Order Cancellation microservices.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 5%;" aria-valuenow="5" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#SQS'>SQS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=SQS_3><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>SQS Question 3</p><br/>A company wants to build an online marketplace application on AWS as a set of loosely coupled microservices For this application, when a customer submits a new order two microservices should handle the event simultaneously. The Email microservice will send a confirmation email and the order processing microservice will start the order delivery process If a customer cancels an order, the order cancellation and Email microservices should handle the event simultaneously.<br/><br/>A solutions architect wants to use Amazon Simple Queue Service (Amazon SQS) and Amazon Simple Notification Service (Amazon SNS) to design the messaging between the microservices.<br/><br/>How should the solutions architect design the solution?<br/><br/>A. Create a single SOS queue and publish order events to it. The Email, OrderProcessing and OrderCancellation microservices can then consume messages off the queue<br/>B. Create three SNS topics for each microservice Publish order events to the three topics Subscribe each of the Email OrderProcessmg, and OrderCancellation microservices to its own topic<br/>C. Create an SNS topic and publish order events to it Create three SQS queues for the Email OrderProcessing and OrderCancellation microservices Subscribe all SQS queues to the SNS topic with message filtering<br/>D. Create two SQS queues and publish order events to both queues simultaneously One queue is for the Email and OrderProcessmg microservices. The second queue is for the Email and Order Cancellation microservices<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample459' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#SQS_4'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#SQS_8'>Random</a></p><div class='collapse' id='collapseExample459'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Create an SNS topic and publish order events to it Create three SQS queues for the Email OrderProcessing and OrderCancellation microservices Subscribe all SQS queues to the SNS topic with message filtering</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 8%;" aria-valuenow="8" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#SQS'>SQS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=SQS_4><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>SQS Question 4</p><br/>A company is designing a web application using AWS that processes insurance quotes. Users will request quotes from the application. Quotes must be separated by quote type must be responded to within 24 hours, and must not be lost. The solution should be simple to set up and maintain.<br/><br/>Which solution meets these requirements?<br/><br/>A. Create multiple Amazon Kinesis data streams based on the quote type. Configure the web application to send messages to the proper data stream. Configure each backend group of application servers to pool messages from its own data stream using the Kinesis Client Library (KCL).<br/>B. Create multiple Amazon Simple Notification Service (Amazon SNS) topics and register Amazon SQS queues to their own SNS topic based on the quote type. Configure the web application to publish messages to the SNS topic queue. Configure each backend application server to work its own SQS queue.<br/>C. Create a single Amazon Simple Notification Service (Amazon SNS) topic and subscribe the Amazon SQS queues to the SNS topic. Configure SNS message filtering to publish messages to the proper SQS queue based on the quote type. Configure each backend application server to work its own SQS queue.<br/>D. Create multiple Amazon Kinesis Data Firehose delivery streams based on the quote type to deliver data streams to an Amazon Elasticsearch Service (Amazon ES) cluster. Configure the web application to send messages to the proper delivery stream. Configure each backend group of application servers to search for the messages from Amazon ES and process them accordingly.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample207' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation207' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#SQS_5'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#SQS_7'>Random</a></p><div class='collapse' id='collapseExample207'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Create a single Amazon Simple Notification Service (Amazon SNS) topic and subscribe the Amazon SQS queues to the SNS topic. Configure SNS message filtering to publish messages to the proper SQS queue based on the quote type. Configure each backend application server to work its own SQS queue.</div></div></div><div class='collapse' id='explanation207'><div class='card card&#45;body'><div>
It all depends on where you want to do the quote type classification i.e. in the app and send to a different/multiple SNS topics (B) or use SNS filtering to do the type classification (C). The question doesn't really give you enough info to make a clear choice but configuring SNS filtering is probably less work and easier to maintain than maintaining app code.

References:
Amazon Simple Notification Service > Developer Guide > Amazon SNS message filtering
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 11%;" aria-valuenow="11" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#SQS'>SQS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=SQS_5><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>SQS Question 5</p><br/>A company uses a payment processing system that requires messages for a particular payment ID to be received in the same order that they were sent Otherwise, the payments might be processed incorrectly.<br/><br/>Which actions should a solutions architect take to meet this requirement? (Select TWO.)<br/><br/>A. Write the messages to an Amazon DynamoDB table with the payment ID as the partition key<br/>B. Write the messages to an Amazon Kinesis data stream with the payment ID as the partition key.<br/>C. Write the messages to an Amazon ElastiCache for Memcached cluster with the payment ID as the key<br/>D. Write the messages to an Amazon Simple Queue Service (Amazon SQS) queue Set the message attribute to use the payment ID<br/>E. Write the messages to an Amazon Simple Queue Service (Amazon SQS) FIFO queue. Set the message group to use the payment ID<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample450' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#SQS_6'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#SQS_0'>Random</a></p><div class='collapse' id='collapseExample450'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Write the messages to an Amazon DynamoDB table with the payment ID as the partition key
<br><b>E. </b>Write the messages to an Amazon Simple Queue Service (Amazon SQS) FIFO queue. Set the message group to use the payment ID</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 13%;" aria-valuenow="13" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#SQS'>SQS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=SQS_6><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>SQS Question 6</p><br/>A company has developed a microservices application. It uses a client&#8211;facing API with Amazon API Gateway and multiple internal services hosted on Amazon EC2 instances to process user requests. The API is designed to support unpredictable surges in traffic, but internal services may become overwhelmed and unresponsive for a period of time during surges. A solutions architect needs to design a more reliable solution that reduces errors when internal services become unresponsive or unavailable.<br/><br/>Which solution meets these requirements?<br/><br/>A. Use AWS Auto Scaling to scale up internal services when there is a surge in traffic.<br/>B. Use different Availability Zones to host internal services. Send a notification to a system administrator when an internal service becomes unresponsive.<br/>C. Use an Elastic Load Balancer to distribute the traffic between internal services. Configure Amazon CloudWatch metrics to monitor traffic to internal services.<br/>D. Use Amazon Simple Queue Service (Amazon SQS) to store user requests as they arrive. Change the internal services to retrieve the requests from the queue for processing.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample285' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#SQS_7'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#SQS_32'>Random</a></p><div class='collapse' id='collapseExample285'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Use Amazon Simple Queue Service (Amazon SQS) to store user requests as they arrive. Change the internal services to retrieve the requests from the queue for processing.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 16%;" aria-valuenow="16" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#SQS'>SQS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=SQS_7><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>SQS Question 7</p><br/>A company has two applications: a sender application that sends messages with payloads to be processed and a processing application intended to receive messages with payloads. The company wants to implement an AWS service to handle messages between the two applications. The sender application can send about 1,000 messages each hour. The messages may take up to 2 days to be processed. If the messages fail to process, they must be retained so that they do not impact the processing of any remaining messages.<br/><br/>Which solution meets these requirements and is the MOST operationally efficient?<br/><br/>A. Set up an Amazon EC2 instance running a Redis database. Configure both applications to use the instance. Store, process, and delete the messages, respectively.<br/>B. Use an Amazon Kinesis data stream to receive the messages from the sender application. Integrate the processing application with the Kinesis Client Library (KCL).<br/>C. Integrate the sender and processor applications with an Amazon Simple Queue Service (Amazon SQS) queue. Configure a dead&#8211;letter queue to collect the messages that failed to process.<br/>D. Subscribe the processing application to an Amazon Simple Notification Service (Amazon SNS) topic to receive notifications to process. Integrate the sender application to write to the SNS topic.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample258' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#SQS_8'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#SQS_5'>Random</a></p><div class='collapse' id='collapseExample258'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Integrate the sender and processor applications with an Amazon Simple Queue Service (Amazon SQS) queue. Configure a dead-letter queue to collect the messages that failed to process.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 19%;" aria-valuenow="19" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#SQS'>SQS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=SQS_8><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>SQS Question 8</p><br/>A solutions architect is designing the cloud architecture for a new application being deployed on AWS. The process should run in parallel while adding and removing application nodes as needed based on the number of jobs to be processed. The processor application is stateless. The solutions architect must ensure that the application is loosely coupled and the job items are durably stored.<br/><br/>Which design should the solutions architect use?<br/><br/>A. Create an Amazon SNS topic to send the jobs that need to be processed. Create an Amazon Machine Image (AMI) that consists of the processor application. Create a launch configuration that uses the AMI. Create an Auto Scaling group using the launch configuration. Set the scaling policy for the Auto Scaling group to add and remove nodes based on CPU usage.<br/>B. Create an Amazon SQS queue to hold the jobs that need to be processed. Create an Amazon Machine Image (AMI) that consists of the processor application. Create a launch configuration that uses the AMI. Create an Auto Scaling group using the launch configuration. Set the scaling policy for the Auto Scaling group to add and remove nodes based on network usage.<br/>C. Create an Amazon SQS queue to hold the jobs that need to be processed. Create an Amazon Machine Image (AMI) that consists of the processor application. Create a launch template that uses the AMI. Create an Auto Scaling group using the launch template. Set the scaling policy for the Auto Scaling group to add and remove nodes based on the number of items in the SQS queue.<br/>D. Create an Amazon SNS topic to send the jobs that need to be processed. Create an Amazon Machine Image (AMI) that consists of the processor application. Create a launch template that uses the AMI. Create an Auto Scaling group using the launch template. Set the scaling policy for the Auto Scaling group to add and remove nodes based on the number of messages published to the SNS topic.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample189' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation189' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#SQS_9'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#SQS_12'>Random</a></p><div class='collapse' id='collapseExample189'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Create an Amazon SQS queue to hold the jobs that need to be processed. Create an Amazon Machine Image (AMI) that consists of the processor application. Create a launch template that uses the AMI. Create an Auto Scaling group using the launch template. Set the scaling policy for the Auto Scaling group to add and remove nodes based on the number of items in the SQS queue.</div></div></div><div class='collapse' id='explanation189'><div class='card card&#45;body'><div>
Amazon Simple Queue Service (SQS) is a fully managed message queuing service that enables you to decouple and scale microservices, distributed systems, and serverless applications. SQS eliminates the complexity and overhead associated with managing and operating message oriented middleware, and empowers developers to focus on differentiating work. Using SQS, you can send, store, and receive messages between software components at any volume, without losing messages or requiring other services to be available. Get started with SQS in minutes using the AWS console, Command Line Interface or SDK of your choice, and three simple commands.

SQS offers two types of message queues. Standard queues offer maximum throughput, best-effort ordering, and at-least-once delivery. SQS FIFO queues are designed to guarantee that messages are processed exactly once, in the exact order that they are sent.

Scaling Based on Amazon SQS
There are some scenarios where you might think about scaling in response to activity in an Amazon SQS queue. For example, suppose that you have a web app that lets users upload images and use them online. In this scenario, each image requires resizing and encoding before it can be published. The app runs on EC2 instances in an Auto Scaling group, and it's configured to handle your typical upload rates. Unhealthy instances are terminated and replaced to maintain current instance levels at all times. The app places the raw bitmap data of the images in an SQS queue for processing. It processes the images and then publishes the processed images where they can be viewed by users. The architecture for this scenario works well if the number of image uploads doesn't vary over time. But if the number of uploads changes over time, you might consider using dynamic scaling to scale the capacity of your Auto Scaling group.

In this case we need to find a durable and loosely coupled solution for storing jobs. Amazon SQS is ideal for this use case and can be configured to use dynamic scaling based on the number of jobs waiting in the queue.

To configure this scaling you can use the backlog per instance metric with the target value being the acceptable backlog per instance to maintain. You can calculate these numbers as follows: Backlog per instance: To calculate your backlog per instance, start with the ApproximateNumberOfMessages queue attribute to determine the length of the SQS queue (number of messages available for retrieval from the queue). Divide that number by the fleet's running capacity, which for an Auto Scaling group is the number of instances in the InService state, to get the backlog per instance.

Acceptable backlog per instance: To calculate your target value, first determine what your application can accept in terms of latency. Then, take the acceptable latency value and divide it by the average time that an EC2 instance takes to process a message.

This solution will scale EC2 instances using Auto Scaling based on the number of jobs waiting in the SQS queue.

CORRECT: "Create an Amazon SQS queue to hold the jobs that needs to be processed. Create an Amazon EC2 Auto Scaling group for the compute application. Set the scaling policy for the Auto Scaling group to add and remove nodes based on the number of items in the SQS queue" is the correct answer.

INCORRECT: "Create an Amazon SQS queue to hold the jobs that need to be processed. Create an Amazon EC2 Auto Scaling group for the compute application. Set the scaling policy for the Auto Scaling group to add and remove nodes based on network usage" is incorrect as scaling on network usage does not relate to the number of jobs waiting to be processed.

INCORRECT: "Create an Amazon SNS topic to send the jobs that need to be processed. Create an Amazon EC2 Auto Scaling group for the compute application. Set the scaling policy for the

Auto Scaling group to add and remove nodes based on CPU usage" is incorrect. Amazon SNS is a notification service so it delivers notifications to subscribers. It does store data durably but is less suitable than SQS for this use case. Scaling on CPU usage is not the best solution as it does not relate to the number of jobs waiting to be processed.

INCORRECT: "Create an Amazon SNS topic to send the jobs that need to be processed. Create an Amazon EC2 Auto Scaling group for the compute application. Set the scaling policy for the Auto Scaling group to add and remove nodes based on the number of messages published to the SNS topic" is incorrect. Amazon SNS is a notification service so it delivers notifications to subscribers. It does store data durably but is less suitable than SQS for this use case. Scaling on the number of notifications in SNS is not possible.

References:

Amazon EC2 Auto Scaling > User Guide > Scaling based on Amazon SQS</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 22%;" aria-valuenow="22" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#SQS'>SQS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=SQS_9><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>SQS Question 9</p><br/>A company is Re&#8211;architecting a strongly coupled application to be loosely coupled Previously the application used a request/response pattern to communicate between tiers. The company plans to use Amazon Simple Queue Service (Amazon SQS) to achieve decoupling requirements. The initial design contains one queue for requests and one for responses However, this approach is not processing all the messages as the application scales.<br/><br/>What should a solutions architect do to resolve this issue?<br/><br/>A. Configure a dead&#8211;letter queue on the ReceiveMessage API action of the SQS queue.<br/>B. Configure a FIFO queue, and use the message deduplication ID and message group I<br/>C. Create a temporary queue, with the Temporary Queue Client to receive each response message.<br/>D. Create a queue for each request and response on startup for each producer, and use a correlation ID message attribute.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample483' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#SQS_10'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#SQS_4'>Random</a></p><div class='collapse' id='collapseExample483'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Configure a dead-letter queue on the ReceiveMessage API action of the SQS queue.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 25%;" aria-valuenow="25" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#SQS'>SQS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=SQS_10><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>SQS Question 10</p><br/>A restaurant reservation application needs to access a waiting list.<br/><br/>When a customer tries to reserve a table, and none are available, the customer application will put the user on the waiting list, and the application will notify the customer when a table becomes free.<br/><br/>The waiting list must preserve the order in which customers were added to the waiting list. Which service should the solutions architect recommend to store this waiting list?<br/><br/>A. Amazon Simple Notification Service (Amazon SNS)<br/>B. AWS Step Functions invoking AWS Lambda functions<br/>C. A FIFO queue in Amazon Simple Queue Service (Amazon SQS)<br/>D. A standard queue in Amazon Simple Queue Service (Amazon SQS)<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample530' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#SQS_11'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#SQS_26'>Random</a></p><div class='collapse' id='collapseExample530'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>A FIFO queue in Amazon Simple Queue Service (Amazon SQS)</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 27%;" aria-valuenow="27" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#SQS'>SQS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=SQS_11><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>SQS Question 11</p><br/>A company runs an application that uses multiple Amazon EC2 instances to gather data from its users. The data is then processed and transferred to Amazon S3 for long&#8211;term storage. A review of the application shows that there were long periods of time when the EC2 instances were not being used. A solutions architect needs to design a solution that optimizes utilization and reduces costs.<br/><br/>Which solution meets these requirements?<br/><br/>A. Use Amazon EC2 in an Auto Scaling group with On&#8211;Demand instances.<br/>B. Build the application to use Amazon Lightsail with On&#8211;Demand Instances.<br/>C. Create an Amazon CloudWatch cron job to automatically stop the EC2 instances when there is no activity.<br/>D. Redesign the application to use an event&#8211;driven design with Amazon Simple Queue Service (Amazon SQS) and AWS Lambda.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample356' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#SQS_12'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#SQS_27'>Random</a></p><div class='collapse' id='collapseExample356'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Redesign the application to use an event-driven design with Amazon Simple Queue Service (Amazon SQS) and AWS Lambda.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 30%;" aria-valuenow="30" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#SQS'>SQS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=SQS_12><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>SQS Question 12</p><br/>A company has an automobile sales website that stores its listings in a database on Amazon RDS. When an automobile is sold, the listing needs to be removed from the website and the data must be sent to multiple target systems.<br/><br/>Which design should a solutions architect recommend?<br/><br/>A. Create an AWS Lambda function triggered when the database on Amazon RDS is updated to send the information to an Amazon Simple Queue Service (Amazon SQS) queue for the targets to consume.<br/>B. Create an AWS Lambda function triggered when the database on Amazon RDS is updated to send the information to an Amazon Simple Queue Service (Amazon SQS) FIFO queue for the targets to consume.<br/>C. Subscribe to an RDS event notification and send an Amazon Simple Queue Service (Amazon SQS) queue fanned out to multiple Amazon Simple Notification Service (Amazon SNS) topics. Use AWS Lambda functions to update the targets.<br/>D. Subscribe to an RDS event notification and send an Amazon Simple Notification Service (Amazon SNS) topic fanned out to multiple Amazon Simple Queue Service (Amazon SQS) queues. Use AWS Lambda functions to update the targets.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample224' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation224' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#SQS_13'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#SQS_2'>Random</a></p><div class='collapse' id='collapseExample224'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Create an AWS Lambda function triggered when the database on Amazon RDS is updated to send the information to an Amazon Simple Queue Service (Amazon SQS) queue for the targets to consume.</div></div></div><div class='collapse' id='explanation224'><div class='card card&#45;body'><div>
You can use AWS Lambda to process event notifications from an Amazon Relational Database Service (Amazon RDS) database. Amazon RDS sends notifications to an Amazon Simple Notification Service (Amazon SNS) topic, which you can configure to invoke a Lambda function. Amazon SNS wraps the message from Amazon RDS in its own event document and sends it to your function.

References:

AWS Lambda > Developer Guide > Using AWS Lambda with Amazon SNS
AWS Compute Blog > Messaging Fanout Pattern for Serverless Architectures Using Amazon SNS</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 33%;" aria-valuenow="33" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#SQS'>SQS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=SQS_13><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>SQS Question 13</p><br/>A company is developing a new machine learning model solution in AWS. The models are developed as independent microservices that fetch about 1 GB of model data from Amazon S3 at startup and load the data into memory. users access the models through an asynchronous API. Users can send a request or a batch of requests and specify where the result should be sent.<br/><br/>The company provides models to hundreds of users. The usage patterns for the models are irregular. somes models could be unused for days or weeks. other models could receive batches of thousands of requests at a time.<br/><br/>Which solution meets these requirements?<br/><br/>A. The requests from the API are sent to an Application Load Balancer (ALB). Models are deployed as AWS lambda functions invoked by the ALB<br/>B. The requests from the API are sent to the models Amazon Simple Queue Service (Amazon SOS) queue. Models are deployed as AWS Lambda functions triggered by SOS events. AWS auto scaling is enabled on Lambda to increase the number vCPUSs based on the SQS queue size.<br/>C. The requests from the API are sent to the model's Amazon simple Queue Service (Amazon SQS) queue. Model are deployed as Amazon Elastic container service ( AMAzon ECS) service reading from the queue. AWS App Mesh scales the instances of the ECS cluster based on the SQS queue size.<br/>D. The requests from the API are sent to the model's Amazon simple Queue Service (Amazon SQS) queue. Models are deployed as Amazon Elastics container service ( Amazon ECS) services reading from the queue. AWS Auto Scaling is enabled ECS for both the cluster and copies the service based on the queue size.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample709' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#SQS_14'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#SQS_28'>Random</a></p><div class='collapse' id='collapseExample709'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>The requests from the API are sent to the model's Amazon simple Queue Service (Amazon SQS) queue. Models are deployed as Amazon Elastics container service ( Amazon ECS) services reading from the queue. AWS Auto Scaling is enabled ECS for both the cluster and copies the service based on the queue size.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 36%;" aria-valuenow="36" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#SQS'>SQS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=SQS_14><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>SQS Question 14</p><br/>A company has a media catalog with metadata for each item in the catalog. Different types of metadata are extracted from the media items by an application running on AWS Lambda.<br/><br/>Metadata is extracted according to a number of rules, with the output stored in an Amazon ElastiCache for Redis cluster. The extraction process is done in batches and takes around 40 minutes to complete. The update process is triggered manually whenever the metadata extraction rules change.<br/><br/>The company wants to reduce the amount of time it takes to extract metadata from its media catalog. To achieve this, a solutions architect has split the single metadata extraction Lambda function into a Lambda function for each type of metadata.<br/><br/>Which additional steps should the solutions architect take to meet the requirements?<br/><br/>A. Create an AWS Step Functions workflow to run the Lambda functions in parallel. Create another Step Functions workflow that retrieves a list of media items and executes a metadata extraction workflow for each one.<br/>B. Create an AWS Batch compute environment for each Lambda function. Configure an AWS Batch job queue for the compute environment. Create a Lambda function to retrieve a list of media items and write each item to the job queue.<br/>C. Create an AWS Step Functions workflow to run the Lambda functions in parallel. Create a Lambda function to retrieve a list of media items and write each item to an Amazon SQS queue. Configure the SQS queue as an input to the Step Functions workflow.<br/>D. Create a Lambda function to retrieve a list of media items and write each item to an Amazon SQS queue. Subscribe the metadata extraction Lambda functions to the SQS queue with a large batch size.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample689' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#SQS_15'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#SQS_24'>Random</a></p><div class='collapse' id='collapseExample689'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Create an AWS Step Functions workflow to run the Lambda functions in parallel. Create a Lambda function to retrieve a list of media items and write each item to an Amazon SQS queue. Configure the SQS queue as an input to the Step Functions workflow.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 38%;" aria-valuenow="38" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#SQS'>SQS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=SQS_15><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>SQS Question 15</p><br/>A web application must persist order data to Amazon S3 to support near&#8211;real&#8211;time processing. A solutions architect needs create an architecture that is both scalable and fault tolerant.<br/><br/>Which solutions meet these requirements? (Select TWO)<br/><br/>A. Write the order event to an Amazon DynamoDB table. Use DynamoDB Streams to trigger an AWS Lambda function that parses the payload and writes the data to Amazon<br/>B. Write the order event to an Amazon Simple Queue Service (Amazon SQS) queue. Use the queue to trigger an AWS Lambda function that parses the payload and writes the data to Amazon S3.<br/>C. Write the order event to an Amazon Simple Notification Service (Amazon SNS) topic. Use the SNS topic to trigger an AWS Lambda function that parses the payload and writes the data to Amazon S3.<br/>D. Write the order event to an Amazon Simple Queue Service (Amazon SQS) queue. Use an Amazon EventBridge (Amazon CloudWatch Events) rule to trigger an AWS Lambda function that parses the payload and writes the data to Amazon S3.<br/>E. Write the order event to an Amazon Simple Notification Service (Amazon SNS) topic. Use an Amazon EventBridge (Amazon CloudWatch Events) rule to trigger an AWS Lambda function that parses the payload and writes the data to Amazon S3.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample692' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#SQS_16'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#SQS_31'>Random</a></p><div class='collapse' id='collapseExample692'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Write the order event to an Amazon DynamoDB table. Use DynamoDB Streams to trigger an AWS Lambda function that parses the payload and writes the data to Amazon
<br><b>B. </b>Write the order event to an Amazon Simple Queue Service (Amazon SQS) queue. Use the queue to trigger an AWS Lambda function that parses the payload and writes the data to Amazon S3.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 41%;" aria-valuenow="41" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#SQS'>SQS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=SQS_16><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>SQS Question 16</p><br/>A solutions architect is designing an application for a two&#8211;step order process. The first step is synchronous and must return to the user with little latency. The second step takes longer, so it will be implemented in a separate component. Orders must be processed exactly once and in the order in which they are received.<br/><br/>How should the solutions architect integrate these components?<br/><br/>A. Use Amazon SQS FIFO queues.<br/>B. Use an AWS Lambda function along with Amazon SQS standard queues.<br/>C. Create an SNS topic and subscribe an Amazon SQS FIFO queue to that topic.<br/>D. Create an SNS topic and subscribe an Amazon SQS Standard queue to that topic.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample372' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation372' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#SQS_17'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#SQS_22'>Random</a></p><div class='collapse' id='collapseExample372'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Use Amazon SQS FIFO queues.</div></div></div><div class='collapse' id='explanation372'><div class='card card&#45;body'><div>
"Standard queues provide at-least-once delivery, which means that each message is delivered at least once.

FIFO queues provide exactly-once processing, which means that each message is delivered once and remains available until a consumer processes it and deletes it. Duplicates are not introduced into the queue."

References:

Amazon Simple Queue Service > Developer Guide > What is Amazon Simple Queue Service?</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 44%;" aria-valuenow="44" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#SQS'>SQS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=SQS_17><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>SQS Question 17</p><br/>A company has a service that produces event data. The company wants to use AWS to process the event data as it is received. The data is written in a specific order that must be maintained throughout processing.<br/><br/>The company wants to implement a solution that minimizes operational overhead.<br/><br/>How should a solution architect accomplish this?<br/><br/>A. Create an Amazon Simple Queue Service (Amazon SQS) FIFO queue to hold messages. Set up an AWS Lambda function to process messages from the queue.<br/>B. Create an Amazon Simple Notification Service (Amazon SNS) topic to deliver notifications containing payloads to process. Configure an AWS Lambda function as a subscriber.<br/>C. Create an Amazon Simple Queue Service (Amazon SQS) standard queue to hold messages. Set up an AWS Lambda function to process messages from the queue independently.<br/>D. Create an Amazon Simple Notification Service (Amazon SNS) topic to deliver notifications containing payloads to process. Configure an Amazon Simple Queue Service (Amazon SQS) queue as a subscriber.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample303' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#SQS_18'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#SQS_29'>Random</a></p><div class='collapse' id='collapseExample303'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Create an Amazon Simple Queue Service (Amazon SQS) FIFO queue to hold messages. Set up an AWS Lambda function to process messages from the queue.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 47%;" aria-valuenow="47" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#SQS'>SQS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=SQS_18><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>SQS Question 18</p><br/>A company is designing a message&#8211;driven order processing application on AWS.<br/><br/>The application consists of many services and needs to communicate the results of its processing to multiple consuming services.<br/><br/>Each of the consuming services may take up to 5 days to receive the messages. Which process will meet these requirements?<br/><br/>A. The application sends the results of its processing to an Amazon Simple Notification Service (Amazon SNS) topic. Each consuming service subscribes to this SNS topic and consumes the results<br/>B. The application sends the results of its processing to an Amazon Simple Notification Service (Amazon SNS) topic. Each consuming service consumes the messages directly from its corresponding SNS topic.<br/>C. The application sends the results of its processing to an Amazon Simple Queue Service (Amazon SQS) queue. Each consuming service runs as an AWS Lambda function that consumes this single SQS queue.<br/>D. The application sends the results of its processing to an Amazon Simple Notification Service (Amazon SNS) topic. An Amazon Simple Queue Service (Amazon SQS) queue is created for each service and each queue is configured to be a subscriber of the SNS topic.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample716' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#SQS_19'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#SQS_34'>Random</a></p><div class='collapse' id='collapseExample716'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>The application sends the results of its processing to an Amazon Simple Queue Service (Amazon SQS) queue. Each consuming service runs as an AWS Lambda function that consumes this single SQS queue.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 50%;" aria-valuenow="50" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#SQS'>SQS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=SQS_19><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>SQS Question 19</p><br/>A company is developing a video conversion application hosted on AWS. The application will be available in two tiers: a free tier and a paid tier. Users in the paid tier will have their videos converted first and then the tree tier users will have their videos converted.<br/><br/>Which solution meets these requirements and is MOST cost&#8211;effective?<br/><br/>A. One FIFO queue for the paid tier and one standard queue for the free tier.<br/>B. A single FIFO Amazon Simple Queue Service (Amazon SQS) queue for all file types.<br/>C. A single standard Amazon Simple Queue Service (Amazon SQS) queue for all file types.<br/>D. Two standard Amazon Simple Queue Service (Amazon SQS) queues with one for the paid tier and one for the free tier.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample397' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation397' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#SQS_20'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#SQS_30'>Random</a></p><div class='collapse' id='collapseExample397'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Two standard Amazon Simple Queue Service (Amazon SQS) queues with one for the paid tier and one for the free tier.</div></div></div><div class='collapse' id='explanation397'><div class='card card&#45;body'><div>
In AWS, the queue service is the Simple Queue Service (SQS). Multiple SQS queues may be prepared to prepare queues for individual priority levels (with a priority queue and a secondary queue). Moreover, you may also use the message Delayed Send function to delay process execution.
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 52%;" aria-valuenow="52" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#SQS'>SQS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=SQS_20><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>SQS Question 20</p><br/>A development team is collaborating with another company to create an integrated product. The other company needs to access an Amazon Simple Queue Service (Amazon SQS) queue that is contained in the development team's account. The other company wants to poll the queue without giving up its own account permissions to do so.<br/><br/>How should a solutions architect provide access to the SQS queue?<br/><br/>A. Create an instance profile that provides the other company access to the SQS queue.<br/>B. Create an IAM policy that provides the other company access to the SQS queue.<br/>C. Create an SQS access policy that provides the other company access to the SQS queue.<br/>D. Create an Amazon Simple Notification Service (Amazon SNS) access policy that provides the other company access to the SQS queue.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample333' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#SQS_21'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#SQS_16'>Random</a></p><div class='collapse' id='collapseExample333'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Create an SQS access policy that provides the other company access to the SQS queue.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 55%;" aria-valuenow="55" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#SQS'>SQS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=SQS_21><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>SQS Question 21</p><br/>An online photo application lets users upload photos and perform image editing operations. The application offers two classes of service: free and paid. Photos submitted by paid users are processed before those submitted by free users. Photos are uploaded to Amazon S3 and the job information is sent to Amazon SQS.<br/><br/>Which configuration should a solutions architect recommend?<br/><br/>A. Use one SQS FIFO queue. Assign a higher priority to the paid photos so they are processed first.<br/>B. Use two SQS FIFO queues: one for paid and one for free. Set the free queue to use short polling and the paid queue to use long polling.<br/>C. Use two SQS standard queues: one for paid and one for free. Configure Amazon EC2 instances to prioritize polling for the paid queue over the free queue.<br/>D. Use one SQS standard queue. Set the visibility timeout of the paid photos to zero. Configure Amazon EC2 instances to prioritize visibility settings so paid photos are processed first.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample217' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#SQS_22'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#SQS_18'>Random</a></p><div class='collapse' id='collapseExample217'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Use one SQS FIFO queue. Assign a higher priority to the paid photos so they are processed first.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 58%;" aria-valuenow="58" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#SQS'>SQS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=SQS_22><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>SQS Question 22</p><br/>A company is working with an external vendor that requires write access to the company's Amazon Simple Queue Service (Amazon SQS) queue. The vendor has its own AWS account.<br/><br/>What should a solutions architect do to implement least privilege access?<br/><br/>A. Update the permission policy on the SQS queue to give write access to the vendor's AWS account.<br/>B. Create an IAM user with write access to the SQS queue and share the credentials for the IAM user.<br/>C. Update AWS Resource Access Manager to provide write access to the SQS queue from the vendor's AWS account.<br/>D. Create a cross&#8211;account role with access to all SQS queues and use the vendor's AWS account in the trust document for the role.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample319' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#SQS_23'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#SQS_21'>Random</a></p><div class='collapse' id='collapseExample319'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Create a cross-account role with access to all SQS queues and use the vendor's AWS account in the trust document for the role.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 61%;" aria-valuenow="61" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#SQS'>SQS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=SQS_23><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>SQS Question 23</p><br/>A company's operations team has an existing Amazon S3 bucket configured to notify an Amazon SQS queue when new objects are created within the bucket. The development team also wants to receive events when new objects are created. The existing operations team workflow must remain intact.<br/><br/>Which solution would satisfy these requirements?<br/><br/>A. Create another SQS queue. Update the S3 events in the bucket to also update the new queue when a new object is created.<br/>B. Create a new SQS queue that only allows Amazon S3 to access the queue. Update Amazon S3 to update this queue when a new object is created.<br/>C. Create an Amazon SNS topic and SQS queue for the bucket updates. Update the bucket to send events to the new topic. Updates both queues to poll Amazon SNS.<br/>D. Create an Amazon SNS topic and SQS queue for the bucket updates. Update the bucket to send events to the new topic. Add subscriptions for both queues in the topic.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample47' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#SQS_24'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#SQS_15'>Random</a></p><div class='collapse' id='collapseExample47'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Create an Amazon SNS topic and SQS queue for the bucket updates. Update the bucket to send events to the new topic. Add subscriptions for both queues in the topic.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 63%;" aria-valuenow="63" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#SQS'>SQS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=SQS_24><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>SQS Question 24</p><br/>A company is developing a new machine learning model solution in AWS. The models are developed as independent microservices that fetch about 1 GB of model data from Amazon S3 at startup and load the data into memory. Users access the models through an asynchronous API. Users can send a request or a batch of requests and specify where the results should be sent.<br/><br/>The company provides models to hundreds of users. The usage patterns for the models are irregular Some models could be unused for days or weeks. Other models could receive batches of thousands of requests at a time.<br/><br/>Which solution meets these requirements?<br/><br/>A. The requests from the API are sent to an Application Load Balancer (ALB). Models are deployed as AWS Lambda functions invoked by the ALB.<br/>B. The requests from the API are sent to the models Amazon Simple Queue Service (Amazon SQS) queue. Models are deployed as AWS Lambda functions triggered by SQS events AWS Auto Scaling is enabled on Lambda to increase the number of vCPUs based on the SQS queue size.<br/>C. The requests from the API are sent to the model's Amazon Simple Queue Service (Amazon SQS) queue. Models are deployed as Amazon Elastic Container Service (Amazon ECS) services reading from the queue AWS App Mesh scales the instances of the ECS cluster based on the SQS queue size.<br/>D. The requests from the API are sent to the models Amazon Simple Queue Service (Amazon SQS) queue. Models are deployed as Amazon Elastic Container Service (Amazon ECS) services reading from the queue AWS Auto Scaling is enabled on Amazon ECS for both the cluster and copies of the service based on the queue size.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample400' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#SQS_25'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#SQS_35'>Random</a></p><div class='collapse' id='collapseExample400'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>The requests from the API are sent to the models Amazon Simple Queue Service (Amazon SQS) queue. Models are deployed as Amazon Elastic Container Service (Amazon ECS) services reading from the queue AWS Auto Scaling is enabled on Amazon ECS for both the cluster and copies of the service based on the queue size.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 66%;" aria-valuenow="66" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#SQS'>SQS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=SQS_25><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>SQS Question 25</p><br/>A three&#8211;tier web application processes orders from customers. The web tier consists of Amazon EC2 instances behind an Application Load Balancer, a middle tier of three EC2 instances decoupled from the web tier using Amazon SQS, and an Amazon DynamoDB backend. At peak times, customers who submit orders using the site have to wait much longer than normal to receive confirmations due to lengthy processing times. A solutions architect needs to reduce these processing times.<br/><br/>Which action will be MOST effective in accomplishing this?<br/><br/>A. Replace the SQS queue with Amazon Kinesis Data Firehose.<br/>B. Use Amazon ElastiCache for Redis in front of the DynamoDB backend tier.<br/>C. Add an Amazon CloudFront distribution to cache the responses for the web tier.<br/>D. Use Amazon EC2 Auto Scaling to scale out the middle tier instances based on the SQS queue depth.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample79' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#SQS_26'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#SQS_20'>Random</a></p><div class='collapse' id='collapseExample79'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Use Amazon EC2 Auto Scaling to scale out the middle tier instances based on the SQS queue depth.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 69%;" aria-valuenow="69" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#SQS'>SQS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=SQS_26><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>SQS Question 26</p><br/>A company has an application that ingests incoming messages. These messages are then quickly consumed by dozens of other applications and microservices. The number of messages varies drastically and sometimes spikes as high as 100,000 each second. The company wants to decouple the solution and increase scalability.<br/><br/>Which solution meets these requirements?<br/><br/>A. Persist the messages to Amazon Kinesis Data Analytics. All the applications will read and process the messages.<br/>B. Deploy the application on Amazon EC2 instances in an Auto Scaling group, which scales the number of EC2 instances based on CPU metrics.<br/>C. Write the messages to Amazon Kinesis Data Streams with a single shard. All applications will read from the stream and process the messages.<br/>D. Publish the messages to an Amazon Simple Notification Service (Amazon SNS) topic with one or more Amazon Simple Queue Service (Amazon SQS) subscriptions. All applications then process the messages from the queues.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample283' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation283' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#SQS_27'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#SQS_11'>Random</a></p><div class='collapse' id='collapseExample283'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Publish the messages to an Amazon Simple Notification Service (Amazon SNS) topic with one or more Amazon Simple Queue Service (Amazon SQS) subscriptions. All applications then process the messages from the queues.</div></div></div><div class='collapse' id='explanation283'><div class='card card&#45;body'><div>
Q: How large can Amazon SQS message queues be?
A single Amazon SQS message queue can contain an unlimited number of messages. However, there is a 120,000 quota for the number of inflight messages for a standard queue and 20,000 for a FIFO queue. Messages are inflight after they have been received from the queue by a consuming component, but have not yet been deleted from the queue.

References:

Amazon SQS FAQs</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 72%;" aria-valuenow="72" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#SQS'>SQS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=SQS_27><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>SQS Question 27</p><br/>A solutions architect is redesigning a monolithic application to be a loosely coupled application composed of two microservices: Microservice A and Microservice B.<br/><br/>Microservice A places messages in a main Amazon Simple Queue Service (Amazon SQS) queue for Microservice B to consume. When Microservice B fails to process a message after four retries, the message needs to be removed from the queue and stored for further investigation.<br/><br/>What should the solutions architect do to meet these requirements?<br/><br/>A. Create an SQS dead&#8211;letter queue. Microservice B adds failed messages to that queue after it receives and fails to process the message four times.<br/>B. Create an SQS dead&#8211;letter queue. Configure the main SQS queue to deliver messages to the dead letter queue after the message has been received four times.<br/>C. Create an SQS queue for failed messages. Microservice A adds failed messages to that queue after Microservice B receives and fails to process the message four times.<br/>D. Create an SQS queue for failed messages. Configure the SQS queue for failed messages to pull messages from the main SQS queue after the original message has been received four times.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample325' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#SQS_28'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#SQS_6'>Random</a></p><div class='collapse' id='collapseExample325'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Create an SQS dead-letter queue. Configure the main SQS queue to deliver messages to the dead letter queue after the message has been received four times.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 75%;" aria-valuenow="75" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#SQS'>SQS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=SQS_28><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>SQS Question 28</p><br/>A company built a food ordering application that captures user data and stores it for future analysis. The application's static front end is deployed on an Amazon EC2 instance. The front&#8211;end application sends the requests to the backend application running on separate EC2 instance. The backend application then stores the data in Amazon RDS.<br/><br/>What should a solutions architect do to decouple the architecture and make it scalable?<br/><br/>A. Use Amazon S3 to serve the front&#8211;end application, which sends requests to Amazon EC2 to execute the backend application. The backend application will process and store the data in Amazon RDS.<br/>B. Use Amazon S3 to serve the front&#8211;end application and write requests to an Amazon Simple Notification Service (Amazon SNS) topic. Subscribe Amazon EC2 instances to the HTTP/HTTPS endpoint of the topic, and process and store the data in Amazon RDS.<br/>C. Use an EC2 instance to serve the front end and write requests to an Amazon SQS queue. Place the backend instance in an Auto Scaling group, and scale based on the queue depth to process and store the data in Amazon RDS.<br/>D. Use Amazon S3 to serve the static front&#8211;end application and send requests to Amazon API Gateway, which writes the requests to an Amazon SQS queue. Place the backend instances in an Auto Scaling group, and scale based on the queue depth to process and store the data in Amazon RDS.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample43' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation43' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#SQS_29'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#SQS_1'>Random</a></p><div class='collapse' id='collapseExample43'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Use Amazon S3 to serve the static front-end application and send requests to Amazon API Gateway, which writes the requests to an Amazon SQS queue. Place the backend instances in an Auto Scaling group, and scale based on the queue depth to process and store the data in Amazon RDS.</div></div></div><div class='collapse' id='explanation43'><div class='card card&#45;body'><div>
Keyword: Static + Decouple + Scalable Static=S3

Decouple=SQS Queue Scalable=ASG

Option B will not be there in the race due to Auto-Scaling unavailability. Option A will not be there in the race due to Decouple unavailability.

Option C & D will be in the race and Option D will be correct answers due to all 3 combination matches [Static=S3; Decouple=SQS Queue; Scalable=ASG] & Option C will loose due to Static option unavailability
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 77%;" aria-valuenow="77" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#SQS'>SQS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=SQS_29><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>SQS Question 29</p><br/>A mobile gaming company runs application servers on Amazon EC2 instances. The servers receive updates from players every 15 minutes. The mobile game creates a JSON object of the progress made in the game since the last update, and sends the JSON object to an Application Load Balancer. As the mobile game is played, game updates are being lost. The company wants to create a durable way to get the updates in older.<br/><br/>What should a solutions architect recommend to decouple the system?<br/><br/>A. Use Amazon Kinesis Data Streams to capture the data and store the JSON object in Amazon S3.<br/>B. Use Amazon Kinesis Data Firehose to capture the data and store the JSON object in Amazon S3.<br/>C. Use Amazon Simple Queue Service (Amazon SQS) FIFO queues to capture the data and EC2 instances to process the messages in the queue.<br/>D. Use Amazon Simple Notification Service (Amazon SNS) to capture the data and EC2 instances to process the messages sent to the Application Load Balancer.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample404' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#SQS_30'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#SQS_33'>Random</a></p><div class='collapse' id='collapseExample404'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Use Amazon Simple Queue Service (Amazon SQS) FIFO queues to capture the data and EC2 instances to process the messages in the queue.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 80%;" aria-valuenow="80" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#SQS'>SQS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=SQS_30><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>SQS Question 30</p><br/>A company has an asynchronous web application where Amazon API Gateway triggers AWS Lambda functions to perform write and update operations on an Amazon RDS DB instance. During periods of extreme use API Gateway and Lambda scale in response to the incoming workload but service outages occur due to congestion with Amazon RDS.<br/><br/>The company is seeking a cost&#8211;effective design to alleviate this congestion. What should a solutions architect recommend'?<br/><br/>A. implement RDS storage autoscaling with a larger instance type<br/>B. Create read replicas to alleviate me read requests on the database<br/>C. Use Amazon Kinesis to poll the incoming requests from API Gateway to the Lambda functions<br/>D. Use Amazon Simple Queue Service (Amazon SQS) to buffer the incoming requests before delivering them to the Lambda functions<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample516' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#SQS_31'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#SQS_9'>Random</a></p><div class='collapse' id='collapseExample516'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Use Amazon Simple Queue Service (Amazon SQS) to buffer the incoming requests before delivering them to the Lambda functions</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 83%;" aria-valuenow="83" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#SQS'>SQS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=SQS_31><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>SQS Question 31</p><br/>A company has an application running as a service in Amazon Elastic Container Service (Amazon EC2) using the Amazon launch type.<br/><br/>The application code makes AWS API calls to publish messages to Amazon Simple Queue Service (Amazon SQS).<br/><br/>What is the MOST secure method of giving the application permission to publish messages to Amazon SQS?<br/><br/>A. Use AWS Identity and Access Management (IAM) to grant SQS permissions to the role used by the launch configuration for the Auto Scaling group of the ECS cluster.<br/>B. Create a new IAM user with SQS permissions. The update the task definition to declare the access key ID and secret access key as environment variables.<br/>C. Create a new IAM role with SQS permissions. The update the task definition to use this role for the task role setting.<br/>D. Update the security group used by the ECS cluster to allow access to Amazon SQS<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample536' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#SQS_32'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#SQS_19'>Random</a></p><div class='collapse' id='collapseExample536'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Create a new IAM user with SQS permissions. The update the task definition to declare the access key ID and secret access key as environment variables.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 86%;" aria-valuenow="86" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#SQS'>SQS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=SQS_32><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>SQS Question 32</p><br/>A company is running an application on AWS to process weather sensor data that is stored in an Amazon S3 bucket.<br/><br/>Three batch jobs run hourly to process the data in the S3 bucket for different purposes.<br/><br/>The company wants to reduce the overall processing time by running the three applications in parallel using an event&#8211;based approach.<br/><br/>What should a solutions architect do to meet these requirements?<br/><br/>A. Enable S3 Event Notifications for new objects to an Amazon Simple Queue Service (Amazon SQS) FIFO queue. Subscribe all applications to the queue for processing<br/>B. Enable S3 Event Notifications for new objects to an Amazon Simple Queue Service (Amazon SQS) standard queue. Create an additional SQS queue for all applications and subscribe all applications to the initial queue for processing<br/>C. Enable S3 Event Notifications for new objects to separate Amazon Simple Queue Service (Amazon SQS) FIFO queues. Create an additional SQS queue for each application and subscribe each queue to the initial topic for processing<br/>D. Enable S3 Event Notifications for new objects to an Amazon Simple Notification Service (Amazon SNS) topic. Create an Amazon Simple Queue Service (Amazon SQS) queue for each application and subscribe each queue to the topic for processing<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample629' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#SQS_33'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#SQS_13'>Random</a></p><div class='collapse' id='collapseExample629'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Enable S3 Event Notifications for new objects to separate Amazon Simple Queue Service (Amazon SQS) FIFO queues. Create an additional SQS queue for each application and subscribe each queue to the initial topic for processing</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 88%;" aria-valuenow="88" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#SQS'>SQS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=SQS_33><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>SQS Question 33</p><br/>A web application runs on Amazon EC2 instances behind an Application Load Balancer. The application allows users to create custom reports of historical weather data. Generating a report can take up to 5 minutes. These long&#8211;running requests use many of the available incoming connections, making the system unresponsive to other users.<br/><br/>How can a solutions architect make the system more responsive?<br/><br/>A. Use Amazon SQS with AWS Lambda to generate reports.<br/>B. Increase the idle timeout on the Application Load Balancer to 5 minutes.<br/>C. Update the client&#8211;side application code to increase its request timeout to 5 minutes.<br/>D. Publish the reports to Amazon S3 and use Amazon CloudFront for downloading to the user.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample77' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#SQS_34'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#SQS_23'>Random</a></p><div class='collapse' id='collapseExample77'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Use Amazon SQS with AWS Lambda to generate reports.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 91%;" aria-valuenow="91" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#SQS'>SQS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=SQS_34><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>SQS Question 34</p><br/>A company wants to move a multi&#8211;tiered application from on&#8211;premises to the AWS Cloud to improve the application's performance. The application consists of application tiers that communicate with each other by way of RESTful services.<br/><br/>Transactions are dropped when one tier becomes overloaded. A solutions architect must design a solution that resolves these issues and modernizes the application.<br/><br/>Which solution meets these requirements and is the MOST operationally efficient?<br/><br/>A. Use Amazon API Gateway and direct transactions to the AWS Lambda functions as the application layer. Use Amazon Simple Queue Service (Amazon SQS) as the communication layer between application services.<br/>B. Use Amazon CloudWatch metrics to analyze the application performance history to determine the server's peak utilization during the performance failures. Increase the size of the application server's Amazon EC2 instances to meet the peak requirements.<br/>C. Use Amazon Simple Notification Service (Amazon SNS) to handle the messaging between application servers running on Amazon EC2 in an Auto Scaling group. Use Amazon CloudWatch to monitor the SNS queue length and scale up and down as required.<br/>D. Use Amazon Simple Queue Service (Amazon SQS) to handle the messaging between application servers running on Amazon EC2 in an Auto Scaling group. Use Amazon CloudWatch to monitor the SQS queue length and scale up when communication failures are detected.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample255' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#SQS_35'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#SQS_3'>Random</a></p><div class='collapse' id='collapseExample255'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Use Amazon Simple Queue Service (Amazon SQS) to handle the messaging between application servers running on Amazon EC2 in an Auto Scaling group. Use Amazon CloudWatch to monitor the SQS queue length and scale up when communication failures are detected.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 94%;" aria-valuenow="94" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#SQS'>SQS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=SQS_35><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>SQS Question 35</p><br/>A company has an application that posts messages to Amazon SQS. Another application polls the queue and processes the messages in an I/O&#8211;intensive operation. The company has a service level agreement (SLA) that specifies the maximum amount of time that can elapse between receiving the messages and responding to the users. Due to an increase in the number of messages, the company has difficulty meeting its SLA consistently.<br/><br/>What should a solutions architect do to help improve the application's processing time and ensure it can handle the load at any level?<br/><br/>A. Create an Amazon Machine Image (AMI) from the instance used for processing. Terminate the instance and replace it with a larger size.<br/>B. Create an Amazon Machine Image (AMI) from the instance used for processing. Terminate the instance and replace it with an Amazon EC2 Dedicated Instance.<br/>C. Create an Amazon Machine Image (AMI) from the instance used for processing. Create an Auto Scaling group using this image in its launch configuration. Configure the group with a target tracking policy to keep its aggregate CPU utilization below 70%.<br/>D. Create an Amazon Machine Image (AMI) from the instance used for processing. Create an Auto Scaling group using this image in its launch configuration. Configure the group with a target tracking policy based on the age of the oldest message in the SQS queue.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample118' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#SQS_36'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#SQS_14'>Random</a></p><div class='collapse' id='collapseExample118'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Create an Amazon Machine Image (AMI) from the instance used for processing. Create an Auto Scaling group using this image in its launch configuration. Configure the group with a target tracking policy based on the age of the oldest message in the SQS queue.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 97%;" aria-valuenow="97" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#SQS'>SQS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=SQS_36><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>SQS Question 36</p><br/>A company is planning a large event where a promotional offer will be introduced. The company's website is hosted on AWS and backed by an Amazon RDS for PostgreSQL DB instance. The website explains the promotion and includes a sign&#8211;up page that collects user information and preferences. Management expects large and unpredictable volumes of traffic periodically, which will create many database writes.<br/><br/>A solutions architect needs to build a solution that does not change the underlying data model and ensures that submissions are not dropped before they are committed to the database.<br/><br/>Which solutions meets these requirements?<br/><br/>A. Immediately before the event, scale up the existing DB instance to meet the anticipated demand. Then scale down after the event.<br/>B. Use Amazon SQS to decouple the application and database layers. Configure an AWS Lambda function to write items from the queue into the database.<br/>C. Migrate to Amazon DynamoDB and manage throughput capacity with automatic scaling.<br/>D. Use Amazon ElastiCache for Memcached to increase write capacity to the DB instance.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample686' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#SQS_37'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#SQS_10'>Random</a></p><div class='collapse' id='collapseExample686'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Use Amazon SQS to decouple the application and database layers. Configure an AWS Lambda function to write items from the queue into the database.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 100%;" aria-valuenow="100" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#SQS'>SQS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><a id=EFS><h2>EFS</h2></a> - 30 Questions <br><a href='#EFS'>EFS(30)</a> <a href='#' <i class='bi bi&#45;house'> &nbsp;Home</i><hr> </a><div class='row' id=EFS_1><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EFS Question 1</p><br/>A solutions architect is designing an elastic application that will have between 10 and 50 Amazon EC2 concurrent instances running depending on the load.<br/><br/>Each instance must mount storage that will read and write to the same 50 GB folder.<br/><br/>Which storage type meets the requirements?<br/><br/>A. Amazon S3<br/>B. Amazon Elastic File System (Amazon EFS)<br/>C. Amazon Amazon Elastic Block Store (Amazon EBS) volumes<br/>D. Amazon EC2 instance store<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample543' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EFS_2'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EFS_21'>Random</a></p><div class='collapse' id='collapseExample543'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Amazon Elastic File System (Amazon EFS)</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 3%;" aria-valuenow="3" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EFS'>EFS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EFS_2><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EFS Question 2</p><br/>A company is migrating a Linux&#8211;based web server group to AWS. The web servers must access files in a shared file store for some content to meet the migration date, minimal changes can be made.<br/><br/>What should a solutions architect do to meet these requirements?<br/><br/>A. Create an Amazon S3 Standard bucket with access to the web server.<br/>B. Configure an Amazon CloudFront distribution with an Amazon S3 bucket as the origin.<br/>C. Create an Amazon Elastic File System (Amazon EFS) volume and mount it on all web servers.<br/>D. Configure Amazon Elastic Block Store (Amazon EBS) Provisioned IOPS SSD (io1) volumes and mount them on all web servers.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample693' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EFS_3'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EFS_25'>Random</a></p><div class='collapse' id='collapseExample693'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Create an Amazon Elastic File System (Amazon EFS) volume and mount it on all web servers.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 6%;" aria-valuenow="6" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EFS'>EFS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EFS_3><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EFS Question 3</p><br/>A company uses on&#8211;premises servers to host its applications. The company is running out of storage capacity. The applications use both block storage and NFS storage. The company needs a high&#8211;performing solution that supports local caching without re&#8211;architecting its existing applications.<br/><br/>Which combination of actions should a solutions architect take to meet these requirements? (Choose two.)<br/><br/>A. Mount Amazon S3 as a file system to the on&#8211;premises servers.<br/>B. Deploy an AWS Storage Gateway file gateway to replace NFS storage.<br/>C. Deploy AWS Snowball Edge to provision NFS mounts to on&#8211;premises servers.<br/>D. Deploy an AWS Storage Gateway volume gateway to replace the block storage.<br/>E. Deploy Amazon Elastic Fife System (Amazon EFS) volumes and mount them to on&#8211;premises servers.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample313' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EFS_4'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EFS_14'>Random</a></p><div class='collapse' id='collapseExample313'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Deploy an AWS Storage Gateway volume gateway to replace the block storage.
<br><b>E. </b>Deploy Amazon Elastic Fife System (Amazon EFS) volumes and mount them to on-premises servers.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 10%;" aria-valuenow="10" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EFS'>EFS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EFS_4><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EFS Question 4</p><br/>A solutions architect is designing a solution that involves orchestrating a series of Amazon Elastic Container Service (Amazon ECS) task types running on Amazon EC2 instances that are part of an ECS cluster. The output and state data for all tasks needs to be stored.<br/><br/>The amount of data output by each task is approximately 10MB, and there could be hundreds of tasks running at a time. The system should be optimized for high&#8211;frequency reading and writing. As old outputs are archived and deleted, the storage size is not expected to exceed 1TB.<br/><br/>Which storage solution should the solutions architect recommend?<br/><br/>A. An Amazon DynamoDB table accessible by all ECS cluster instances.<br/>B. An Amazon Elastic File System (Amazon EFS) with Provisioned Throughput mode.<br/>C. An Amazon Elastic File System (Amazon EFS) file system with Bursting Throughput mode.<br/>D. An Amazon Elastic File System (Amazon EFS) volume mounted to the ECS cluster instances.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample683' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EFS_5'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EFS_17'>Random</a></p><div class='collapse' id='collapseExample683'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>An Amazon Elastic File System (Amazon EFS) file system with Bursting Throughput mode.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 13%;" aria-valuenow="13" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EFS'>EFS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EFS_5><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EFS Question 5</p><br/>A company is planning to migrate a legacy application to AWS. The application currently uses NFS to communicate to an on&#8211;premises storage solution to store application data. The application cannot be modified to use any other communication protocols other than NFS for this purpose.<br/><br/>Which storage solution should a solutions architect recommend for use after the migrations?<br/><br/>A. AWS DataSync<br/>B. Amazon Elastic Block Store (Amazon EBS)<br/>C. Amazon Elastic File System (Amazon EFS)<br/>D. Amazon EMR File System (Amazon EMRFS)<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample705' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EFS_6'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EFS_28'>Random</a></p><div class='collapse' id='collapseExample705'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Amazon Elastic File System (Amazon EFS)

References:

Amazon Elastic File System</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 16%;" aria-valuenow="16" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EFS'>EFS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EFS_6><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EFS Question 6</p><br/>A solutions architect is designing the cloud architecture for a new application being deployed to AWS. The application allows users to interactively download and upload files. Files older than 2 years will be accessed less frequently. The solutions architect needs to ensure that the application can scale to any number of files while maintaining high availability and durability.<br/><br/>Which scalable solutions should the solutions architect recommend? (Choose two.)<br/><br/>A. Store the files on Amazon S3 with a lifecycle policy that moves objects older than 2 years to S3 Glacier.<br/>B. Store the files on Amazon S3 with a lifecycle policy that moves objects older than 2 years to S3 Standard&#8211;Infrequent Access (S3 Standard&#8211;IA)<br/>C. Store the files on Amazon Elastic File System (Amazon EFS) with a lifecycle policy that moves objects older than 2 years to EFS Infrequent Access (EFS IA).<br/>D. Store the files in Amazon Elastic Block Store (Amazon EBS) volumes. Schedule snapshots of the volumes. Use the snapshots to archive data older than 2 years.<br/>E. Store the files in RAID&#8211;striped Amazon Elastic Block Store (Amazon EBS) volumes. Schedule snapshots of the volumes. Use the snapshots to archive data older than 2 years.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample104' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EFS_7'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EFS_2'>Random</a></p><div class='collapse' id='collapseExample104'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Store the files on Amazon S3 with a lifecycle policy that moves objects older than 2 years to S3 Glacier.
<br><b>C. </b>Store the files on Amazon Elastic File System (Amazon EFS) with a lifecycle policy that moves objects older than 2 years to EFS Infrequent Access (EFS IA).</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 20%;" aria-valuenow="20" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EFS'>EFS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EFS_7><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EFS Question 7</p><br/>A company is running a media store across multiple Amazon EC2 instances distributed across multiple Availability Zones in a single VPC.<br/><br/>The company wants a high&#8211;performing solution to share data between all the EC2 instances, and prefers to keep the data within the VPC only.<br/><br/>What should a solutions architect recommend?<br/><br/>A. Create an Amazon S3 bucket and call the service APIs from each instance's application.<br/>B. Create an Amazon S3 bucket and configure all instances to access it as a mounted volume.<br/>C. Configure an Amazon Elastic Block Store (Amazon EBS) volume and mount it across all instances.<br/>D. Configure an Amazon Elastic File System (Amazon EFS) file system and mount it across all instances.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample684' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EFS_8'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EFS_1'>Random</a></p><div class='collapse' id='collapseExample684'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Configure an Amazon Elastic File System (Amazon EFS) file system and mount it across all instances.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 23%;" aria-valuenow="23" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EFS'>EFS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EFS_8><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EFS Question 8</p><br/>A solutions architect is investigating AWS file storage solutions that can be used with a company's on&#8211;premises Linux servers and applications. The company has an existing VPN connection set up between the company's VPC and its on&#8211;premises network.<br/><br/>Which AWS services should the solutions architect use? (Select TWO)<br/><br/>A. AWS Backup<br/>B. AWS DataSync<br/>C. AWS Snowball Edge<br/>D. AWS Storage Gateway<br/>E. Amazon Elastic File System (Amazon EFS)<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample644' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EFS_9'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EFS_13'>Random</a></p><div class='collapse' id='collapseExample644'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>AWS Backup
<br><b>E. </b>Amazon Elastic File System (Amazon EFS)</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 26%;" aria-valuenow="26" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EFS'>EFS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EFS_9><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EFS Question 9</p><br/>An application running on an Amazon EC2 instance needs to securely access files on an Amazon Elastic File System (Amazon EFS) file system. The EFS files are stores using encryptions at rest.<br/><br/>Which solution for accessing the files in MOST secure?<br/><br/>A. Enable TLS when mounting Amazon EFS.<br/>B. Store the encryption key in the code of the application.<br/>C. Enable AWS Key Management Service (AKS KMS) when mounting Amazon EFS.<br/>D. Store the encryption key in an Amazon S3 bucket and use IAM roles to grand the EC2 instance access permission.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample697' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EFS_10'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EFS_22'>Random</a></p><div class='collapse' id='collapseExample697'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Enable AWS Key MAnagement Service (AKS KMS) when mounting Amazon EFS.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 30%;" aria-valuenow="30" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EFS'>EFS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EFS_10><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EFS Question 10</p><br/>A company wants to move its on&#8211;premises network, attached storage (NAS) to AWS. The company wants to make the data available to any Linux instances within its VPC and ensure changes are automatically synchronized across all instances accessing the data store. The majority of the data is accessed very rarely, and some files are accessed by multiple users at the same time.<br/>Which solution meets these requirements and is MOST cost&#8211;effective?<br/><br/>A. Create an Amazon Elastic Block Store (Amazon EBS) snapshot containing the data. Share it with users within the VPC.<br/>B. Create an Amazon S3 bucket that has a lifecycle policy set to transition the data to S3 Standard Infrequent Access (S3 Standard&#8211;IA) after the appropriate number of days.<br/>C. Create an Amazon Elastic File System (Amazon EFS) file system within the VPC. Set the throughput mode to Provisioned and to the required amount of IOPS to support concurrent usage.<br/>D. Create an Amazon Elastic File System (Amazon EFS) file system within the VPC. Set the lifecycle policy to transition the data to EFS Infrequent Access (EFS IA) after the appropriate number of days.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample393' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EFS_11'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EFS_5'>Random</a></p><div class='collapse' id='collapseExample393'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Create an Amazon Elastic File System (Amazon EFS) file system within the VP<br><b>C. </b>Set the lifecycle policy to transition the data to EFS Infrequent Access (EFS IA) after the appropriate number of days.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 33%;" aria-valuenow="33" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EFS'>EFS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EFS_11><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EFS Question 11</p><br/>A company has a build server that is in an Auto Scaling group and often has multiple Linux instances running. The build server requires consistent and mountable shared NFS storage for jobs and configurations.<br/><br/>Which storage option should a solutions architect recommend?<br/><br/>A. Amazon S3<br/>B. Amazon FSx<br/>C. Amazon Elastic Block Store (Amazon EBS)<br/>D. Amazon Elastic File System (Amazon EFS)<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample368' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EFS_12'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EFS_10'>Random</a></p><div class='collapse' id='collapseExample368'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Amazon Elastic File System (Amazon EFS)</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 36%;" aria-valuenow="36" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EFS'>EFS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EFS_12><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EFS Question 12</p><br/>A media company is using two video conversion tools that run on Amazon EC2 instances. One tool runs on Windows instances, and the other tool runs on Linux instances. Each video file is large in size and must be processed by both tools.<br/><br/>The company needs a storage solution that can provide a centralized file system that can be mounted on all the EC2 instances that are used in this process.<br/><br/>Which solution meets these requirements?<br/><br/>A. Use Amazon FSx for Windows File Server for the Windows instances. Use Amazon Elastic File System (Amazon EFS) with Max I/O performance mode for the Linux instances.<br/>B. Use Amazon FSx for Windows File Server for the Windows instances. Use Amazon FSx for Lustre for the Linux instances. Link both Amazon FSx file systems to the same Amazon S3 bucket.<br/>C. Use Amazon Elastic File System (Amazon EFS) with General Purpose performance mode for the Windows instances and the Linux instances<br/>D. Use Amazon FSx for Windows File Server for the Windows instances and the Linux instances.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample425' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EFS_13'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EFS_6'>Random</a></p><div class='collapse' id='collapseExample425'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Use Amazon Elastic File System (Amazon EFS) with General Purpose performance mode for the Windows instances and the Linux instances</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 40%;" aria-valuenow="40" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EFS'>EFS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EFS_13><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EFS Question 13</p><br/>A company seeks a storage solution for its application. The solution must be highly available and scalable.<br/><br/>The solution also must function as a file system, be mountable by multiple Linux instances in AWS and on&#8211;premises through native protocols, and have no minimum size requirements.<br/><br/>The company has set up a Site&#8211;to&#8211;Site VPN for access from its on&#8211;premises network to its VPC. Which storage solution meets these requirements?<br/><br/>A. Amazon FSx Multi&#8211;AZ deployments<br/>B. Amazon Elastic Block Store (Amazon EBS) Multi&#8211;Attach volumes<br/>C. Amazon Elastic File System (Amazon EFS) with multiple mount targets<br/>D. Amazon Elastic File System (Amazon EFS) with a single mount target and multiple access points<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample646' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EFS_14'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EFS_12'>Random</a></p><div class='collapse' id='collapseExample646'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Amazon Elastic File System (Amazon EFS) with multiple mount targets</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 43%;" aria-valuenow="43" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EFS'>EFS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EFS_14><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EFS Question 14</p><br/>A solutions architect needs to design a resilient solution for Windows users' home directories. The solution must provide fault tolerance, file&#8211;level backup and recovery, and access control, based upon the company's Active Directory.<br/><br/>Which storage solution meets these requirements?<br/><br/>A. Configure Amazon S3 to store the users' home directories. Join Amazon S3 to Active Directory.<br/>B. Configure a Multi&#8211;AZ file system with Amazon FSx for Windows File Server. Join Amazon FSx to Active Directory.<br/>C. Configure Amazon Elastic File System (Amazon EFS) for the users' home directories. Configure AWS Single Sign&#8211;On with Active Directory.<br/>D. Configure Amazon Elastic Block Store (Amazon EFS) to store the users' home directories. Configure AWS Single Sign&#8211;On with Active Directory.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample254' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EFS_15'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EFS_20'>Random</a></p><div class='collapse' id='collapseExample254'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Configure Amazon Elastic File System (Amazon EFS) for the users' home directories. Configure AWS Single Sign-On with Active Directory.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 46%;" aria-valuenow="46" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EFS'>EFS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EFS_15><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EFS Question 15</p><br/>A company is hosting a web application on AWS using a single Amazon EC2 instance that stores user uploaded documents in an Amazon EBS volume. For better scalability and availability, the company duplicated the architecture and created a second EC2 instance and EBS volume in another Availability Zone, placing both behind an Application Load Balancer. After completing this change, users reported that each time they refreshed the website, they could see one subset of their documents or the other, but never all of the documents at the same time.<br/><br/>What should a solutions architect propose to ensure users see all of their documents at once?<br/><br/>A. Copy the data so both EBS volumes contain all the documents.<br/>B. Configure the Application Load Balancer to direct a user to the server with the documents.<br/>C. Copy the data from both EBS volumes to Amazon EFS. Modify the application to save new documents to Amazon EFS.<br/>D. Configure the Application Load Balancer to send the request to both servers. Return each document from the correct server.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample31' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation31' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#EFS_16'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EFS_7'>Random</a></p><div class='collapse' id='collapseExample31'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Copy the data from both EBS volumes to Amazon EFS. Modify the application to save new documents to Amazon EFS.</div></div></div><div class='collapse' id='explanation31'><div class='card card&#45;body'><div>
Amazon EFS provides file storage in the AWS Cloud. With Amazon EFS, you can create a file system, mount the file system on an Amazon EC2 instance, and then read and write data to and from your file system. You can mount an Amazon EFS file system in your VPC, through the Network File System versions 4.0 and 4.1 (NFSv4) protocol. We recommend using a current generation Linux NFSv4.1 client, such as those found in the latest Amazon Linux, Redhat, and Ubuntu AMIs, in conjunction with the Amazon EFS Mount Helper. For instructions, see Using the amazon-efs-utils Tools.

For a list of Amazon EC2 Linux Amazon Machine Images (AMIs) that support this protocol, see NFS Support. For some AMIs, you'll need to install an NFS client to mount your file system on your Amazon EC2 instance. For instructions, see Installing the NFS Client.

You can access your Amazon EFS file system concurrently from multiple NFS clients, so applications that scale beyond a single connection can access a file system. Amazon EC2 instances running in multiple Availability Zones within the same AWS Region can access the file system, so that many users can access and share a common data source.

How Amazon EFS Works with Amazon EC2</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 50%;" aria-valuenow="50" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EFS'>EFS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EFS_16><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EFS Question 16</p><br/>A company's web application is using multiple Linux Amazon EC2 instances and storing data on Amazon EBS volumes. The company is looking for a solution to increase the resiliency of the application in case of a failure and to provide storage that complies with atomicity, consistency, isolation, and durability (ACID).<br/><br/>What should a solutions architect do to meet these requirements?<br/><br/>A. Launch the application on EC2 instances in each Availability Zone. Attach EBS volumes to each EC2 instance.<br/>B. Create an Application Load Balancer with Auto Scaling groups across multiple Availability Zones. Mount an instance store on each EC2 instance.<br/>C. Create an Application Load Balancer with Auto Scaling groups across multiple Availability Zones. Store data on Amazon EFS and mount a target on each instance.<br/>D. Create an Application Load Balancer with Auto Scaling groups across multiple Availability Zones. Store data using Amazon S3 One Zone&#8211;Infrequent Access (S3 One Zone&#8211;IA).<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample29' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation29' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#EFS_17'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EFS_15'>Random</a></p><div class='collapse' id='collapseExample29'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Create an Application Load Balancer with Auto Scaling groups across multiple Availability Zones. Store data on Amazon EFS and mount a target on each instance.</div></div></div><div class='collapse' id='explanation29'><div class='card card&#45;body'><div>
How Amazon EFS Works with Amazon EC2
The following illustration shows an example VPC accessing an Amazon EFS file system. Here, EC2 instances in the VPC have file systems mounted.

In this illustration, the VPC has three Availability Zones, and each has one mount target created in it. We recommend that you access the file system from a mount target within the same Availability Zone. One of the Availability Zones has two subnets. However, a mount target is created in only one of the subnets.



Benefits of Auto Scaling
Better fault tolerance. Amazon EC2 Auto Scaling can detect when an instance is unhealthy, terminate it, and launch an instance to replace it. You can also configure Amazon EC2 Auto Scaling to use multiple Availability Zones. If one Availability Zone becomes unavailable, Amazon EC2 Auto Scaling can launch instances in another one to compensate.

Better availability. Amazon EC2 Auto Scaling helps ensure that your application always has the right amount of capacity to handle the current traffic demand.

Better cost management. Amazon EC2 Auto Scaling can dynamically increase and decrease capacity as needed. Because you pay for the EC2 instances you use, you save money by launching instances when they are needed and terminating them when they aren't.

To increase the resiliency of the application the solutions architect can use Auto Scaling groups to launch and terminate instances across multiple availability zones based on demand. An application load balancer (ALB) can be used to direct traffic to the web application running on the EC2 instances.

Lastly, the Amazon Elastic File System (EFS) can assist with increasing the resilience of the application by providing a shared file system that can be mounted by multiple EC2 instances from multiple availability zones.

CORRECT: "Create an Application Load Balancer with Auto Scaling groups across multiple Availability Zones. Store data on Amazon EFS and mount a target on each instance" is the correct answer.

INCORRECT: "Launch the application on EC2 instances in each Availability Zone. Attach EBS volumes to each EC2 instance" is incorrect as the EBS volumes are single points of failure which are not shared with other instances.

INCORRECT: "Create an Application Load Balancer with Auto Scaling groups across multiple Availability Zones. Mount an instance store on each EC2 instance" is incorrect as instance stores are ephemeral data stores which means data is lost when powered down. Also, instance stores cannot be shared between instances.

INCORRECT: "Create an Application Load Balancer with Auto Scaling groups across multiple Availability Zones. Store data using Amazon S3 One Zone-Infrequent Access (S3 One Zone-IA)" is incorrect as there are data retrieval charges associated with this S3 tier. It is not a suitable storage tier for application files.

References:

Amazon Elastic File System Documentation
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 53%;" aria-valuenow="53" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EFS'>EFS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EFS_17><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EFS Question 17</p><br/>A company is planning to migrate a legacy application to AWS. The application currently uses NFS to communicate to an on&#8211;premises storage solution to store application data. The application cannot be modified to use any other communication protocols other than NFS for this purpose.<br/><br/>Which storage solution should a solutions architect recommend for use after the migration?<br/><br/>A. AWS DataSync<br/>B. Amazon Elastic Block Store (Amazon EBS)<br/>C. Amazon Elastic File System (Amazon EFS)<br/>D. Amazon EMR File System (Amazon EMRFS)<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample365' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EFS_18'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EFS_4'>Random</a></p><div class='collapse' id='collapseExample365'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Amazon Elastic File System (Amazon EFS)</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 56%;" aria-valuenow="56" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EFS'>EFS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EFS_18><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EFS Question 18</p><br/>A company has a build server that is in an Auto Scaling group and often has multiple Linux instances running.<br/><br/>The build server requires consistent shared NFS storage for jobs and configurations.<br/><br/>Which storage option should a solution architect recommend?<br/><br/>A. Amazon S3<br/>B. Amazon FSx<br/>C. Amazon Elastic Block Store (Amazon EBS)<br/>D. Amazon Elastic File System (Ama on EFS)<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample586' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EFS_19'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EFS_27'>Random</a></p><div class='collapse' id='collapseExample586'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Amazon Elastic File System (Ama on EFS)</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 60%;" aria-valuenow="60" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EFS'>EFS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EFS_19><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EFS Question 19</p><br/>A company has an application that uses Amazon Elastic File System (Amazon EFS) to store data. The files are 1 GB in size or larger and are accessed often only for the first few days after creation. The application data is shared across a cluster of Linux servers. The company wants to reduce storage costs for the application.<br/><br/>What should a solutions architect do to meet these requirements?<br/><br/>A. Implement Amazon FSx and mount the network drive on each server.<br/>B. Move the fees from Amazon EFS and store them locally on each Amazon EC2 instance.<br/>C. Configure a Lifecycle policy to move the files to the EFS Infrequent Access (IA) swage class after 7 days.<br/>D. Move the files to Amazon S3 with S3 lifecycle policies enabled. Rewrite the application to support mounting the S3 bucket.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample302' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EFS_20'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EFS_24'>Random</a></p><div class='collapse' id='collapseExample302'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Configure a Lifecycle policy to move the files to the EFS Infrequent Access (IA) swage class after 7 days.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 63%;" aria-valuenow="63" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EFS'>EFS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EFS_20><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EFS Question 20</p><br/>A solutions architect is designing a shared storage solution for a web application that is deployed across multiple Availability Zones.<br/><br/>The web application runs on Amazon EC2 instances in an Auto Scaling group.<br/><br/>The company anticipates making frequent changes to the content, so the solution must have strong consistency.<br/><br/>Which solution meets these requirements?<br/><br/>A. Create an Amazon S3 bucket to store the web content Use Amazon CloudFront to deliver the content.<br/>B. Create an Amazon Elastic File System (Amazon EFS) file system and mount it on the individual EC2 instances.<br/>C. Create a shared Amazon Elastic Block Store (Amazon EBS) volume and mount it on the individual EC2 instances.<br/>D. Use AWS DataSync to perform continuous synchronization of data between EC2 hosts in the Auto Scaling group.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample654' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EFS_21'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EFS_8'>Random</a></p><div class='collapse' id='collapseExample654'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Create an Amazon Elastic File System (Amazon EFS) file system and mount it on the individual EC2 instances.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 66%;" aria-valuenow="66" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EFS'>EFS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EFS_21><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EFS Question 21</p><br/>A company has two applications it wants to migrate to AWS. Both applications process a large set of files by accessing the same files at the same time. Both applications need to read the files with low latency.<br/><br/>Which architecture should a solutions architect recommend for this situation?<br/><br/>A. Configure two AWS Lambda functions to run the applications. Create an Amazon EC2 instance with an instance store volume to store the data.<br/>B. Configure two AWS Lambda functions to run the applications. Create an Amazon EC2 instance with an Amazon Elastic Block Store (Amazon EBS) volume to store the data.<br/>C. Configure one memory optimized Amazon EC2 instance to run both applications simultaneously. Create an Amazon Elastic Block Store (Amazon EBS) volume with Provisioned IOPS to store the data.<br/>D. Configure two Amazon EC2 instances to run both applications. Configure Amazon Elastic File System (Amazon EFS) with General Purpose performance mode and Bursting Throughput mode to store the data.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample67' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EFS_22'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EFS_16'>Random</a></p><div class='collapse' id='collapseExample67'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Configure two Amazon EC2 instances to run both applications. Configure Amazon Elastic File System (Amazon EFS) with General Purpose performance mode and Bursting Throughput mode to store the data.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 70%;" aria-valuenow="70" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EFS'>EFS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EFS_22><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EFS Question 22</p><br/>A solutions architect needs to design a resilient solution for Windows users' home directories. The solution must provide fault tolerance, file&#8211;level backup and recovery, and access control, based upon the company's Active Directory.<br/><br/>Which storage solution meets these requirements?<br/><br/>A. Configure Amazon S3 to store the users' home directories. Join Amazon S3 to Active Directory.<br/>B. Configure a Multi&#8211;AZ file system with Amazon FSx for Windows File Server Join Amazon FSx to Active Directory.<br/>C. Configure Amazon Elastic File System (Amazon EFS) for the users' home directories. Configure AWS Single Sign&#8211;On with Active Directory.<br/>D. Configure Amazon Elastic Block Store (Amazon EBS) to store the users' home directories Configure AWS Single Sign&#8211;On with Active Directory.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample485' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EFS_23'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EFS_26'>Random</a></p><div class='collapse' id='collapseExample485'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Configure Amazon Elastic File System (Amazon EFS) for the users' home directories. Configure AWS Single Sign-On with Active Directory.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 73%;" aria-valuenow="73" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EFS'>EFS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EFS_23><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EFS Question 23</p><br/>A solutions architect needs to host a high performance computing (HPC) workload in the AWS Cloud.<br/><br/>The workload will run on hundreds of Amazon EC2 instances and will require parallel access to a shared file system to enable distributed processing of large datasets. Datasets will be accessed across multiple instances simultaneously.<br/><br/>The workload requires access latency within 1 ms.<br/><br/>After processing has completed, engineer will need access to the dataset for manual postprocessing.<br/><br/>Which solution will meet these requirements?<br/><br/>A. Use Amazon Elastic File System (Amazon EFS) as a shared file system. Access the dataset from Amazon EFS.<br/>B. Mount an Amazon S3 bucket to serve as the shared file system Perform postprocessing directly from the S3 bucket<br/>C. Use Amazon FSx for Lustre as a shared file system. Link the file system to an Amazon S3 bucket for postprocessing.<br/>D. Configure AWS Resource Access Manager to share an Amazon S3 bucket so that it can be mounted to all instances for processing and postprocessing<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample647' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EFS_24'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EFS_11'>Random</a></p><div class='collapse' id='collapseExample647'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Use Amazon Elastic File System (Amazon EFS) as a shared file system. Access the dataset from Amazon EFS.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 76%;" aria-valuenow="76" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EFS'>EFS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EFS_24><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EFS Question 24</p><br/>A product team is creating a new application that will store a large amount of data. The data will be analyzed hourly and modified by multiple Amazon EC2 Linux instances. The application team believes the amount of space needed will continue to grow for the next 6 months.<br/><br/>Which set of actions should a solutions architect take to support these needs?<br/><br/>A. Store the data in an Amazon EBS volume. Mount the EBS volume on the application instances.<br/>B. Store the data in an Amazon EFS file system. Mount the file system on the application instances.<br/>C. Store the data in Amazon S3 Glacier. Update the vault policy to allow access to the application instances.<br/>D. Store the data in Amazon S3 Standard&#8211;Infrequent Access (S3 Standard&#8211;IA). Update the bucket policy to allow access to the application instances.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample7' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation7' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#EFS_25'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EFS_23'>Random</a></p><div class='collapse' id='collapseExample7'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Store the data in an Amazon EFS file system. Mount the file system on the application instances.</div></div></div><div class='collapse' id='explanation7'><div class='card card&#45;body'><div>
Amazon Elastic File System (Amazon EFS) provides a simple, scalable, fully managed elastic NFS file system for use with AWS Cloud services and on-premises resources. It is built to scale on demand to petabytes without disrupting applications, growing and shrinking automatically as you add and remove files, eliminating the need to provision and manage capacity to accommodate growth.

"The data will be analyzed hourly and modified by multiple Amazon EC2 Linux instances."

Amazon EFS is designed to provide massively parallel shared access to thousands of Amazon EC2 instances, enabling your applications to achieve high levels of aggregate throughput and IOPS with consistent low latencies.

Amazon EFS is well suited to support a broad spectrum of use cases from home directories to business-critical applications. Customers can use EFS to lift-and-shift existing enterprise applications to the AWS Cloud. Other use cases include big data analytics, web serving and content management, application development and testing, media and entertainment workflows, database backups, and container storage.

Amazon EFS is a regional service storing data within and across multiple Availability Zones (AZs) for high availability and durability. Amazon EC2 instances can access your file system across AZs, regions, and VPCs, while on-premises servers can access using AWS Direct Connect or AWS VPN.
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 80%;" aria-valuenow="80" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EFS'>EFS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EFS_25><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EFS Question 25</p><br/>A solutions architect is designing a solution that involves orchestrating a series of Amazon Elastic Container Service (Amazon ECS) task types running on Amazon EC2 instances that are part of an ECS cluster. The output and state data for all tasks needs to be stored. The amount of data output by each task is approximately 10 MB, and there could be hundreds of tasks running at a time. The system should be optimized for high&#8211;frequency reading and writing. As old outputs are archived and deleted, the storage size is not expected to exceed 1 TB.<br/><br/>Which storage solution should the solutions architect recommend?<br/><br/>A. An Amazon DynamoDB table accessible by all ECS cluster instances.<br/>B. An Amazon Elastic File System (Amazon EFS) with Provisioned Throughput mode.<br/>C. An Amazon Elastic File System (Amazon EFS) file system with Bursting Throughput mode.<br/>D. An Amazon Elastic Block Store (Amazon EBS) volume mounted to the ECS cluster instances.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample137' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EFS_26'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EFS_0'>Random</a></p><div class='collapse' id='collapseExample137'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>An Amazon Elastic File System (Amazon EFS) file system with Bursting Throughput mode.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 83%;" aria-valuenow="83" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EFS'>EFS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EFS_26><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EFS Question 26</p><br/>A solution architect is designing a shared storage solution for an Auto Scaling web application. The company anticipates making frequent changes to the content, so the solution must have strong consistency.<br/><br/>Which solution requires the LEAST amount of effort?<br/><br/>A. Create an Amazon S3 bucket to store the web content and use Amazon Cloudfront to deliver the content<br/>B. Create an Amazon Elastic File system (Amazon EFS) file system and mount it on the individual Amazon EC2 instance<br/>C. Create a shared Amazon Elastic Block Store (Amazon EBS) volume and mount it on the individual Amazon EC2 instance<br/>D. Use AWS Datasync to perform continuous synchronization of data between Amazon EC2 hosts in the Auto scaling group.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample710' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EFS_27'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EFS_18'>Random</a></p><div class='collapse' id='collapseExample710'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Create an Amazon Elastic File system ( Amazon EFS ) file system and mount it on the individual Amazon EC2 instance</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 86%;" aria-valuenow="86" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EFS'>EFS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EFS_27><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EFS Question 27</p><br/>A company wants to move its on&#8211;premises network, attached storage (NAS) to AWS. The company wants to make the data available to any Linux instances within its VPC and ensure changes are automatically synchronized across all instances accessing the data store. The majority of the data is accessed very rarely, and some files are accessed by multiple users at the same time.<br/>Which solution meets these requirements and is MOST cost&#8211;effective?<br/><br/>A. Create an Amazon Elastic Block Store (Amazon EBS) snapshot containing the data. Share it with users within the VP<br/>B. Create an Amazon S3 bucket that has a lifecycle policy set to transition the data to S3 Standard&#8211;Infrequent Access (S3 Standard&#8211;IA) after the appropriate number of days.<br/>C. Create an Amazon Elastic File System (Amazon EFS) file system within the VP<br/>D. Set the throughput mode to Provisioned and to the required amount of IOPS to support concurrent usage.<br/>E. Create an Amazon Elastic File System (Amazon EFS) file system within the VP<br/>F. Set the lifecycle policy to transition the data to £FS Infrequent Access (EFS IA) after the appropriate number of days.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample508' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EFS_28'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EFS_9'>Random</a></p><div class='collapse' id='collapseExample508'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Create an Amazon Elastic File System (Amazon EFS) file system within the VP</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 90%;" aria-valuenow="90" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EFS'>EFS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EFS_28><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EFS Question 28</p><br/>A company runs multiple Amazon EC2 Linux instances in a VPC with applications that use a hierarchical directory structure. The applications need to rapidly and concurrently read and write to shared storage.<br/><br/>How can this be achieved?<br/><br/>A. Create an Amazon EFS file system and mount it from each EC2 instance.<br/>B. Create an Amazon S3 bucket and permit access from all the EC2 instances in the VPC.<br/>C. Create a file system on an Amazon EBS Provisioned IOPS SSD (io1) volume. Attach the volume to all the EC2 instances.<br/>D. Create file systems on Amazon EBS volumes attached to each EC2 instance. Synchronize the Amazon EBS volumes across the different EC2 instances.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample195' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EFS_29'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EFS_29'>Random</a></p><div class='collapse' id='collapseExample195'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Create an Amazon EFS file system and mount it from each EC2 instance.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 93%;" aria-valuenow="93" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EFS'>EFS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EFS_29><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EFS Question 29</p><br/>A solutions architect needs to design a network that will allow multiple Amazon EC2 instances to access a common data source used for mission&#8211;critical data that can be accessed by all the EC2 instances simultaneously. The solution must be highly scalable, easy to implement, and support the NFS protocol.<br/><br/>Which solution meets these requirements?<br/><br/>A. Create an Amazon EFS file system. Configure a mount target in each Availability Zone. Attach each instance to the appropriate mount target.<br/>B. Create an additional EC2 instance and configure it as a file server. Create security group that allows communication between the instances and apply that to the additional instance.<br/>C. Create an Amazon S3 bucket with the appropriate permissions. Create a role in AWS IAM that grants the correct permissions to the S3 bucket. Attach the role to the EC2 instances that need access to the data.<br/>D. Create an Amazon EBS volume with the appropriate permissions. Create a role in AWS IAM that grants the correct permissions to the EBS volume. Attach the role to then EC2 instances that need access to the data.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample708' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EFS_30'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EFS_3'>Random</a></p><div class='collapse' id='collapseExample708'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Create an Amazon EFS file system. Configure a mount target in each Availability Zone. Attach each instance to the appropriate mount target.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 96%;" aria-valuenow="96" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EFS'>EFS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EFS_30><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EFS Question 30</p><br/>A solutions architect needs to design a network that will allow multiple Amazon EC2 instances to access a common data source used for mission&#8211;critical data that can be accessed by all the EC2 instances simultaneously. The solution must be highly scalable, easy to implement and support the NFS protocol.<br/><br/>Which solution meets these requirements?<br/><br/>A. Create an Amazon EFS file system. Configure a mount target in each Availability Zone. Attach each instance to the appropriate mount target.<br/>B. Create an additional EC2 instance and configure it as a file server. Create a security group that allows communication between the Instances and apply that to the additional instance.<br/>C. Create an Amazon S3 bucket with the appropriate permissions. Create a role in AWS IAM that grants the correct permissions to the S3 bucket. Attach the role to the EC2 Instances that need access to the data.<br/>D. Create an Amazon EBS volume with the appropriate permissions. Create a role in AWS IAM that grants the correct permissions to the EBS volume. Attach the role to the EC2 instances that need access to the data.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample384' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EFS_31'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EFS_19'>Random</a></p><div class='collapse' id='collapseExample384'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Create an Amazon EFS file system. Configure a mount target in each Availability Zone. Attach each instance to the appropriate mount target.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 100%;" aria-valuenow="100" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EFS'>EFS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><a id=EBS><h2>EBS</h2></a> - 22 Questions <br><a href='#EBS'>EBS(22)</a> <a href='#' <i class='bi bi&#45;house'> &nbsp;Home</i><hr> </a><div class='row' id=EBS_1><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EBS Question 1</p><br/>A company is building a web application that servers a content management system.<br/><br/>The content management system runs on Amazon EC2 instances behind an Application Load Balancer (ALB).<br/><br/>The EC2 instances run in an Auto Scaling group across Availability Zones.<br/><br/>Users are constantly adding and updating files, blogs, and other website assets in the content management system.<br/><br/>Which solution meets these requirements?<br/><br/>A. Update the EC2 user data in the Auto Scaling group lifecycle policy to copy the website assets from the EC2 instance that was launched most recently. Configure the ALB to make changes to the websites assets only in the newest EC2 instance.<br/>B. Copy the website assets to an Amazon Elastic File System (Amazon EFS) Me system. Configure each EC2 instance to mount the EFS m system locally. Configure the website hosting application to reference the website assets that are stored in the EFS file system.<br/>C. Copy the website assets to an Amazon S3 bucket. Ensure that each EC2 instance downloads the website assets from the S3 bucket to the attached Amazon Basic Block Store (Amazon EBS) volume. Run the S3 sync command once each hour to keep files up to date.<br/>D. Restore an Amazon Elastic Block Store (Amazon EBS) snapshot w.th the website assets. Attach the EBS snapshot as a secondary EBS volume when a new EBS EC2 instance is launched. Configure the website hosting application to reference the website assets that are stored in the secondary EBS volume.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample602' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EBS_2'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EBS_20'>Random</a></p><div class='collapse' id='collapseExample602'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Copy the website assets to an Amazon S3 bucket. Ensure that each EC2 instance downloads the website assets from the S3 bucket to the attached Amazon Basic Block Store (Amazon EBS) volume. Run the S3 sync command once each hour to keep files up to date.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 4%;" aria-valuenow="4" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EBS'>EBS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EBS_2><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EBS Question 2</p><br/>A company has many applications on Amazon EC2 instances running in Auto Scaling groups. Company policy requires that the data on the attached Amazon Elastic Block Store (Amazon EBS) volumes be retained.<br/><br/>Which action will meet these requirements without impacting performance?<br/><br/>A. Enable termination protection on the Amazon EC2 instances.<br/>B. Disable the DeleteOnTermination attribute for the Amazon EBS volumes.<br/>C. Use Amazon EC2 user data to set up a synchronization job for root volume.<br/>D. Change the Auto scaling health check to point to a source on the root volume.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample615' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EBS_3'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EBS_11'>Random</a></p><div class='collapse' id='collapseExample615'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Disable the DeleteOnTermination attribute for the Amazon EBS volumes.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 9%;" aria-valuenow="9" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EBS'>EBS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EBS_3><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EBS Question 3</p><br/>A company wants to run a static website served through Amazon CloudFront.<br/><br/>What is an advantage of storing the website content in an Amazon S3 bucket instead of an Amazon Elastic Block Store (Amazon EBS) volume?<br/><br/>A. S3 buckets are replicated globally, allowing for large scalability. EBS volumes are replicated only within an AWS Region.<br/>B. S3 is an origin for CloudFront. EBS volumes would need EC2 instances behind an Elastic Load Balancing load balancer to be an origin<br/>C. S3 buckets can be encrypted, allowing for secure storage of the web files. EBS volumes cannot be encrypted.<br/>D. S3 buckets support object&#8211;level read throttling, preventing abuse. EBS volumes do not provide object&#8211;level throttling.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample538' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EBS_4'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EBS_2'>Random</a></p><div class='collapse' id='collapseExample538'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>S3 is an origin for CloudFront. EBS volumes would need EC2 instances behind an Elastic Load Balancing load balancer to be an origin</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 13%;" aria-valuenow="13" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EBS'>EBS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EBS_4><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EBS Question 4</p><br/>A company hosts an application on an Amazon EC2 instance that requires a maximum of 200 GB storage space. The application is used infrequently, with peaks during mornings and evenings. Disk I/O varies, but peaks at 3,000 IOPS. The chief financial officer of the company is concerned about costs and has asked a solutions architect to recommend the most cost&#8211;effective storage option that does not sacrifice performance.<br/><br/>Which solution should the solutions architect recommend?<br/><br/>A. Amazon EBS Cold HDD (sc1)<br/>B. Amazon EBS General Purpose SSD (gp2)<br/>C. Amazon EBS Provisioned IOPS SSD (io1)<br/>D. Amazon EBS Throughput Optimized HDD (st1)<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample199' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation199' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#EBS_5'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EBS_10'>Random</a></p><div class='collapse' id='collapseExample199'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Amazon EBS General Purpose SSD (gp2)</div></div></div><div class='collapse' id='explanation199'><div class='card card&#45;body'><div>
General Purpose SSD (gp2) volumes offer cost-effective storage that is ideal for a broad range of workloads. These volumes deliver single-digit millisecond latencies and the ability to burst to 3,000 IOPS for extended periods of time.

Between a minimum of 100 IOPS (at 33.33 GiB and below) and a maximum of 16,000 IOPS (at 5,334 GiB and above), baseline performance scales linearly at 3 IOPS per GiB of volume size. AWS designs gp2 volumes to deliver their provisioned performance 99% of the time. A gp2 volume can range in size from 1 GiB to 16 TiB.

In this case the volume would have a baseline performance of 3 x 200 = 600 IOPS. The volume could also burst to 3,000 IOPS for extended periods. As the I/O varies, this should be suitable. CORRECT: "Amazon EBS General Purpose SSD (gp2)" is the correct answer.

INCORRECT: "Amazon EBS Provisioned IOPS SSD (io1) " is incorrect as this would be a more expensive option and is not required for the performance characteristics of this workload.

INCORRECT: "Amazon EBS Cold HDD (sc1)" is incorrect as there is no IOPS SLA for HDD volumes and they would likely not perform well enough for this workload.

INCORRECT: "Amazon EBS Throughput Optimized HDD (st1)" is incorrect as there is no IOPS SLA for HDD volumes and they would likely not perform well enough for this workload.

References:
Amazon Elastic Compute Cloud > User Guide for Linux Instances > Amazon EBS volume types
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 18%;" aria-valuenow="18" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EBS'>EBS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EBS_5><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EBS Question 5</p><br/>A company runs a legacy application with a single&#8211;tier architecture on an Amazon EC2 instance Disk I/O is low. With occasional small spikes during business hours. The company requires the instance to be stopped from 8 PM to 8 AM daily.<br/><br/>Which storage option is MOST appropriate for this workload?<br/><br/>A. Amazon EC2 instance storage<br/>B. Amazon EBS General Purpose SSD (gp2) storage<br/>C. Amazon S3<br/>D. Amazon EBS Provisioned IOPS SSD (io2) storage<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample656' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EBS_6'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EBS_9'>Random</a></p><div class='collapse' id='collapseExample656'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Amazon EBS General Purpose SSD (gp2) storage</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 22%;" aria-valuenow="22" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EBS'>EBS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EBS_6><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EBS Question 6</p><br/>A company is building a document storage application on AWS. The application runs on Amazon EC2 instances in multiple Availability Zones. The company requires the document store to be highly available.<br/><br/>The documents need to be returned immediately when requested. The lead engineer has configured the application to use Amazon Elastic Block Store (Amazon EBS) to store the documents, but is willing to consider other options to meet the availability requirement.<br/><br/>What should a solutions architect recommend?<br/><br/>A. Snapshot the EBS volumes regularly and build new volumes using those snapshots in additional Availability Zones.<br/>B. Use Amazon EBS for the EC2 instance root volumes. Configure the application to build the document store on Amazon S3.<br/>C. Use Amazon EBS for the EC2 instance root volumes. Configure the application to build the document store on Amazon S3 Glacier.<br/>D. Use at least three Provisioned IOPS EBS volumes for EC2 instances. Mount the volumes to the EC2 instances in a RAID 5 configuration.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample380' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EBS_7'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EBS_19'>Random</a></p><div class='collapse' id='collapseExample380'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Use Amazon EBS for the EC2 instance root volumes. Configure the application to build the document store on Amazon S3.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 27%;" aria-valuenow="27" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EBS'>EBS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EBS_7><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EBS Question 7</p><br/>A company is hosting a web application on AWS using a single Amazon EC2 instance that stores user uploaded documents in an Amazon EBS volume. For better scalability and availability, the company duplicated the architecture and created a second EC2 instance and EBS volume in another Availability Zone, placing both behind an Application Load Balancer. After completing this change, users reported that each time they refreshed the website, they could see one subset of their documents or the other, but never all of the documents at the same time.<br/><br/>What should a solutions architect propose to ensure users see all of their documents at once?<br/><br/>A. Copy the data so both EBS volumes contain all the documents.<br/>B. Configure the Application Load Balancer to direct a user to the server with the documents.<br/>C. Copy the data from both EBS volumes to Amazon EFS. Modify the application to save new documents to Amazon EFS.<br/>D. Configure the Application Load Balancer to send the request to both servers. Return each document from the correct server.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample31' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation31' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#EBS_8'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EBS_16'>Random</a></p><div class='collapse' id='collapseExample31'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Copy the data from both EBS volumes to Amazon EFS. Modify the application to save new documents to Amazon EFS.</div></div></div><div class='collapse' id='explanation31'><div class='card card&#45;body'><div>
Amazon EFS provides file storage in the AWS Cloud. With Amazon EFS, you can create a file system, mount the file system on an Amazon EC2 instance, and then read and write data to and from your file system. You can mount an Amazon EFS file system in your VPC, through the Network File System versions 4.0 and 4.1 (NFSv4) protocol. We recommend using a current generation Linux NFSv4.1 client, such as those found in the latest Amazon Linux, Redhat, and Ubuntu AMIs, in conjunction with the Amazon EFS Mount Helper. For instructions, see Using the amazon-efs-utils Tools.

For a list of Amazon EC2 Linux Amazon Machine Images (AMIs) that support this protocol, see NFS Support. For some AMIs, you'll need to install an NFS client to mount your file system on your Amazon EC2 instance. For instructions, see Installing the NFS Client.

You can access your Amazon EFS file system concurrently from multiple NFS clients, so applications that scale beyond a single connection can access a file system. Amazon EC2 instances running in multiple Availability Zones within the same AWS Region can access the file system, so that many users can access and share a common data source.

How Amazon EFS Works with Amazon EC2</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 31%;" aria-valuenow="31" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EBS'>EBS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EBS_8><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EBS Question 8</p><br/>You are trying to launch an EC2 instance, however the instance seems to go into a terminated status immediately. What would probably not be a reason that this is happening?<br/><br/>A. The AMI is missing a required part.<br/>B. The snapshot is corrupt.<br/>C. You need to create storage in EBS first.<br/>D. You've reached your volume limit.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample786' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation786' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#EBS_9'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EBS_17'>Random</a></p><div class='collapse' id='collapseExample786'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>You need to create storage in EBS first.</div></div></div><div class='collapse' id='explanation786'><div class='card card&#45;body'><div>
Amazon EC2 provides a virtual computing environments, known as an instance. After you launch an instance, AWS recommends that you check its status to confirm that it goes from the pending status to the running status, the not terminated status. The following are a few reasons why an Amazon EBS-backed instance might immediately terminate:

You've reached your volume limit. The AMI is missing a required part. The snapshot is corrupt.

References:

Amazon Elastic Compute Cloud > User Guide for Linux Instances > Instance terminates immediately</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 36%;" aria-valuenow="36" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EBS'>EBS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EBS_9><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EBS Question 9</p><br/>A solutions architect must design a solution for a persistent database that is being migrated from on&#8211;premises to AWS. The database requires 64,000 IOPS according to the database administrator. If possible, the database administrator wants to use a single Amazon Elastic Block Store (Amazon EBS) volume to host the database instance.<br/><br/>Which solution effectively meets the database administrator's criteria?<br/><br/>A. Use an instance from the I3 I/O optimized family and leverage local ephemeral storage to achieve the IOPS requirement.<br/>B. Create an Nitro&#8211;based Amazon EC2 instance with an Amazon EBS Provisioned IOPS SSD (io1) volume attached. Configure the volume to have 64,000 IOPS.<br/>C. Create and map an Amazon Elastic File System (Amazon EFS) volume to the database instance and use the volume to achieve the required IOPS for the database.<br/>D. Provision two volumes and assign 32,000 IOPS to each. Create a logical volume at the operating system level that aggregates both volumes to achieve the IOPS requirements.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample166' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EBS_10'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EBS_8'>Random</a></p><div class='collapse' id='collapseExample166'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Create an Nitro-based Amazon EC2 instance with an Amazon EBS Provisioned IOPS SSD (io1) volume attached. Configure the volume to have 64,000 IOPS.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 40%;" aria-valuenow="40" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EBS'>EBS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EBS_10><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EBS Question 10</p><br/>A company slops a cluster of Amazon EC2 instances over a weekend. The costs decrease, but they do not drop to zero.<br/><br/>Which resources could still be generating costs? (Select TWO.)<br/><br/>A. Elastic IP addresses<br/>B. Data transfer out<br/>C. Regional data transfers<br/>D. Amazon Elastic Block Store (Amazon EBS) volumes<br/>E. AWS Auto Scaling<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample562' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EBS_11'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EBS_3'>Random</a></p><div class='collapse' id='collapseExample562'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Elastic IP addresses
<br><b>D. </b>Amazon Elastic Block Store (Amazon EBS) volumes</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 45%;" aria-valuenow="45" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EBS'>EBS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EBS_11><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EBS Question 11</p><br/>A media company is evaluating the possibility of moving its systems to the AWS Cloud. The company needs at least 10 TB of storage with the maximum possible I/O performance for video processing. 300 TB of very durable storage for storing media content, and 900 TB of storage to meet requirements for archival media that is not in use anymore.<br/><br/>Which set of services should a solutions architect recommend to meet these requirements?<br/><br/>A. Amazon EBS for maximum performance, Amazon S3 for durable data storage, and Amazon S3 Glacier for archival storage<br/>B. Amazon EBS for maximum performance. Amazon EFS for durable data storage, and Amazon S3 Glacier for archival storage<br/>C. Amazon EC2 instance store for maximum performance, Amazon EFS for durable data storage, and Amazon S3 for archival storage<br/>D. Amazon EC2 instance store for maximum performance, Amazon S3 for durable data storage, and Amazon S3 Glacier for archival storage<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample735' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EBS_12'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EBS_12'>Random</a></p><div class='collapse' id='collapseExample735'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Amazon EBS for maximum performance, Amazon S3 for durable data storage, and Amazon S3 Glacier for archival storage</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 50%;" aria-valuenow="50" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EBS'>EBS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EBS_12><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EBS Question 12</p><br/>A company is deploying a production portal application on AWS. The database tier has structured data.<br/><br/>The company requires a solution that is easily manageable and highly available.<br/><br/>How can these requirements be met?<br/><br/>A. Deploy the database on multiple Amazon EC2 instances backed by Amazon Elastic Block Store (Amazon EBS) across multiple Availability Zones.<br/>B. Use Amazon RDS with a multiple Availability Zone option<br/>C. Use Amazon RDS with a single Availability Zone option and schedule periodic database snapshots.<br/>D. Use Amazon DynamoDB<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample572' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EBS_13'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EBS_6'>Random</a></p><div class='collapse' id='collapseExample572'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Deploy the database on multiple Amazon EC2 instances backed by Amazon Elastic Block Store (Amazon EBS) across multiple Availability Zones.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 54%;" aria-valuenow="54" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EBS'>EBS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EBS_13><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EBS Question 13</p><br/>A solutions architect needs to ensure that all Amazon Elastic Block Store (Amazon EBS) volumes restored from unencrypted EBC snapshots are encrypted.<br/><br/>What should the solutions architect do to accomplish this?<br/><br/>A. Enable EBS encryption by default for the AWS Region.<br/>B. Enable EBS encryption by default for the specific volumes.<br/>C. Create a new volume and specify the symmetric customer master key (CMK) to use for encryption.<br/>D. Create a new volume and specify the asymmetric customer master key (CMK) to use for encryption.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample228' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation228' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#EBS_14'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EBS_21'>Random</a></p><div class='collapse' id='collapseExample228'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Enable EBS encryption by default for the AWS Region.</div></div></div><div class='collapse' id='explanation228'><div class='card card&#45;body'><div>
Question asked is to ensure that all volumes restored are encrypted. So have to be "Enable encryption by default".
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 59%;" aria-valuenow="59" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EBS'>EBS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EBS_14><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EBS Question 14</p><br/>A company is deploying a public&#8211;facing global application on AWS using Amazon CloudFront. The application communicates with an external system. A solutions architect needs to ensure the data is secured during end&#8211;to&#8211;end transit and at rest.<br/><br/>Which combination of steps will satisfy these requirements? (Select TWO)<br/><br/>A. Create a public certificate for the required domain in AWS Certificate Manager and deploy it to CloudFront, an Application Load Balancer, and Amazon EC2 instances.<br/>B. Acquire a public certificate from a third&#8211;party vendor and deploy it to CloudFront, an Application Load Balancer, and Amazon EC2 instances.<br/>C. Provision Amazon EBS encrypted volumes using AWS KMS and ensure explicit encryption of data when writing to Amazon EBS.<br/>D. Use SSL or encrypt data while communicating with the external system using a VPN.<br/>E. Communicate with the external system using plaintext and use the VPN to encrypt the data in transit.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample688' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EBS_15'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EBS_14'>Random</a></p><div class='collapse' id='collapseExample688'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Provision Amazon EBS encrypted volumes using AWS KMS and ensure explicit encryption of data when writing to Amazon EBS.
<br><b>D. </b>Use SSL or encrypt data while communicating with the external system using a VPN.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 63%;" aria-valuenow="63" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EBS'>EBS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EBS_15><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EBS Question 15</p><br/>A company finds that, as its use of Amazon EC2 instances grows us Amazon Elastic Block Store (Amazon EDS) storage costs are increasing faster man expected.<br/><br/>Which EBS management practices would help reduce costs? (Select TWO. )<br/><br/>A. Convert the EBS volumes to an EC2 instance store.<br/>B. Monitor and enforce that the Delete on termination attribute is set to true for all EBS volumes, unless persistence requirements dictate otherwise.<br/>C. Purchase an EC2 Instance Savings Plan for an EBS volumes that are serving persistent business requirements.<br/>D. For EBS volumes needed for retention purposes that are not being actively used, take a snapshot and terminate the instance and volume.<br/>E. Convert the existing EBS volumes to EBS Provisio ed IOPS SSD (io1).<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample592' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EBS_16'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EBS_4'>Random</a></p><div class='collapse' id='collapseExample592'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Monitor and enforce that the Delete on termination attribute is set to true for all EBS volumes, unless persistence requirements dictate otherwise.
<br><b>D. </b>For EBS volumes needed for retention purposes that are not being actively used, take a snapshot and terminate the instance and volume.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 68%;" aria-valuenow="68" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EBS'>EBS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EBS_16><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EBS Question 16</p><br/>A solutions architect is deploying a distributed database on multiple Amazon EC2 instances. The database stores all data on multiple instances so it can withstand the loss of an instance. The database requires block storage with latency and throughput to support several million transactions per second per server.<br/><br/>Which storage solution should the solutions architect use?<br/><br/>A. Amazon EBS<br/>B. Amazon EC2 instance store<br/>C. Amazon EFS<br/>D. Amazon S3<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample9' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation9' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#EBS_17'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EBS_15'>Random</a></p><div class='collapse' id='collapseExample9'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Amazon EBS</div></div></div><div class='collapse' id='explanation9'><div class='card card&#45;body'><div>
Amazon Elastic Block Store (EBS) is an easy to use, high performance block storage service designed for use with Amazon Elastic Compute Cloud (EC2) for both throughput and transaction intensive workloads at any scale. A broad range of workloads, such as relational and non-relational databases, enterprise applications, containerized applications, big data analytics engines, file systems, and media workflows are widely deployed on Amazon EBS.

References:
https://quizform.net/exam/24/learning/14
Amazon Elastic Compute Cloud > User Guide for Linux Instances > Amazon EC2 instance store</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 72%;" aria-valuenow="72" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EBS'>EBS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EBS_17><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EBS Question 17</p><br/>A company is running a highly sensitive application on Amazon EC2 backed by an Amazon RDS database.<br/><br/>Compliance regulations mandate that all personally identifiable information (PII) be encrypted at rest.<br/><br/>Which solution should a solutions architect recommend to meet this requirement with the LEAST amount of changes to the infrastructure?<br/><br/>A. Deploy AWS Certificate Manager to generate certificates. Use the certificates to encrypt the database volume.<br/>B. Deploy AWS CloudHSM, generate encryption keys, and use the customer master key (CMK) to encrypt database volumes.<br/>C. Configure SSL encryption using AWS Key Management Service customer master keys (AWS KMS CMKs) to encrypt database volumes.<br/>D. Configure Amazon Elastic Block Store (Amazon EBS) encryption and Amazon RDS encryption with AWS Key Management Service (AWS KMS) keys to encrypt instance and database volumes.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample69' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EBS_18'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EBS_1'>Random</a></p><div class='collapse' id='collapseExample69'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Configure Amazon Elastic Block Store (Amazon EBS) encryption and Amazon RDS encryption with AWS Key Management Service (AWS KMS) keys to encrypt instance and database volumes.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 77%;" aria-valuenow="77" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EBS'>EBS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EBS_18><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EBS Question 18</p><br/>A financial company operates its production AWS environment in the us&#8211;east&#8211;1 Region and uses Amazon Elastic Block Store (Amazon EBS) snapshots to back up its instances.<br/><br/>To meet a compliance requirement, the company must maintain a secondary copy of all critical data at least 100 miles (160.9 km) away from its primary location.<br/><br/>What is the MOST cost&#8211;effective way for the company to meet this requirement?<br/><br/>A. Replicate the EBS snapshots to a different Availability Zone in us&#8211;east&#8211;1.<br/>B. Replicate the EBS snapshots to us&#8211;east&#8211;2.<br/>C. Replicate the EBS snapshots to us&#8211;west&#8211;1.<br/>D. Replicate the EBS snapshots to us&#8211;west&#8211;2<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample645' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EBS_19'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EBS_18'>Random</a></p><div class='collapse' id='collapseExample645'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Replicate the EBS snapshots to us-west-1.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 81%;" aria-valuenow="81" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EBS'>EBS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EBS_19><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EBS Question 19</p><br/>A company wants a storage option that enables its data science team to analyze its data on&#8211;premises and in the AWS Cloud. The team needs to be able to run statistical analyses by using the data on&#8211;premises and by using a fleet of Amazon EC2 instances across multiple Availability Zones.<br/><br/>What should a solutions architect do to meet these requirements?<br/><br/>A. Use an AWS Storage Gateway tape gateway to copy the on&#8211;premises files into Amazon S3.<br/>B. Use an AWS Storage Gateway volume gateway to copy the on&#8211;premises files into Amazon S3.<br/>C. Use an AWS Storage Gateway file gateway to copy the on&#8211;premises files to Amazon Elastic Block Store (Amazon EBS).<br/>D. Attach an Amazon Elastic File System (Amazon EFS) file system to the on&#8211;premises servers. Copy the files to Amazon EFS.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample386' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EBS_20'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EBS_13'>Random</a></p><div class='collapse' id='collapseExample386'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Use an AWS Storage Gateway file gateway to copy the on-premises files to Amazon Elastic Block Store (Amazon EBS).</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 86%;" aria-valuenow="86" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EBS'>EBS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EBS_20><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EBS Question 20</p><br/>A company runs an application on three very large Amazon EC2 instances.<br/><br/>In a single Availability Zone in the us&#8211;east&#8211;1 Region Multiple 16 TB Amazon Elastic Block Store (Amazon EBS) volumes are attached to each EC2 instance.<br/><br/>The operations team uses an AWS Lambda script triggered by a schedule&#8211;based Amazon EventBridge (Amazon CloudWatch Events) rule to stop the instances on evenings and weekends, and start the instances on weekday mornings.<br/><br/>Before deploying the solution, the company used the public AWS pricing documentation to estimate the overall costs of running this data warehouse solution 5 days a week for 10 hours a day.<br/><br/>When looking at monthly Cost Explorer charges for this new account, the overall charges are higher than the estimate.<br/><br/>What is the MOST likely cost factor that the company overlooked?<br/><br/>A. EC2 data transfer charges between the instances are much higher than expected<br/>B. EC2 and EBS rates are higher in us&#8211;east&#8211;1 than most other AWS Regions<br/>C. The Lambda charges to stop and start the instances are much higher than expected.<br/>D. The company is being billed for the EBS storage on nights and weekends<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample584' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EBS_21'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EBS_5'>Random</a></p><div class='collapse' id='collapseExample584'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>The company is being billed for the EBS storage on nights and weekends</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 90%;" aria-valuenow="90" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EBS'>EBS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EBS_21><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EBS Question 21</p><br/>Cost Explorer is showing charges higher than expected for Amazon Elastic Block Store (Amazon EBS) volumes connected to application servers in a production account.<br/><br/>A significant portion of the changes from Amazon EBS are from volumes that were created as Provisioned IOPS SSD (101) volume types Controlling costs is the highest priority for this application.<br/><br/>Which steps should the user take to analyze and reduce the EBS costs without incurring any application downtime? (Select TWO )<br/><br/>A. Use the Amazon EC2 ModifylnstanceAttribute action to enable EBS optimization on the application server instances<br/>B. Use the Amazon CloudWatch GetMetricData action to evaluate the read write operations and read/write bytes of each volume<br/>C. Use the Amazon EC2 ModifyVolume action to reduce the size of the underutilized 101 volumes<br/>D. Use the Amazon EC2 ModifyVolume action to change the volume type of the underutilized io1 volumes to General Purpose SSD (gp2)<br/>E. Use an Amazon S3 PutBucketPolicy action to migrate existing volume snapshots to Amazon S3 Glacier<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample621' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EBS_22'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EBS_7'>Random</a></p><div class='collapse' id='collapseExample621'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Use the Amazon EC2 ModifylnstanceAttribute action to enable EBS optimization on the application server instances
<br><b>D. </b>Use the Amazon EC2 ModifyVolume action to change the volume type of the underutilized io1 volumes to General Purpose SSD (gp2)</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 95%;" aria-valuenow="95" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EBS'>EBS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=EBS_22><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>EBS Question 22</p><br/>A media company is evaluating the possibility of moving its systems to the AWS Cloud. The company needs at least 10 TB of storage with the maximum possible I/O performance for video processing, 300 TB of very durable storage for storing media content, and 900 TB of storage to meet requirements for archival media that is not in use anymore.<br/><br/>Which set of services should a solutions architect recommend to meet these requirements?<br/><br/>A. Amazon EBS for maximum performance, Amazon S3 for durable data storage, and Amazon S3 Glacier for archival storage<br/>B. Amazon EBS for maximum performance, Amazon EFS for durable data storage, and Amazon S3 Glacier for archival storage<br/>C. Amazon EC2 instance store for maximum performance, Amazon EFS for durable data storage, and Amazon S3 for archival storage<br/>D. Amazon EC2 instance store for maximum performance, Amazon S3 for durable data storage, and Amazon S3 Glacier for archival storage<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample75' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#EBS_23'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#EBS_0'>Random</a></p><div class='collapse' id='collapseExample75'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Amazon EBS for maximum performance, Amazon S3 for durable data storage, and Amazon S3 Glacier for archival storage</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 100%;" aria-valuenow="100" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#EBS'>EBS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><a id=IAM><h2>IAM</h2></a> - 22 Questions <br><a href='#IAM'>IAM(22)</a> <a href='#' <i class='bi bi&#45;house'> &nbsp;Home</i><hr> </a><div class='row' id=IAM_1><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>IAM Question 1</p><br/>A solutions architect is using an AWS Cloud Formation template to deploy a three&#8211;tier web application. The web application consists of a web tier and an application tier that stores and retrieves user data in Amazon DynamoDB tables. The web and application tiers are hosted on Amazon EC2 instances, and the database tier is not publicly accessible. The application EC2 instances need to access the DynamoDB tables without exposing API credentials in the template.<br/><br/>What should the solutions architect do to meet these requirements?<br/><br/>A. Create an IAM role to read the DynamoOB tables. Associate the role with the application instances by reference an instance profile<br/>B. Create an IAM role that has the required permissions to read and write from the DynamoOB tables. Add the role to the EC2 instance profile and associate the instance profile with the apphcanon instances<br/>C. Use the parameter section in the AWS CkHidFormaton template to have the user input access and secret keys from an already&#8211;created IAM user mat has the required permissions to read and write from the DynamoOB tables<br/>D. Create an IAM user m the AWS CioudFormation template that has the required permissions to read and write from the DynamoOB tables. Use the GetAti function to retrieve the access and secret keys and pass them to the application instances through the user data<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample525' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#IAM_2'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#IAM_6'>Random</a></p><div class='collapse' id='collapseExample525'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Create an IAM role that has the required permissions to read and write from the DynamoOB tables. Add the role to the EC2 instance profile and associate the instance profile with the apphcanon instances</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 4%;" aria-valuenow="4" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#IAM'>IAM</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=IAM_2><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>IAM Question 2</p><br/>A marketing company is storing CSV files in an Amazon S3 bucket for statistical analysis. An application on an Amazon EC2 instance needs permission to efficiently process the CSV data stored in the S3 bucket.<br/><br/>Which action will MOST securely grant the EC2 instance access to the S3 bucket?<br/><br/>A. Attach a resource&#8211;based policy to the S3 bucket.<br/>B. Create an IAM user for the application with specific permissions to the S3 bucket.<br/>C. Associate an IAM role with least privilege permissions to the EC2 instance profile.<br/>D. Store AWS credentials directly on the EC2 instance for applications on the instance to use for API calls.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample153' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation153' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#IAM_3'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#IAM_18'>Random</a></p><div class='collapse' id='collapseExample153'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Associate an IAM role with least privilege permissions to the EC2 instance profile.</div></div></div><div class='collapse' id='explanation153'><div class='card card&#45;body'><div>
Keyword: Privilege Permission + IAM Role

AWS Identity and Access Management (IAM) enables you to manage access to AWS services and resources securely. Using IAM, you can create and manage AWS users and groups, and use permissions to allow and deny their access to AWS resources.

IAM is a feature of your AWS account offered at no additional charge. You will be charged only for use of other AWS services by your users.

IAM roles for Amazon EC2
Applications must sign their API requests with AWS credentials. Therefore, if you are an application developer, you need a strategy for managing credentials for your applications that run on EC2 instances. For example, you can securely distribute your AWS credentials to the instances, enabling the applications on those instances to use your credentials to sign requests, while protecting your credentials from other users. However, it's challenging to securely distribute credentials to each instance, especially those that AWS creates on your behalf, such as Spot Instances or instances in Auto Scaling groups. You must also be able to update the credentials on each instance when you rotate your AWS credentials.

We designed IAM roles so that your applications can securely make API requests from your instances, without requiring you to manage the security credentials that the applications use.

Instead of creating and distributing your AWS credentials, you can delegate permission to make API requests using IAM roles as follows:

Create an IAM role.

Define which accounts or AWS services can assume the role.

Define which API actions and resources the application can use after assuming the role. Specify the role when you launch your instance, or attach the role to an existing instance. Have the application retrieve a set of temporary credentials and use them.

For example, you can use IAM roles to grant permissions to applications running on your instances that need to use a bucket in Amazon S3. You can specify permissions for IAM roles by creating a policy in JSON format. These are similar to the policies that you create for IAM users. If you change a role, the change is propagated to all instances.

When creating IAM roles, associate least privilege IAM policies that restrict access to the specific API calls the application requires.

References:

AWS Identity and Access Management (IAM) FAQs
Amazon Elastic Compute Cloud > User Guide for Linux Instances > IAM roles for Amazon EC2

</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 9%;" aria-valuenow="9" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#IAM'>IAM</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=IAM_3><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>IAM Question 3</p><br/>A company has several web servers that need to frequently access a common Amazon RDS MySQL Multi&#8211;AZ instance.<br/><br/>The company wants a secure method for the web servers to connect to the database while meeting a security requirement to rotate user credentials frequently.<br/><br/>A company has several web servers that need to frequently access a common Amazon ROS MySQL Muto&#8211;AZ DB instance.<br/><br/>The company wants a secure method for the web servers to connect to the database while meeting a security requirement to rotate user credentials frequently.<br/><br/>Which solution meets these requirements?<br/><br/>A. Store the database user credentials in AWS Secrets Manager. Grant the necessary IAM permissions to allow the web servers to access AWS Secrets Manager<br/>B. Store the database user credentials m AWS Systems Manager OpsCenter. Grant the necessary IAM permissions to allow the web servers to access OpsCenter<br/>C. Store the database user credentials in a secure Amazon S3 bucket. Grant the necessary IAM permissions to allow the web servers to retrieve credentials and access the database<br/>D. Store the database user credentials in fries encrypted with AWS Key Management Service (AWS KMS) on the web server file system. The web server should be able to decrypt the files and access the database<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample517' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#IAM_4'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#IAM_12'>Random</a></p><div class='collapse' id='collapseExample517'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Store the database user credentials in AWS Secrets Manager. Grant the necessary IAM permissions to allow the web servers to access AWS Secrets Manager</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 13%;" aria-valuenow="13" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#IAM'>IAM</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=IAM_4><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>IAM Question 4</p><br/>A company has established a new AWS account. The account is newly provisioned and no changed have been made to the default settings. The company is concerned about the security of the AWS account root user.<br/><br/>What should be done to secure the root user?<br/><br/>A. Create IAM users for daily administrative tasks. Disable the root user.<br/>B. Create IAM users for daily administrative tasks. Enable multi&#8211;factor authentication on the root user.<br/>C. Generate an access key for the root user. Use the access key for daily administration tasks instead of the AWS Management Console.<br/>D. Provide the root user credentials to the most senior solutions architect. Have the solutions architect use the root user for daily administration tasks.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample92' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#IAM_5'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#IAM_3'>Random</a></p><div class='collapse' id='collapseExample92'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Create IAM users for daily administrative tasks. Enable multi-factor authentication on the root user.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 18%;" aria-valuenow="18" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#IAM'>IAM</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=IAM_5><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>IAM Question 5</p><br/>A company has two AWS accounts: Production and Development. There are code changes ready in the Development account to push to the Production account. In the alpha phase, only two senior developers on the development team need access to the Production account. In the beta phase, more developers might need access to perform testing as well.<br/><br/>What should a solutions architect recommend?<br/><br/>A. Create two policy documents using the AWS Management Console in each account. Assign the policy to developers who need access.<br/>B. Create an IAM role in the Development account. Give one IAM role access to the Production account. Allow developers to assume the role.<br/>C. Create an IAM role in the Production account with the trust policy that specifies the Development account. Allow developers to assume the role.<br/>D. Create an IAM group in the Production account and add it as a principal in the trust policy that specifies the Production account. Add developers to the group.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample306' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#IAM_6'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#IAM_16'>Random</a></p><div class='collapse' id='collapseExample306'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Create an IAM group in the Production account and add it as a principal in the trust policy that specifies the Production account. Add developers to the group.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 22%;" aria-valuenow="22" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#IAM'>IAM</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=IAM_6><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>IAM Question 6</p><br/>A company has enabled AWS CloudTrail logs to deliver log files to an Amazon S3 bucket for each of its developer accounts. The company has created a central AWS account for streamlining management and audit reviews. An internal auditor needs to access the CloudTrail logs, yet access needs to be restricted for all developer account users. The solution must be secure and optimized.<br/><br/>How should a solutions architect meet these requirements?<br/><br/>A. Configure an AWS Lambda function in each developer account to copy the log files to the central account. Create an IAM role in the central account for the auditor. Attach an IAM policy providing read only permissions to the bucket.<br/>B. Configure CloudTrail from each developer account to deliver the log files to an S3 bucket in the central account. Create an IAM user in the central account for the auditor. Attach an IAM policy providing full permissions to the bucket.<br/>C. Configure CloudTrail from each developer account to deliver the log files to an S3 bucket in the central account. Create an IAM role in the central account for the auditor. Attach an IAM policy providing read only permissions to the bucket.<br/>D. Configure an AWS Lambda function in the central account to copy the log files from the S3 bucket in each developer account. Create an IAM user in the central account for the auditor. Attach an IAM policy providing full permissions to the bucket.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample71' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#IAM_7'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#IAM_19'>Random</a></p><div class='collapse' id='collapseExample71'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Configure CloudTrail from each developer account to deliver the log files to an S3 bucket in the central account. Create an IAM role in the central account for the auditor. Attach an IAM policy providing read only permissions to the bucket.

 Go to dashboard</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 27%;" aria-valuenow="27" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#IAM'>IAM</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=IAM_7><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>IAM Question 7</p><br/>An application running on an Amazon EC2 instance needs to access an Amazon DynamoDB table. Both the EC2 instance and the DynamoDB table are in the same AWS account. A solutions architect must configure the necessary permissions.<br/><br/>Which solution will allow least privilege access to the DynamoDB table from the EC2 instance?<br/><br/>A. Create an IAM role with the appropriate policy to allow access to the DynamoDB table. Create an instance profile to assign this IAM role to the EC2 instance.<br/>B. Create an IAM role with the appropriate policy to allow access to the DynamoDB table. Add the EC2 instance to the trust relationship policy document to allow it to assume the role.<br/>C. Create an IAM user with the appropriate policy to allow access to the DynamoDB table. Store the credentials in an Amazon S3 bucket and read them from within the application code directly.<br/>D. Create an IAM user with the appropriate policy to allow access to the DynamoDB table. Ensure that the application stores the IAM credentials securely on local storage and uses them to make the DynamoDB calls.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample136' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#IAM_8'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#IAM_0'>Random</a></p><div class='collapse' id='collapseExample136'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Create an IAM role with the appropriate policy to allow access to the DynamoDB table. Create an instance profile to assign this IAM role to the EC2 instance.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 31%;" aria-valuenow="31" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#IAM'>IAM</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=IAM_8><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>IAM Question 8</p><br/>A company has an application workflow that uses an AWS Lambda function to download and decrypt files from Amazon S3.<br/><br/>These files are encrypted using AWS Key Management Service Customer Master Keys (AWS KMS CMKs).<br/><br/>A solutions architect needs to design a solution that will ensure the required permissions are set correctly.<br/><br/>Which combination of actions accomplish this? (Select TWO)<br/><br/>A. Attach the kms.decrypt permission to the Lambda function's resource policy.<br/>B. Grant the decrypt permission for the Lambda IAM role in the KMS key's policy.<br/>C. Grant the decrypt permission for the Lambda resource policy in the KMS key's policy.<br/>D. Create a new IAM policy with the kms:decrypt permission and attach the policy to the Lambda function.<br/>E. Create a new IAM role with the kms decrypt permission and attach the execution role to the Lambda function.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample691' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#IAM_9'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#IAM_9'>Random</a></p><div class='collapse' id='collapseExample691'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Grant the decrypt permission for the Lambda IAM role in the KMS key's policy.
<br><b>E. </b>Create a new IAM role with the kms decrypt permission and attach the execution role to the Lambda function.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 36%;" aria-valuenow="36" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#IAM'>IAM</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=IAM_9><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>IAM Question 9</p><br/>A company has an application workflow that uses an AWS Lambda function to download and decrypt files from Amazon S3. These files are encrypted using AWS Key Management Service Customer Master Keys (AWS KMS CMKs). A solutions architect needs to design a solution that will ensure the required permissions are set correctly.<br/><br/>Which combination of actions accomplish this? (Choose two.)<br/><br/>A. Attach the kms:decrypt permission to the Lambda function's resource policy.<br/>B. Grant the decrypt permission for the Lambda IAM role in the KMS key's policy.<br/>C. Grant the decrypt permission for the Lambda resource policy in the KMS key's policy.<br/>D. Create a new IAM policy with the kms:decrypt permission and attach the policy to the Lambda function.<br/>E. Create a new IAM role with the kms:decrypt permission and attach the execution role to the Lambda function.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample358' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#IAM_10'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#IAM_4'>Random</a></p><div class='collapse' id='collapseExample358'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Grant the decrypt permission for the Lambda IAM role in the KMS key's policy.
<br><b>E. </b>Create a new IAM role with the kms:decrypt permission and attach the execution role to the Lambda function.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 40%;" aria-valuenow="40" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#IAM'>IAM</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=IAM_10><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>IAM Question 10</p><br/>An engineering team is developing and deploying AWS Lambda functions. The team needs to create roles and manage policies in AWS IAM to configure the permissions of the Lambda functions.<br/><br/>How should the permissions for the team be configured so they also adhere to the concept of least privilege?<br/><br/>A. Create an IAM role with a managed policy attached. Allow the engineering team and the Lambda functions to assume this role.<br/>B. Create an IAM group for the engineering team with an IAMFullAccess policy attached. Add all the users from the team to this IAM group.<br/>C. Create an execution role for the Lambda functions. Attach a managed policy that has permission boundaries specific to these Lambda functions.<br/>D. Create an IAM role with a managed policy attached that has permission boundaries specific to the Lambda functions. Allow the engineering team to assume this role.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample361' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#IAM_11'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#IAM_10'>Random</a></p><div class='collapse' id='collapseExample361'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Create an IAM role with a managed policy attached. Allow the engineering team and the Lambda functions to assume this role.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 45%;" aria-valuenow="45" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#IAM'>IAM</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=IAM_11><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>IAM Question 11</p><br/>A user wants to list the IAM role that is attached to their Amazon EC2 instance. The user has login access to the EC2 instance but does not have IAM permissions.<br/><br/>What should a solutions architect do to retrieve this information?<br/><br/>A. Run the following EC2 command: curl http://169.254.169.254/latest/meta&#8211;data/iam/info<br/>B. Run the following EC2 command: curl http://169.254.169.254/latest/user&#8211;data/iam/info<br/>C. Run the following EC2 command: http://169.254.169.254/latest/dynamic/instance&#8211;identity/<br/>D. Run the following AWS CLI command: aws iam get&#8211;instance&#8211;profile &#8211;&#8211;instance&#8211;profile&#8211;name ExampleInstanceProfile<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample289' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#IAM_12'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#IAM_11'>Random</a></p><div class='collapse' id='collapseExample289'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Run the following EC2 command: curl http://169.254.169.254/latest/meta-data/iam/info

References:

Amazon Elastic Compute Cloud > User Guide for Linux Instances > IAM roles for Amazon EC2</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 50%;" aria-valuenow="50" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#IAM'>IAM</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=IAM_12><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>IAM Question 12</p><br/>A company runs an application using Amazon ECS. The application creates resized versions of an original image and then makes Amazon S3 API calls to store the resized images in Amazon S3. How can a solutions architect ensure that the application has permission to access Amazon S3?<br/><br/>A. Update the S3 role in AWS IAM to allow read/write access from Amazon ECS, and then relaunch the container.<br/>B. Create an IAM role with S3 permissions, and then specify that role as the taskRoleArn in the task definition.<br/>C. Create a security group that allows access from Amazon ECS to Amazon S3, and update the launch configuration used by the ECS cluster.<br/>D. Create an IAM user with S3 permissions, and then relaunch the Amazon EC2 instances for the ECS cluster while logged in as this account.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample204' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#IAM_13'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#IAM_20'>Random</a></p><div class='collapse' id='collapseExample204'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Create an IAM role with S3 permissions, and then specify that role as the taskRoleArn in the task definition.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 54%;" aria-valuenow="54" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#IAM'>IAM</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=IAM_13><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>IAM Question 13</p><br/>A company is running a publicly accessible serverless application that uses Amazon API Gateway and AWS Lambda.<br/><br/>The application's traffic recently spiked due to fraudulent requests from botnets.<br/><br/>Which steps should a solutions architect take to block requests from unauthorized users? (Select TWO.)<br/><br/>A. Create a usage plan with an API key that is shared with genuine users only.<br/>B. Integrate logic within the Lambda function to ignore the requests from fraudulent addresses.<br/>C. Implement an AWS WAF rule to target malicious requests and trigger actions to filter them out.<br/>D. Convert the existing public API to a private API. Update the DNS records to redirect users to the new API endpoint.<br/>E. Create an IAM role for each user attempting to access the API. A user will assume the role when making the API call.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample606' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#IAM_14'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#IAM_17'>Random</a></p><div class='collapse' id='collapseExample606'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Integrate logic within the Lambda function to ignore the requests from fraudulent addresses.
<br><b>E. </b>Create an IAM role for each user attempting to access the API. A user will assume the role when making the API call.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 59%;" aria-valuenow="59" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#IAM'>IAM</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=IAM_14><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>IAM Question 14</p><br/>A solutions architect needs to design a managed storage solution for a company's application that includes high&#8211;performance machine learning. This application runs on AWS Fargate, and the connected storage needs to have concurrent access to files and deliver high performance.<br/><br/>Which storage option should the solutions architect recommend?<br/><br/>A. Create an Amazon S3 bucket for the application and establish an IAM role for Fargate to communicate with Amazon S3.<br/>B. Create an Amazon FSx for Lustre file share and establish an IAM role that allows Fargate to communicate with FSx for Lustre.<br/>C. Create an Amazon Elastic File System (Amazon EFS) file share and establish an IAM role that allows Fargate to communicate with Amazon EFS.<br/>D. Create an Amazon Elastic Block Store (Amazon EBS) volume for the application and establish an IAM role that allows Fargate to communicate with Amazon EBS.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample264' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation264' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#IAM_15'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#IAM_14'>Random</a></p><div class='collapse' id='collapseExample264'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Create an Amazon FSx for Lustre file share and establish an IAM role that allows Fargate to communicate with FSx for Lustre.</div></div></div><div class='collapse' id='explanation264'><div class='card card&#45;body'><div>
Keyword: Concurrent Access to files + Deliver High Performance
Amazon FSx: A high-performance file system optimized for fast processing of workloads. Lustre is a popular open-source parallel file system. Also supports concurrent access to the same file or directory from thousands of compute instances.

Amazon IAM with FSx: Amazon FSx is integrated with AWS Identity and Access Management (IAM). This integration means that you can control the actions your AWS IAM users and groups can take to manage your file systems (such as creating and deleting file systems). You can also tag your Amazon FSx resources and control the actions that your IAM users and groups can take based on those.

Fargate Launch Type – So, Answer C & D Ruled-out as per Neal David. Fargate automatically provisions resources Fargate provisions and manages compute Charged for running tasks. No EFS and EBS integration Fargate handles cluster optimization.

Limited control, infrastructure is automated

References:

Amazon Elastic File System</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 63%;" aria-valuenow="63" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#IAM'>IAM</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=IAM_15><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>IAM Question 15</p><br/>A solutions architect is designing a new workload in which an AWS Lambda function will access an Amazon DynamoDB table.<br/><br/>What is the MOST secure means of granting the Lambda function access to the DynamoDB labia?<br/><br/>A. Create an IAM role with the necessary permissions to access the DynamoDB table. Assign the role to the Lambda function.<br/>B. Create a DynamoDB user name and password and give them to the developer to use in the Lambda function.<br/>C. Create an IAM user, and create access and secret keys for the user. Give the user the necessary permissions to access the DynarnoOB table. Have the developer use these keys to access the resources.<br/>D. Create an IAM role allowing access from AWS Lambda. Assign the role to the DynamoDB table<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample540' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#IAM_16'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#IAM_5'>Random</a></p><div class='collapse' id='collapseExample540'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Create an IAM role with the necessary permissions to access the DynamoDB table. Assign the role to the Lambda function.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 68%;" aria-valuenow="68" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#IAM'>IAM</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=IAM_16><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>IAM Question 16</p><br/>An organization has three separate AWS accounts, one each for development, testing, and production. The organization wants the testing team to have access to certain AWS resources in the production account. How can the organization achieve this?<br/><br/>A. It is not possible to access resources of one account with another account.<br/>B. Create the IAM roles with cross account access.<br/>C. Create the IAM user in a test account, and allow it access to the production environment with the IAM policy.<br/>D. Create the IAM users with cross account access.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample760' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation760' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#IAM_17'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#IAM_1'>Random</a></p><div class='collapse' id='collapseExample760'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Create the IAM roles with cross account access.</div></div></div><div class='collapse' id='explanation760'><div class='card card&#45;body'><div>
An organization has multiple AWS accounts to isolate a development environment from a testing or production environment. At times the users from one account need to access resources in the other account, such as promoting an update from the development environment to the production environment. In this case the IAM role with cross account access will provide a solution. Cross account access lets one account share access to their resources with users in the other AWS accounts.

References:

AWS Security Best Practices</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 72%;" aria-valuenow="72" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#IAM'>IAM</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=IAM_17><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>IAM Question 17</p><br/>A company needs a storage solution for an application that runs on a high performance computing (HPC) cluster. The cluster is hosted on AWS Fargate for Amazon Elastic Container Service (Amazon ECS). The company needs a mountable file system that provides concurrent access to files while delivering hundreds of Gbps of throughput at sub&#8211;millisecond latencies<br/><br/>Which solution meets these requirements?<br/><br/>A. Create an Amazon FSx for Lustre file share for the application data Create an IAM role that allows Fargate to access the FSx for Lustre file share<br/>B. Create an Amazon Elastic File System (Amazon EFS) file share for the application data. Create an IAM role that allows Fargate to access the EFS file share.<br/>C. Create an Amazon S3 bucket for the application data. Create an S3 bucket policy that allows Fargate to access the S3 bucket<br/>D. Create an Amazon Elastic Block Store (Amazon EBS) Provisioned IOPS SSD (io2) volume for the application data Create an IAM role that allows Fargate to access the volume.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample456' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#IAM_18'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#IAM_21'>Random</a></p><div class='collapse' id='collapseExample456'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Create an Amazon FSx for Lustre file share for the application data Create an IAM role that allows Fargate to access the FSx for Lustre file share</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 77%;" aria-valuenow="77" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#IAM'>IAM</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=IAM_18><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>IAM Question 18</p><br/>A company wants to share forensic accounting data that is stored in an Amazon RDS DB instance with an external auditor. The auditor has its own AWS account and requires its own copy of the database.<br/><br/>How should the company securely share the database with the auditor?<br/><br/>A. Create a read replica of the database and configure IAM standard database authentication to grant the auditor access.<br/>B. Copy a snapshot of the database to Amazon S3 and assign an IAM role to the auditor to grant access to the object in that bucket.<br/>C. Export the database contents to text files, store the files in Amazon S3, and create a new IAM user for the auditor with access to that bucket.<br/>D. Make an encrypted snapshot of the database, share the snapshot, and allow access to the AWS Key Management Service (AWS KMS) encryption key.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample278' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#IAM_19'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#IAM_8'>Random</a></p><div class='collapse' id='collapseExample278'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Create a read replica of the database and configure IAM standard database authentication to grant the auditor access.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 81%;" aria-valuenow="81" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#IAM'>IAM</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=IAM_19><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>IAM Question 19</p><br/>A company has an application running as a service in Amazon Elastic Container Service (Amazon EC2) using the Amazon launch type.<br/><br/>The application code makes AWS API calls to publish messages to Amazon Simple Queue Service (Amazon SQS).<br/><br/>What is the MOST secure method of giving the application permission to publish messages to Amazon SQS?<br/><br/>A. Use AWS Identity and Access Management (IAM) to grant SQS permissions to the role used by the launch configuration for the Auto Scaling group of the ECS cluster.<br/>B. Create a new IAM user with SQS permissions. The update the task definition to declare the access key ID and secret access key as environment variables.<br/>C. Create a new IAM role with SQS permissions. The update the task definition to use this role for the task role setting.<br/>D. Update the security group used by the ECS cluster to allow access to Amazon SQS<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample536' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#IAM_20'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#IAM_7'>Random</a></p><div class='collapse' id='collapseExample536'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Create a new IAM user with SQS permissions. The update the task definition to declare the access key ID and secret access key as environment variables.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 86%;" aria-valuenow="86" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#IAM'>IAM</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=IAM_20><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>IAM Question 20</p><br/>A company allows its developers to attach existing IAM policies to existing IAM roles to enable faster experimentation and agility. However, the security operations team is concerned that the developers could attach the existing administrator policy, which would allow the developers to circumvent any other security policies.<br/><br/>How should a solutions architect address this issue?<br/><br/>A. Create an Amazon SNS topic to send an alert every time a developer creates a new policy.<br/>B. Use service control policies to disable IAM activity across all account in the organizational unit.<br/>C. Prevent the developers from attaching any policies and assign all IAM duties to the security operations team.<br/>D. Set an IAM permissions boundary on the developer IAM role that explicitly denies attaching the administrator policy.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample35' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation35' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#IAM_21'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#IAM_15'>Random</a></p><div class='collapse' id='collapseExample35'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Set an IAM permissions boundary on the developer IAM role that explicitly denies attaching the administrator policy.</div></div></div><div class='collapse' id='explanation35'><div class='card card&#45;body'><div>
The permissions boundary for an IAM entity (user or role) sets the maximum permissions that the entity can have. This can change the effective permissions for that user or role. The effective permissions for an entity are the permissions that are granted by all the policies that affect the user or role. Within an account, the permissions for an entity can be affected by identity-based policies, resource-based policies, permissions boundaries, Organizations SCPs, or session policies.

Therefore, the solutions architect can set an IAM permissions boundary on the developer IAM role that explicitly denies attaching the administrator policy.

CORRECT: "Set an IAM permissions boundary on the developer IAM role that explicitly denies attaching the administrator policy" is the correct answer.

INCORRECT: "Create an Amazon SNS topic to send an alert every time a developer creates a new policy" is incorrect as this would mean investigating every incident which is not an efficient solution.

INCORRECT: "Use service control policies to disable IAM activity across all accounts in the organizational unit" is incorrect as this would prevent the developers from being able to work with IAM completely.

INCORRECT: "Prevent the developers from attaching any policies and assign all IAM duties to the security operations team" is incorrect as this is not necessary. The requirement is to allow developers to work with policies, the solution needs to find a secure way of achieving this.

References:
AWS Identity and Access Management > User Guide > Permissions boundaries for IAM entities
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 90%;" aria-valuenow="90" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#IAM'>IAM</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=IAM_21><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>IAM Question 21</p><br/>A company fails an AWS security review conducted by a third party.<br/><br/>The review finds that some of the company's methods to access the Amazon EMR API are not secure.<br/><br/>Developers are using AWS Cloud9, and access keys are connecting to the Amazon EMR API through the public internet.<br/><br/>Which combination of steps should the company take to MOST improve its security? (Select TWO)<br/><br/>A. Set up a VPC peering connection to the Amazon EMR API<br/>B. Set up VPC endpoints to connect to the Amazon EMR API<br/>C. Set up a NAT gateway to connect to the Amazon EMR API.<br/>D. Set up IAM roles to be used to connect to the Amazon EMR API<br/>E. Set up each developer with AWS Secrets Manager to store access keys<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample532' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#IAM_22'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#IAM_13'>Random</a></p><div class='collapse' id='collapseExample532'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Set up VPC endpoints to connect to the Amazon EMR API
<br><b>D. </b>Set up IAM roles to be used to connect to the Amazon EMR API</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 95%;" aria-valuenow="95" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#IAM'>IAM</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=IAM_22><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>IAM Question 22</p><br/>A new employee has joined a company as a deployment engineer. The deployment engineer will be using AWS CloudFormation templates to create multiple AWS resources. A solutions architect wants the deployment engineer to perform job activities while following the principle of least privilege.<br/><br/>Which combination of actions should the solutions architect take to accomplish this goal? (Choose two.)<br/><br/>A. Have the deployment engineer use AWS account root user credentials for performing AWS CloudFormation stack operations.<br/>B. Create a new IAM user for the deployment engineer and add the IAM user to a group that has the PowerUsers IAM policy attached.<br/>C. Create a new IAM user for the deployment engineer and add the IAM user to a group that has the Administrate/Access IAM policy attached.<br/>D. Create a new IAM User for the deployment engineer and add the IAM user to a group that has an IAM policy that allows AWS CloudFormation actions only.<br/>E. Create an IAM role for the deployment engineer to explicitly define the permissions specific to the AWS CloudFormation stack and launch stacks using Dial IAM role.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample389' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#IAM_23'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#IAM_2'>Random</a></p><div class='collapse' id='collapseExample389'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Have the deployment engineer use AWS account root user credentials for performing AWS CloudFormation stack operations.
<br><b>E. </b>Create an IAM role for the deployment engineer to explicitly define the permissions specific to the AWS CloudFormation stack and launch stacks using Dial IAM role.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 100%;" aria-valuenow="100" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#IAM'>IAM</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><a id=security_group><h2>security group</h2></a> - 19 Questions <br><a href='#security_group'>security group(19)</a> <a href='#' <i class='bi bi&#45;house'> &nbsp;Home</i><hr> </a><div class='row' id=security_group_1><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>security group Question 1</p><br/>A solutions architect is developing a multiple&#8211;subnet VPC architecture. The solution will consist of six subnets in two Availability Zones. The subnets are defined as public, private and dedicated for databases.<br/><br/>Only the Amazon EC2 instances running in the private subnets should be able to access a database.<br/><br/>Which solution meets these requirements?<br/><br/>A. Create a new route table that excludes the route to the public subnets' CIDR blocks. Associate the route table to the database subnets.<br/>B. Create a security group that denies ingress from the security group used by instances in the public subnets. Attach the security group to an Amazon RDS DB instance.<br/>C. Create a security group that allows ingress from the security group used by instances in the private subnets. Attach the security group to an Amazon RDS DB instance.<br/>D. Create a new peering connection between the public subnets and the private subnets. Create a different peering connection between the private subnets and the database subnets.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample359' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#security_group_2'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#security_group_3'>Random</a></p><div class='collapse' id='collapseExample359'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Create a security group that allows ingress from the security group used by instances in the private subnets. Attach the security group to an Amazon RDS DB instance.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 5%;" aria-valuenow="5" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#security_group'>security group</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=security_group_2><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>security group Question 2</p><br/>Which of the following is true of Amazon EC2 security group?<br/><br/>A. You can modify the outbound rules for EC2&#8211;Classic.<br/>B. You can modify the rules for a security group only if the security group controls the traffic for just one instance.<br/>C. You can modify the rules for a security group only when a new instance is created.<br/>D. You can modify the rules for a security group at any time.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample754' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation754' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#security_group_3'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#security_group_10'>Random</a></p><div class='collapse' id='collapseExample754'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>You can modify the rules for a security group at any time.</div></div></div><div class='collapse' id='explanation754'><div class='card card&#45;body'><div>
A security group acts as a virtual firewall that controls the traffic for one or more instances. When you launch an instance, you associate one or more security groups with the instance. You add rules to each security group that allow traffic to or from its associated instances. You can modify the rules for a security group at any time; the new rules are automatically applied to all instances that are associated with the security group.

References:

Amazon Elastic Compute Cloud > User Guide for Linux Instances > Amazon EC2 security groups for Linux instances</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 10%;" aria-valuenow="10" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#security_group'>security group</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=security_group_3><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>security group Question 3</p><br/>A solutions architect is creating a new VPC design. There are two public subnet for the load balancer, two private subnets for web servers, and two private subnets for MySQL. The web serves use only HTTPS. The solutions architect has already created a security group for the load Balancer allowing port 443 from 0.0 0.0/0. Company policy requires that each resource has the least access required to still be able to perform its tasks.<br/><br/>Which additional configuration strategy should the solution architect use to meet these requirements?<br/><br/>A. Create a security group for the web servers and allow port 443 from 0.0.0.070. Create a security group for the MySQL serve's aid allow port 3306 from the web servers security group.<br/>B. Create a network ACL for the web servers and allow port 443 from 0.0.0.0/0. Create a network ACL for the MySQL servers and allow port 3306 from the web servers security group<br/>C. Create a security group for the web servers and allow port 443 from the load balancer. Create a security group for the MySQL servers and allow port 3306 from the web sewers security group<br/>D. Create a network ACL for the web servers and allow port 443 from the web balancer. Create a network ACL for the MySQL servers and allow port 3306 from the web servers security group.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample504' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#security_group_4'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#security_group_6'>Random</a></p><div class='collapse' id='collapseExample504'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Create a security group for the web servers and allow port 443 from the load balancer. Create a security group for the MySQL servers and allow port 3306 from the web sewers security group</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 15%;" aria-valuenow="15" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#security_group'>security group</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=security_group_4><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>security group Question 4</p><br/>A company hosts a popular web application. The web application connects to a database running in a private VPC subnet.<br/><br/>The web servers must be accessible only to customers on an SSL connection.<br/><br/>The Amazon RDS for MySQL database services be accessible only from the web servers.<br/><br/>How should a solution architect design a solution to meet the requirements without impacting applications?<br/><br/>A. Create a network ACL on the web server's subnet and allow HTTPS inbound and MySQL outbound. Place both database and web servers on the same subnet.<br/>B. Open an HTTPS port on the security group for web server and set the source to 0. 0. 0.0/0. Open the MySQL port on the database security group and attach it to the MySQL instance. Set the source to web server security group.<br/>C. Create a network ACL on the web server's subnet, allow HTTP, allow inbound and specify the source as 0 .0 .0 .0/0. Create a network ACL on a database subnet allow MySQL port inbound for web servers and deny all outbound traffic.<br/>D. Open the MySQL port on the security group for web servers and set the source to 0.0.0.0/0. Open the HTTPS port on the database security group and attach it to the MySQL instance. Set the source to web server security group.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample620' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#security_group_5'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#security_group_15'>Random</a></p><div class='collapse' id='collapseExample620'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Open an HTTPS port on the security group for web server and set the source to 0. 0. 0.0/0. Open the MySQL port on the database security group and attach it to the MySQL instance. Set the source to web server security group.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 21%;" aria-valuenow="21" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#security_group'>security group</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=security_group_5><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>security group Question 5</p><br/>A company is deploying a two&#8211;tier web application in a VPC. The web tier is using an Amazon EC2 Auto Scaling group with public subnets that span multiple Availability Zones. The database tier consists of an Amazon RDS for MySQL DB instance in separate private subnets. The web tier requires access to the database to retrieve product information.<br/><br/>The web application is not working as intended. The web application reports that it cannot connect to the database. The database is confirmed to be up and running. All configurations for the network ACLs. security groups, and route tables are still in their default states.<br/><br/>What should a solutions architect recommend to fix the application?<br/><br/>A. Add an explicit rule to the private subnet's network ACL to allow traffic from the web tier's EC2 instances.<br/>B. Add a route in the VPC route table to allow traffic between the web tier's EC2 instances and The database tier.<br/>C. Deploy the web tier's EC2 instances and the database tier's RDS instance into two separate VPCs. and configure VPC peering.<br/>D. Add an inbound rule to the security group of the database tier's RDS instance to allow traffic from the web tier's security group.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample477' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#security_group_6'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#security_group_8'>Random</a></p><div class='collapse' id='collapseExample477'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Add an inbound rule to the security group of the database tier's RDS instance to allow traffic from the web tier's security group.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 26%;" aria-valuenow="26" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#security_group'>security group</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=security_group_6><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>security group Question 6</p><br/>A solutions architect is designing a two&#8211;tier web application. The application consists of a public&#8211;facing web tier hosted on Amazon EC2 in public subnets. The database tier consists of Microsoft SQL Server running on Amazon EC2 in a private subnet. Security is a high priority for the company.<br/><br/>How should security groups be configured in this situation? (Choose two.)<br/><br/>A. Configure the security group for the web tier to allow inbound traffic on port 443 from 0.0.0.0/0.<br/>B. Configure the security group for the web tier to allow outbound traffic on port 443 from 0.0.0.0/0.<br/>C. Configure the security group for the database tier to allow inbound traffic on port 1433 from the security group for the web tier.<br/>D. Configure the security group for the database tier to allow outbound traffic on ports 443 and 1433 to the security group for the web tier.<br/>E. Configure the security group for the database tier to allow inbound traffic on ports 443 and 1433 from the security group for the web tier.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample187' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation187' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#security_group_7'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#security_group_2'>Random</a></p><div class='collapse' id='collapseExample187'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Configure the security group for the web tier to allow inbound traffic on port 443 from 0.0.0.0/0.
<br><b>C. </b>Configure the security group for the database tier to allow inbound traffic on port 1433 from the security group for the web tier.</div></div></div><div class='collapse' id='explanation187'><div class='card card&#45;body'><div>
In this scenario an inbound rule is required to allow traffic from any internet client to the web front end on SSL/TLS port 443. The source should therefore be set to 0.0.0.0/0 to allow any inbound traffic.

To secure the connection from the web frontend to the database tier, an outbound rule should be created from the public EC2 security group with a destination of the private EC2 security group. The port should be set to 1433 for MySQL. The private EC2 security group will also need to allow inbound traffic on 1433 from the public EC2 security group.

This configuration can be seen in the diagram:

CORRECT: "Configure the security group for the web tier to allow inbound traffic on port 443 from 0.0.0.0/0" is a correct answer.

CORRECT: "Configure the security group for the database tier to allow inbound traffic on port 1433 from the security group for the web tier" is also a correct answer.

INCORRECT: "Configure the security group for the web tier to allow outbound traffic on port 443 from 0.0.0.0/0" is incorrect as this is configured backwards.

INCORRECT: "Configure the security group for the database tier to allow outbound traffic on ports 443 and 1433 to the security group for the web tier" is incorrect as the MySQL database instance does not need to send outbound traffic on either of these ports.

INCORRECT: "Configure the security group for the database tier to allow inbound traffic on ports 443 and 1433 from the security group for the web tier" is incorrect as the database tier does not need to allow inbound traffic on port 443.

References:
Amazon Virtual Private Cloud > User Guide > Security groups for your VPC
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 31%;" aria-valuenow="31" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#security_group'>security group</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=security_group_7><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>security group Question 7</p><br/>A company operates a two&#8211;tier application for image processing. The application uses two Availability Zones, each with one public subnet and one private subnet. An Application Load Balancer (ALB) for the web tier uses the public subnets.<br/><br/>Amazon EC2 instances for the application tier use the private subnets.<br/><br/>Users report that the application is running more slowly than expected. A security audit of the web server log files shows that the application is receiving millions of illegitimate requests from a small number of IP addresses. A solutions architect needs to resolve the immediate performance problem while the company investigates a more permanent solution.<br/><br/>What should the solutions architect recommend to meet this requirement?<br/><br/>A. Modify the inbound security group for the web tier. Add a deny rule for the IP addresses that are consuming resources.<br/>B. Modify the network ACL for the web tier subnets. Add an inbound deny rule for the IP addresses that are consuming resources.<br/>C. Modify the inbound security group for the application tier. Add a deny rule for the IP addresses that are consuming resources.<br/>D. Modify the network ACL for the application tier subnets. Add an inbound deny rule for the IP addresses that are consuming resources.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample426' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#security_group_8'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#security_group_0'>Random</a></p><div class='collapse' id='collapseExample426'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Modify the inbound security group for the web tier. Add a deny rule for the IP addresses that are consuming resources.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 36%;" aria-valuenow="36" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#security_group'>security group</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=security_group_8><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>security group Question 8</p><br/>A solutions architect is creating a new VPC design. There are two public subnets for the load balancer, two private subnets for web servers, and two private subnets for MySQL. The web servers use only HTTPS.<br/><br/>The solutions architect has already created a security group for the load balancer allowing port 443 from 0.0.0.0/0. Company policy requires that each resource has the least access required to still be able to perform its tasks.<br/><br/>Which additional configuration strategy should the solutions architect use to meet these requirements?<br/><br/>A. Create a security group for the web servers and allow port 443 from 0.0.0.0/0. Create a security group for the MySQL servers and allow port 3306 from the web servers security group.<br/>B. Create a network ACL for the web servers and allow port 443 from 0.0.0.0/0. Create a network ACL for the MySQL servers and allow port 3306 from the web servers security group.<br/>C. Create a security group for the web servers and allow port 443 from the load balancer. Create a security group for the MySQL servers and allow port 3306 from the web servers security group.<br/>D. Create a network ACL for the web servers and allow port 443 from the load balancer. Create a network ACL for the MySQL servers and allow port 3306 from the web servers security group.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample249' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#security_group_9'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#security_group_9'>Random</a></p><div class='collapse' id='collapseExample249'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Create a network ACL for the web servers and allow port 443 from 0.0.0.0/0. Create a network ACL for the MySQL servers and allow port 3306 from the web servers security group.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 42%;" aria-valuenow="42" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#security_group'>security group</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=security_group_9><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>security group Question 9</p><br/>A company is reviewing a recent migration of a three&#8211;tier application to a VPC. The security team discovers that the principle of least privilege is not being applied to Amazon EC2 security group ingress and egress rules between the application tiers.<br/><br/>What should a solutions architect do to correct this issue?<br/><br/>A. Create security group rules using the instance ID as the source or destination.<br/>B. Create security group rules using the security group ID as the source or destination.<br/>C. Create security group rules using the VPC CIDR blocks as the source or destination.<br/>D. Create security group rules using the subnet CIDR blocks as the source or destination.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample332' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#security_group_10'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#security_group_18'>Random</a></p><div class='collapse' id='collapseExample332'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Create security group rules using the security group ID as the source or destination.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 47%;" aria-valuenow="47" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#security_group'>security group</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=security_group_10><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>security group Question 10</p><br/>A company is planning on deploying a newly built application on AWS in a default VPC. The application will consist of a web layer and database layer. The web server was created in public subnets, and the MySQL database was created in private subnets. All subnets are created with the default network ACL settings, and the default security group in the VPC will be replaced with new custom security groups.<br/>The following are the key requirements:<br/><br/>The web servers must be accessible only to users on an SSL connection.<br/>The database should be accessible to the web layer, which is created in a public subnet only.<br/>All traffic to and from the IP range 182.20.0.0/16 subnet should be blocked.<br/>Which combination of steps meets these requirements? (Select two.)<br/><br/>A. Create a database server security group with inbound and outbound rules for MySQL port 3306 traffic to and from anywhere (0 0.0.0/0).<br/>B. Create a database server security group with an inbound rule for MySQL port 3306 and specify the source as a web server security group.<br/>C. Create a web server security group with an inbound allow rule for HTTPS port 443 traffic from anywhere (0.0.0.0/0) and an inbound deny rule for IP range 182.20.0.0/16.<br/>D. Create a web server security group with an inbound rule for HTTPS port 443 traffic from anywhere (0.0.0.0/0). Create network ACL inbound and outbound deny rules for IP range 182.20.0.0/16.<br/>E. Create a web server security group with inbound and outbound rules for HTTPS port 443 traffic to and from anywhere (0.0.0.0/0). Create a network ACL inbound deny rule for IP range 182.20.0.0/16.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample382' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#security_group_11'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#security_group_17'>Random</a></p><div class='collapse' id='collapseExample382'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Create a database server security group with an inbound rule for MySQL port 3306 and specify the source as a web server security group.
<br><b>D. </b>Create a web server security group with an inbound rule for HTTPS port 443 traffic from anywhere (0.0.0.0/0). Create network ACL inbound and outbound deny rules for IP range 182.20.0.0/16.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 52%;" aria-valuenow="52" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#security_group'>security group</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=security_group_11><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>security group Question 11</p><br/>A company is reviewing a recent migration of a three&#8211;tier application to a VPC. The security team discovers that the principle of least privilege is not being applied to Amazon EC2 security group ingress and egress rules between the application tiers.<br/><br/>What should a solutions architect do to correct this issue?<br/><br/>A. Create security group rules using the instance ID as the source or destination.<br/>B. Create security group rules using the security group ID as the source or destination.<br/>C. Create security group rules using the VPC CIDR block as the source or destination.<br/>D. Create security group rules using the subnet CIDR block as the source or destination.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample695' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#security_group_12'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#security_group_12'>Random</a></p><div class='collapse' id='collapseExample695'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Create security group rules using the security group ID as the source or destination.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 57%;" aria-valuenow="57" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#security_group'>security group</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=security_group_12><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>security group Question 12</p><br/>A Solutions Architect is designing the architecture for a web application that will be hosted on AWS. Internet users will access the application using HTTP and HTTPS.<br/><br/>How should the Architect design the traffic control requirements?<br/><br/>A. Use a network ACL to allow outbound ports for HTTP and HTTPS. Deny other traffic for inbound and outbound.<br/>B. Use a network ACL to allow inbound ports for HTTP and HTTPS. Deny other traffic for inbound and outbound.<br/>C. Allow inbound ports for HTTP and HTTPS in the security group used by the web servers.<br/>D. Allow outbound ports for HTTP and HTTPS in the security group used by the web servers.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample736' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#security_group_13'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#security_group_4'>Random</a></p><div class='collapse' id='collapseExample736'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Allow inbound ports for HTTP and HTTPS in the security group used by the web servers.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 63%;" aria-valuenow="63" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#security_group'>security group</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=security_group_13><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>security group Question 13</p><br/>A company has a web server running on an Amazon EC2 instance in a public subnet with an Elastic IP address. The default security group is assigned to the EC2 instance. The default network ACL has been modified to block all traffic. A solutions architect needs to make the web server accessible from everywhere on port 443.<br/><br/>Which combination of steps will accomplish this task? (Choose two.)<br/><br/>A. Create a security group with a rule to allow TCP port 443 from source 0.0.0.0/0.<br/>B. Create a security group with a rule to allow TCP port 443 to destination 0.0.0.0/0.<br/>C. Update the network ACL to allow TCP port 443 from source 0.0.0.0/0.<br/>D. Update the network ACL to allow inbound/outbound TCP port 443 from source 0.0.0.0/0 and to destination 0.0.0.0/0.<br/>E. Update the network ACL to allow inbound TCP port 443 from source 0.0.0.0/0 and outbound TCP port 32768&#8211;65535 to destination 0.0.0.0/0.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample174' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#security_group_14'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#security_group_16'>Random</a></p><div class='collapse' id='collapseExample174'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Create a security group with a rule to allow TCP port 443 from source 0.0.0.0/0.
<br><b>B. </b>Create a security group with a rule to allow TCP port 443 to destination 0.0.0.0/0.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 68%;" aria-valuenow="68" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#security_group'>security group</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=security_group_14><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>security group Question 14</p><br/>A company is designing an internet&#8211;facing web application. The application runs on Amazon EC2 for Linux&#8211;based instances that store sensitive user data in Amazon RDS MySQL Multi&#8211;AZ DB instances. The EC2 instances are in public subnets, and the RDS DB instances are in private subnets. The security team has mandated that the DB instances be secured against web&#8211;based attacks.<br/><br/>What should a solutions architect recommend?<br/><br/>A. Ensure the EC2 instances are part of an Auto Scaling group and are behind an Application Load Balancer. Configure the EC2 instance iptables rules to drop suspicious web traffic. Create a security group for the DB instances. Configure the RDS security group to only allow port 3306 inbound from the individual EC2 instances.<br/>B. Ensure the EC2 instances are part of an Auto Scaling group and are behind an Application Load Balancer. Move DB instances to the same subnets that EC2 instances are located in. Create a security group for the DB instances. Configure the RDS security group to only allow port 3306 inbound from the individual EC2 instances.<br/>C. Ensure the EC2 instances are part of an Auto Scaling group and are behind an Application Load Balancer. Use AWS WAF to monitor inbound web traffic for threats. Create a security group for the web application servers and a security group for the DB instances. Configure the RDS security group to only allow port 3306 inbound from the web application server security group.<br/>D. Ensure the EC2 instances are part of an Auto Scaling group and are behind an Application Load Balancer. Use AWS WAF to monitor inbound web traffic for threats. Configure the Auto Scaling group to automatically create new DB instances under heavy traffic. Create a security group for the RDS DB instances. Configure the RDS security group to only allow port 3306 inbound.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample385' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#security_group_15'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#security_group_7'>Random</a></p><div class='collapse' id='collapseExample385'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Ensure the EC2 instances are part of an Auto Scaling group and are behind an Application Load Balancer. Use AWS WAF to monitor inbound web traffic for threats. Create a security group for the web application servers and a security group for the DB instances. Configure the RDS security group to only allow port 3306 inbound from the web application server security group.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 73%;" aria-valuenow="73" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#security_group'>security group</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=security_group_15><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>security group Question 15</p><br/>A company recently launched Linux&#8211;based application instances on Amazon EC2 in a private subnet and launched a Linux&#8211;based bastion host on an Amazon EC2 instance in a public subnet of a VPC. A solutions architect needs to connect from the on&#8211;premises network, though the company's internet connection, to the bastion host, and to the application servers. The solutions architect must make sure that the security groups of all the EC2 instances will allow that access.<br/><br/>Which combination of steps should the solutions architect take to meet these requirements? (Choose two.)<br/><br/>A. Replace the current security group of the bastion host with one that only allows inbound access from the application instances.<br/>B. Replace the current security group of the bastion host with one that only allows inbound access from the internal IP range for the company.<br/>C. Replace the current security group of the bastion host with one that only allows inbound access from the external IP range for the company.<br/>D. Replace the current security group of the application instances with one that allows inbound SSH access from only the private IP address of the bastion host.<br/>E. Replace the current security group of the application instances with one that allows inbound SSH access from only the public IP address of the bastion host.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample311' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#security_group_16'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#security_group_11'>Random</a></p><div class='collapse' id='collapseExample311'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Replace the current security group of the bastion host with one that only allows inbound access from the application instances.
<br><b>C. </b>Replace the current security group of the bastion host with one that only allows inbound access from the external IP range for the company.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 78%;" aria-valuenow="78" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#security_group'>security group</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=security_group_16><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>security group Question 16</p><br/>A solutions architect is moving the static content from a public website hosted on Amazon EC2 instances to an Amazon S3 bucket. An Amazon CloudFront distribution will be used to deliver the static assets. The security group used by the EC2 instances restricts access to a limited set of IP ranges. Access to the static content should be similarly restricted.<br/><br/>Which combination of steps will meet these requirements? (Choose two.)<br/><br/>A. Create an origin access identity (OAI) and associate it with the distribution. Change the permissions in the bucket policy so that only the OAI can read the objects.<br/>B. Create an AWS WAF web ACL that includes the same IP restrictions that exist in the EC2 security group. Associate this new web ACL with the CloudFront distribution.<br/>C. Create a new security group that includes the same IP restrictions that exist in the current EC2 security group. Associate this new security group with the CloudFront distribution.<br/>D. Create a new security group that includes the same IP restrictions that exist in the current EC2 security group. Associate this new security group with the S3 bucket hosting the static content.<br/>E. Create a new IAM role and associate the role with the distribution. Change the permissions either on the S3 bucket or on the files within the S3 bucket so that only the newly created IAM role has read and download permissions.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample162' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#security_group_17'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#security_group_14'>Random</a></p><div class='collapse' id='collapseExample162'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Create an origin access identity (OAI) and associate it with the distribution. Change the permissions in the bucket policy so that only the OAI can read the objects.
<br><b>B. </b>Create an AWS WAF web ACL that includes the same IP restrictions that exist in the EC2 security group. Associate this new web ACL with the CloudFront distribution.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 84%;" aria-valuenow="84" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#security_group'>security group</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=security_group_17><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>security group Question 17</p><br/>A computer is reviewing a recent migration of a three&#8211;tier application to a VPC. The security team discover that the principle of least privilege is not being applied to Amazon EC2 security group ingress and egress rules between the application tiers.<br/><br/>What should a solution architect do to connect issue?<br/><br/>A. Create security group rules using the instance ID as the source destination.<br/>B. Create security group rules using the security ID as the source or destination.<br/>C. Create security group rules using the VPC CDR blocks as the source or destination<br/>D. Create security group rules using the subnet CDR blocks as the source or destination<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample441' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#security_group_18'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#security_group_13'>Random</a></p><div class='collapse' id='collapseExample441'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Create security group rules using the instance ID as the source destination.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 89%;" aria-valuenow="89" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#security_group'>security group</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=security_group_18><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>security group Question 18</p><br/>A company is running an application on Amazon EC2 instances hosted in a private subnet of a VPC.<br/><br/>The EC2 instances are configured in an Auto Scaling group behind an Elastic Load Balancer (ELB).<br/><br/>The EC2 instances use a NAT gateway for outbound internet access.<br/><br/>However the EC2 instances are not able to connect to the public internet to download software updates.<br/><br/>What are the possible root causes of this issue? (Select TWO )<br/><br/>A. The ELB is not configured with a proper health check<br/>B. The route tables in the VPC are configured incorrectly<br/>C. The EC2 instances are not associated with an Elastic IP address<br/>D. The security group attached to the NAT gateway is configured incorrectly<br/>E. The outbound rules on the security group attached to the EC2 Instances are configured incorrectly.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample658' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#security_group_19'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#security_group_5'>Random</a></p><div class='collapse' id='collapseExample658'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>The route tables in the VPC are configured incorrectly
<br><b>E. </b>The outbound rules on the security group attached to the EC2 Instances are configured incorrectly.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 94%;" aria-valuenow="94" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#security_group'>security group</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=security_group_19><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>security group Question 19</p><br/>A company Is designing an internet&#8211;facing web application. The application runs on Amazon EC2 for Linux&#8211;based instances that store sensitive user data in Amazon RDS MySQL Multi&#8211;AZ DB instances.<br/><br/>The EC2 instances are in public subnets, and the RDS DB instances are in private subnets. The security team has mandated that the DB instances be secured against web&#8211;based attacks.<br/><br/>What should a solutions architect recommend?<br/><br/>A. Ensure the EC2 instances are part of an Auto Scaling group and are behind an Application Load Balancer. Configure the EC2 instance iptables rules to drop suspicious web traffic. Create a security group for the DB instances. Configure the RDS security group to only allow port 3306 inbound from the individual EC2 instances.<br/>B. Ensure the EC2 instances are part of an Auto Scaling group and are behind an Application Load Balancer. Move DB instances to the same subnets that EC2 instances are located in. Create a security group for the DB instances. Configure the RDS security group to only allow port 3306 inbound from the individual EC2 instances.<br/>C. Ensure the EC2 instances are part of an Auto Scaling group and are behind an Application Load Balancer. Use AWS WAF to monitor inbound web traffic for threats. Create a security group for the web application servers and a security group for the DB instances. Configure the RDS security group to only allow port 3306 inbound from the web application server security group.<br/>D. Ensure the EC2 instances are part of an Auto Scaling group and are behind an Application Load Balancer. Use AWS WAF to monitor inbound web traffic for threats. Configure the Auto Scaling group to automatically create new DB instances under heavy traffic. Create a security group for the RDS DB instances. Configure the RDS security group to only allow port 3306 inbound.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample680' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#security_group_20'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#security_group_1'>Random</a></p><div class='collapse' id='collapseExample680'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Ensure the EC2 instances are part of an Auto Scaling group and are behind an Application Load Balancer. Use AWS WAF to monitor inbound web traffic for threats. Configure the Auto Scaling group to automatically create new DB instances under heavy traffic. Create a security group for the RDS DB instances. Configure the RDS security group to only allow port 3306 inbound.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 100%;" aria-valuenow="100" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#security_group'>security group</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><a id=ECS><h2>ECS</h2></a> - 13 Questions <br><a href='#ECS'>ECS(13)</a> <a href='#' <i class='bi bi&#45;house'> &nbsp;Home</i><hr> </a><div class='row' id=ECS_1><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>ECS Question 1</p><br/>A solutions architect is creating a data processing job that runs once daily and can take up to 2 hours to complete If the job is interrupted, it has to restart from the beginning<br/><br/>How should the solutions architect address this issue in the MOST cost&#8211;effective manner?<br/><br/>A. Create a script that runs locally on an Amazon EC2 Reserved Instance that is triggered by a cron job.<br/>B. Create an AWS Lambda function triggered by an Amazon EventBridge (Amazon CloudWatch Events} scheduled event<br/>C. Use an Amazon Elastic Container Service (Amazon ECS) Fargate task triggered by an Amazon EventBridge (Amazon CloudWatch Events) scheduled event.<br/>D. Use an Amazon Elastic Container Service (Amazon ECS) task running on Amazon EC2 triggered by an Amazon EventBridge (Amazon CloudWatch Events) scheduled event.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample486' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#ECS_2'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#ECS_7'>Random</a></p><div class='collapse' id='collapseExample486'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Use an Amazon Elastic Container Service (Amazon ECS) Fargate task triggered by an Amazon EventBridge (Amazon CloudWatch Events) scheduled event.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 7%;" aria-valuenow="7" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#ECS'>ECS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=ECS_2><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>ECS Question 2</p><br/>A company is developing an eCommerce application that will consist of a load&#8211;balanced front end. a container&#8211;based application and a relational database A solutions architect needs to create a highly available solution that operates with as little manual intervention as possible<br/><br/>Which solutions meet these requirements? (Select TWO.)<br/><br/>A. Create an Amazon RDS DB instance in Multi&#8211;AZ mode<br/>B. Create an Amazon RDS DB instance and one or more replicas in another Availability Zone<br/>C. Create an Amazon EC2 instance&#8211;based Docker cluster to handle the dynamic application load<br/>D. Create an Amazon Elastic Container Service (Amazon ECS) cluster with a Fargate launch type to handle the dynamic application load<br/>E. Create an Amazon Elastic Container Service (Amazon ECS) cluster with an Amazon EC2 launch type to handle the dynamic application load<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample502' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation502' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#ECS_3'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#ECS_12'>Random</a></p><div class='collapse' id='collapseExample502'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Create an Amazon RDS DB instance in Multi-AZ mode
<br><b>D. </b>Create an Amazon Elastic Container Service (Amazon ECS) cluster with a Fargate launch type to handle the dynamic application load</div></div></div><div class='collapse' id='explanation502'><div class='card card&#45;body'><div>
Relational database: RDS
Container-based applications: ECS
"Amazon ECS enables you to launch and stop your container-based applications by using simple API calls. You can also retrieve the state of your cluster from a centralized service and have access to many familiar Amazon EC2 features."
Little manual intervention: Fargate
You can run your tasks and services on a serverless infrastructure that is managed by AWS Fargate. Alternatively, for more control over your infrastructure, you can run your tasks and services on a cluster of Amazon EC2 instances that you manage.

References:

Amazon Elastic Container Service > Developer Guide > What is Amazon Elastic Container Service?</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 15%;" aria-valuenow="15" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#ECS'>ECS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=ECS_3><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>ECS Question 3</p><br/>An eCommerce website is deploying its web application as Amazon Elastic Container Service (Amazon ECS) container instances behind an Application Load Balancer (ALB). During periods of high activity, the website slows down and availability is reduced.<br/><br/>A solutions architect uses Amazon CloudWatch alarms to receive notifications whenever there is an availability issue so they can scale out resources. Company management wants a solution that automatically responds to such events.<br/><br/>Which solution meets these requirements?<br/><br/>A. Set up AWS Auto Scaling to scale out the ECS service when there are timeouts on the ALB. Set up AWS Auto Scaling to scale out the ECS cluster when the CPU or memory reservation is too high.<br/>B. Set up AWS Auto Scaling to scale out the ECS service when the ALB CPU utilization is too high. Set up AWS Auto Scaling to scale out the ECS cluster when the CPU or memory reservation is too high.<br/>C. Sot up AWS Auto Scaling to scale out the ECS service when the service's CPU utilization is too high. Set up AWS Auto Scaling to scale out the ECS cluster when the CPU or memory reservation is too high.<br/>D. Set up AWS Auto Scaling to scale out the ECS service when the ALB target group CPU utilization is too high. Set up AWS Auto Scaling to scale out the ECS cluster when the CPU or memory reservation is too high.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample674' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#ECS_4'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#ECS_9'>Random</a></p><div class='collapse' id='collapseExample674'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Set up AWS Auto Scaling to scale out the ECS service when there are timeouts on the AL<br><b>B. </b>Set up AWS Auto Scaling to scale out the ECS cluster when the CPU or memory reservation is too high.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 23%;" aria-valuenow="23" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#ECS'>ECS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=ECS_4><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>ECS Question 4</p><br/>A company is developing a new machine learning model solution in AWS. The models are developed as independent microservices that fetch about 1 GB of model data from Amazon S3 at startup and load the data into memory. users access the models through an asynchronous API. Users can send a request or a batch of requests and specify where the result should be sent.<br/><br/>The company provides models to hundreds of users. The usage patterns for the models are irregular. somes models could be unused for days or weeks. other models could receive batches of thousands of requests at a time.<br/><br/>Which solution meets these requirements?<br/><br/>A. The requests from the API are sent to an Application Load Balancer (ALB). Models are deployed as AWS lambda functions invoked by the ALB<br/>B. The requests from the API are sent to the models Amazon Simple Queue Service (Amazon SOS) queue. Models are deployed as AWS Lambda functions triggered by SOS events. AWS auto scaling is enabled on Lambda to increase the number vCPUSs based on the SQS queue size.<br/>C. The requests from the API are sent to the model's Amazon simple Queue Service (Amazon SQS) queue. Model are deployed as Amazon Elastic container service ( AMAzon ECS) service reading from the queue. AWS App Mesh scales the instances of the ECS cluster based on the SQS queue size.<br/>D. The requests from the API are sent to the model's Amazon simple Queue Service (Amazon SQS) queue. Models are deployed as Amazon Elastics container service ( Amazon ECS) services reading from the queue. AWS Auto Scaling is enabled ECS for both the cluster and copies the service based on the queue size.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample709' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#ECS_5'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#ECS_2'>Random</a></p><div class='collapse' id='collapseExample709'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>The requests from the API are sent to the model's Amazon simple Queue Service (Amazon SQS) queue. Models are deployed as Amazon Elastics container service ( Amazon ECS) services reading from the queue. AWS Auto Scaling is enabled ECS for both the cluster and copies the service based on the queue size.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 30%;" aria-valuenow="30" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#ECS'>ECS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=ECS_5><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>ECS Question 5</p><br/>A company is building its web application using containers on AWS. The company requires three instances of the web application to run at all times. The application must be able to scale to meet increases in demand. Management is extremely sensitive to cost but agrees that the application should be highly available.<br/><br/>What should a solutions architect recommend?<br/><br/>A. Create an Amazon Elastic Container Service (Amazon ECS) cluster using the Fargate launch type. Create a task definition for the web application. Create an ECS service with a desired count of three tasks.<br/>B. Create an Amazon Elastic Container Service (Amazon ECS) cluster using the Amazon EC2 launch type with three container instances in one Availability Zone. Create a task definition for the web application. Place one task for each container instance.<br/>C. Create an Amazon Elastic Container Service (Amazon ECS) cluster using the Fargate launch type with one container instance in three different Availability Zones. Create a task definition for the web application. Create an ECS service with a desired count of three tasks.<br/>D. Create an Amazon Elastic Container Service (Amazon ECS) cluster using the Amazon EC2 launch type with one container instance in two different Availability Zones. Create a task definition for the web application. Place two tasks on one container instance and one task on the remaining container instance.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample322' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#ECS_6'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#ECS_10'>Random</a></p><div class='collapse' id='collapseExample322'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Create an Amazon Elastic Container Service (Amazon ECS) cluster using the Amazon EC2 launch type with one container instance in two different Availability Zones. Create a task definition for the web application. Place two tasks on one container instance and one task on the remaining container instance.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 38%;" aria-valuenow="38" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#ECS'>ECS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=ECS_6><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>ECS Question 6</p><br/>An eCommerce website is deploying its web application as Amazon Elastic Container Service (Amazon ECS) container instance behind an Application Load Balancer (ALB). During periods of high activity, the website slows down and availability is reduced.<br/><br/>A solutions architect uses Amazon CloudWatch alarms to receive notifications whenever there is an availability issues so they can scale out resource Company management wants a solution that automatically responds to such events.<br/><br/>Which solution meets these requirements?<br/><br/>A. Set up AWS Auto Scaling to scale out the ECS service when there are timeouts on the ALB. Set up AWS Auto Scaling to scale out the ECS cluster when the CPU or memory reservation is too high.<br/>B. Set up AWS Auto Scaling to scale out the ECS service when the ALB CPU utilization is too high. Set up AWS Auto Scaling to scale out the ECS cluster when the CPU or memory reservation is too high.<br/>C. Set up AWS Auto Scaling to scale out the ECS service when the service's CPU utilization is too high. Set up AWS Auto Scaling to scale out the ECS cluster when the CPU or memory reservation is too high.<br/>D. Set up AWS Auto Scaling to scale out the ECS service when the ALB target group CPU utilization is too high. Set up AWS Auto Scaling to scale out the ECS cluster when the CPU or memory reservation is too high.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample696' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#ECS_7'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#ECS_4'>Random</a></p><div class='collapse' id='collapseExample696'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Set up AWS Auto Scaling to scale out the ECS service when the ALB target group CPU utilization is too high. Set up AWS Auto Scaling to scale out the ECS cluster when the CPU or memory reservation is too high.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 46%;" aria-valuenow="46" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#ECS'>ECS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=ECS_7><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>ECS Question 7</p><br/>A company is developing a new machine learning model solution in AWS. The models are developed as independent microservices that fetch about 1 GB of model data from Amazon S3 at startup and load the data into memory. Users access the models through an asynchronous API. Users can send a request or a batch of requests and specify where the results should be sent.<br/><br/>The company provides models to hundreds of users. The usage patterns for the models are irregular Some models could be unused for days or weeks. Other models could receive batches of thousands of requests at a time.<br/><br/>Which solution meets these requirements?<br/><br/>A. The requests from the API are sent to an Application Load Balancer (ALB). Models are deployed as AWS Lambda functions invoked by the ALB.<br/>B. The requests from the API are sent to the models Amazon Simple Queue Service (Amazon SQS) queue. Models are deployed as AWS Lambda functions triggered by SQS events AWS Auto Scaling is enabled on Lambda to increase the number of vCPUs based on the SQS queue size.<br/>C. The requests from the API are sent to the model's Amazon Simple Queue Service (Amazon SQS) queue. Models are deployed as Amazon Elastic Container Service (Amazon ECS) services reading from the queue AWS App Mesh scales the instances of the ECS cluster based on the SQS queue size.<br/>D. The requests from the API are sent to the models Amazon Simple Queue Service (Amazon SQS) queue. Models are deployed as Amazon Elastic Container Service (Amazon ECS) services reading from the queue AWS Auto Scaling is enabled on Amazon ECS for both the cluster and copies of the service based on the queue size.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample400' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#ECS_8'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#ECS_11'>Random</a></p><div class='collapse' id='collapseExample400'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>The requests from the API are sent to the models Amazon Simple Queue Service (Amazon SQS) queue. Models are deployed as Amazon Elastic Container Service (Amazon ECS) services reading from the queue AWS Auto Scaling is enabled on Amazon ECS for both the cluster and copies of the service based on the queue size.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 53%;" aria-valuenow="53" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#ECS'>ECS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=ECS_8><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>ECS Question 8</p><br/>A company is running a multi&#8211;tier web application on&#8211;premises. The web application is containerized and runs on a number of Linux hosts connected to a PostgreSQL database that contains user records. The operational overhead of maintaining the infrastructure and capacity planning is limiting the company's growth. A solutions architect must improve the application's infrastructure.<br/><br/>Which combination of actions should the solutions architect take to accomplish this? (Select TWO.)<br/><br/>A. Migrate the PostgreSQL database to Amazon Aurora<br/>B. Migrate the web application to be hosted on Amazon EC2 instances.<br/>C. Set up an Amazon CloudFront distribution for the web application content.<br/>D. Set up Amazon ElastiCache between the web application and the PostgreSQL database<br/>E. Migrate the web application to be hosted on AWS Fargate with Amazon Elastic Container Service (Amazon ECS)<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample681' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#ECS_9'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#ECS_6'>Random</a></p><div class='collapse' id='collapseExample681'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Migrate the PostgreSQL database to Amazon Aurora
<br><b>E. </b>Migrate the web application to be hosted on AWS Fargate with Amazon Elastic Container Service (Amazon ECS)</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 61%;" aria-valuenow="61" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#ECS'>ECS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=ECS_9><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>ECS Question 9</p><br/>A company's near&#8211;real&#8211;time streaming application is running on AWS. As the data is ingested, a job runs on the data and takes 30 minutes to complete. The workload frequently experiences high latency due to large amounts of incoming data. A solutions architect needs to design a scalable and serverless solution to enhance performance.<br/><br/>Which combination of steps should the solutions architect take? (Choose two.)<br/><br/>A. Use Amazon Kinesis Data Firehose to ingest the data.<br/>B. Use AWS Lambda with AWS Step Functions to process the data.<br/>C. Use AWS Database Migration Service (AWS DMS) to ingest the data.<br/>D. Use Amazon EC2 instances in an Auto Scaling group to process the data.<br/>E. Use AWS Fargate with Amazon Elastic Container Service (Amazon ECS) to process the data.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample135' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#ECS_10'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#ECS_5'>Random</a></p><div class='collapse' id='collapseExample135'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Use Amazon Kinesis Data Firehose to ingest the data.
<br><b>E. </b>Use AWS Fargate with Amazon Elastic Container Service (Amazon ECS) to process the data.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 69%;" aria-valuenow="69" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#ECS'>ECS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=ECS_10><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>ECS Question 10</p><br/>A company expects its user base to increase five times over one year. Its application is hosted in one region and uses an Amazon RDS for MySQL database, and Application Load Balance Amazon Elastic Container Service (Amazon ECS) to host the website and its microservices.<br/><br/>Which design changes should a solutions architect recommend to support the expected growth? (Select TWO.)<br/><br/>A. Move static files from Amazon ECS to Amazon S3<br/>B. Use an Amazon Route 53 geolocation routing policy.<br/>C. Scale the environment based on real&#8211;time AWS CloudTrail logs.<br/>D. Create a dedicated Elastic Load Balancer for each microservice.<br/>E. Create RDS lead replicas and change the application to use these replicas.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample539' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#ECS_11'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#ECS_8'>Random</a></p><div class='collapse' id='collapseExample539'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Move static files from Amazon ECS to Amazon S3
<br><b>E. </b>Create RDS lead replicas and change the application to use these replicas.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 76%;" aria-valuenow="76" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#ECS'>ECS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=ECS_11><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>ECS Question 11</p><br/>A company wants to run its critical applications in containers to meet requirements for scalability and availability. The company prefers to focus on maintenance of the critical applications. The company does not want to be responsible for provisioning and managing the underlying infrastructure that runs the containerized workload.<br/><br/>What should a solutions architect do to meet these requirements?<br/><br/>A. Use Amazon EC2 instances, and install Docker on the instances.<br/>B. Use Amazon Elastic Container Service (Amazon ECS) on Amazon EC2 worker nodes.<br/>C. Use Amazon Elastic Container Service (Amazon ECS) on AWS Fargate.<br/>D. Use Amazon EC2 instances from an Amazon Elastic Container Service (Amazon ECS)&#8211;optimized Amazon Machine Image (AMI).<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample414' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#ECS_12'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#ECS_1'>Random</a></p><div class='collapse' id='collapseExample414'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Use Amazon Elastic Container Service (Amazon ECS) on AWS Fargate.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 84%;" aria-valuenow="84" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#ECS'>ECS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=ECS_12><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>ECS Question 12</p><br/>A company that recently started using AWS establishes a Site&#8211;to&#8211;Site VPN between its on&#8211;premises datacenter and AWS. The company's security mandate states that traffic originating from on&#8211;premises should stay within the company's private IP space when communicating with an Amazon Elastic Container Service (Amazon ECS) cluster that is hosting a sample web application.<br/><br/>Which solution meets this requirement?<br/><br/>A. Configure a gateway endpoint for Amazon ECS. Modify the route table to include an entry pointing to the ECS cluster.<br/>B. Create a Network Load Balancer and AWS PrivateLink endpoint for Amazon ECS in the same VPC that is hosting the ECS cluster.<br/>C. Create a Network Load Balancer in one VPC and an AWS PrivateLink endpoint for Amazon ECS in another VPC. Connect the two VPCs by using VPC peering.<br/>D. Configure an Amazon Route 53 record with Amazon ECS as the target. Apply a server certificate to Route 53 from AWS Certificate Manager (ACM) for SSL offloading.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample394' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#ECS_13'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#ECS_3'>Random</a></p><div class='collapse' id='collapseExample394'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Create a Network Load Balancer in one VPC and an AWS PrivateLink endpoint for Amazon ECS in another VP<b>C. </b>Connect the two VPCs by using VPC peering.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 92%;" aria-valuenow="92" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#ECS'>ECS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=ECS_13><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>ECS Question 13</p><br/>A company is building an application that consists of several microservices. The company has decided to use container technologies to deploy its software on AWS. The company needs a solution that minimizes the amount of ongoing effort for maintenance and scaling. The company cannot manage additional infrastructure.<br/><br/>Which combination of actions should a solutions architect take to meet these requirements? (Choose two.)<br/><br/>A. Deploy an Amazon Elastic Container Service (Amazon ECS) cluster.<br/>B. Deploy the Kubernetes control plane on Amazon EC2 instances that span multiple Availability Zones.<br/>C. Deploy an Amazon Elastic Container Service (Amazon ECS) service with an Amazon EC2 launch type. Specify a desired task number level of greater than or equal to 2.<br/>D. Deploy an Amazon Elastic Container Service (Amazon ECS) service with a Fargate launch type. Specify a desired task number level of greater than or equal to 2.<br/>E. Deploy Kubernetes worker nodes on Amazon EC2 instances that span multiple Availability Zones. Create a deployment that specifies two or more replicas for each microservice.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample419' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#ECS_14'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#ECS_0'>Random</a></p><div class='collapse' id='collapseExample419'><div class='card card&#45;body'><div class=' border border&#45;success'><b>A. </b>Deploy an Amazon Elastic Container Service (Amazon ECS) cluster.
<br><b>B. </b>Deploy the Kubernetes control plane on Amazon EC2 instances that span multiple Availability Zones.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 100%;" aria-valuenow="100" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#ECS'>ECS</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><a id=AMI><h2>AMI</h2></a> - 6 Questions <br><a href='#AMI'>AMI(6)</a> <a href='#' <i class='bi bi&#45;house'> &nbsp;Home</i><hr> </a><div class='row' id=AMI_1><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>AMI Question 1</p><br/>A company has a three&#8211;tier, stateless web application. The company's web and application tiers run on Amazon BC2 instances in an Auto Scaling group with an Amazon Elastic Block Store (Amazon EBS) root volume, and the database tier runs on Amazon RDS for PostgreSQL.<br/><br/>The company's recovery point objective (RPO) is 2 hours.<br/><br/>What should a solutions architect recommend to enable backups for this environment?<br/><br/>A. Take snapshots of EBS volumes of the EC2 instances and database every 2 hours<br/>B. Configure a snapshot lifecycle policy to take EBS snapshots and configure an automated database backup in Amazon RDS to meet the RPO<br/>C. Take snapshots of EBS volumes of the EC2 instances every 2 hours. Configure automated database backup in Amazon RDS so that it runs every 2 hours<br/>D. Retain the latest Amazon Machine Images (AMIs) of the web and application tiers Configure daily Amazon RDS snapshots and use point&#8211;in&#8211;time recovery to meet the RPO.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample662' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#AMI_2'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#AMI_2'>Random</a></p><div class='collapse' id='collapseExample662'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Retain the latest Amazon Machine Images (AMIs) of the web and application tiers Configure daily Amazon RDS snapshots and use point-in-time recovery to meet the RPO.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 16%;" aria-valuenow="16" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#AMI'>AMI</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=AMI_2><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>AMI Question 2</p><br/>A development team stores its Amazon RDS MySQL DB instance user name and password credentials in a configuration file. The configuration file is stored as plaintext on the root device volume of the team's Amazon EC2 instance. When the team's application needs to reach the database, it reads the file and loads the credentials into the code. The team has modified the permissions of the configuration file so that only the application can read its content. A solution architect must design a more secure solution.<br/><br/>What should the solutions architect do to meet this requirement?<br/><br/>A. Store the configuration file in Amazon S3. Grant the application access to read the configuration file.<br/>B. Create an IAM role with permission to access the database. Attach this IAM role to the EC2 instance.<br/>C. Enable SSL connections on the database instance. Alter the database user to require SSL when logging in.<br/>D. Move the configuration file to an EC2 instance store, and create an Amazon Machine Image (AMI) of the instance. Launch new instances from this AMI.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample316' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#AMI_3'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#AMI_3'>Random</a></p><div class='collapse' id='collapseExample316'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Move the configuration file to an EC2 instance store, and create an Amazon Machine Image (AMI) of the instance. Launch new instances from this AMI.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 33%;" aria-valuenow="33" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#AMI'>AMI</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=AMI_3><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>AMI Question 3</p><br/>A company has an application that is hosted on Amazon EC2 instances in two private subnets. A solutions architect must make the application available on the public internet with the least amount of administrative effort.<br/><br/>What should the solutions architect recommend?<br/><br/>A. Create a load balancer and associate two public subnets from the same Availability Zones as the private instances. Add the private instances to the load balancer.<br/>B. Create a load balancer and associate two private subnets from the same Availability Zones as the private instances. Add the private instances to the load balancer.<br/>C. Create an Amazon Machine Image (AMI) of the instances in the private subnet and restore in the public subnet. Create a load balancer and associate two public subnets from the same Availability Zones as the public instances.<br/>D. Create an Amazon Machine Image (AMI) of the instances in the private subnet and restore in the public subnet. Create a load balancer and associate two private subnets from the same Availability Zones as the public instances.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample290' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#AMI_4'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#AMI_1'>Random</a></p><div class='collapse' id='collapseExample290'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Create an Amazon Machine Image (AMI) of the instances in the private subnet and restore in the public subnet. Create a load balancer and associate two public subnets from the same Availability Zones as the public instances.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 50%;" aria-valuenow="50" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#AMI'>AMI</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=AMI_4><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>AMI Question 4</p><br/>A solutions architect is designing the cloud architecture for a new application being deployed on AWS. The process should run in parallel while adding and removing application nodes as needed based on the number of jobs to be processed. The processor application is stateless. The solutions architect must ensure that the application is loosely coupled and the job items are durably stored.<br/><br/>Which design should the solutions architect use?<br/><br/>A. Create an Amazon SNS topic to send the jobs that need to be processed. Create an Amazon Machine Image (AMI) that consists of the processor application. Create a launch configuration that uses the AMI. Create an Auto Scaling group using the launch configuration. Set the scaling policy for the Auto Scaling group to add and remove nodes based on CPU usage.<br/>B. Create an Amazon SQS queue to hold the jobs that need to be processed. Create an Amazon Machine Image (AMI) that consists of the processor application. Create a launch configuration that uses the AMI. Create an Auto Scaling group using the launch configuration. Set the scaling policy for the Auto Scaling group to add and remove nodes based on network usage.<br/>C. Create an Amazon SQS queue to hold the jobs that need to be processed. Create an Amazon Machine Image (AMI) that consists of the processor application. Create a launch template that uses the AMI. Create an Auto Scaling group using the launch template. Set the scaling policy for the Auto Scaling group to add and remove nodes based on the number of items in the SQS queue.<br/>D. Create an Amazon SNS topic to send the jobs that need to be processed. Create an Amazon Machine Image (AMI) that consists of the processor application. Create a launch template that uses the AMI. Create an Auto Scaling group using the launch template. Set the scaling policy for the Auto Scaling group to add and remove nodes based on the number of messages published to the SNS topic.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample189' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation189' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#AMI_5'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#AMI_4'>Random</a></p><div class='collapse' id='collapseExample189'><div class='card card&#45;body'><div class=' border border&#45;success'><b>C. </b>Create an Amazon SQS queue to hold the jobs that need to be processed. Create an Amazon Machine Image (AMI) that consists of the processor application. Create a launch template that uses the AMI. Create an Auto Scaling group using the launch template. Set the scaling policy for the Auto Scaling group to add and remove nodes based on the number of items in the SQS queue.</div></div></div><div class='collapse' id='explanation189'><div class='card card&#45;body'><div>
Amazon Simple Queue Service (SQS) is a fully managed message queuing service that enables you to decouple and scale microservices, distributed systems, and serverless applications. SQS eliminates the complexity and overhead associated with managing and operating message oriented middleware, and empowers developers to focus on differentiating work. Using SQS, you can send, store, and receive messages between software components at any volume, without losing messages or requiring other services to be available. Get started with SQS in minutes using the AWS console, Command Line Interface or SDK of your choice, and three simple commands.

SQS offers two types of message queues. Standard queues offer maximum throughput, best-effort ordering, and at-least-once delivery. SQS FIFO queues are designed to guarantee that messages are processed exactly once, in the exact order that they are sent.

Scaling Based on Amazon SQS
There are some scenarios where you might think about scaling in response to activity in an Amazon SQS queue. For example, suppose that you have a web app that lets users upload images and use them online. In this scenario, each image requires resizing and encoding before it can be published. The app runs on EC2 instances in an Auto Scaling group, and it's configured to handle your typical upload rates. Unhealthy instances are terminated and replaced to maintain current instance levels at all times. The app places the raw bitmap data of the images in an SQS queue for processing. It processes the images and then publishes the processed images where they can be viewed by users. The architecture for this scenario works well if the number of image uploads doesn't vary over time. But if the number of uploads changes over time, you might consider using dynamic scaling to scale the capacity of your Auto Scaling group.

In this case we need to find a durable and loosely coupled solution for storing jobs. Amazon SQS is ideal for this use case and can be configured to use dynamic scaling based on the number of jobs waiting in the queue.

To configure this scaling you can use the backlog per instance metric with the target value being the acceptable backlog per instance to maintain. You can calculate these numbers as follows: Backlog per instance: To calculate your backlog per instance, start with the ApproximateNumberOfMessages queue attribute to determine the length of the SQS queue (number of messages available for retrieval from the queue). Divide that number by the fleet's running capacity, which for an Auto Scaling group is the number of instances in the InService state, to get the backlog per instance.

Acceptable backlog per instance: To calculate your target value, first determine what your application can accept in terms of latency. Then, take the acceptable latency value and divide it by the average time that an EC2 instance takes to process a message.

This solution will scale EC2 instances using Auto Scaling based on the number of jobs waiting in the SQS queue.

CORRECT: "Create an Amazon SQS queue to hold the jobs that needs to be processed. Create an Amazon EC2 Auto Scaling group for the compute application. Set the scaling policy for the Auto Scaling group to add and remove nodes based on the number of items in the SQS queue" is the correct answer.

INCORRECT: "Create an Amazon SQS queue to hold the jobs that need to be processed. Create an Amazon EC2 Auto Scaling group for the compute application. Set the scaling policy for the Auto Scaling group to add and remove nodes based on network usage" is incorrect as scaling on network usage does not relate to the number of jobs waiting to be processed.

INCORRECT: "Create an Amazon SNS topic to send the jobs that need to be processed. Create an Amazon EC2 Auto Scaling group for the compute application. Set the scaling policy for the

Auto Scaling group to add and remove nodes based on CPU usage" is incorrect. Amazon SNS is a notification service so it delivers notifications to subscribers. It does store data durably but is less suitable than SQS for this use case. Scaling on CPU usage is not the best solution as it does not relate to the number of jobs waiting to be processed.

INCORRECT: "Create an Amazon SNS topic to send the jobs that need to be processed. Create an Amazon EC2 Auto Scaling group for the compute application. Set the scaling policy for the Auto Scaling group to add and remove nodes based on the number of messages published to the SNS topic" is incorrect. Amazon SNS is a notification service so it delivers notifications to subscribers. It does store data durably but is less suitable than SQS for this use case. Scaling on the number of notifications in SNS is not possible.

References:

Amazon EC2 Auto Scaling > User Guide > Scaling based on Amazon SQS</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 66%;" aria-valuenow="66" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#AMI'>AMI</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=AMI_5><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>AMI Question 5</p><br/>A company's application is running on Amazon EC2 instances in a single Region. In the event of a disaster, a solutions architect needs to ensure that the resources can also be deployed to a second Region.<br/><br/>Which combination of actions should the solutions architect take to accomplish this? (Choose two.)<br/><br/>A. Detach a volume on an EC2 instance and copy it to Amazon S3.<br/>B. Launch a new EC2 instance from an Amazon Machine Image (AMI) in a new Region.<br/>C. Launch a new EC2 instance in a new Region and copy a volume from Amazon S3 to the new instance.<br/>D. Copy an Amazon Machine Image (AMI) of an EC2 instance and specify a different Region for the destination.<br/>E. Copy an Amazon Elastic Block Store (Amazon EBS) volume from Amazon S3 and launch an EC2 instance in the destination Region using that EBS volume.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample145' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary' data-toggle='collapse' href='#explanation145' role='button' aria-expanded='false' aria-controls='collapseExample'>Explanation</a><a class='m-2 btn btn&#45;primary float-right' href='#AMI_6'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#AMI_0'>Random</a></p><div class='collapse' id='collapseExample145'><div class='card card&#45;body'><div class=' border border&#45;success'><b>B. </b>Launch a new EC2 instance from an Amazon Machine Image (AMI) in a new Region.
<br><b>D. </b>Copy an Amazon Machine Image (AMI) of an EC2 instance and specify a different Region for the destination.</div></div></div><div class='collapse' id='explanation145'><div class='card card&#45;body'><div>
Cross Region EC2 AMI Copy
We know that you want to build applications that span AWS Regions and we're working to provide you with the services and features needed to do so. We started out by launching the EBS Snapshot Copy feature late last year. This feature gave you the ability to copy a snapshot from Region to Region with just a couple of clicks. In addition, last month we made a significant reduction (26% to 83%) in the cost of transferring data between AWS Regions, making it less expensive to operate in more than one AWS region.

Today we are introducing a new feature: Amazon Machine Image (AMI) Copy. AMI Copy enables you to easily copy your Amazon Machine Images between AWS Regions. AMI Copy helps enable several key scenarios including:

Simple and Consistent Multi-Region Deployment – You can copy an AMI from one region to another, enabling you to easily launch consistent instances based on the same AMI into different regions.

Scalability – You can more easily design and build world-scale applications that meet the needs of your users, regardless of their location.

Performance – You can increase performance by distributing your application and locating critical components of your application in closer proximity to your users. You can also take advantage of region specific features such as instance types or other AWS services.

Even Higher Availability – You can design and deploy applications across AWS regions, to increase availability. Once the new AMI is in an Available state the copy is complete.

Once the new AMI is in an Available state the copy is complete.
</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 83%;" aria-valuenow="83" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#AMI'>AMI</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div><div class='row' id=AMI_6><div class='col'><div class='shadow p&#45;3 mb&#45;5 bg&#45;white rounded'><br/><p class='lead'>AMI Question 6</p><br/>A company has an application that posts messages to Amazon SQS. Another application polls the queue and processes the messages in an I/O&#8211;intensive operation. The company has a service level agreement (SLA) that specifies the maximum amount of time that can elapse between receiving the messages and responding to the users. Due to an increase in the number of messages, the company has difficulty meeting its SLA consistently.<br/><br/>What should a solutions architect do to help improve the application's processing time and ensure it can handle the load at any level?<br/><br/>A. Create an Amazon Machine Image (AMI) from the instance used for processing. Terminate the instance and replace it with a larger size.<br/>B. Create an Amazon Machine Image (AMI) from the instance used for processing. Terminate the instance and replace it with an Amazon EC2 Dedicated Instance.<br/>C. Create an Amazon Machine Image (AMI) from the instance used for processing. Create an Auto Scaling group using this image in its launch configuration. Configure the group with a target tracking policy to keep its aggregate CPU utilization below 70%.<br/>D. Create an Amazon Machine Image (AMI) from the instance used for processing. Create an Auto Scaling group using this image in its launch configuration. Configure the group with a target tracking policy based on the age of the oldest message in the SQS queue.<br/><div class='m-2'><p><a class='btn btn&#45;primary' data-toggle='collapse' href='#collapseExample118' role='button' aria-expanded='false' aria-controls='collapseExample'>Reveal Answer</a><a class='m-2 btn btn&#45;primary float-right' href='#AMI_7'>Next</a><a class='m-2 btn btn&#45;primary float-right' href='#AMI_5'>Random</a></p><div class='collapse' id='collapseExample118'><div class='card card&#45;body'><div class=' border border&#45;success'><b>D. </b>Create an Amazon Machine Image (AMI) from the instance used for processing. Create an Auto Scaling group using this image in its launch configuration. Configure the group with a target tracking policy based on the age of the oldest message in the SQS queue.</div></div></div><div class="progress" style="height: 1px;"><div class="progress-bar" role="progressbar" style="width: 100%;" aria-valuenow="100" aria-valuemin="0" aria-valuemax="100"></div></div></div></div><a href='#AMI'>AMI</a> <a href='#' <i class='bi bi&#45;house'>Home</i><hr> </a></div></div></div>

<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/popper.js@1.14.6/dist/umd/popper.min.js" integrity="sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@4.2.1/dist/js/bootstrap.min.js" integrity="sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k" crossorigin="anonymous"></script>
</body>
</html>